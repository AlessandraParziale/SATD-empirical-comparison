ID,FilePath,ClassName,MethodName,Content,CommentFor,CommentsIn,CommentsAssociated,StartLine,EndLine,eachLabelCommentFor,CommentForLabel,eachLabelCommentsIn,CommentsInLabel,eachLabelCommentsAssociated,CommentsAssociatedLabel,PseudoLabelForCASFromMAT,PseudoLabelForCASFromGGSATD,PseudoLabelForCASFromXGBoost,MethodSimplified,class,method,constructor,line,cbo,cboModified,fanin,fanout,wmc,rfc,loc,returnsQty,variablesQty,parametersQty,methodsInvokedQty,methodsInvokedLocalQty,methodsInvokedIndirectLocalQty,loopQty,comparisonsQty,tryCatchQty,parenthesizedExpsQty,stringLiteralsQty,numbersQty,assignmentsQty,mathOperationsQty,maxNestedBlocksQty,anonymousClassesQty,innerClassesQty,lambdasQty,uniqueWordsQty,modifiers,logStatementsQty,hasJavaDoc
0,..\projects\antlr4-4.11.0\antlr4-maven-plugin\src\main\java\org\antlr\mojo\antlr4\Antlr4ErrorLog.java,org.antlr.mojo.antlr4.Antlr4ErrorLog,void info(String),"/**
 * {@inheritDoc}
 * <p>
 * This implementation passes the message to the Maven log.
 * </p>
 * @param message The message to send to Maven
 */
@Override
public void info(String message) {
    if (tool.errMgr.formatWantsSingleLineMessage()) {
        message = message.replace('\n', ' ');
    }
    log.info(message);
}","/**
 * {@inheritDoc}
 * <p>
 * This implementation passes the message to the Maven log.
 * </p>
 * @param message The message to send to Maven
 */
", ,/** * {@inheritDoc} * <p> * This implementation passes the message to the Maven log. * </p> * @param message The message to send to Maven */,47,53,[0],0,[0],0,[0],0,0,0,0,info(String),org.antlr.mojo.antlr4.Antlr4ErrorLog,info/1[java.lang.String],False,48,0,0,0,0,2,3,6,0,0,1,3,0,0,0,0,0,0,0,0,1,0,1,0,0,0,11,1,1,True
1,..\projects\antlr4-4.11.0\antlr4-maven-plugin\src\main\java\org\antlr\mojo\antlr4\Antlr4ErrorLog.java,org.antlr.mojo.antlr4.Antlr4ErrorLog,void error(ANTLRMessage),"/**
 * {@inheritDoc}
 * <p>
 * This implementation passes the message to the Maven log.
 * </p>
 * @param message The message to send to Maven.
 */
@Override
public void error(ANTLRMessage message) {
    ST msgST = tool.errMgr.getMessageTemplate(message);
    String outputMsg = msgST.render();
    if (tool.errMgr.formatWantsSingleLineMessage()) {
        outputMsg = outputMsg.replace('\n', ' ');
    }
    log.error(outputMsg);
    if (message.fileName != null) {
        String text = message.getMessageTemplate(false).render();
        buildContext.addMessage(new File(message.fileName), message.line, message.charPosition, text, BuildContext.SEVERITY_ERROR, message.getCause());
    }
}","/**
 * {@inheritDoc}
 * <p>
 * This implementation passes the message to the Maven log.
 * </p>
 * @param message The message to send to Maven.
 */
", ,/** * {@inheritDoc} * <p> * This implementation passes the message to the Maven log. * </p> * @param message The message to send to Maven. */,62,76,[0],0,[0],0,[0],0,0,0,0,error(ANTLRMessage),org.antlr.mojo.antlr4.Antlr4ErrorLog,error/1[org.antlr.mojo.antlr4.ANTLRMessage],False,63,2,0,0,0,3,7,12,0,3,1,7,0,0,0,1,0,0,0,0,4,0,1,0,0,0,25,1,1,True
2,..\projects\antlr4-4.11.0\antlr4-maven-plugin\src\main\java\org\antlr\mojo\antlr4\Antlr4ErrorLog.java,org.antlr.mojo.antlr4.Antlr4ErrorLog,void warning(ANTLRMessage),"/**
 * {@inheritDoc}
 * <p>
 * This implementation passes the message to the Maven log.
 * </p>
 * @param message
 */
@Override
public void warning(ANTLRMessage message) {
    ST msgST = tool.errMgr.getMessageTemplate(message);
    String outputMsg = msgST.render();
    if (tool.errMgr.formatWantsSingleLineMessage()) {
        outputMsg = outputMsg.replace('\n', ' ');
    }
    log.warn(outputMsg);
    if (message.fileName != null) {
        String text = message.getMessageTemplate(false).render();
        buildContext.addMessage(new File(message.fileName), message.line, message.charPosition, text, BuildContext.SEVERITY_WARNING, message.getCause());
    }
}","/**
 * {@inheritDoc}
 * <p>
 * This implementation passes the message to the Maven log.
 * </p>
 * @param message
 */
", ,/** * {@inheritDoc} * <p> * This implementation passes the message to the Maven log. * </p> * @param message */,85,99,[0],0,[0],0,[0],0,0,0,0,warning(ANTLRMessage),org.antlr.mojo.antlr4.Antlr4ErrorLog,warning/1[org.antlr.mojo.antlr4.ANTLRMessage],False,86,2,0,0,0,3,7,12,0,3,1,7,0,0,0,1,0,0,0,0,4,0,1,0,0,0,23,1,1,True
3,..\projects\antlr4-4.11.0\antlr4-maven-plugin\src\main\java\org\antlr\mojo\antlr4\Antlr4Mojo.java,org.antlr.mojo.antlr4.Antlr4Mojo,void execute(),"/**
 * The main entry point for this Mojo, it is responsible for converting
 * ANTLR 4.x grammars into the target language specified by the grammar.
 *
 * @exception MojoExecutionException if a configuration or grammar error causes
 * the code generation process to fail
 * @exception MojoFailureException if an instance of the ANTLR 4 {@link Tool}
 * cannot be created
 */
@Override
public void execute() throws MojoExecutionException, MojoFailureException {
    Log log = getLog();
    outputEncoding = validateEncoding(outputEncoding);
    if (log.isDebugEnabled()) {
        for (String e : excludes) {
            log.debug(""ANTLR: Exclude: "" + e);
        }
        for (String e : includes) {
            log.debug(""ANTLR: Include: "" + e);
        }
        log.debug(""ANTLR: Output: "" + outputDirectory);
        log.debug(""ANTLR: Library: "" + libDirectory);
    }
    if (!sourceDirectory.isDirectory()) {
        log.info(""No ANTLR 4 grammars to compile in "" + sourceDirectory.getAbsolutePath());
        return;
    }
    // Ensure that the output directory path is all in tact so that
    // ANTLR can just write into it.
    // 
    File outputDir = getOutputDirectory();
    if (!outputDir.exists()) {
        outputDir.mkdirs();
    }
    GrammarDependencies dependencies = new GrammarDependencies(sourceDirectory, libDirectory, arguments, getDependenciesStatusFile(), getLog());
    // Now pick up all the files and process them with the Tool
    // 
    List<List<String>> argumentSets;
    Set<File> grammarFiles;
    Set<File> importGrammarFiles;
    try {
        List<String> args = getCommandArguments();
        grammarFiles = getGrammarFiles(sourceDirectory);
        importGrammarFiles = getImportFiles(sourceDirectory);
        argumentSets = processGrammarFiles(args, grammarFiles, dependencies, sourceDirectory);
    } catch (Exception e) {
        log.error(e);
        throw new MojoExecutionException(""Fatal error occured while evaluating the names of the grammar files to analyze"", e);
    }
    log.debug(""Output directory base will be "" + outputDirectory.getAbsolutePath());
    log.info(""ANTLR 4: Processing source directory "" + sourceDirectory.getAbsolutePath());
    for (List<String> args : argumentSets) {
        try {
            // Create an instance of the ANTLR 4 build tool
            tool = new CustomTool(args.toArray(new String[0]));
        } catch (Exception e) {
            log.error(""The attempt to create the ANTLR 4 build tool failed, see exception report for details"", e);
            throw new MojoFailureException(""Error creating an instanceof the ANTLR tool."", e);
        }
        try {
            dependencies.analyze(grammarFiles, importGrammarFiles, tool);
        } catch (Exception e) {
            log.error(""Dependency analysis failed, see exception report for details"", e);
            throw new MojoFailureException(""Dependency analysis failed."", e);
        }
        // Set working directory for ANTLR to be the base source directory
        tool.inputDirectory = sourceDirectory;
        tool.processGrammarsOnCommandLine();
        // If any of the grammar files caused errors but did nto throw exceptions
        // then we should have accumulated errors in the counts
        if (tool.getNumErrors() > 0) {
            throw new MojoExecutionException(""ANTLR 4 caught "" + tool.getNumErrors() + "" build errors."");
        }
    }
    if (project != null) {
        // Tell Maven that there are some new source files underneath the output directory.
        addSourceRoot(this.getOutputDirectory());
    }
    try {
        dependencies.save();
    } catch (IOException ex) {
        log.warn(""Could not save grammar dependency status"", ex);
    }
}","/**
 * The main entry point for this Mojo, it is responsible for converting
 * ANTLR 4.x grammars into the target language specified by the grammar.
 *
 * @exception MojoExecutionException if a configuration or grammar error causes
 * the code generation process to fail
 * @exception MojoFailureException if an instance of the ANTLR 4 {@link Tool}
 * cannot be created
 */
","// Ensure that the output directory path is all in tact so that
[[SEP]]// ANTLR can just write into it.
[[SEP]]// Now pick up all the files and process them with the Tool
[[SEP]]// 
[[SEP]]// 
[[SEP]]// If any of the grammar files caused errors but did nto throw exceptions
[[SEP]]// Create an instance of the ANTLR 4 build tool
[[SEP]]// Set working directory for ANTLR to be the base source directory
[[SEP]]// then we should have accumulated errors in the counts
[[SEP]]// Tell Maven that there are some new source files underneath the output directory.
","/** * The main entry point for this Mojo, it is responsible for converting * ANTLR 4.x grammars into the target language specified by the grammar. * * @exception MojoExecutionException if a configuration or grammar error causes * the code generation process to fail * @exception MojoFailureException if an instance of the ANTLR 4 {@link Tool} * cannot be created */[[SEP]]// Ensure that the output directory path is all in tact so that// ANTLR can just write into it.//[[SEP]]// Now pick up all the files and process them with the Tool//[[SEP]]// Create an instance of the ANTLR 4 build tool[[SEP]]// Set working directory for ANTLR to be the base source directory[[SEP]]// If any of the grammar files caused errors but did nto throw exceptions// then we should have accumulated errors in the counts[[SEP]]// Tell Maven that there are some new source files underneath the output directory.",222,315,[0],0,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]",0,"[0, 0, 0, 0, 0, 0, 0]",0,0,0,0,execute(),org.antlr.mojo.antlr4.Antlr4Mojo,execute/0,False,223,6,12,0,12,13,23,68,1,7,0,23,8,4,3,1,4,0,15,2,10,8,2,0,0,0,101,1,11,True
4,..\projects\antlr4-4.11.0\antlr4-maven-plugin\src\main\java\org\antlr\mojo\antlr4\Antlr4Mojo.java,org.antlr.mojo.antlr4.Antlr4Mojo,List<String> getCommandArguments(),"private List<String> getCommandArguments() {
    List<String> args = new ArrayList<String>();
    if (getOutputDirectory() != null) {
        args.add(""-o"");
        args.add(outputDirectory.getAbsolutePath());
    }
    // Where do we want ANTLR to look for .tokens and import grammars?
    if (getLibDirectory() != null && getLibDirectory().isDirectory()) {
        args.add(""-lib"");
        args.add(libDirectory.getAbsolutePath());
    }
    // Next we need to set the options given to us in the pom into the
    // tool instance we have created.
    if (atn) {
        args.add(""-atn"");
    }
    if (inputEncoding != null && !inputEncoding.isEmpty()) {
        args.add(""-encoding"");
        outputEncoding = inputEncoding;
        args.add(inputEncoding);
    }
    if (listener) {
        args.add(""-listener"");
    } else {
        args.add(""-no-listener"");
    }
    if (visitor) {
        args.add(""-visitor"");
    } else {
        args.add(""-no-visitor"");
    }
    if (treatWarningsAsErrors) {
        args.add(""-Werror"");
    }
    if (forceATN) {
        args.add(""-Xforce-atn"");
    }
    if (options != null) {
        for (Map.Entry<String, String> option : options.entrySet()) {
            args.add(String.format(""-D%s=%s"", option.getKey(), option.getValue()));
        }
    }
    if (arguments != null) {
        args.addAll(arguments);
    }
    return args;
}", ,"// Next we need to set the options given to us in the pom into the
[[SEP]]// Where do we want ANTLR to look for .tokens and import grammars?
[[SEP]]// tool instance we have created.
",// Where do we want ANTLR to look for .tokens and import grammars?[[SEP]]// Next we need to set the options given to us in the pom into the// tool instance we have created.,317,376,[0],0,"[0, 0, 0]",0,"[0, 0]",0,0,0,0,getCommandArguments(),org.antlr.mojo.antlr4.Antlr4Mojo,getCommandArguments/0,False,317,1,3,1,2,14,11,46,1,1,0,11,2,1,1,5,0,0,11,0,2,0,2,0,0,0,27,2,0,False
5,..\projects\antlr4-4.11.0\antlr4-maven-plugin\src\main\java\org\antlr\mojo\antlr4\Antlr4Mojo.java,org.antlr.mojo.antlr4.Antlr4Mojo,"List<List<String>> processGrammarFiles(List<String>, Set<File>, GrammarDependencies, File)","/**
 * @param sourceDirectory
 * @exception InclusionScanException
 */
private List<List<String>> processGrammarFiles(List<String> args, Set<File> grammarFiles, GrammarDependencies dependencies, File sourceDirectory) throws InclusionScanException, IOException {
    // We don't want the plugin to run for every grammar, regardless of whether
    // it's changed since the last compilation. Check the mtime of the tokens vs
    // the grammar file mtime to determine whether we even need to execute.
    Set<File> grammarFilesToProcess = new HashSet<File>();
    for (File grammarFile : grammarFiles) {
        String tokensFileName = grammarFile.getName().split(""\\."")[0] + "".tokens"";
        File outputFile = new File(outputDirectory, tokensFileName);
        if ((!outputFile.exists()) || outputFile.lastModified() <= grammarFile.lastModified() || dependencies.isDependencyChanged(grammarFile)) {
            grammarFilesToProcess.add(grammarFile);
        }
    }
    grammarFiles = grammarFilesToProcess;
    if (grammarFiles.isEmpty()) {
        getLog().info(""No grammars to process"");
        return Collections.emptyList();
    }
    MultiMap<String, File> grammarFileByFolder = new MultiMap<String, File>();
    // Iterate each grammar file we were given and add it into the tool's list of
    // grammars to process.
    for (File grammarFile : grammarFiles) {
        buildContext.refresh(grammarFile);
        buildContext.removeMessages(grammarFile);
        getLog().debug(""Grammar file '"" + grammarFile.getPath() + ""' detected."");
        String relPathBase = MojoUtils.findSourceSubdir(sourceDirectory, grammarFile);
        String relPath = relPathBase + grammarFile.getName();
        getLog().debug(""  ... relative path is: "" + relPath);
        grammarFileByFolder.map(relPathBase, grammarFile);
    }
    List<List<String>> result = new ArrayList<List<String>>();
    for (Map.Entry<String, List<File>> entry : grammarFileByFolder.entrySet()) {
        List<String> folderArgs = new ArrayList<String>(args);
        if (!folderArgs.contains(""-package"") && !entry.getKey().isEmpty()) {
            folderArgs.add(""-package"");
            folderArgs.add(getPackageName(entry.getKey()));
        }
        for (File file : entry.getValue()) {
            folderArgs.add(entry.getKey() + file.getName());
        }
        result.add(folderArgs);
    }
    return result;
}","/**
 * @param sourceDirectory
 * @exception InclusionScanException
 */
","// We don't want the plugin to run for every grammar, regardless of whether
[[SEP]]// it's changed since the last compilation. Check the mtime of the tokens vs
[[SEP]]// Iterate each grammar file we were given and add it into the tool's list of
[[SEP]]// the grammar file mtime to determine whether we even need to execute.
[[SEP]]// grammars to process.
","/** * @param sourceDirectory * @exception InclusionScanException */[[SEP]]// We don't want the plugin to run for every grammar, regardless of whether// it's changed since the last compilation. Check the mtime of the tokens vs// the grammar file mtime to determine whether we even need to execute.[[SEP]]// Iterate each grammar file we were given and add it into the tool's list of// grammars to process.",383,443,[0],0,"[0, 0, 0, 0, 0]",0,"[0, 0, 0]",0,0,0,0,"processGrammarFiles(List<String>, Set<File>, GrammarDependencies, File)",org.antlr.mojo.antlr4.Antlr4Mojo,"processGrammarFiles/4[java.util.List<java.lang.String>,java.util.Set<java.io.File>,org.antlr.mojo.antlr4.GrammarDependencies,java.io.File]",False,387,4,6,1,5,11,24,38,2,8,4,24,1,1,4,0,0,1,8,1,9,5,2,0,0,0,35,2,3,True
6,..\projects\antlr4-4.11.0\antlr4-maven-plugin\src\main\java\org\antlr\mojo\antlr4\Antlr4Mojo.java,org.antlr.mojo.antlr4.Antlr4Mojo,Set<File> getGrammarFiles(File),"private Set<File> getGrammarFiles(File sourceDirectory) throws InclusionScanException {
    // Which files under the source set should we be looking for as grammar files
    SourceMapping mapping = new SuffixMapping(""g4"", Collections.<String>emptySet());
    // What are the sets of includes (defaulted or otherwise).
    Set<String> includes = getIncludesPatterns();
    // Now, to the excludes, we need to add the imports directory
    // as this is autoscanned for imported grammars and so is auto-excluded from the
    // set of grammar fields we should be analyzing.
    excludes.add(""imports/**"");
    SourceInclusionScanner scan = new SimpleSourceInclusionScanner(includes, excludes);
    scan.addSourceMapping(mapping);
    return scan.getIncludedSources(sourceDirectory, null);
}", ,"// Now, to the excludes, we need to add the imports directory
[[SEP]]// as this is autoscanned for imported grammars and so is auto-excluded from the
[[SEP]]// Which files under the source set should we be looking for as grammar files
[[SEP]]// What are the sets of includes (defaulted or otherwise).
[[SEP]]// set of grammar fields we should be analyzing.
","// Which files under the source set should we be looking for as grammar files[[SEP]]// What are the sets of includes (defaulted or otherwise).[[SEP]]// Now, to the excludes, we need to add the imports directory// as this is autoscanned for imported grammars and so is auto-excluded from the// set of grammar fields we should be analyzing.",459,476,[0],0,"[0, 0, 0, 0, 0]",0,"[0, 0, 0]",0,0,0,0,getGrammarFiles(File),org.antlr.mojo.antlr4.Antlr4Mojo,getGrammarFiles/1[java.io.File],False,460,5,2,1,1,1,5,8,1,3,1,5,1,1,0,0,0,0,2,0,3,0,0,0,0,0,21,2,0,False
7,..\projects\antlr4-4.11.0\antlr4-maven-plugin\src\main\java\org\antlr\mojo\antlr4\Antlr4Mojo.java,org.antlr.mojo.antlr4.Antlr4Mojo,String getPackageName(String),"private static String getPackageName(String relativeFolderPath) {
    if (relativeFolderPath.contains("".."")) {
        throw new UnsupportedOperationException(""Cannot handle relative paths containing '..'"");
    }
    List<String> parts = new ArrayList<String>(Arrays.asList(relativeFolderPath.split(""[/\\\\\\.]+"")));
    while (parts.remove("""")) {
        // intentionally blank
    }
    return Utils.join(parts.iterator(), ""."");
}", ,"// intentionally blank
",// intentionally blank,478,489,[0],0,[0],0,[0],0,0,0,0,getPackageName(String),org.antlr.mojo.antlr4.Antlr4Mojo,getPackageName/1[java.lang.String],False,478,1,2,1,1,3,6,9,1,1,1,6,0,0,1,0,0,0,5,0,1,0,1,0,0,0,13,10,0,False
8,..\projects\antlr4-4.11.0\antlr4-maven-plugin\src\main\java\org\antlr\mojo\antlr4\Antlr4Mojo.java,org.antlr.mojo.antlr4.Antlr4Mojo,String validateEncoding(String),"/**
 * Validates the given encoding.
 *
 * @return  the validated encoding. If {@code null} was provided, returns the platform default encoding.
 */
private String validateEncoding(String encoding) {
    return (encoding == null) ? Charset.defaultCharset().name() : Charset.forName(encoding.trim()).name();
}","/**
 * Validates the given encoding.
 *
 * @return  the validated encoding. If {@code null} was provided, returns the platform default encoding.
 */
", ,"/** * Validates the given encoding. * * @return  the validated encoding. If {@code null} was provided, returns the platform default encoding. */",561,563,[0],0,[0],0,[0],0,0,0,0,validateEncoding(String),org.antlr.mojo.antlr4.Antlr4Mojo,validateEncoding/1[java.lang.String],False,561,0,1,1,0,2,4,3,1,0,1,4,0,0,0,1,0,1,0,0,0,0,0,0,0,0,12,2,0,True
9,..\projects\antlr4-4.11.0\antlr4-maven-plugin\src\main\java\org\antlr\mojo\antlr4\Antlr4Mojo.java,org.antlr.mojo.antlr4.Antlr4Mojo.CustomTool,"Writer getOutputFileWriter(Grammar, String)","@Override
public Writer getOutputFileWriter(Grammar g, String fileName) throws IOException {
    if (outputDirectory == null) {
        return new StringWriter();
    }
    // output directory is a function of where the grammar file lives
    // for subdir/T.g4, you get subdir here.  Well, depends on -o etc...
    // But, if this is a .tokens file, then we force the output to
    // be the base output directory (or current directory if there is not a -o)
    // 
    File outputDir;
    if (fileName.endsWith(CodeGenerator.VOCAB_FILE_EXTENSION)) {
        outputDir = new File(outputDirectory);
    } else {
        outputDir = getOutputDirectory(g.fileName);
    }
    File outputFile = new File(outputDir, fileName);
    if (!outputDir.exists()) {
        outputDir.mkdirs();
    }
    URI relativePath = project.getBasedir().toURI().relativize(outputFile.toURI());
    getLog().debug(""  Writing file: "" + relativePath);
    OutputStream outputStream = buildContext.newFileOutputStream(outputFile);
    if (outputEncoding != null && !outputEncoding.isEmpty()) {
        return new BufferedWriter(new OutputStreamWriter(outputStream, outputEncoding));
    } else {
        return new BufferedWriter(new OutputStreamWriter(outputStream));
    }
}", ,"// output directory is a function of where the grammar file lives
[[SEP]]// for subdir/T.g4, you get subdir here.  Well, depends on -o etc...
[[SEP]]// But, if this is a .tokens file, then we force the output to
[[SEP]]// be the base output directory (or current directory if there is not a -o)
[[SEP]]// 
","// output directory is a function of where the grammar file lives// for subdir/T.g4, you get subdir here.  Well, depends on -o etc...// But, if this is a .tokens file, then we force the output to// be the base output directory (or current directory if there is not a -o)//",521,553,[0],0,"[0, 0, 0, 0, 0]",0,[0],0,0,0,0,"getOutputFileWriter(Grammar, String)",org.antlr.mojo.antlr4.Antlr4Mojo$CustomTool,"getOutputFileWriter/2[org.antlr.mojo.antlr4.Grammar,java.lang.String]",False,522,2,1,0,1,6,12,25,3,4,2,12,0,0,0,2,0,0,1,0,5,1,1,0,0,0,24,1,1,False
10,..\projects\antlr4-4.11.0\antlr4-maven-plugin\src\main\java\org\antlr\mojo\antlr4\GrammarDependencies.java,org.antlr.mojo.antlr4.GrammarDependencies,String getPackage(List<String>),"/**
 * Determines the package to use.
 *
 * @param   arguments  the tool arguments.
 *
 * @return  the package. Returns {@code null} to indicate that no package should be
 *          used.
 */
private String getPackage(List<String> arguments) {
    int index = (arguments != null) ? arguments.indexOf(""-package"") : -1;
    return (index > -1) ? (arguments.get(index + 1).replace('.', File.separatorChar) + File.separatorChar) : null;
}","/**
 * Determines the package to use.
 *
 * @param   arguments  the tool arguments.
 *
 * @return  the package. Returns {@code null} to indicate that no package should be
 *          used.
 */
", ,/** * Determines the package to use. * * @param   arguments  the tool arguments. * * @return  the package. Returns {@code null} to indicate that no package should be *          used. */,63,70,[0],0,[0],0,[0],0,0,0,0,getPackage(List<String>),org.antlr.mojo.antlr4.GrammarDependencies,getPackage/1[java.util.List<java.lang.String>],False,63,0,1,1,0,3,3,4,1,1,1,3,0,0,0,1,0,3,1,3,1,2,0,0,0,0,14,2,0,True
11,..\projects\antlr4-4.11.0\antlr4-maven-plugin\src\main\java\org\antlr\mojo\antlr4\GrammarDependencies.java,org.antlr.mojo.antlr4.GrammarDependencies,"GrammarDependencies analyze(Set<File>, Set<File>, Tool)","/**
 * Performs dependency analysis for the given grammar files.
 *
 * @param   grammarFiles        the grammar files.
 * @param   importGrammarFiles  the import grammar files.
 * @param   tool                the tool to use.
 *
 * @return  self-reference.
 */
public GrammarDependencies analyze(Set<File> grammarFiles, Set<File> importGrammarFiles, Tool tool) throws IOException {
    log.debug(""Analysing grammar dependencies "" + sourceDirectory);
    // for dependency analysis we require all grammars
    Collection<File> grammarsAndTokens = new HashSet<File>();
    grammarsAndTokens.addAll(importGrammarFiles);
    grammarsAndTokens.addAll(grammarFiles);
    for (File grammarFile : grammarsAndTokens) {
        // .tokens files must not be parsed, they can just be referenced
        if (!grammarFile.getName().endsWith("".tokens""))
            analyse(grammarFile, grammarsAndTokens, tool);
    }
    for (File grammarFile : grammarFiles) {
        Collection<String> usages = findUsages(getRelativePath(grammarFile));
        if (!usages.isEmpty()) {
            grammars.put(grammarFile, new AbstractMap.SimpleImmutableEntry<byte[], Collection<String>>(MojoUtils.checksum(grammarFile), usages));
            log.debug(""  "" + getRelativePath(grammarFile) + "" used by "" + usages);
        }
    }
    for (File grammarFile : importGrammarFiles) {
        // imported files are not allowed to be qualified
        Collection<String> usages = findUsages(grammarFile.getName());
        if (!usages.isEmpty()) {
            grammars.put(grammarFile, new AbstractMap.SimpleImmutableEntry<byte[], Collection<String>>(MojoUtils.checksum(grammarFile), usages));
            log.debug(""  "" + grammarFile.getName() + "" imported by "" + usages);
        }
    }
    return this;
}","/**
 * Performs dependency analysis for the given grammar files.
 *
 * @param   grammarFiles        the grammar files.
 * @param   importGrammarFiles  the import grammar files.
 * @param   tool                the tool to use.
 *
 * @return  self-reference.
 */
","// for dependency analysis we require all grammars
[[SEP]]// .tokens files must not be parsed, they can just be referenced
[[SEP]]// imported files are not allowed to be qualified
","/** * Performs dependency analysis for the given grammar files. * * @param   grammarFiles        the grammar files. * @param   importGrammarFiles  the import grammar files. * @param   tool                the tool to use. * * @return  self-reference. */[[SEP]]// for dependency analysis we require all grammars[[SEP]]// .tokens files must not be parsed, they can just be referenced[[SEP]]// imported files are not allowed to be qualified",96,137,[0],0,"[0, 0, 0]",0,"[0, 0, 0, 0]",0,0,0,0,"analyze(Set<File>, Set<File>, Tool)",org.antlr.mojo.antlr4.GrammarDependencies,"analyze/3[java.util.Set<java.io.File>,java.util.Set<java.io.File>,org.antlr.mojo.antlr4.Tool]",False,97,4,5,1,4,7,10,24,1,3,3,10,3,3,3,0,0,0,6,0,3,3,2,0,0,0,34,1,3,True
12,..\projects\antlr4-4.11.0\antlr4-maven-plugin\src\main\java\org\antlr\mojo\antlr4\GrammarDependencies.java,org.antlr.mojo.antlr4.GrammarDependencies,boolean isDependencyChanged(File),"/**
 * Determines whether a grammar used by the given grammar was modified since the last
 * build.
 *
 * @param   grammarFile  the grammar.
 *
 * @return  {@code true} if a grammar used by the given grammar has been modified.
 */
public boolean isDependencyChanged(File grammarFile) throws IOException {
    String grammarPath = getRelativePath(grammarFile);
    for (Map.Entry<File, Map.Entry<byte[], Collection<String>>> e : grammars.entrySet()) {
        File depGrammarFile = e.getKey();
        byte[] checksum = e.getValue().getKey();
        Collection<String> usages = e.getValue().getValue();
        if (usages.contains(grammarPath)) {
            if (!depGrammarFile.exists() || !Arrays.equals(MojoUtils.checksum(depGrammarFile), checksum)) {
                log.debug(""  "" + grammarPath + "": dependency "" + depGrammarFile.getName() + "" changed"");
                return true;
            }
        }
    }
    return false;
}","/**
 * Determines whether a grammar used by the given grammar was modified since the last
 * build.
 *
 * @param   grammarFile  the grammar.
 *
 * @return  {@code true} if a grammar used by the given grammar has been modified.
 */
", ,/** * Determines whether a grammar used by the given grammar was modified since the last * build. * * @param   grammarFile  the grammar. * * @return  {@code true} if a grammar used by the given grammar has been modified. */,148,167,[0],0,[0],0,[0],0,0,0,0,isDependencyChanged(File),org.antlr.mojo.antlr4.GrammarDependencies,isDependencyChanged/1[java.io.File],False,148,3,3,1,2,5,12,15,2,4,1,12,1,1,1,0,0,0,3,0,4,1,3,0,0,0,32,1,1,True
13,..\projects\antlr4-4.11.0\antlr4-maven-plugin\src\main\java\org\antlr\mojo\antlr4\GrammarDependencies.java,org.antlr.mojo.antlr4.GrammarDependencies,String getRelativePath(File),"/**
 * Determines the relative target path of the given grammar file.
 *
 * @param   grammarFile  the grammar file.
 *
 * @return  the relative path.
 */
private String getRelativePath(File grammarFile) {
    // the library directory does not allow sub-directories
    if (grammarFile.getPath().startsWith(libDirectory.getPath()))
        return grammarFile.getName();
    // if a package is given, we have to use it
    if (packageName != null)
        return packageName + grammarFile.getName();
    // otherwise resolve the path relative to the source directory
    String path = MojoUtils.findSourceSubdir(sourceDirectory, grammarFile);
    return path + grammarFile.getName();
}","/**
 * Determines the relative target path of the given grammar file.
 *
 * @param   grammarFile  the grammar file.
 *
 * @return  the relative path.
 */
","// the library directory does not allow sub-directories
[[SEP]]// if a package is given, we have to use it
[[SEP]]// otherwise resolve the path relative to the source directory
","/** * Determines the relative target path of the given grammar file. * * @param   grammarFile  the grammar file. * * @return  the relative path. */[[SEP]]// the library directory does not allow sub-directories[[SEP]]// if a package is given, we have to use it[[SEP]]// otherwise resolve the path relative to the source directory",176,189,[0],0,"[0, 0, 0]",0,"[0, 0, 0, 0]",0,0,0,0,getRelativePath(File),org.antlr.mojo.antlr4.GrammarDependencies,getRelativePath/1[java.io.File],False,176,1,4,3,1,3,4,6,3,1,1,4,0,0,0,1,0,0,0,0,1,2,1,0,0,0,15,2,0,True
14,..\projects\antlr4-4.11.0\antlr4-maven-plugin\src\main\java\org\antlr\mojo\antlr4\GrammarDependencies.java,org.antlr.mojo.antlr4.GrammarDependencies,Collection<String> findUsages(String),"/**
 * Returns the grammar file names that directly or indirectly use the given grammar.
 *
 * @param   grammarFileName  the grammar file name.
 *
 * @return  the grammar file names that use the given grammar file.
 */
private Collection<String> findUsages(String grammarFileName) {
    Collection<String> result = new ArrayList<String>();
    explore(grammarFileName, result);
    return result;
}","/**
 * Returns the grammar file names that directly or indirectly use the given grammar.
 *
 * @param   grammarFileName  the grammar file name.
 *
 * @return  the grammar file names that use the given grammar file.
 */
", ,/** * Returns the grammar file names that directly or indirectly use the given grammar. * * @param   grammarFileName  the grammar file name. * * @return  the grammar file names that use the given grammar file. */,198,203,[0],0,[0],0,[0],0,0,0,0,findUsages(String),org.antlr.mojo.antlr4.GrammarDependencies,findUsages/1[java.lang.String],False,198,1,2,1,1,1,1,5,1,1,1,1,1,1,0,0,0,0,0,0,1,0,0,0,0,0,17,2,0,True
15,..\projects\antlr4-4.11.0\antlr4-maven-plugin\src\main\java\org\antlr\mojo\antlr4\GrammarDependencies.java,org.antlr.mojo.antlr4.GrammarDependencies,"void analyse(File, Collection<File>, Tool)","private void analyse(File grammarFile, Collection<File> grammarFiles, Tool tool) {
    GrammarRootAST grammar = tool.parseGrammar(grammarFile.getAbsolutePath());
    if (grammar == null)
        return;
    for (GrammarAST importDecl : grammar.getAllChildrenWithType(ANTLRParser.IMPORT)) {
        for (Tree id : importDecl.getAllChildrenWithType(ANTLRParser.ID)) {
            // missing id is not valid, but we don't want to prevent the root cause from
            // being reported by the ANTLR tool
            if (id != null) {
                String grammarPath = getRelativePath(grammarFile);
                graph.addEdge(id.getText() + "".g4"", grammarPath);
            }
        }
    }
    for (GrammarAST options : grammar.getAllChildrenWithType(ANTLRParser.OPTIONS)) {
        for (int i = 0, count = options.getChildCount(); i < count; i++) {
            Tree option = options.getChild(i);
            if (option.getType() == ANTLRParser.ASSIGN) {
                String key = option.getChild(0).getText();
                String value = option.getChild(1).getText();
                if (""tokenVocab"".equals(key)) {
                    String name = stripQuotes(value);
                    // the grammar name may be qualified, but we resolve the path anyway
                    String grammarName = stripPath(name);
                    String grammarPath = MojoUtils.findSourceSubdir(sourceDirectory, grammarFile);
                    File depGrammarFile = resolve(grammarName, grammarPath);
                    // if a package has been given, we use it instead of the file directory path
                    // (files probably reside in the root directory anyway with such a configuration )
                    if (packageName != null)
                        grammarPath = packageName;
                    graph.addEdge(getRelativePath(depGrammarFile), grammarPath + grammarFile.getName());
                }
            }
        }
    }
}", ,"// missing id is not valid, but we don't want to prevent the root cause from
[[SEP]]// being reported by the ANTLR tool
[[SEP]]// if a package has been given, we use it instead of the file directory path
[[SEP]]// the grammar name may be qualified, but we resolve the path anyway
[[SEP]]// (files probably reside in the root directory anyway with such a configuration )
","// missing id is not valid, but we don't want to prevent the root cause from// being reported by the ANTLR tool[[SEP]]// the grammar name may be qualified, but we resolve the path anyway[[SEP]]// if a package has been given, we use it instead of the file directory path// (files probably reside in the root directory anyway with such a configuration )",212,257,[0],0,"[0, 0, 0, 0, 0]",0,"[0, 0, 0]",0,0,0,0,"analyse(File, Collection<File>, Tool)",org.antlr.mojo.antlr4.GrammarDependencies,"analyse/3[java.io.File,java.util.Collection<java.io.File>,org.antlr.mojo.antlr4.Tool]",False,212,6,7,1,6,10,15,29,1,11,3,15,4,1,4,4,0,0,2,3,12,2,5,0,0,0,30,2,0,False
16,..\projects\antlr4-4.11.0\antlr4-maven-plugin\src\main\java\org\antlr\mojo\antlr4\GrammarDependencies.java,org.antlr.mojo.antlr4.GrammarDependencies,"File resolve(String, String)","/**
 * Resolves the given grammar name.
 *
 * @param   name  the name.
 * @param   path  the relative path.
 *
 * @return  the grammar file.
 */
private File resolve(String name, String path) {
    File file = new File(sourceDirectory, path + name + "".g4"");
    if (file.exists())
        return file;
    file = new File(libDirectory, name + "".g4"");
    if (file.exists())
        return file;
    return new File(libDirectory, name + "".tokens"");
}","/**
 * Resolves the given grammar name.
 *
 * @param   name  the name.
 * @param   path  the relative path.
 *
 * @return  the grammar file.
 */
", ,/** * Resolves the given grammar name. * * @param   name  the name. * @param   path  the relative path. * * @return  the grammar file. */,267,279,[0],0,[0],0,[0],0,0,0,0,"resolve(String, String)",org.antlr.mojo.antlr4.GrammarDependencies,"resolve/2[java.lang.String,java.lang.String]",False,267,0,1,1,0,3,1,7,3,1,2,1,0,0,0,0,0,0,3,0,2,3,1,0,0,0,10,2,0,True
17,..\projects\antlr4-4.11.0\antlr4-maven-plugin\src\main\java\org\antlr\mojo\antlr4\MojoUtils.java,org.antlr.mojo.antlr4.MojoUtils,byte[] checksum(File),"/**
 * Creates the MD5 checksum for the given file.
 *
 * @param   file  the file.
 *
 * @return  the checksum.
 */
public static byte[] checksum(File file) throws IOException {
    try {
        InputStream in = new FileInputStream(file);
        byte[] buffer = new byte[2048];
        MessageDigest complete = MessageDigest.getInstance(""MD5"");
        try {
            int n;
            do {
                n = in.read(buffer);
                if (n > 0) {
                    complete.update(buffer, 0, n);
                }
            } while (n != -1);
        } finally {
            in.close();
        }
        return complete.digest();
    } catch (NoSuchAlgorithmException ex) {
        throw new IOException(""Could not create checksum "" + file, ex);
    }
}","/**
 * Creates the MD5 checksum for the given file.
 *
 * @param   file  the file.
 *
 * @return  the checksum.
 */
", ,/** * Creates the MD5 checksum for the given file. * * @param   file  the file. * * @return  the checksum. */,25,49,[0],0,[0],0,[0],0,0,0,0,checksum(File),org.antlr.mojo.antlr4.MojoUtils,checksum/1[java.io.File],False,25,1,3,3,0,4,5,24,1,4,1,5,0,0,1,1,2,0,2,4,4,1,4,0,0,0,25,9,0,True
18,..\projects\antlr4-4.11.0\antlr4-maven-plugin\src\main\java\org\antlr\mojo\antlr4\MojoUtils.java,org.antlr.mojo.antlr4.MojoUtils,"String findSourceSubdir(File, File)","/**
 * Given the source directory File object and the full PATH to a grammar, produce the
 * path to the named grammar file in relative terms to the {@code sourceDirectory}.
 * This will then allow ANTLR to produce output relative to the base of the output
 * directory and reflect the input organization of the grammar files.
 *
 * @param   sourceDirectory  The source directory {@link File} object
 * @param   grammarFileName  The full path to the input grammar file
 *
 * @return  The path to the grammar file relative to the source directory
 */
public static String findSourceSubdir(File sourceDirectory, File grammarFile) {
    String srcPath = sourceDirectory.getPath() + File.separator;
    String path = grammarFile.getPath();
    if (!path.startsWith(srcPath)) {
        throw new IllegalArgumentException(""expected "" + path + "" to be prefixed with "" + sourceDirectory);
    }
    File unprefixedGrammarFileName = new File(path.substring(srcPath.length()));
    if (unprefixedGrammarFileName.getParent() == null) {
        return """";
    }
    return unprefixedGrammarFileName.getParent() + File.separator;
}","/**
 * Given the source directory File object and the full PATH to a grammar, produce the
 * path to the named grammar file in relative terms to the {@code sourceDirectory}.
 * This will then allow ANTLR to produce output relative to the base of the output
 * directory and reflect the input organization of the grammar files.
 *
 * @param   sourceDirectory  The source directory {@link File} object
 * @param   grammarFileName  The full path to the input grammar file
 *
 * @return  The path to the grammar file relative to the source directory
 */
", ,"/** * Given the source directory File object and the full PATH to a grammar, produce the * path to the named grammar file in relative terms to the {@code sourceDirectory}. * This will then allow ANTLR to produce output relative to the base of the output * directory and reflect the input organization of the grammar files. * * @param   sourceDirectory  The source directory {@link File} object * @param   grammarFileName  The full path to the input grammar file * * @return  The path to the grammar file relative to the source directory */",62,78,[0],0,[0],0,[0],0,0,0,0,"findSourceSubdir(File, File)",org.antlr.mojo.antlr4.MojoUtils,"findSourceSubdir/2[java.io.File,java.io.File]",False,62,0,3,3,0,3,5,12,2,3,2,5,0,0,0,1,0,0,3,0,3,3,1,0,0,0,52,9,0,True
19,..\projects\antlr4-4.11.0\antlr4-maven-plugin\src\test\java\org\antlr\mojo\antlr4\Antlr4MojoTest.java,org.antlr.mojo.antlr4.Antlr4MojoTest,void importTokens(),"@Test
public void importTokens() throws Exception {
    Path baseDir = resources.getBasedir(""importTokens"").toPath();
    Path antlrDir = baseDir.resolve(""src/main/antlr4"");
    Path generatedSources = baseDir.resolve(""target/generated-sources/antlr4"");
    Path genParser = generatedSources.resolve(""test/SimpleParser.java"");
    Path tokens = antlrDir.resolve(""imports/SimpleLexer.tokens"");
    MavenProject project = maven.readMavenProject(baseDir.toFile());
    MavenSession session = maven.newMavenSession(project);
    MojoExecution exec = maven.newMojoExecution(""antlr4"");
    // //////////////////////////////////////////////////////////////////////
    // 1st - all grammars have to be processed
    // //////////////////////////////////////////////////////////////////////
    assertFalse(Files.exists(genParser));
    maven.executeMojo(session, project, exec);
    assertTrue(Files.exists(genParser));
    // //////////////////////////////////////////////////////////////////////
    // 2nd - nothing has been modified, no grammars have to be processed
    // //////////////////////////////////////////////////////////////////////
    {
        byte[] sum = checksum(genParser);
        maven.executeMojo(session, project, exec);
        assertTrue(Arrays.equals(sum, checksum(genParser)));
    }
    // //////////////////////////////////////////////////////////////////////
    // 3rd - the imported grammar changed, every dependency has to be processed
    // //////////////////////////////////////////////////////////////////////
    try (Change change = Change.of(tokens, ""DOT=4"")) {
        byte[] sum = checksum(genParser);
        maven.executeMojo(session, project, exec);
        assertFalse(Arrays.equals(sum, checksum(genParser)));
    }
}", ,"// //////////////////////////////////////////////////////////////////////
[[SEP]]// 1st - all grammars have to be processed
[[SEP]]// //////////////////////////////////////////////////////////////////////
[[SEP]]// //////////////////////////////////////////////////////////////////////
[[SEP]]// 2nd - nothing has been modified, no grammars have to be processed
[[SEP]]// //////////////////////////////////////////////////////////////////////
[[SEP]]// //////////////////////////////////////////////////////////////////////
[[SEP]]// 3rd - the imported grammar changed, every dependency has to be processed
[[SEP]]// //////////////////////////////////////////////////////////////////////
","// //////////////////////////////////////////////////////////////////////// 1st - all grammars have to be processed// //////////////////////////////////////////////////////////////////////[[SEP]]// //////////////////////////////////////////////////////////////////////// 2nd - nothing has been modified, no grammars have to be processed// //////////////////////////////////////////////////////////////////////[[SEP]]// //////////////////////////////////////////////////////////////////////// 3rd - the imported grammar changed, every dependency has to be processed// //////////////////////////////////////////////////////////////////////",40,86,[0],0,"[0, 0, 0, 0, 0, 0, 0, 0, 0]",0,"[0, 0, 0]",0,0,0,0,importTokens(),org.antlr.mojo.antlr4.Antlr4MojoTest,importTokens/0,False,41,7,2,0,2,1,14,23,0,11,0,14,1,1,0,0,1,0,7,0,11,0,1,0,0,0,29,1,0,False
20,..\projects\antlr4-4.11.0\antlr4-maven-plugin\src\test\java\org\antlr\mojo\antlr4\Antlr4MojoTest.java,org.antlr.mojo.antlr4.Antlr4MojoTest,void importsCustomLayout(),"@Test
public void importsCustomLayout() throws Exception {
    Path baseDir = resources.getBasedir(""importsCustom"").toPath();
    Path antlrDir = baseDir.resolve(""src/main/antlr4"");
    Path generatedSources = baseDir.resolve(""src/main/java"");
    Path genTestLexer = generatedSources.resolve(""foo/TestLexer.java"");
    Path genTestParser = generatedSources.resolve(""foo/TestParser.java"");
    Path genHello = generatedSources.resolve(""foo/HelloParser.java"");
    Path baseGrammar = antlrDir.resolve(""imports/TestBaseLexer.g4"");
    Path lexerGrammar = antlrDir.resolve(""TestLexer.g4"");
    Path parserGrammar = antlrDir.resolve(""TestParser.g4"");
    Xpp3Dom outputDirectory = TestMavenRuntime.newParameter(""outputDirectory"", ""src/main/java/foo"");
    Xpp3Dom arguments = new Xpp3Dom(""arguments"");
    arguments.addChild(TestMavenRuntime.newParameter(""argument"", ""-package""));
    arguments.addChild(TestMavenRuntime.newParameter(""argument"", ""foo""));
    MavenProject project = maven.readMavenProject(baseDir.toFile());
    MavenSession session = maven.newMavenSession(project);
    MojoExecution exec = maven.newMojoExecution(""antlr4"", outputDirectory, arguments);
    // //////////////////////////////////////////////////////////////////////
    // 1st - all grammars have to be processed
    // //////////////////////////////////////////////////////////////////////
    assertFalse(Files.exists(genHello));
    assertFalse(Files.exists(genTestParser));
    assertFalse(Files.exists(genTestLexer));
    maven.executeMojo(session, project, exec);
    assertTrue(Files.exists(genHello));
    assertTrue(Files.exists(genTestParser));
    assertTrue(Files.exists(genTestLexer));
    // //////////////////////////////////////////////////////////////////////
    // 2nd - nothing has been modified, no grammars have to be processed
    // //////////////////////////////////////////////////////////////////////
    {
        byte[] testLexerSum = checksum(genTestLexer);
        byte[] testParserSum = checksum(genTestParser);
        byte[] helloSum = checksum(genHello);
        maven.executeMojo(session, project, exec);
        assertTrue(Arrays.equals(testLexerSum, checksum(genTestLexer)));
        assertTrue(Arrays.equals(testParserSum, checksum(genTestParser)));
        assertTrue(Arrays.equals(helloSum, checksum(genHello)));
    }
    // //////////////////////////////////////////////////////////////////////
    // 3rd - the imported grammar changed, every dependency has to be processed
    // //////////////////////////////////////////////////////////////////////
    // modify the grammar to make checksum comparison detect a change
    try (Change change = Change.of(baseGrammar, ""DOT: '.' ;"")) {
        byte[] testLexerSum = checksum(genTestLexer);
        byte[] testParserSum = checksum(genTestParser);
        byte[] helloSum = checksum(genHello);
        maven.executeMojo(session, project, exec);
        assertFalse(Arrays.equals(testLexerSum, checksum(genTestLexer)));
        assertFalse(Arrays.equals(testParserSum, checksum(genTestParser)));
        assertTrue(Arrays.equals(helloSum, checksum(genHello)));
    }
    // //////////////////////////////////////////////////////////////////////
    // 4th - the lexer grammar changed, the parser grammar has to be processed as well
    // //////////////////////////////////////////////////////////////////////
    // modify the grammar to make checksum comparison detect a change
    try (Change change = Change.of(lexerGrammar, ""fragment DOT : '.';"")) {
        byte[] testLexerSum = checksum(genTestLexer);
        byte[] testParserSum = checksum(genTestParser);
        byte[] helloSum = checksum(genHello);
        maven.executeMojo(session, project, exec);
        assertFalse(Arrays.equals(testLexerSum, checksum(genTestLexer)));
        assertFalse(Arrays.equals(testParserSum, checksum(genTestParser)));
        assertTrue(Arrays.equals(helloSum, checksum(genHello)));
    }
    // //////////////////////////////////////////////////////////////////////
    // 5th - the parser grammar changed, no other grammars have to be processed
    // //////////////////////////////////////////////////////////////////////
    // modify the grammar to make checksum comparison detect a change
    try (Change change = Change.of(parserGrammar, "" t : WS* ;"")) {
        byte[] testLexerSum = checksum(genTestLexer);
        byte[] testParserSum = checksum(genTestParser);
        byte[] helloSum = checksum(genHello);
        maven.executeMojo(session, project, exec);
        assertTrue(Arrays.equals(testLexerSum, checksum(genTestLexer)));
        assertFalse(Arrays.equals(testParserSum, checksum(genTestParser)));
        assertTrue(Arrays.equals(helloSum, checksum(genHello)));
    }
}", ,"// //////////////////////////////////////////////////////////////////////
[[SEP]]// 1st - all grammars have to be processed
[[SEP]]// //////////////////////////////////////////////////////////////////////
[[SEP]]// //////////////////////////////////////////////////////////////////////
[[SEP]]// 2nd - nothing has been modified, no grammars have to be processed
[[SEP]]// //////////////////////////////////////////////////////////////////////
[[SEP]]// //////////////////////////////////////////////////////////////////////
[[SEP]]// 3rd - the imported grammar changed, every dependency has to be processed
[[SEP]]// //////////////////////////////////////////////////////////////////////
[[SEP]]// //////////////////////////////////////////////////////////////////////
[[SEP]]// 4th - the lexer grammar changed, the parser grammar has to be processed as well
[[SEP]]// //////////////////////////////////////////////////////////////////////
[[SEP]]// //////////////////////////////////////////////////////////////////////
[[SEP]]// 5th - the parser grammar changed, no other grammars have to be processed
[[SEP]]// //////////////////////////////////////////////////////////////////////
[[SEP]]// modify the grammar to make checksum comparison detect a change
[[SEP]]// modify the grammar to make checksum comparison detect a change
[[SEP]]// modify the grammar to make checksum comparison detect a change
","// //////////////////////////////////////////////////////////////////////// 1st - all grammars have to be processed// //////////////////////////////////////////////////////////////////////[[SEP]]// //////////////////////////////////////////////////////////////////////// 2nd - nothing has been modified, no grammars have to be processed// //////////////////////////////////////////////////////////////////////[[SEP]]// //////////////////////////////////////////////////////////////////////// 3rd - the imported grammar changed, every dependency has to be processed// //////////////////////////////////////////////////////////////////////// modify the grammar to make checksum comparison detect a change[[SEP]]// //////////////////////////////////////////////////////////////////////// 4th - the lexer grammar changed, the parser grammar has to be processed as well// //////////////////////////////////////////////////////////////////////// modify the grammar to make checksum comparison detect a change[[SEP]]// //////////////////////////////////////////////////////////////////////// 5th - the parser grammar changed, no other grammars have to be processed// //////////////////////////////////////////////////////////////////////// modify the grammar to make checksum comparison detect a change",88,192,[0],0,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]",0,"[0, 0, 0, 0, 0]",0,0,0,0,importsCustomLayout(),org.antlr.mojo.antlr4.Antlr4MojoTest,importsCustomLayout/0,False,89,8,2,0,2,1,16,61,0,29,0,16,1,1,0,0,3,0,20,0,29,0,1,0,0,0,48,1,0,False
21,..\projects\antlr4-4.11.0\antlr4-maven-plugin\src\test\java\org\antlr\mojo\antlr4\Antlr4MojoTest.java,org.antlr.mojo.antlr4.Antlr4MojoTest,void importsStandardLayout(),"@Test
public void importsStandardLayout() throws Exception {
    Path baseDir = resources.getBasedir(""importsStandard"").toPath();
    Path antlrDir = baseDir.resolve(""src/main/antlr4"");
    Path generatedSources = baseDir.resolve(""target/generated-sources/antlr4"");
    Path genTestLexer = generatedSources.resolve(""test/TestLexer.java"");
    Path genTestParser = generatedSources.resolve(""test/TestParser.java"");
    Path genHello = generatedSources.resolve(""test/HelloParser.java"");
    Path baseGrammar = antlrDir.resolve(""imports/TestBaseLexer.g4"");
    Path baseGrammar2 = antlrDir.resolve(""imports/TestBaseLexer2.g4"");
    Path lexerGrammar = antlrDir.resolve(""test/TestLexer.g4"");
    Path parserGrammar = antlrDir.resolve(""test/TestParser.g4"");
    MavenProject project = maven.readMavenProject(baseDir.toFile());
    MavenSession session = maven.newMavenSession(project);
    MojoExecution exec = maven.newMojoExecution(""antlr4"");
    // //////////////////////////////////////////////////////////////////////
    // 1st - all grammars have to be processed
    // //////////////////////////////////////////////////////////////////////
    assertFalse(Files.exists(genHello));
    assertFalse(Files.exists(genTestParser));
    assertFalse(Files.exists(genTestLexer));
    maven.executeMojo(session, project, exec);
    assertTrue(Files.exists(genHello));
    assertTrue(Files.exists(genTestParser));
    assertTrue(Files.exists(genTestLexer));
    byte[] origTestLexerSum = checksum(genTestLexer);
    byte[] origTestParserSum = checksum(genTestParser);
    byte[] origHelloSum = checksum(genHello);
    // //////////////////////////////////////////////////////////////////////
    // 2nd - nothing has been modified, no grammars have to be processed
    // //////////////////////////////////////////////////////////////////////
    {
        maven.executeMojo(session, project, exec);
        assertTrue(Arrays.equals(origTestLexerSum, checksum(genTestLexer)));
        assertTrue(Arrays.equals(origTestParserSum, checksum(genTestParser)));
        assertTrue(Arrays.equals(origHelloSum, checksum(genHello)));
    }
    // //////////////////////////////////////////////////////////////////////
    // 3rd - the imported grammar changed, every dependency has to be processed
    // //////////////////////////////////////////////////////////////////////
    // modify the grammar to make checksum comparison detect a change
    try (Change change = Change.of(baseGrammar, ""DOT: '.' ;"")) {
        maven.executeMojo(session, project, exec);
        assertFalse(Arrays.equals(origTestLexerSum, checksum(genTestLexer)));
        assertFalse(Arrays.equals(origTestParserSum, checksum(genTestParser)));
        assertTrue(Arrays.equals(origHelloSum, checksum(genHello)));
    }
    // Restore file and confirm it was restored.
    maven.executeMojo(session, project, exec);
    assertTrue(Arrays.equals(origTestLexerSum, checksum(genTestLexer)));
    assertTrue(Arrays.equals(origTestParserSum, checksum(genTestParser)));
    assertTrue(Arrays.equals(origHelloSum, checksum(genHello)));
    // //////////////////////////////////////////////////////////////////////
    // 4th - the second imported grammar changed, every dependency has to be processed
    // //////////////////////////////////////////////////////////////////////
    // modify the grammar to make checksum comparison detect a change
    try (Change change = Change.of(baseGrammar2, ""BANG: '!' ;"")) {
        maven.executeMojo(session, project, exec);
        assertFalse(Arrays.equals(origTestLexerSum, checksum(genTestLexer)));
        assertFalse(Arrays.equals(origTestParserSum, checksum(genTestParser)));
        assertTrue(Arrays.equals(origHelloSum, checksum(genHello)));
    }
    // Restore file and confirm it was restored.
    maven.executeMojo(session, project, exec);
    assertTrue(Arrays.equals(origTestLexerSum, checksum(genTestLexer)));
    assertTrue(Arrays.equals(origTestParserSum, checksum(genTestParser)));
    assertTrue(Arrays.equals(origHelloSum, checksum(genHello)));
    // //////////////////////////////////////////////////////////////////////
    // 5th - the lexer grammar changed, the parser grammar has to be processed as well
    // //////////////////////////////////////////////////////////////////////
    // modify the grammar to make checksum comparison detect a change
    try (Change change = Change.of(lexerGrammar, ""FOO: 'foo' ;"")) {
        maven.executeMojo(session, project, exec);
        assertFalse(Arrays.equals(origTestLexerSum, checksum(genTestLexer)));
        assertFalse(Arrays.equals(origTestParserSum, checksum(genTestParser)));
        assertTrue(Arrays.equals(origHelloSum, checksum(genHello)));
    }
    // Restore file and confirm it was restored.
    maven.executeMojo(session, project, exec);
    assertTrue(Arrays.equals(origTestLexerSum, checksum(genTestLexer)));
    assertTrue(Arrays.equals(origTestParserSum, checksum(genTestParser)));
    assertTrue(Arrays.equals(origHelloSum, checksum(genHello)));
    // //////////////////////////////////////////////////////////////////////
    // 6th - the parser grammar changed, no other grammars have to be processed
    // //////////////////////////////////////////////////////////////////////
    // modify the grammar to make checksum comparison detect a change
    try (Change change = Change.of(parserGrammar, "" t : WS* ;"")) {
        maven.executeMojo(session, project, exec);
        assertTrue(Arrays.equals(origTestLexerSum, checksum(genTestLexer)));
        assertFalse(Arrays.equals(origTestParserSum, checksum(genTestParser)));
        assertTrue(Arrays.equals(origHelloSum, checksum(genHello)));
    }
    // Restore file and confirm it was restored.
    maven.executeMojo(session, project, exec);
    assertTrue(Arrays.equals(origTestLexerSum, checksum(genTestLexer)));
    assertTrue(Arrays.equals(origTestParserSum, checksum(genTestParser)));
    assertTrue(Arrays.equals(origHelloSum, checksum(genHello)));
}", ,"// //////////////////////////////////////////////////////////////////////
[[SEP]]// 1st - all grammars have to be processed
[[SEP]]// //////////////////////////////////////////////////////////////////////
[[SEP]]// //////////////////////////////////////////////////////////////////////
[[SEP]]// 2nd - nothing has been modified, no grammars have to be processed
[[SEP]]// //////////////////////////////////////////////////////////////////////
[[SEP]]// //////////////////////////////////////////////////////////////////////
[[SEP]]// 3rd - the imported grammar changed, every dependency has to be processed
[[SEP]]// //////////////////////////////////////////////////////////////////////
[[SEP]]// //////////////////////////////////////////////////////////////////////
[[SEP]]// 4th - the second imported grammar changed, every dependency has to be processed
[[SEP]]// //////////////////////////////////////////////////////////////////////
[[SEP]]// //////////////////////////////////////////////////////////////////////
[[SEP]]// 5th - the lexer grammar changed, the parser grammar has to be processed as well
[[SEP]]// //////////////////////////////////////////////////////////////////////
[[SEP]]// //////////////////////////////////////////////////////////////////////
[[SEP]]// 6th - the parser grammar changed, no other grammars have to be processed
[[SEP]]// //////////////////////////////////////////////////////////////////////
[[SEP]]// modify the grammar to make checksum comparison detect a change
[[SEP]]// Restore file and confirm it was restored.
[[SEP]]// modify the grammar to make checksum comparison detect a change
[[SEP]]// Restore file and confirm it was restored.
[[SEP]]// modify the grammar to make checksum comparison detect a change
[[SEP]]// Restore file and confirm it was restored.
[[SEP]]// modify the grammar to make checksum comparison detect a change
[[SEP]]// Restore file and confirm it was restored.
","// //////////////////////////////////////////////////////////////////////// 1st - all grammars have to be processed// //////////////////////////////////////////////////////////////////////[[SEP]]// //////////////////////////////////////////////////////////////////////// 2nd - nothing has been modified, no grammars have to be processed// //////////////////////////////////////////////////////////////////////[[SEP]]// //////////////////////////////////////////////////////////////////////// 3rd - the imported grammar changed, every dependency has to be processed// //////////////////////////////////////////////////////////////////////// modify the grammar to make checksum comparison detect a change[[SEP]]// Restore file and confirm it was restored.[[SEP]]// //////////////////////////////////////////////////////////////////////// 4th - the second imported grammar changed, every dependency has to be processed// //////////////////////////////////////////////////////////////////////// modify the grammar to make checksum comparison detect a change[[SEP]]// Restore file and confirm it was restored.[[SEP]]// //////////////////////////////////////////////////////////////////////// 5th - the lexer grammar changed, the parser grammar has to be processed as well// //////////////////////////////////////////////////////////////////////// modify the grammar to make checksum comparison detect a change[[SEP]]// Restore file and confirm it was restored.[[SEP]]// //////////////////////////////////////////////////////////////////////// 6th - the parser grammar changed, no other grammars have to be processed// //////////////////////////////////////////////////////////////////////// modify the grammar to make checksum comparison detect a change[[SEP]]// Restore file and confirm it was restored.",194,313,[0],0,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]",0,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]",0,0,0,0,importsStandardLayout(),org.antlr.mojo.antlr4.Antlr4MojoTest,importsStandardLayout/0,False,195,7,2,0,2,1,14,71,0,20,0,14,1,1,0,0,4,0,15,0,20,0,1,0,0,0,40,1,0,False
22,..\projects\antlr4-4.11.0\antlr4-maven-plugin\src\test\java\org\antlr\mojo\antlr4\Antlr4MojoTest.java,org.antlr.mojo.antlr4.Antlr4MojoTest,void processWhenDependencyRemoved(),"@Test
public void processWhenDependencyRemoved() throws Exception {
    Path baseDir = resources.getBasedir(""dependencyRemoved"").toPath();
    Path antlrDir = baseDir.resolve(""src/main/antlr4"");
    Path baseGrammar = antlrDir.resolve(""imports/HelloBase.g4"");
    MavenProject project = maven.readMavenProject(baseDir.toFile());
    MavenSession session = maven.newMavenSession(project);
    MojoExecution exec = maven.newMojoExecution(""antlr4"");
    maven.executeMojo(session, project, exec);
    try (Change temp = Change.of(baseGrammar)) {
        // if the base grammar no longer exists, processing must be performed
        Files.delete(baseGrammar);
        thrown.expect(MojoExecutionException.class);
        thrown.expectMessage(""ANTLR 4 caught 1 build errors."");
        maven.executeMojo(session, project, exec);
    }
}", ,"// if the base grammar no longer exists, processing must be performed
","// if the base grammar no longer exists, processing must be performed",315,337,[0],0,[0],0,[0],0,0,0,0,processWhenDependencyRemoved(),org.antlr.mojo.antlr4.Antlr4MojoTest,processWhenDependencyRemoved/0,False,316,6,1,0,1,1,12,15,0,7,0,12,0,0,0,0,1,0,5,0,7,0,1,0,0,0,23,1,0,False
23,..\projects\antlr4-4.11.0\runtime-testsuite\test\org\antlr\v4\test\runtime\CustomDescriptors.java,org.antlr.v4.test.runtime.CustomDescriptors,RuntimeTestDescriptor getAtnStatesSizeMoreThan65535Descriptor(),"private static RuntimeTestDescriptor getAtnStatesSizeMoreThan65535Descriptor() {
    // I tried playing around with different sizes, and I think 1002 works for Go but 1003 does not;
    // the executing lexer gets a token syntax error for T208 or something like that
    final int tokensCount = 1024;
    final String suffix = String.join("""", Collections.nCopies(70, ""_""));
    final String grammarName = ""L"";
    StringBuilder grammar = new StringBuilder();
    grammar.append(""lexer grammar "").append(grammarName).append("";\n"");
    grammar.append('\n');
    StringBuilder input = new StringBuilder();
    StringBuilder output = new StringBuilder();
    int startOffset;
    int stopOffset = -2;
    for (int i = 0; i < tokensCount; i++) {
        String ruleName = String.format(""T_%06d"", i);
        String value = ruleName + suffix;
        grammar.append(ruleName).append("": '"").append(value).append(""';\n"");
        input.append(value).append('\n');
        startOffset = stopOffset + 2;
        stopOffset += value.length() + 1;
        output.append(""[@"").append(i).append(',').append(startOffset).append(':').append(stopOffset).append(""='"").append(value).append(""',<"").append(i + 1).append("">,"").append(i + 1).append("":0]\n"");
    }
    grammar.append(""\n"");
    grammar.append(""WS: [ \\t\\r\\n]+ -> skip;\n"");
    startOffset = stopOffset + 2;
    stopOffset = startOffset - 1;
    output.append(""[@"").append(tokensCount).append(',').append(startOffset).append(':').append(stopOffset).append(""='<EOF>',<-1>,"").append(tokensCount + 1).append("":0]\n"");
    return new RuntimeTestDescriptor(GrammarType.Lexer, ""AtnStatesSizeMoreThan65535"", ""Regression for https://github.com/antlr/antlr4/issues/1863"", input.toString(), output.toString(), """", """", grammarName, grammar.toString(), null, false, false, new String[] { ""CSharp"", ""Python2"", ""Python3"", ""Go"", ""PHP"", ""Swift"", ""JavaScript"", ""Dart"" }, uri);
}", ,"// I tried playing around with different sizes, and I think 1002 works for Go but 1003 does not;
[[SEP]]// the executing lexer gets a token syntax error for T208 or something like that
","// I tried playing around with different sizes, and I think 1002 works for Go but 1003 does not;// the executing lexer gets a token syntax error for T208 or something like that[[SEP]]//github.com/antlr/antlr4/issues/1863"", input.toString(), output.toString(), """", """", grammarName, grammar.toString(), null, false, false, new String[] { ""CSharp"", ""Python2"", ""Python3"", ""Go"", ""PHP"", ""Swift"", ""JavaScript"", ""Dart"" }, uri);",104,152,[0],0,"[1, 0]",1,"[1, 0]",1,0,1,0,getAtnStatesSizeMoreThan65535Descriptor(),org.antlr.v4.test.runtime.CustomDescriptors,getAtnStatesSizeMoreThan65535Descriptor/0,False,104,1,2,1,1,2,8,27,1,11,0,8,0,0,1,0,0,0,30,11,14,8,1,0,0,0,28,10,0,False
24,..\projects\antlr4-4.11.0\runtime-testsuite\test\org\antlr\v4\test\runtime\FileUtils.java,org.antlr.v4.test.runtime.FileUtils,void mkdir(String),"public static void mkdir(String dir) {
    File f = new File(dir);
    // noinspection ResultOfMethodCallIgnored
    f.mkdirs();
}", ,"// noinspection ResultOfMethodCallIgnored
",// noinspection ResultOfMethodCallIgnored,51,55,[0],0,[0],0,[0],0,0,0,0,mkdir(String),org.antlr.v4.test.runtime.FileUtils,mkdir/1[java.lang.String],False,51,0,6,6,0,1,1,4,0,1,1,1,0,0,0,0,0,0,0,0,1,0,0,0,0,0,4,9,0,False
25,..\projects\antlr4-4.11.0\runtime-testsuite\test\org\antlr\v4\test\runtime\Generator.java,org.antlr.v4.test.runtime.Generator,"ErrorQueue antlrOnString(String, String, String, String, boolean, String...)","/**
 * Write a grammar to tmpdir and run antlr
 */
public static ErrorQueue antlrOnString(String workdir, String targetName, String grammarFileName, String grammarStr, boolean defaultListener, String... extraOptions) {
    FileUtils.mkdir(workdir);
    writeFile(workdir, grammarFileName, grammarStr);
    return antlrOnString(workdir, targetName, grammarFileName, defaultListener, extraOptions);
}","/**
 * Write a grammar to tmpdir and run antlr
 */
", ,/** * Write a grammar to tmpdir and run antlr */,23,33,[0],0,[0],0,[0],0,0,0,0,"antlrOnString(String, String, String, String, boolean, String[])",org.antlr.v4.test.runtime.Generator,"antlrOnString/6[java.lang.String,java.lang.String,java.lang.String,java.lang.String,boolean,java.lang.String[]]",False,29,3,4,1,3,1,3,5,1,0,6,3,1,1,0,0,0,0,0,0,0,0,0,0,0,0,17,9,0,True
26,..\projects\antlr4-4.11.0\runtime-testsuite\test\org\antlr\v4\test\runtime\Generator.java,org.antlr.v4.test.runtime.Generator,"ErrorQueue antlrOnString(String, String, String, boolean, String...)","/**
 * Run ANTLR on stuff in workdir and error queue back
 */
public static ErrorQueue antlrOnString(String workdir, String targetName, String grammarFileName, boolean defaultListener, String... extraOptions) {
    final List<String> options = new ArrayList<>();
    Collections.addAll(options, extraOptions);
    if (targetName != null) {
        options.add(""-Dlanguage="" + targetName);
    }
    if (!options.contains(""-o"")) {
        options.add(""-o"");
        options.add(workdir);
    }
    if (!options.contains(""-lib"")) {
        options.add(""-lib"");
        options.add(workdir);
    }
    if (!options.contains(""-encoding"")) {
        options.add(""-encoding"");
        options.add(""UTF-8"");
    }
    options.add(new File(workdir, grammarFileName).toString());
    final String[] optionsA = new String[options.size()];
    options.toArray(optionsA);
    Tool antlr = new Tool(optionsA);
    ErrorQueue equeue = new ErrorQueue(antlr);
    antlr.addListener(equeue);
    if (defaultListener) {
        antlr.addListener(new DefaultToolListener(antlr));
    }
    antlr.processGrammarsOnCommandLine();
    List<String> errors = new ArrayList<>();
    if (!defaultListener && !equeue.errors.isEmpty()) {
        for (int i = 0; i < equeue.errors.size(); i++) {
            ANTLRMessage msg = equeue.errors.get(i);
            ST msgST = antlr.errMgr.getMessageTemplate(msg);
            errors.add(msgST.render());
        }
    }
    if (!defaultListener && !equeue.warnings.isEmpty()) {
        for (int i = 0; i < equeue.warnings.size(); i++) {
            ANTLRMessage msg = equeue.warnings.get(i);
            // antlrToolErrors.append(msg); warnings are hushed
        }
    }
    return equeue;
}","/**
 * Run ANTLR on stuff in workdir and error queue back
 */
","// antlrToolErrors.append(msg); warnings are hushed
",/** * Run ANTLR on stuff in workdir and error queue back */[[SEP]]// antlrToolErrors.append(msg); warnings are hushed,36,88,[0],0,[0],0,"[0, 0]",0,0,0,0,"antlrOnString(String, String, String, boolean, String[])",org.antlr.v4.test.runtime.Generator,"antlrOnString/5[java.lang.String,java.lang.String,java.lang.String,boolean,java.lang.String[]]",False,41,5,2,1,1,12,13,43,1,10,5,13,0,0,2,1,0,0,8,2,10,1,2,0,0,0,37,9,0,True
27,..\projects\antlr4-4.11.0\runtime-testsuite\test\org\antlr\v4\test\runtime\RuntimeRunner.java,org.antlr.v4.test.runtime.RuntimeRunner,State run(RunOptions),"public State run(RunOptions runOptions) {
    List<String> options = new ArrayList<>();
    if (runOptions.useVisitor) {
        options.add(""-visitor"");
    }
    if (runOptions.superClass != null && runOptions.superClass.length() > 0) {
        options.add(""-DsuperClass="" + runOptions.superClass);
    }
    ErrorQueue errorQueue = Generator.antlrOnString(getTempDirPath(), getLanguage(), runOptions.grammarFileName, runOptions.grammarStr, false, options.toArray(new String[0]));
    List<GeneratedFile> generatedFiles = getGeneratedFiles(runOptions);
    GeneratedState generatedState = new GeneratedState(errorQueue, generatedFiles, null);
    if (generatedState.containsErrors() || runOptions.endStage == Stage.Generate) {
        return generatedState;
    }
    if (!initAntlrRuntimeIfRequired()) {
        // Do not repeat ANTLR runtime initialization error
        return new CompiledState(generatedState, new Exception(getTitleName() + "" ANTLR runtime is not initialized""));
    }
    writeRecognizerFile(runOptions);
    CompiledState compiledState = compile(runOptions, generatedState);
    if (compiledState.containsErrors() || runOptions.endStage == Stage.Compile) {
        return compiledState;
    }
    writeFile(getTempDirPath(), ""input"", runOptions.input);
    return execute(runOptions, compiledState);
}", ,"// Do not repeat ANTLR runtime initialization error
",// Do not repeat ANTLR runtime initialization error,155,189,[0],0,[0],0,[0],0,0,0,0,run(RunOptions),org.antlr.v4.test.runtime.RuntimeRunner,run/1[org.antlr.v4.test.runtime.RunOptions],False,155,10,15,1,14,9,15,25,4,5,1,15,8,11,0,3,0,0,4,2,5,2,1,0,0,0,41,1,0,False
28,..\projects\antlr4-4.11.0\runtime-testsuite\test\org\antlr\v4\test\runtime\RuntimeRunner.java,org.antlr.v4.test.runtime.RuntimeRunner,boolean initAntlrRuntimeIfRequired(),"private boolean initAntlrRuntimeIfRequired() {
    String language = getLanguage();
    InitializationStatus status;
    // Create initialization status for every runtime with lock object
    synchronized (runtimeInitializationStatuses) {
        status = runtimeInitializationStatuses.get(language);
        if (status == null) {
            status = new InitializationStatus();
            runtimeInitializationStatuses.put(language, status);
        }
    }
    if (status.isInitialized != null) {
        return status.isInitialized;
    }
    // Locking per runtime, several runtimes can be being initialized simultaneously
    synchronized (status.lockObject) {
        if (status.isInitialized == null) {
            Exception exception = null;
            try {
                initRuntime();
            } catch (Exception e) {
                exception = e;
                e.printStackTrace();
            }
            status.isInitialized = exception == null;
            status.exception = exception;
        }
    }
    return status.isInitialized;
}", ,"// Create initialization status for every runtime with lock object
[[SEP]]// Locking per runtime, several runtimes can be being initialized simultaneously
","// Create initialization status for every runtime with lock object[[SEP]]// Locking per runtime, several runtimes can be being initialized simultaneously",241,273,[0],0,"[0, 0]",0,"[0, 0]",0,0,0,0,initAntlrRuntimeIfRequired(),org.antlr.v4.test.runtime.RuntimeRunner,initAntlrRuntimeIfRequired/0,False,241,2,4,1,3,5,5,29,2,3,0,5,2,1,0,4,1,0,0,0,7,0,3,0,0,0,17,2,0,False
29,..\projects\antlr4-4.11.0\runtime-testsuite\test\org\antlr\v4\test\runtime\RuntimeTestDescriptor.java,org.antlr.v4.test.runtime.RuntimeTestDescriptor,boolean ignore(String),"/**
 * Return true if this test should be ignored for the indicated target
 */
public boolean ignore(String targetName) {
    return Arrays.asList(skipTargets).contains(targetName);
}","/**
 * Return true if this test should be ignored for the indicated target
 */
", ,/** * Return true if this test should be ignored for the indicated target */,81,83,[0],0,[0],0,[0],0,0,0,0,ignore(String),org.antlr.v4.test.runtime.RuntimeTestDescriptor,ignore/1[java.lang.String],False,81,0,1,1,0,1,2,3,1,0,1,2,0,0,0,0,0,0,0,0,0,0,0,0,0,0,13,1,0,True
30,..\projects\antlr4-4.11.0\runtime-testsuite\test\org\antlr\v4\test\runtime\RuntimeTestDescriptorParser.java,org.antlr.v4.test.runtime.RuntimeTestDescriptorParser,"RuntimeTestDescriptor parse(String, String, URI)","/**
 *   Read stuff like:
 * 	 [grammar]
 * 	 grammar T;
 * 	 s @after {<DumpDFA()>}
 * 	 : ID | ID {} ;
 * 	 ID : 'a'..'z'+;
 * 	 WS : (' '|'\t'|'\n')+ -> skip ;
 *
 * 	 [grammarName]
 * 	 T
 *
 * 	 [start]
 * 	 s
 *
 * 	 [input]
 * 	 abc
 *
 * 	 [output]
 * 	 Decision 0:
 * 	 s0-ID->:s1^=>1
 *
 * 	 [errors]
 * 	 """"""line 1:0 reportAttemptingFullContext d=0 (s), input='abc'
 * 	 """"""
 *
 * 	 Some can be missing like [errors].
 *
 * 	 Get gr names automatically ""lexer grammar Unicode;"" ""grammar T;"" ""parser grammar S;""
 *
 * 	 Also handle slave grammars:
 *
 * 	 [grammar]
 * 	 grammar M;
 * 	 import S,T;
 * 	 s : a ;
 * 	 B : 'b' ; // defines B from inherited token space
 * 	 WS : (' '|'\n') -> skip ;
 *
 * 	 [slaveGrammar]
 * 	 parser grammar T;
 * 	 a : B {<writeln(""\""T.a\"""")>};<! hidden by S.a !>
 *
 * 	 [slaveGrammar]
 * 	 parser grammar S;
 * 	 a : b {<writeln(""\""S.a\"""")>};
 * 	 b : B;
 */
public static RuntimeTestDescriptor parse(String name, String text, URI uri) throws RuntimeException {
    String currentField = null;
    StringBuilder currentValue = new StringBuilder();
    List<Pair<String, String>> pairs = new ArrayList<>();
    String[] lines = text.split(""\r?\n"");
    for (String line : lines) {
        boolean newSection = false;
        String sectionName = null;
        if (line.startsWith(""["") && line.length() > 2) {
            sectionName = line.substring(1, line.length() - 1);
            newSection = sections.contains(sectionName);
        }
        if (newSection) {
            if (currentField != null) {
                pairs.add(new Pair<>(currentField, currentValue.toString()));
            }
            currentField = sectionName;
            currentValue.setLength(0);
        } else {
            currentValue.append(line);
            currentValue.append(""\n"");
        }
    }
    pairs.add(new Pair<>(currentField, currentValue.toString()));
    String notes = """";
    GrammarType testType = GrammarType.Lexer;
    String grammar = """";
    String grammarName = """";
    List<Pair<String, String>> slaveGrammars = new ArrayList<>();
    String startRule = """";
    String input = """";
    String output = """";
    String errors = """";
    boolean showDFA = false;
    boolean showDiagnosticErrors = false;
    String[] skipTargets = new String[0];
    for (Pair<String, String> p : pairs) {
        String section = p.a;
        String value = """";
        if (p.b != null) {
            value = p.b.trim();
        }
        if (value.startsWith(""\""\""\"""")) {
            value = value.replace(""\""\""\"""", """");
        } else if (value.indexOf('\n') >= 0) {
            // if multi line and not quoted, leave \n on end.
            value = value + ""\n"";
        }
        switch(section) {
            case ""notes"":
                notes = value;
                break;
            case ""type"":
                testType = Enum.valueOf(GrammarType.class, value);
                break;
            case ""grammar"":
                grammarName = getGrammarName(value.split(""\n"")[0]);
                grammar = value;
                break;
            case ""slaveGrammar"":
                String gname = getGrammarName(value.split(""\n"")[0]);
                slaveGrammars.add(new Pair<>(gname, value));
            case ""start"":
                startRule = value;
                break;
            case ""input"":
                input = value;
                break;
            case ""output"":
                output = value;
                break;
            case ""errors"":
                errors = value;
                break;
            case ""flags"":
                String[] flags = value.split(""\n"");
                for (String f : flags) {
                    switch(f) {
                        case ""showDFA"":
                            showDFA = true;
                            break;
                        case ""showDiagnosticErrors"":
                            showDiagnosticErrors = true;
                            break;
                    }
                }
                break;
            case ""skip"":
                skipTargets = value.split(""\n"");
                break;
            default:
                throw new RuntimeException(""Unknown descriptor section ignored: "" + section);
        }
    }
    return new RuntimeTestDescriptor(testType, name, notes, input, output, errors, startRule, grammarName, grammar, slaveGrammars, showDFA, showDiagnosticErrors, skipTargets, uri);
}","/**
 *   Read stuff like:
 * 	 [grammar]
 * 	 grammar T;
 * 	 s @after {<DumpDFA()>}
 * 	 : ID | ID {} ;
 * 	 ID : 'a'..'z'+;
 * 	 WS : (' '|'\t'|'\n')+ -> skip ;
 *
 * 	 [grammarName]
 * 	 T
 *
 * 	 [start]
 * 	 s
 *
 * 	 [input]
 * 	 abc
 *
 * 	 [output]
 * 	 Decision 0:
 * 	 s0-ID->:s1^=>1
 *
 * 	 [errors]
 * 	 """"""line 1:0 reportAttemptingFullContext d=0 (s), input='abc'
 * 	 """"""
 *
 * 	 Some can be missing like [errors].
 *
 * 	 Get gr names automatically ""lexer grammar Unicode;"" ""grammar T;"" ""parser grammar S;""
 *
 * 	 Also handle slave grammars:
 *
 * 	 [grammar]
 * 	 grammar M;
 * 	 import S,T;
 * 	 s : a ;
 * 	 B : 'b' ; // defines B from inherited token space
 * 	 WS : (' '|'\n') -> skip ;
 *
 * 	 [slaveGrammar]
 * 	 parser grammar T;
 * 	 a : B {<writeln(""\""T.a\"""")>};<! hidden by S.a !>
 *
 * 	 [slaveGrammar]
 * 	 parser grammar S;
 * 	 a : b {<writeln(""\""S.a\"""")>};
 * 	 b : B;
 */
","// if multi line and not quoted, leave \n on end.
","/** *   Read stuff like: * 	 [grammar] * 	 grammar T; * 	 s @after {<DumpDFA()>} * 	 : ID | ID {} ; * 	 ID : 'a'..'z'+; * 	 WS : (' '|'\t'|'\n')+ -> skip ; * * 	 [grammarName] * 	 T * * 	 [start] * 	 s * * 	 [input] * 	 abc * * 	 [output] * 	 Decision 0: * 	 s0-ID->:s1^=>1 * * 	 [errors] * 	 """"""line 1:0 reportAttemptingFullContext d=0 (s), input='abc' * 	 """""" * * 	 Some can be missing like [errors]. * * 	 Get gr names automatically ""lexer grammar Unicode;"" ""grammar T;"" ""parser grammar S;"" * * 	 Also handle slave grammars: * * 	 [grammar] * 	 grammar M; * 	 import S,T; * 	 s : a ; * 	 B : 'b' ; // defines B from inherited token space * 	 WS : (' '|'\n') -> skip ; * * 	 [slaveGrammar] * 	 parser grammar T; * 	 a : B {<writeln(""\""T.a\"""")>};<! hidden by S.a !> * * 	 [slaveGrammar] * 	 parser grammar S; * 	 a : b {<writeln(""\""S.a\"""")>}; * 	 b : B; */[[SEP]]// if multi line and not quoted, leave \n on end.",66,167,[0],0,[0],0,"[0, 0]",0,0,0,0,"parse(String, String, URI)",org.antlr.v4.test.runtime.RuntimeTestDescriptorParser,"parse/3[java.lang.String,java.lang.String,java.net.URI]",False,66,4,4,1,3,23,14,97,1,22,3,14,1,1,3,2,0,0,32,8,39,3,4,0,0,0,87,9,0,True
31,..\projects\antlr4-4.11.0\runtime-testsuite\test\org\antlr\v4\test\runtime\RuntimeTestDescriptorParser.java,org.antlr.v4.test.runtime.RuntimeTestDescriptorParser,String getGrammarName(String),"/**
 * Get A, B, or C from:
 * ""lexer grammar A;"" ""grammar B;"" ""parser grammar C;""
 */
private static String getGrammarName(String grammarDeclLine) {
    int gi = grammarDeclLine.indexOf(""grammar "");
    if (gi < 0) {
        return ""<unknown grammar name>"";
    }
    gi += ""grammar "".length();
    int gsemi = grammarDeclLine.indexOf(';');
    return grammarDeclLine.substring(gi, gsemi);
}","/**
 * Get A, B, or C from:
 * ""lexer grammar A;"" ""grammar B;"" ""parser grammar C;""
 */
", ,"/** * Get A, B, or C from: * ""lexer grammar A;"" ""grammar B;"" ""parser grammar C;"" */",172,180,[0],0,[0],0,[0],0,0,0,0,getGrammarName(String),org.antlr.v4.test.runtime.RuntimeTestDescriptorParser,getGrammarName/1[java.lang.String],False,172,0,1,1,0,2,4,9,2,2,1,4,0,0,0,0,0,0,3,1,3,0,1,0,0,0,14,10,0,True
32,..\projects\antlr4-4.11.0\runtime-testsuite\test\org\antlr\v4\test\runtime\RuntimeTests.java,org.antlr.v4.test.runtime.RuntimeTests,"String prepareGrammars(RuntimeTestDescriptor, RuntimeRunner)","private static String prepareGrammars(RuntimeTestDescriptor descriptor, RuntimeRunner runner) {
    String targetName = runner.getLanguage();
    STGroup targetTemplates;
    synchronized (cachedTargetTemplates) {
        targetTemplates = cachedTargetTemplates.get(targetName);
        if (targetTemplates == null) {
            ClassLoader classLoader = RuntimeTests.class.getClassLoader();
            URL templates = classLoader.getResource(""org/antlr/v4/test/runtime/templates/"" + targetName + "".test.stg"");
            assert templates != null;
            targetTemplates = new STGroupFile(templates, ""UTF-8"", '<', '>');
            targetTemplates.registerRenderer(String.class, rendered);
            cachedTargetTemplates.put(targetName, targetTemplates);
        }
    }
    // write out any slave grammars
    List<Pair<String, String>> slaveGrammars = descriptor.slaveGrammars;
    if (slaveGrammars != null) {
        for (Pair<String, String> spair : slaveGrammars) {
            STGroup g = new STGroup('<', '>');
            g.registerRenderer(String.class, rendered);
            g.importTemplates(targetTemplates);
            ST grammarST = new ST(g, spair.b);
            writeFile(runner.getTempDirPath(), spair.a + "".g4"", grammarST.render());
        }
    }
    STGroup g = new STGroup('<', '>');
    g.importTemplates(targetTemplates);
    g.registerRenderer(String.class, rendered);
    ST grammarST = new ST(g, descriptor.grammar);
    return grammarST.render();
}", ,"// write out any slave grammars
",// write out any slave grammars,177,210,[0],0,[0],0,[0],0,0,0,0,"prepareGrammars(RuntimeTestDescriptor, RuntimeRunner)",org.antlr.v4.test.runtime.RuntimeTests,"prepareGrammars/2[org.antlr.v4.test.runtime.RuntimeTestDescriptor,org.antlr.v4.test.runtime.RuntimeRunner]",False,177,8,4,1,3,4,10,30,1,9,2,10,0,0,1,3,0,0,4,0,10,2,2,0,0,0,33,10,0,False
33,..\projects\antlr4-4.11.0\runtime-testsuite\test\org\antlr\v4\test\runtime\StreamReader.java,org.antlr.v4.test.runtime.StreamReader,void join(),"/**
 * wait for the thread to finish
 */
public void join() throws InterruptedException {
    worker.join();
}","/**
 * wait for the thread to finish
 */
", ,/** * wait for the thread to finish */,49,51,[0],0,[0],0,[0],0,0,0,0,join(),org.antlr.v4.test.runtime.StreamReader,join/0,False,49,0,2,2,0,1,1,3,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,8,1,0,True
34,..\projects\antlr4-4.11.0\runtime-testsuite\test\org\antlr\v4\test\runtime\go\GoRunner.java,org.antlr.v4.test.runtime.go.GoRunner,"CompiledState compile(RunOptions, GeneratedState)","@Override
protected CompiledState compile(RunOptions runOptions, GeneratedState generatedState) {
    List<GeneratedFile> generatedFiles = generatedState.generatedFiles;
    String tempDirPath = getTempDirPath();
    File generatedParserDir = new File(tempDirPath, ""parser"");
    if (!generatedParserDir.mkdir()) {
        return new CompiledState(generatedState, new Exception(""can't make dir "" + generatedParserDir));
    }
    // The generated files seem to need to be in the parser subdirectory.
    // We have no need to change the import of the runtime because of go mod replace so, we could just generate them
    // directly in to the parser subdir. But in case down the line, there is some reason to want to replace things in
    // the generated code, then I will leave this here, and we can use replaceInFile()
    // 
    for (GeneratedFile generatedFile : generatedFiles) {
        try {
            Path originalFile = Paths.get(tempDirPath, generatedFile.name);
            Files.move(originalFile, Paths.get(tempDirPath, ""parser"", generatedFile.name));
        } catch (IOException e) {
            return new CompiledState(generatedState, e);
        }
    }
    writeFile(tempDirPath, ""go.mod"", cachedGoMod);
    Exception ex = null;
    try {
        Processor.run(new String[] { getRuntimeToolPath(), ""mod"", ""tidy"" }, tempDirPath, environment);
    } catch (InterruptedException | IOException e) {
        ex = e;
    }
    return new CompiledState(generatedState, ex);
}", ,"// The generated files seem to need to be in the parser subdirectory.
[[SEP]]// We have no need to change the import of the runtime because of go mod replace so, we could just generate them
[[SEP]]// directly in to the parser subdir. But in case down the line, there is some reason to want to replace things in
[[SEP]]// the generated code, then I will leave this here, and we can use replaceInFile()
[[SEP]]// 
","// The generated files seem to need to be in the parser subdirectory.// We have no need to change the import of the runtime because of go mod replace so, we could just generate them// directly in to the parser subdir. But in case down the line, there is some reason to want to replace things in// the generated code, then I will leave this here, and we can use replaceInFile()//",103,135,[0],0,"[0, 0, 0, 0, 0]",0,[0],0,0,0,0,"compile(RunOptions, GeneratedState)",org.antlr.v4.test.runtime.go.GoRunner,"compile/2[org.antlr.v4.test.runtime.RunOptions,org.antlr.v4.test.runtime.states.GeneratedState]",False,104,7,5,0,5,5,7,26,3,5,2,7,0,0,1,0,2,0,6,0,6,1,2,0,0,0,28,4,0,False
35,..\projects\antlr4-4.11.0\runtime-testsuite\test\org\antlr\v4\test\runtime\java\JavaRunner.java,org.antlr.v4.test.runtime.java.JavaRunner,"JavaCompiledState compile(RunOptions, GeneratedState)","@Override
protected JavaCompiledState compile(RunOptions runOptions, GeneratedState generatedState) {
    String tempTestDir = getTempDirPath();
    List<GeneratedFile> generatedFiles = generatedState.generatedFiles;
    GeneratedFile firstFile = generatedFiles.get(0);
    if (!firstFile.isParser) {
        FileUtils.writeFile(tempTestDir, runtimeTestLexerName + "".java"", testLexerContent);
        try {
            // superClass for combined grammar generates the same extends base class for Lexer and Parser
            // So, for lexer it should be replaced on correct base lexer class
            replaceInFile(Paths.get(getTempDirPath(), firstFile.name), ""extends "" + runtimeTestParserName + "" {"", ""extends "" + runtimeTestLexerName + "" {"");
        } catch (IOException e) {
            return new JavaCompiledState(generatedState, null, null, null, e);
        }
    }
    if (generatedFiles.stream().anyMatch(file -> file.isParser)) {
        FileUtils.writeFile(tempTestDir, runtimeTestParserName + "".java"", testParserContent);
    }
    ClassLoader loader = null;
    Class<? extends Lexer> lexer = null;
    Class<? extends Parser> parser = null;
    Exception exception = null;
    try {
        StandardJavaFileManager fileManager = compiler.getStandardFileManager(null, null, null);
        ClassLoader systemClassLoader = ClassLoader.getSystemClassLoader();
        List<File> files = new ArrayList<>();
        File f = new File(tempTestDir, getTestFileWithExt());
        files.add(f);
        Iterable<? extends JavaFileObject> compilationUnits = fileManager.getJavaFileObjectsFromFiles(files);
        Iterable<String> compileOptions = Arrays.asList(""-g"", ""-source"", ""1.8"", ""-target"", ""1.8"", ""-implicit:class"", ""-Xlint:-options"", ""-d"", tempTestDir, ""-cp"", tempTestDir + PathSeparator + classPath);
        JavaCompiler.CompilationTask task = compiler.getTask(null, fileManager, null, compileOptions, null, compilationUnits);
        task.call();
        loader = new URLClassLoader(new URL[] { new File(tempTestDir).toURI().toURL() }, systemClassLoader);
        if (runOptions.lexerName != null) {
            lexer = loader.loadClass(runOptions.lexerName).asSubclass(Lexer.class);
        }
        if (runOptions.parserName != null) {
            parser = loader.loadClass(runOptions.parserName).asSubclass(Parser.class);
        }
    } catch (Exception ex) {
        exception = ex;
    }
    return new JavaCompiledState(generatedState, loader, lexer, parser, exception);
}", ,"// superClass for combined grammar generates the same extends base class for Lexer and Parser
[[SEP]]// So, for lexer it should be replaced on correct base lexer class
","// superClass for combined grammar generates the same extends base class for Lexer and Parser// So, for lexer it should be replaced on correct base lexer class",71,131,[0],0,"[0, 0]",0,[0],0,0,0,0,"compile(RunOptions, GeneratedState)",org.antlr.v4.test.runtime.java.JavaRunner,"compile/2[org.antlr.v4.test.runtime.RunOptions,org.antlr.v4.test.runtime.states.GeneratedState]",False,72,8,5,0,5,7,20,43,2,15,2,20,0,0,0,2,2,0,15,1,18,5,2,0,0,1,50,4,0,False
36,..\projects\antlr4-4.11.0\runtime-testsuite\test\org\antlr\v4\test\runtime\java\JavaRunner.java,org.antlr.v4.test.runtime.java.JavaRunner,"JavaExecutedState execWithObject(RunOptions, JavaCompiledState)","private JavaExecutedState execWithObject(RunOptions runOptions, JavaCompiledState javaCompiledState) {
    ParseTree parseTree = null;
    Exception exception = null;
    try {
        Pair<Lexer, Parser> lexerParser = javaCompiledState.initializeLexerAndParser(runOptions.input);
        if (runOptions.parserName != null) {
            Method startRule;
            Object[] args = null;
            try {
                startRule = javaCompiledState.parser.getMethod(runOptions.startRuleName);
            } catch (NoSuchMethodException noSuchMethodException) {
                // try with int _p arg for recursive func
                startRule = javaCompiledState.parser.getMethod(runOptions.startRuleName, int.class);
                args = new Integer[] { 0 };
            }
            parseTree = (ParseTree) startRule.invoke(lexerParser.b, args);
        }
    } catch (Exception ex) {
        exception = ex;
    }
    return new JavaExecutedState(javaCompiledState, null, null, parseTree, exception);
}", ,"// try with int _p arg for recursive func
",// try with int _p arg for recursive func,146,168,[0],0,[0],0,[0],0,0,0,0,"execWithObject(RunOptions, JavaCompiledState)",org.antlr.v4.test.runtime.java.JavaRunner,"execWithObject/2[org.antlr.v4.test.runtime.RunOptions,org.antlr.v4.test.runtime.states.JavaCompiledState]",False,146,7,3,1,2,4,3,23,1,5,2,3,0,0,0,1,2,0,0,1,9,0,3,0,0,0,26,2,0,False
37,..\projects\antlr4-4.11.0\runtime-testsuite\test\org\antlr\v4\test\runtime\java\TestCharStreams.java,org.antlr.v4.test.runtime.java.TestCharStreams,void fromSMPUTF8SequenceStraddlingBufferBoundary(Path),"@Test
public void fromSMPUTF8SequenceStraddlingBufferBoundary(@TempDir Path tempDir) throws Exception {
    Path p = getTestFile(tempDir);
    Files.write(p, ""hello \uD83C\uDF0E"".getBytes(StandardCharsets.UTF_8));
    try (SeekableByteChannel c = Files.newByteChannel(p)) {
        CharStream s = CharStreams.fromChannel(c, // Note this buffer size ensures the SMP code point
        // straddles the boundary of two buffers
        8, CodingErrorAction.REPLACE, ""foo"");
        assertEquals(7, s.size());
        assertEquals(0, s.index());
        assertEquals(""hello \uD83C\uDF0E"", s.toString());
    }
}", ,"// Note this buffer size ensures the SMP code point
[[SEP]]// straddles the boundary of two buffers
",// Note this buffer size ensures the SMP code point[[SEP]]// straddles the boundary of two buffers,148,164,[0],0,"[0, 0]",0,"[0, 0]",0,0,0,0,fromSMPUTF8SequenceStraddlingBufferBoundary(Path),org.antlr.v4.test.runtime.java.TestCharStreams,fromSMPUTF8SequenceStraddlingBufferBoundary/1[java.nio.file.Path],False,149,6,4,0,4,1,9,10,0,3,1,9,1,1,0,0,1,0,3,3,3,0,1,0,0,0,28,1,0,False
38,..\projects\antlr4-4.11.0\runtime-testsuite\test\org\antlr\v4\test\runtime\java\TestCharStreams.java,org.antlr.v4.test.runtime.java.TestCharStreams,void fromSMPUTF32LEPathSMPHasExpectedSize(Path),"@Test
public void fromSMPUTF32LEPathSMPHasExpectedSize(@TempDir Path tempDir) throws Exception {
    Path p = getTestFile(tempDir);
    // UTF-32 isn't popular enough to have an entry in StandardCharsets.
    Charset c = Charset.forName(""UTF-32LE"");
    Files.write(p, ""hello \uD83C\uDF0E"".getBytes(c));
    CharStream s = CharStreams.fromPath(p, c);
    assertEquals(7, s.size());
    assertEquals(0, s.index());
    assertEquals(""hello \uD83C\uDF0E"", s.toString());
    assertEquals(p.toString(), s.getSourceName());
}", ,"// UTF-32 isn't popular enough to have an entry in StandardCharsets.
",// UTF-32 isn't popular enough to have an entry in StandardCharsets.,212,223,[0],0,[0],0,[0],0,0,0,0,fromSMPUTF32LEPathSMPHasExpectedSize(Path),org.antlr.v4.test.runtime.java.TestCharStreams,fromSMPUTF32LEPathSMPHasExpectedSize/1[java.nio.file.Path],False,213,6,5,0,5,1,11,10,0,3,1,11,1,1,0,0,0,0,3,2,3,0,0,0,0,0,27,1,0,False
39,..\projects\antlr4-4.11.0\runtime-testsuite\test\org\antlr\v4\test\runtime\java\TestIntegerList.java,org.antlr.v4.test.runtime.java.TestIntegerList,void surrogateRangeIntegerToCharArray(),"@Test
public void surrogateRangeIntegerToCharArray() {
    IntegerList l = new IntegerList();
    // Java allows dangling surrogates, so (currently) we do
    // as well. We could change this if desired.
    l.add(0xDC00);
    char[] expected = new char[] { 0xDC00 };
    assertArrayEquals(expected, l.toCharArray());
}", ,"// Java allows dangling surrogates, so (currently) we do
[[SEP]]// as well. We could change this if desired.
","// Java allows dangling surrogates, so (currently) we do// as well. We could change this if desired.",32,40,[0],0,"[0, 0]",0,[0],0,0,0,0,surrogateRangeIntegerToCharArray(),org.antlr.v4.test.runtime.java.TestIntegerList,surrogateRangeIntegerToCharArray/0,False,33,3,3,0,3,1,3,6,0,2,0,3,0,0,0,0,0,0,0,2,2,0,0,0,0,0,14,1,0,False
40,..\projects\antlr4-4.11.0\runtime-testsuite\test\org\antlr\v4\test\runtime\java\api\TestExpectedTokens.java,org.antlr.v4.test.runtime.java.api.TestExpectedTokens,void testFollowIncluded(),"@Test
public void testFollowIncluded() throws Exception {
    String gtext = ""parser grammar T;\n"" + ""a : b A ;\n"" + ""b : B | ;"";
    Grammar g = new Grammar(gtext);
    String atnText = ""RuleStart_a_0->s4\n"" + ""s4-b->RuleStart_b_2\n"" + ""s5-A->s6\n"" + ""s6->RuleStop_a_1\n"" + ""RuleStop_a_1-EOF->s11\n"";
    RuntimeTestUtils.checkRuleATN(g, ""a"", atnText);
    atnText = ""RuleStart_b_2->BlockStart_9\n"" + ""BlockStart_9->s7\n"" + ""BlockStart_9->s8\n"" + ""s7-B->BlockEnd_10\n"" + ""s8->BlockEnd_10\n"" + ""BlockEnd_10->RuleStop_b_3\n"" + ""RuleStop_b_3->s5\n"";
    RuntimeTestUtils.checkRuleATN(g, ""b"", atnText);
    ATN atn = g.getATN();
    // From the start of 'b' with empty stack, can only see B and EOF
    int blkStartStateNumber = 9;
    IntervalSet tokens = atn.getExpectedTokens(blkStartStateNumber, ParserRuleContext.EMPTY);
    assertEquals(""{<EOF>, B}"", tokens.toString(g.getTokenNames()));
    // Now call from 'a'
    tokens = atn.getExpectedTokens(blkStartStateNumber, new ParserRuleContext(ParserRuleContext.EMPTY, 4));
    assertEquals(""{A, B}"", tokens.toString(g.getTokenNames()));
}", ,"// From the start of 'b' with empty stack, can only see B and EOF
[[SEP]]// Now call from 'a'
","// From the start of 'b' with empty stack, can only see B and EOF[[SEP]]// Now call from 'a'",68,101,[0],0,"[0, 0]",0,"[0, 0]",0,0,0,0,testFollowIncluded(),org.antlr.v4.test.runtime.java.api.TestExpectedTokens,testFollowIncluded/0,False,68,6,4,0,4,1,6,14,0,6,0,6,0,0,0,0,0,0,19,2,8,3,0,0,0,0,30,1,0,False
41,..\projects\antlr4-4.11.0\runtime-testsuite\test\org\antlr\v4\test\runtime\java\api\TestExpectedTokens.java,org.antlr.v4.test.runtime.java.api.TestExpectedTokens,void testFollowIncludedInLeftRecursiveRule(),"// Test for https://github.com/antlr/antlr4/issues/1480
// can't reproduce
@Test
public void testFollowIncludedInLeftRecursiveRule() throws Exception {
    String gtext = ""grammar T;\n"" + ""s : expr EOF ;\n"" + ""expr : L expr R\n"" + ""     | expr PLUS expr\n"" + ""     | ID\n"" + ""     ;\n"";
    Grammar g = new Grammar(gtext);
    String atnText = ""RuleStart_expr_2->BlockStart_13\n"" + ""BlockStart_13->s7\n"" + ""BlockStart_13->s12\n"" + ""s7-action_1:-1->s8\n"" + ""s12-ID->BlockEnd_14\n"" + ""s8-L->s9\n"" + ""BlockEnd_14->StarLoopEntry_20\n"" + ""s9-expr->RuleStart_expr_2\n"" + ""StarLoopEntry_20->StarBlockStart_18\n"" + ""StarLoopEntry_20->s21\n"" + ""s10-R->s11\n"" + ""StarBlockStart_18->s15\n"" + ""s21->RuleStop_expr_3\n"" + ""s11->BlockEnd_14\n"" + ""s15-2 >= _p->s16\n"" + ""RuleStop_expr_3->s5\n"" + ""RuleStop_expr_3->s10\n"" + ""RuleStop_expr_3->BlockEnd_19\n"" + ""s16-PLUS->s17\n"" + ""s17-expr->RuleStart_expr_2\n"" + ""BlockEnd_19->StarLoopBack_22\n"" + ""StarLoopBack_22->StarLoopEntry_20\n"";
    RuntimeTestUtils.checkRuleATN(g, ""expr"", atnText);
    ATN atn = g.getATN();
    // DOTGenerator gen = new DOTGenerator(g);
    // String dot = gen.getDOT(atn.states.get(2), g.getRuleNames(), false);
    // System.out.println(dot);
    // Simulate call stack after input '(x' from rule s
    ParserRuleContext callStackFrom_s = new ParserRuleContext(null, 4);
    ParserRuleContext callStackFrom_expr = new ParserRuleContext(callStackFrom_s, 9);
    int afterID = 14;
    IntervalSet tokens = atn.getExpectedTokens(afterID, callStackFrom_expr);
    assertEquals(""{R, PLUS}"", tokens.toString(g.getTokenNames()));
    // Simulate call stack after input '(x' from within rule expr
    callStackFrom_expr = new ParserRuleContext(null, 9);
    tokens = atn.getExpectedTokens(afterID, callStackFrom_expr);
    assertEquals(""{R, PLUS}"", tokens.toString(g.getTokenNames()));
}","// can't reproduce
","// DOTGenerator gen = new DOTGenerator(g);
[[SEP]]// String dot = gen.getDOT(atn.states.get(2), g.getRuleNames(), false);
[[SEP]]// System.out.println(dot);
[[SEP]]// Simulate call stack after input '(x' from rule s
[[SEP]]// Simulate call stack after input '(x' from within rule expr
","// Test for https://github.com/antlr/antlr4/issues/1480// can't reproduce[[SEP]]// DOTGenerator gen = new DOTGenerator(g);// String dot = gen.getDOT(atn.states.get(2), g.getRuleNames(), false);// System.out.println(dot);// Simulate call stack after input '(x' from rule s[[SEP]]// Simulate call stack after input '(x' from within rule expr",105,156,[0],0,"[0, 0, 0, 0, 0]",0,"[0, 0, 0]",0,0,0,0,testFollowIncludedInLeftRecursiveRule(),org.antlr.v4.test.runtime.java.api.TestExpectedTokens,testFollowIncludedInLeftRecursiveRule/0,False,105,6,4,0,4,1,6,15,0,8,0,6,0,0,0,0,0,0,31,4,10,2,0,0,0,0,40,1,0,False
42,..\projects\antlr4-4.11.0\runtime-testsuite\test\org\antlr\v4\test\runtime\java\api\TestTokenStream.java,org.antlr.v4.test.runtime.java.api.TestTokenStream,void testBufferedTokenStreamReuseAfterFill(),"/**
 * This is a targeted regression test for antlr/antlr4#1584 ({@link BufferedTokenStream} cannot be reused after EOF).
 */
@Test
public void testBufferedTokenStreamReuseAfterFill() {
    CharStream firstInput = new ANTLRInputStream(""A"");
    BufferedTokenStream tokenStream = new BufferedTokenStream(new VisitorBasicLexer(firstInput));
    tokenStream.fill();
    assertEquals(2, tokenStream.size());
    assertEquals(VisitorBasicLexer.A, tokenStream.get(0).getType());
    assertEquals(Token.EOF, tokenStream.get(1).getType());
    CharStream secondInput = new ANTLRInputStream(""AA"");
    tokenStream.setTokenSource(new VisitorBasicLexer(secondInput));
    tokenStream.fill();
    assertEquals(3, tokenStream.size());
    assertEquals(VisitorBasicLexer.A, tokenStream.get(0).getType());
    assertEquals(VisitorBasicLexer.A, tokenStream.get(1).getType());
    assertEquals(Token.EOF, tokenStream.get(2).getType());
}","/**
 * This is a targeted regression test for antlr/antlr4#1584 ({@link BufferedTokenStream} cannot be reused after EOF).
 */
", ,/** * This is a targeted regression test for antlr/antlr4#1584 ({@link BufferedTokenStream} cannot be reused after EOF). */,25,41,[0],0,[0],0,[0],0,0,0,0,testBufferedTokenStreamReuseAfterFill(),org.antlr.v4.test.runtime.java.api.TestTokenStream,testBufferedTokenStreamReuseAfterFill/0,False,26,6,7,0,7,1,6,15,0,3,0,6,0,0,0,0,0,0,2,7,3,0,0,0,0,0,35,1,0,True
43,..\projects\antlr4-4.11.0\runtime-testsuite\test\org\antlr\v4\test\runtime\java\api\TestTokenStreamRewriter.java,org.antlr.v4.test.runtime.java.api.TestTokenStreamRewriter,void testToStringStartStop(),"@Test
public void testToStringStartStop() throws Exception {
    LexerGrammar g = new LexerGrammar(""lexer grammar T;\n"" + ""ID : 'a'..'z'+;\n"" + ""INT : '0'..'9'+;\n"" + ""SEMI : ';';\n"" + ""MUL : '*';\n"" + ""ASSIGN : '=';\n"" + ""WS : ' '+;\n"");
    // Tokens: 0123456789
    // Input:  x = 3 * 0;
    String input = ""x = 3 * 0;"";
    LexerInterpreter lexEngine = g.createLexerInterpreter(new ANTLRInputStream(input));
    CommonTokenStream stream = new CommonTokenStream(lexEngine);
    stream.fill();
    TokenStreamRewriter tokens = new TokenStreamRewriter(stream);
    tokens.replace(4, 8, ""0"");
    stream.fill();
    // replace 3 * 0 with 0
    String result = tokens.getTokenStream().getText();
    String expecting = ""x = 3 * 0;"";
    assertEquals(expecting, result);
    result = tokens.getText();
    expecting = ""x = 0;"";
    assertEquals(expecting, result);
    result = tokens.getText(Interval.of(0, 9));
    expecting = ""x = 0;"";
    assertEquals(expecting, result);
    result = tokens.getText(Interval.of(4, 8));
    expecting = ""0"";
    assertEquals(expecting, result);
}", ,"// Tokens: 0123456789
[[SEP]]// replace 3 * 0 with 0
[[SEP]]// Input:  x = 3 * 0;
",// Tokens: 0123456789// Input:  x = 3 * 0;[[SEP]]// replace 3 * 0 with 0,128,163,[0],0,"[0, 0, 0]",0,"[0, 0]",0,0,0,0,testToStringStartStop(),org.antlr.v4.test.runtime.java.api.TestTokenStreamRewriter,testToStringStartStop/0,False,128,9,10,0,10,1,9,22,0,7,0,9,0,0,0,0,0,0,13,6,13,1,0,0,0,0,30,1,0,False
44,..\projects\antlr4-4.11.0\runtime-testsuite\test\org\antlr\v4\test\runtime\java\api\TestTokenStreamRewriter.java,org.antlr.v4.test.runtime.java.api.TestTokenStreamRewriter,void testToStringStartStop2(),"@Test
public void testToStringStartStop2() throws Exception {
    LexerGrammar g = new LexerGrammar(""lexer grammar T;\n"" + ""ID : 'a'..'z'+;\n"" + ""INT : '0'..'9'+;\n"" + ""SEMI : ';';\n"" + ""ASSIGN : '=';\n"" + ""PLUS : '+';\n"" + ""MULT : '*';\n"" + ""WS : ' '+;\n"");
    // Tokens: 012345678901234567
    // Input:  x = 3 * 0 + 2 * 0;
    String input = ""x = 3 * 0 + 2 * 0;"";
    LexerInterpreter lexEngine = g.createLexerInterpreter(new ANTLRInputStream(input));
    CommonTokenStream stream = new CommonTokenStream(lexEngine);
    stream.fill();
    TokenStreamRewriter tokens = new TokenStreamRewriter(stream);
    String result = tokens.getTokenStream().getText();
    String expecting = ""x = 3 * 0 + 2 * 0;"";
    assertEquals(expecting, result);
    tokens.replace(4, 8, ""0"");
    stream.fill();
    // replace 3 * 0 with 0
    result = tokens.getText();
    expecting = ""x = 0 + 2 * 0;"";
    assertEquals(expecting, result);
    result = tokens.getText(Interval.of(0, 17));
    expecting = ""x = 0 + 2 * 0;"";
    assertEquals(expecting, result);
    result = tokens.getText(Interval.of(4, 8));
    expecting = ""0"";
    assertEquals(expecting, result);
    result = tokens.getText(Interval.of(0, 8));
    expecting = ""x = 0"";
    assertEquals(expecting, result);
    result = tokens.getText(Interval.of(12, 16));
    expecting = ""2 * 0"";
    assertEquals(expecting, result);
    tokens.insertAfter(17, ""// comment"");
    result = tokens.getText(Interval.of(12, 18));
    expecting = ""2 * 0;// comment"";
    assertEquals(expecting, result);
    result = tokens.getText(Interval.of(0, 8));
    stream.fill();
    // try again after insert at end
    expecting = ""x = 0"";
    assertEquals(expecting, result);
}", ,"// Tokens: 012345678901234567
[[SEP]]// Input:  x = 3 * 0 + 2 * 0;
[[SEP]]// replace 3 * 0 with 0
[[SEP]]// try again after insert at end
","// Tokens: 012345678901234567// Input:  x = 3 * 0 + 2 * 0;[[SEP]]// replace 3 * 0 with 0[[SEP]]// comment"");[[SEP]]// comment"";[[SEP]]// try again after insert at end",165,220,[0],0,"[0, 0, 0, 0]",0,"[0, 0, 0, 0, 0]",0,0,0,0,testToStringStartStop2(),org.antlr.v4.test.runtime.java.api.TestTokenStreamRewriter,testToStringStartStop2/0,False,165,9,11,0,11,1,10,36,0,7,0,10,0,0,0,0,0,0,19,15,21,1,0,0,0,0,30,1,0,False
45,..\projects\antlr4-4.11.0\runtime-testsuite\test\org\antlr\v4\test\runtime\java\api\TestTokenStreamRewriter.java,org.antlr.v4.test.runtime.java.api.TestTokenStreamRewriter,void testInsertThenReplaceSameIndex(),"@Test
public void testInsertThenReplaceSameIndex() throws Exception {
    LexerGrammar g = new LexerGrammar(""lexer grammar T;\n"" + ""A : 'a';\n"" + ""B : 'b';\n"" + ""C : 'c';\n"");
    String input = ""abc"";
    LexerInterpreter lexEngine = g.createLexerInterpreter(new ANTLRInputStream(input));
    CommonTokenStream stream = new CommonTokenStream(lexEngine);
    stream.fill();
    TokenStreamRewriter tokens = new TokenStreamRewriter(stream);
    tokens.insertBefore(0, ""0"");
    tokens.replace(0, ""x"");
    stream.fill();
    // supercedes insert at 0
    String result = tokens.getText();
    String expecting = ""0xbc"";
    assertEquals(expecting, result);
}", ,"// supercedes insert at 0
",// supercedes insert at 0,303,321,[0],0,[0],0,[0],0,0,0,0,testInsertThenReplaceSameIndex(),org.antlr.v4.test.runtime.java.api.TestTokenStreamRewriter,testInsertThenReplaceSameIndex/0,False,303,7,7,0,7,1,6,14,0,7,0,6,0,0,0,0,0,0,8,2,7,1,0,0,0,0,31,1,0,False
46,..\projects\antlr4-4.11.0\runtime-testsuite\test\org\antlr\v4\test\runtime\java\api\TestTokenStreamRewriter.java,org.antlr.v4.test.runtime.java.api.TestTokenStreamRewriter,void testReplaceRangeThenInsertAtRightEdge(),"@Test
public void testReplaceRangeThenInsertAtRightEdge() throws Exception {
    LexerGrammar g = new LexerGrammar(""lexer grammar T;\n"" + ""A : 'a';\n"" + ""B : 'b';\n"" + ""C : 'c';\n"");
    String input = ""abcccba"";
    LexerInterpreter lexEngine = g.createLexerInterpreter(new ANTLRInputStream(input));
    CommonTokenStream stream = new CommonTokenStream(lexEngine);
    stream.fill();
    TokenStreamRewriter tokens = new TokenStreamRewriter(stream);
    tokens.replace(2, 4, ""x"");
    tokens.insertBefore(4, ""y"");
    // no effect; within range of a replace
    stream.fill();
    Exception exc = null;
    try {
        tokens.getText();
    } catch (IllegalArgumentException iae) {
        exc = iae;
    }
    String expecting = ""insert op <InsertBeforeOp@[@4,4:4='c',<3>,1:4]:\""y\""> within boundaries of previous <ReplaceOp@[@2,2:2='c',<3>,1:2]..[@4,4:4='c',<3>,1:4]:\""x\"">"";
    assertNotNull(exc);
    assertEquals(expecting, exc.getMessage());
}", ,"// no effect; within range of a replace
",// no effect; within range of a replace,432,456,[0],0,[0],0,[0],0,0,0,0,testReplaceRangeThenInsertAtRightEdge(),org.antlr.v4.test.runtime.java.api.TestTokenStreamRewriter,testReplaceRangeThenInsertAtRightEdge/0,False,432,7,7,0,7,2,8,21,0,7,0,8,0,0,0,0,1,0,8,3,8,1,1,0,0,0,44,1,0,False
47,..\projects\antlr4-4.11.0\runtime-testsuite\test\org\antlr\v4\test\runtime\java\api\TestTokenStreamRewriter.java,org.antlr.v4.test.runtime.java.api.TestTokenStreamRewriter,void testReplaceThenReplaceSuperset(),"@Test
public void testReplaceThenReplaceSuperset() throws Exception {
    LexerGrammar g = new LexerGrammar(""lexer grammar T;\n"" + ""A : 'a';\n"" + ""B : 'b';\n"" + ""C : 'c';\n"");
    String input = ""abcccba"";
    LexerInterpreter lexEngine = g.createLexerInterpreter(new ANTLRInputStream(input));
    CommonTokenStream stream = new CommonTokenStream(lexEngine);
    stream.fill();
    TokenStreamRewriter tokens = new TokenStreamRewriter(stream);
    tokens.replace(2, 4, ""xyz"");
    tokens.replace(3, 5, ""foo"");
    stream.fill();
    // overlaps, error
    Exception exc = null;
    try {
        tokens.getText();
    } catch (IllegalArgumentException iae) {
        exc = iae;
    }
    String expecting = ""replace op boundaries of <ReplaceOp@[@3,3:3='c',<3>,1:3]..[@5,5:5='b',<2>,1:5]:\""foo\""> overlap with previous <ReplaceOp@[@2,2:2='c',<3>,1:2]..[@4,4:4='c',<3>,1:4]:\""xyz\"">"";
    assertNotNull(exc);
    assertEquals(expecting, exc.getMessage());
}", ,"// overlaps, error
","// overlaps, error",510,535,[0],0,[0],0,[0],0,0,0,0,testReplaceThenReplaceSuperset(),org.antlr.v4.test.runtime.java.api.TestTokenStreamRewriter,testReplaceThenReplaceSuperset/0,False,510,7,6,0,6,2,7,21,0,7,0,7,0,0,0,0,1,0,8,4,8,1,1,0,0,0,41,1,0,False
48,..\projects\antlr4-4.11.0\runtime-testsuite\test\org\antlr\v4\test\runtime\java\api\TestTokenStreamRewriter.java,org.antlr.v4.test.runtime.java.api.TestTokenStreamRewriter,void testReplaceThenReplaceLowerIndexedSuperset(),"@Test
public void testReplaceThenReplaceLowerIndexedSuperset() throws Exception {
    LexerGrammar g = new LexerGrammar(""lexer grammar T;\n"" + ""A : 'a';\n"" + ""B : 'b';\n"" + ""C : 'c';\n"");
    String input = ""abcccba"";
    LexerInterpreter lexEngine = g.createLexerInterpreter(new ANTLRInputStream(input));
    CommonTokenStream stream = new CommonTokenStream(lexEngine);
    stream.fill();
    TokenStreamRewriter tokens = new TokenStreamRewriter(stream);
    tokens.replace(2, 4, ""xyz"");
    tokens.replace(1, 3, ""foo"");
    stream.fill();
    // overlap, error
    Exception exc = null;
    try {
        tokens.getText();
    } catch (IllegalArgumentException iae) {
        exc = iae;
    }
    String expecting = ""replace op boundaries of <ReplaceOp@[@1,1:1='b',<2>,1:1]..[@3,3:3='c',<3>,1:3]:\""foo\""> overlap with previous <ReplaceOp@[@2,2:2='c',<3>,1:2]..[@4,4:4='c',<3>,1:4]:\""xyz\"">"";
    assertNotNull(exc);
    assertEquals(expecting, exc.getMessage());
}", ,"// overlap, error
","// overlap, error",537,562,[0],0,[0],0,[0],0,0,0,0,testReplaceThenReplaceLowerIndexedSuperset(),org.antlr.v4.test.runtime.java.api.TestTokenStreamRewriter,testReplaceThenReplaceLowerIndexedSuperset/0,False,537,7,6,0,6,2,7,21,0,7,0,7,0,0,0,0,1,0,8,4,8,1,1,0,0,0,43,1,0,False
49,..\projects\antlr4-4.11.0\runtime-testsuite\test\org\antlr\v4\test\runtime\java\api\TestTokenStreamRewriter.java,org.antlr.v4.test.runtime.java.api.TestTokenStreamRewriter,void testCombineInsertOnLeftWithReplace(),"@Test
public void testCombineInsertOnLeftWithReplace() throws Exception {
    LexerGrammar g = new LexerGrammar(""lexer grammar T;\n"" + ""A : 'a';\n"" + ""B : 'b';\n"" + ""C : 'c';\n"");
    String input = ""abc"";
    LexerInterpreter lexEngine = g.createLexerInterpreter(new ANTLRInputStream(input));
    CommonTokenStream stream = new CommonTokenStream(lexEngine);
    stream.fill();
    TokenStreamRewriter tokens = new TokenStreamRewriter(stream);
    tokens.replace(0, 2, ""foo"");
    tokens.insertBefore(0, ""z"");
    stream.fill();
    // combine with left edge of rewrite
    String result = tokens.getText();
    String expecting = ""zfoo"";
    assertEquals(expecting, result);
}", ,"// combine with left edge of rewrite
",// combine with left edge of rewrite,619,637,[0],0,[0],0,[0],0,0,0,0,testCombineInsertOnLeftWithReplace(),org.antlr.v4.test.runtime.java.api.TestTokenStreamRewriter,testCombineInsertOnLeftWithReplace/0,False,619,7,7,0,7,1,6,14,0,7,0,6,0,0,0,0,0,0,8,3,7,1,0,0,0,0,32,1,0,False
50,..\projects\antlr4-4.11.0\runtime-testsuite\test\org\antlr\v4\test\runtime\java\api\TestTokenStreamRewriter.java,org.antlr.v4.test.runtime.java.api.TestTokenStreamRewriter,void testCombineInsertOnLeftWithDelete(),"@Test
public void testCombineInsertOnLeftWithDelete() throws Exception {
    LexerGrammar g = new LexerGrammar(""lexer grammar T;\n"" + ""A : 'a';\n"" + ""B : 'b';\n"" + ""C : 'c';\n"");
    String input = ""abc"";
    LexerInterpreter lexEngine = g.createLexerInterpreter(new ANTLRInputStream(input));
    CommonTokenStream stream = new CommonTokenStream(lexEngine);
    stream.fill();
    TokenStreamRewriter tokens = new TokenStreamRewriter(stream);
    tokens.delete(0, 2);
    tokens.insertBefore(0, ""z"");
    stream.fill();
    // combine with left edge of rewrite
    String result = tokens.getText();
    String expecting = ""z"";
    stream.fill();
    // make sure combo is not znull
    assertEquals(expecting, result);
}", ,"// combine with left edge of rewrite
[[SEP]]// make sure combo is not znull
",// combine with left edge of rewrite[[SEP]]// make sure combo is not znull,639,659,[0],0,"[0, 0]",0,"[0, 0]",0,0,0,0,testCombineInsertOnLeftWithDelete(),org.antlr.v4.test.runtime.java.api.TestTokenStreamRewriter,testCombineInsertOnLeftWithDelete/0,False,639,7,7,0,7,1,6,15,0,7,0,6,0,0,0,0,0,0,7,3,7,1,0,0,0,0,32,1,0,False
51,..\projects\antlr4-4.11.0\runtime-testsuite\test\org\antlr\v4\test\runtime\java\api\TestTokenStreamRewriter.java,org.antlr.v4.test.runtime.java.api.TestTokenStreamRewriter,void testOverlappingReplace(),"@Test
public void testOverlappingReplace() throws Exception {
    LexerGrammar g = new LexerGrammar(""lexer grammar T;\n"" + ""A : 'a';\n"" + ""B : 'b';\n"" + ""C : 'c';\n"");
    String input = ""abcc"";
    LexerInterpreter lexEngine = g.createLexerInterpreter(new ANTLRInputStream(input));
    CommonTokenStream stream = new CommonTokenStream(lexEngine);
    stream.fill();
    TokenStreamRewriter tokens = new TokenStreamRewriter(stream);
    tokens.replace(1, 2, ""foo"");
    tokens.replace(0, 3, ""bar"");
    stream.fill();
    // wipes prior nested replace
    String result = tokens.getText();
    String expecting = ""bar"";
    assertEquals(expecting, result);
}", ,"// wipes prior nested replace
",// wipes prior nested replace,680,698,[0],0,[0],0,[0],0,0,0,0,testOverlappingReplace(),org.antlr.v4.test.runtime.java.api.TestTokenStreamRewriter,testOverlappingReplace/0,False,680,7,6,0,6,1,5,14,0,7,0,5,0,0,0,0,0,0,8,4,7,1,0,0,0,0,28,1,0,False
52,..\projects\antlr4-4.11.0\runtime-testsuite\test\org\antlr\v4\test\runtime\java\api\TestTokenStreamRewriter.java,org.antlr.v4.test.runtime.java.api.TestTokenStreamRewriter,void testOverlappingReplace2(),"@Test
public void testOverlappingReplace2() throws Exception {
    LexerGrammar g = new LexerGrammar(""lexer grammar T;\n"" + ""A : 'a';\n"" + ""B : 'b';\n"" + ""C : 'c';\n"");
    String input = ""abcc"";
    LexerInterpreter lexEngine = g.createLexerInterpreter(new ANTLRInputStream(input));
    CommonTokenStream stream = new CommonTokenStream(lexEngine);
    stream.fill();
    TokenStreamRewriter tokens = new TokenStreamRewriter(stream);
    tokens.replace(0, 3, ""bar"");
    tokens.replace(1, 2, ""foo"");
    stream.fill();
    // cannot split earlier replace
    Exception exc = null;
    try {
        tokens.getText();
    } catch (IllegalArgumentException iae) {
        exc = iae;
    }
    String expecting = ""replace op boundaries of <ReplaceOp@[@1,1:1='b',<2>,1:1]..[@2,2:2='c',<3>,1:2]:\""foo\""> overlap with previous <ReplaceOp@[@0,0:0='a',<1>,1:0]..[@3,3:3='c',<3>,1:3]:\""bar\"">"";
    assertNotNull(exc);
    assertEquals(expecting, exc.getMessage());
}", ,"// cannot split earlier replace
",// cannot split earlier replace,700,725,[0],0,[0],0,[0],0,0,0,0,testOverlappingReplace2(),org.antlr.v4.test.runtime.java.api.TestTokenStreamRewriter,testOverlappingReplace2/0,False,700,7,6,0,6,2,7,21,0,7,0,7,0,0,0,0,1,0,8,4,8,1,1,0,0,0,40,1,0,False
53,..\projects\antlr4-4.11.0\runtime-testsuite\test\org\antlr\v4\test\runtime\java\api\TestTokenStreamRewriter.java,org.antlr.v4.test.runtime.java.api.TestTokenStreamRewriter,void testOverlappingReplace3(),"@Test
public void testOverlappingReplace3() throws Exception {
    LexerGrammar g = new LexerGrammar(""lexer grammar T;\n"" + ""A : 'a';\n"" + ""B : 'b';\n"" + ""C : 'c';\n"");
    String input = ""abcc"";
    LexerInterpreter lexEngine = g.createLexerInterpreter(new ANTLRInputStream(input));
    CommonTokenStream stream = new CommonTokenStream(lexEngine);
    stream.fill();
    TokenStreamRewriter tokens = new TokenStreamRewriter(stream);
    tokens.replace(1, 2, ""foo"");
    tokens.replace(0, 2, ""bar"");
    stream.fill();
    // wipes prior nested replace
    String result = tokens.getText();
    String expecting = ""barc"";
    assertEquals(expecting, result);
}", ,"// wipes prior nested replace
",// wipes prior nested replace,727,745,[0],0,[0],0,[0],0,0,0,0,testOverlappingReplace3(),org.antlr.v4.test.runtime.java.api.TestTokenStreamRewriter,testOverlappingReplace3/0,False,727,7,6,0,6,1,5,14,0,7,0,5,0,0,0,0,0,0,8,4,7,1,0,0,0,0,28,1,0,False
54,..\projects\antlr4-4.11.0\runtime-testsuite\test\org\antlr\v4\test\runtime\java\api\TestTokenStreamRewriter.java,org.antlr.v4.test.runtime.java.api.TestTokenStreamRewriter,void testOverlappingReplace4(),"@Test
public void testOverlappingReplace4() throws Exception {
    LexerGrammar g = new LexerGrammar(""lexer grammar T;\n"" + ""A : 'a';\n"" + ""B : 'b';\n"" + ""C : 'c';\n"");
    String input = ""abcc"";
    LexerInterpreter lexEngine = g.createLexerInterpreter(new ANTLRInputStream(input));
    CommonTokenStream stream = new CommonTokenStream(lexEngine);
    stream.fill();
    TokenStreamRewriter tokens = new TokenStreamRewriter(stream);
    tokens.replace(1, 2, ""foo"");
    tokens.replace(1, 3, ""bar"");
    stream.fill();
    // wipes prior nested replace
    String result = tokens.getText();
    String expecting = ""abar"";
    assertEquals(expecting, result);
}", ,"// wipes prior nested replace
",// wipes prior nested replace,747,765,[0],0,[0],0,[0],0,0,0,0,testOverlappingReplace4(),org.antlr.v4.test.runtime.java.api.TestTokenStreamRewriter,testOverlappingReplace4/0,False,747,7,6,0,6,1,5,14,0,7,0,5,0,0,0,0,0,0,8,4,7,1,0,0,0,0,28,1,0,False
55,..\projects\antlr4-4.11.0\runtime-testsuite\test\org\antlr\v4\test\runtime\java\api\TestTokenStreamRewriter.java,org.antlr.v4.test.runtime.java.api.TestTokenStreamRewriter,void testDropIdenticalReplace(),"@Test
public void testDropIdenticalReplace() throws Exception {
    LexerGrammar g = new LexerGrammar(""lexer grammar T;\n"" + ""A : 'a';\n"" + ""B : 'b';\n"" + ""C : 'c';\n"");
    String input = ""abcc"";
    LexerInterpreter lexEngine = g.createLexerInterpreter(new ANTLRInputStream(input));
    CommonTokenStream stream = new CommonTokenStream(lexEngine);
    stream.fill();
    TokenStreamRewriter tokens = new TokenStreamRewriter(stream);
    tokens.replace(1, 2, ""foo"");
    tokens.replace(1, 2, ""foo"");
    stream.fill();
    // drop previous, identical
    String result = tokens.getText();
    String expecting = ""afooc"";
    assertEquals(expecting, result);
}", ,"// drop previous, identical
","// drop previous, identical",767,785,[0],0,[0],0,[0],0,0,0,0,testDropIdenticalReplace(),org.antlr.v4.test.runtime.java.api.TestTokenStreamRewriter,testDropIdenticalReplace/0,False,767,7,6,0,6,1,5,14,0,7,0,5,0,0,0,0,0,0,8,4,7,1,0,0,0,0,29,1,0,False
56,..\projects\antlr4-4.11.0\runtime-testsuite\test\org\antlr\v4\test\runtime\java\api\TestTokenStreamRewriter.java,org.antlr.v4.test.runtime.java.api.TestTokenStreamRewriter,void testDropPrevCoveredInsert(),"@Test
public void testDropPrevCoveredInsert() throws Exception {
    LexerGrammar g = new LexerGrammar(""lexer grammar T;\n"" + ""A : 'a';\n"" + ""B : 'b';\n"" + ""C : 'c';\n"");
    String input = ""abc"";
    LexerInterpreter lexEngine = g.createLexerInterpreter(new ANTLRInputStream(input));
    CommonTokenStream stream = new CommonTokenStream(lexEngine);
    stream.fill();
    TokenStreamRewriter tokens = new TokenStreamRewriter(stream);
    tokens.insertBefore(1, ""foo"");
    tokens.replace(1, 2, ""foo"");
    stream.fill();
    // kill prev insert
    String result = tokens.getText();
    String expecting = ""afoofoo"";
    assertEquals(expecting, result);
}", ,"// kill prev insert
",// kill prev insert,787,805,[0],0,[0],0,[0],0,0,0,0,testDropPrevCoveredInsert(),org.antlr.v4.test.runtime.java.api.TestTokenStreamRewriter,testDropPrevCoveredInsert/0,False,787,7,7,0,7,1,6,14,0,7,0,6,0,0,0,0,0,0,8,3,7,1,0,0,0,0,30,1,0,False
57,..\projects\antlr4-4.11.0\runtime-testsuite\test\org\antlr\v4\test\runtime\java\api\TestTokenStreamRewriter.java,org.antlr.v4.test.runtime.java.api.TestTokenStreamRewriter,void testDistinguishBetweenInsertAfterAndInsertBeforeToPreserverOrder(),"// Test Fix for https://github.com/antlr/antlr4/issues/550
@Test
public void testDistinguishBetweenInsertAfterAndInsertBeforeToPreserverOrder() throws Exception {
    LexerGrammar g = new LexerGrammar(""lexer grammar T;\n"" + ""A : 'a';\n"" + ""B : 'b';\n"" + ""C : 'c';\n"");
    String input = ""aa"";
    LexerInterpreter lexEngine = g.createLexerInterpreter(new ANTLRInputStream(input));
    CommonTokenStream stream = new CommonTokenStream(lexEngine);
    stream.fill();
    TokenStreamRewriter tokens = new TokenStreamRewriter(stream);
    tokens.insertBefore(0, ""<b>"");
    tokens.insertAfter(0, ""</b>"");
    tokens.insertBefore(1, ""<b>"");
    tokens.insertAfter(1, ""</b>"");
    String result = tokens.getText();
    // fails with <b>a<b></b>a</b>""
    String expecting = ""<b>a</b><b>a</b>"";
    assertEquals(expecting, result);
}","// Test Fix for https://github.com/antlr/antlr4/issues/550
","// fails with <b>a<b></b>a</b>""
","// Test Fix for https://github.com/antlr/antlr4/issues/550[[SEP]]// fails with <b>a<b></b>a</b>""",862,881,[0],0,[0],0,"[0, 0]",0,0,0,0,testDistinguishBetweenInsertAfterAndInsertBeforeToPreserverOrder(),org.antlr.v4.test.runtime.java.api.TestTokenStreamRewriter,testDistinguishBetweenInsertAfterAndInsertBeforeToPreserverOrder/0,False,863,7,7,0,7,1,6,15,0,7,0,6,0,0,0,0,0,0,10,4,7,1,0,0,0,0,36,1,0,False
58,..\projects\antlr4-4.11.0\runtime-testsuite\test\org\antlr\v4\test\runtime\java\api\TestTokenStreamRewriter.java,org.antlr.v4.test.runtime.java.api.TestTokenStreamRewriter,void testPreservesOrderOfContiguousInserts(),"// Test Fix for https://github.com/antlr/antlr4/issues/550
@Test
public void testPreservesOrderOfContiguousInserts() throws Exception {
    LexerGrammar g = new LexerGrammar(""lexer grammar T;\n"" + ""A : 'a';\n"" + ""B : 'b';\n"" + ""C : 'c';\n"");
    String input = ""ab"";
    LexerInterpreter lexEngine = g.createLexerInterpreter(new ANTLRInputStream(input));
    CommonTokenStream stream = new CommonTokenStream(lexEngine);
    stream.fill();
    TokenStreamRewriter tokens = new TokenStreamRewriter(stream);
    tokens.insertBefore(0, ""<p>"");
    tokens.insertBefore(0, ""<b>"");
    tokens.insertBefore(0, ""<div>"");
    tokens.insertAfter(0, ""</p>"");
    tokens.insertAfter(0, ""</b>"");
    tokens.insertAfter(0, ""</div>"");
    tokens.insertBefore(1, ""!"");
    String result = tokens.getText();
    String expecting = ""<div><b><p>a</p></b></div>!b"";
    assertEquals(expecting, result);
}","// Test Fix for https://github.com/antlr/antlr4/issues/550
", ,// Test Fix for https://github.com/antlr/antlr4/issues/550,907,929,[0],0,[0],0,[0],0,0,0,0,testPreservesOrderOfContiguousInserts(),org.antlr.v4.test.runtime.java.api.TestTokenStreamRewriter,testPreservesOrderOfContiguousInserts/0,False,908,7,7,0,7,1,6,18,0,7,0,6,0,0,0,0,0,0,13,7,7,1,0,0,0,0,34,1,0,False
59,..\projects\antlr4-4.11.0\runtime-testsuite\test\org\antlr\v4\test\runtime\java\api\TestVisitors.java,org.antlr.v4.test.runtime.java.api.TestVisitors,void testVisitTerminalNode(),"/**
 * This test verifies the basic behavior of visitors, with an emphasis on
 * {@link AbstractParseTreeVisitor#visitTerminal}.
 */
@Test
public void testVisitTerminalNode() {
    String input = ""A"";
    VisitorBasicLexer lexer = new VisitorBasicLexer(new ANTLRInputStream(input));
    VisitorBasicParser parser = new VisitorBasicParser(new CommonTokenStream(lexer));
    VisitorBasicParser.SContext context = parser.s();
    assertEquals(""(s A <EOF>)"", context.toStringTree(parser));
    VisitorBasicVisitor<String> listener = new VisitorBasicBaseVisitor<String>() {

        @Override
        public String visitTerminal(TerminalNode node) {
            return node.getSymbol().toString() + ""\n"";
        }

        @Override
        protected String defaultResult() {
            return """";
        }

        @Override
        protected String aggregateResult(String aggregate, String nextResult) {
            return aggregate + nextResult;
        }
    };
    String result = listener.visit(context);
    String expected = ""[@0,0:0='A',<1>,1:0]\n"" + ""[@1,1:0='<EOF>',<-1>,1:1]\n"";
    assertEquals(expected, result);
}","/**
 * This test verifies the basic behavior of visitors, with an emphasis on
 * {@link AbstractParseTreeVisitor#visitTerminal}.
 */
", ,"/** * This test verifies the basic behavior of visitors, with an emphasis on * {@link AbstractParseTreeVisitor#visitTerminal}. */",30,61,[0],0,[0],0,[0],0,0,0,0,testVisitTerminalNode(),org.antlr.v4.test.runtime.java.api.TestVisitors,testVisitTerminalNode/0,False,31,7,2,0,2,1,4,22,0,7,0,4,0,0,0,0,0,0,4,0,7,1,0,1,0,0,43,1,0,True
60,..\projects\antlr4-4.11.0\runtime-testsuite\test\org\antlr\v4\test\runtime\java\api\TestVisitors.java,org.antlr.v4.test.runtime.java.api.TestVisitors,void testVisitErrorNode(),"/**
 * This test verifies the basic behavior of visitors, with an emphasis on
 * {@link AbstractParseTreeVisitor#visitErrorNode}.
 */
@Test
public void testVisitErrorNode() {
    String input = """";
    VisitorBasicLexer lexer = new VisitorBasicLexer(new ANTLRInputStream(input));
    VisitorBasicParser parser = new VisitorBasicParser(new CommonTokenStream(lexer));
    final List<String> errors = new ArrayList<>();
    parser.removeErrorListeners();
    parser.addErrorListener(new BaseErrorListener() {

        @Override
        public void syntaxError(Recognizer<?, ?> recognizer, Object offendingSymbol, int line, int charPositionInLine, String msg, RecognitionException e) {
            errors.add(""line "" + line + "":"" + charPositionInLine + "" "" + msg);
        }
    });
    VisitorBasicParser.SContext context = parser.s();
    assertEquals(""(s <missing 'A'> <EOF>)"", context.toStringTree(parser));
    assertEquals(1, errors.size());
    assertEquals(""line 1:0 missing 'A' at '<EOF>'"", errors.get(0));
    VisitorBasicVisitor<String> listener = new VisitorBasicBaseVisitor<String>() {

        @Override
        public String visitErrorNode(ErrorNode node) {
            return ""Error encountered: "" + node.getSymbol();
        }

        @Override
        protected String defaultResult() {
            return """";
        }

        @Override
        protected String aggregateResult(String aggregate, String nextResult) {
            return aggregate + nextResult;
        }
    };
    String result = listener.visit(context);
    String expected = ""Error encountered: [@-1,-1:-1='<missing 'A'>',<1>,1:0]"";
    assertEquals(expected, result);
}","/**
 * This test verifies the basic behavior of visitors, with an emphasis on
 * {@link AbstractParseTreeVisitor#visitErrorNode}.
 */
", ,"/** * This test verifies the basic behavior of visitors, with an emphasis on * {@link AbstractParseTreeVisitor#visitErrorNode}. */",67,107,[0],0,[0],0,[0],0,0,0,0,testVisitErrorNode(),org.antlr.v4.test.runtime.java.api.TestVisitors,testVisitErrorNode/0,False,68,8,3,0,3,1,8,32,0,8,0,8,0,0,0,0,0,0,4,2,8,0,0,2,0,0,59,1,0,True
61,..\projects\antlr4-4.11.0\runtime-testsuite\test\org\antlr\v4\test\runtime\java\api\TestVisitors.java,org.antlr.v4.test.runtime.java.api.TestVisitors,void testShouldNotVisitEOF(),"/**
 * This test verifies that {@link AbstractParseTreeVisitor#visitChildren} does not call
 * {@link org.antlr.v4.runtime.tree.ParseTreeVisitor#visit} after
 * {@link org.antlr.v4.runtime.tree.AbstractParseTreeVisitor#shouldVisitNextChild} returns
 * {@code false}.
 */
@Test
public void testShouldNotVisitEOF() {
    String input = ""A"";
    VisitorBasicLexer lexer = new VisitorBasicLexer(new ANTLRInputStream(input));
    VisitorBasicParser parser = new VisitorBasicParser(new CommonTokenStream(lexer));
    VisitorBasicParser.SContext context = parser.s();
    assertEquals(""(s A <EOF>)"", context.toStringTree(parser));
    VisitorBasicVisitor<String> listener = new VisitorBasicBaseVisitor<String>() {

        @Override
        public String visitTerminal(TerminalNode node) {
            return node.getSymbol().toString() + ""\n"";
        }

        @Override
        protected boolean shouldVisitNextChild(RuleNode node, String currentResult) {
            return currentResult == null || currentResult.isEmpty();
        }
    };
    String result = listener.visit(context);
    String expected = ""[@0,0:0='A',<1>,1:0]\n"";
    assertEquals(expected, result);
}","/**
 * This test verifies that {@link AbstractParseTreeVisitor#visitChildren} does not call
 * {@link org.antlr.v4.runtime.tree.ParseTreeVisitor#visit} after
 * {@link org.antlr.v4.runtime.tree.AbstractParseTreeVisitor#shouldVisitNextChild} returns
 * {@code false}.
 */
", ,/** * This test verifies that {@link AbstractParseTreeVisitor#visitChildren} does not call * {@link org.antlr.v4.runtime.tree.ParseTreeVisitor#visit} after * {@link org.antlr.v4.runtime.tree.AbstractParseTreeVisitor#shouldVisitNextChild} returns * {@code false}. */,115,139,[0],0,[0],0,[0],0,0,0,0,testShouldNotVisitEOF(),org.antlr.v4.test.runtime.java.api.TestVisitors,testShouldNotVisitEOF/0,False,116,7,2,0,2,1,4,19,0,7,0,4,0,0,0,0,0,0,3,0,7,0,0,1,0,0,50,1,0,True
62,..\projects\antlr4-4.11.0\runtime-testsuite\test\org\antlr\v4\test\runtime\java\api\TestVisitors.java,org.antlr.v4.test.runtime.java.api.TestVisitors,void testShouldNotVisitTerminal(),"/**
 * This test verifies that {@link AbstractParseTreeVisitor#shouldVisitNextChild} is called before visiting the first
 * child. It also verifies that {@link AbstractParseTreeVisitor#defaultResult} provides the default return value for
 * visiting a tree.
 */
@Test
public void testShouldNotVisitTerminal() {
    String input = ""A"";
    VisitorBasicLexer lexer = new VisitorBasicLexer(new ANTLRInputStream(input));
    VisitorBasicParser parser = new VisitorBasicParser(new CommonTokenStream(lexer));
    VisitorBasicParser.SContext context = parser.s();
    assertEquals(""(s A <EOF>)"", context.toStringTree(parser));
    VisitorBasicVisitor<String> listener = new VisitorBasicBaseVisitor<String>() {

        @Override
        public String visitTerminal(TerminalNode node) {
            throw new RuntimeException(""Should not be reachable"");
        }

        @Override
        protected String defaultResult() {
            return ""default result"";
        }

        @Override
        protected boolean shouldVisitNextChild(RuleNode node, String currentResult) {
            return false;
        }
    };
    String result = listener.visit(context);
    String expected = ""default result"";
    assertEquals(expected, result);
}","/**
 * This test verifies that {@link AbstractParseTreeVisitor#shouldVisitNextChild} is called before visiting the first
 * child. It also verifies that {@link AbstractParseTreeVisitor#defaultResult} provides the default return value for
 * visiting a tree.
 */
", ,/** * This test verifies that {@link AbstractParseTreeVisitor#shouldVisitNextChild} is called before visiting the first * child. It also verifies that {@link AbstractParseTreeVisitor#defaultResult} provides the default return value for * visiting a tree. */,146,175,[0],0,[0],0,[0],0,0,0,0,testShouldNotVisitTerminal(),org.antlr.v4.test.runtime.java.api.TestVisitors,testShouldNotVisitTerminal/0,False,147,7,2,0,2,1,4,22,0,7,0,4,0,0,0,0,0,0,3,0,7,0,0,1,0,0,57,1,0,True
63,..\projects\antlr4-4.11.0\runtime-testsuite\test\org\antlr\v4\test\runtime\java\api\TestVisitors.java,org.antlr.v4.test.runtime.java.api.TestVisitors,void testCalculatorVisitor(),"/**
 * This test verifies that the visitor correctly dispatches calls for labeled outer alternatives.
 */
@Test
public void testCalculatorVisitor() {
    String input = ""2 + 8 / 2"";
    VisitorCalcLexer lexer = new VisitorCalcLexer(new ANTLRInputStream(input));
    VisitorCalcParser parser = new VisitorCalcParser(new CommonTokenStream(lexer));
    VisitorCalcParser.SContext context = parser.s();
    assertEquals(""(s (expr (expr 2) + (expr (expr 8) / (expr 2))) <EOF>)"", context.toStringTree(parser));
    VisitorCalcVisitor<Integer> listener = new VisitorCalcBaseVisitor<Integer>() {

        @Override
        public Integer visitS(VisitorCalcParser.SContext ctx) {
            return visit(ctx.expr());
        }

        @Override
        public Integer visitNumber(VisitorCalcParser.NumberContext ctx) {
            return Integer.valueOf(ctx.INT().getText());
        }

        @Override
        public Integer visitMultiply(VisitorCalcParser.MultiplyContext ctx) {
            Integer left = visit(ctx.expr(0));
            Integer right = visit(ctx.expr(1));
            if (ctx.MUL() != null) {
                return left * right;
            } else {
                return left / right;
            }
        }

        @Override
        public Integer visitAdd(VisitorCalcParser.AddContext ctx) {
            Integer left = visit(ctx.expr(0));
            Integer right = visit(ctx.expr(1));
            if (ctx.ADD() != null) {
                return left + right;
            } else {
                return left - right;
            }
        }

        @Override
        protected Integer defaultResult() {
            throw new RuntimeException(""Should not be reachable"");
        }

        @Override
        protected Integer aggregateResult(Integer aggregate, Integer nextResult) {
            throw new RuntimeException(""Should not be reachable"");
        }
    };
    int result = listener.visit(context);
    int expected = 6;
    assertEquals(expected, result);
}","/**
 * This test verifies that the visitor correctly dispatches calls for labeled outer alternatives.
 */
", ,/** * This test verifies that the visitor correctly dispatches calls for labeled outer alternatives. */,180,238,[0],0,[0],0,[0],0,0,0,0,testCalculatorVisitor(),org.antlr.v4.test.runtime.java.api.TestVisitors,testCalculatorVisitor/0,False,181,7,2,0,2,1,4,45,0,7,0,4,0,0,0,0,0,0,2,1,7,0,0,1,0,0,54,1,0,True
64,..\projects\antlr4-4.11.0\runtime-testsuite\test\org\antlr\v4\test\runtime\java\api\perf\TimeLexerSpeed.java,org.antlr.v4.test.runtime.java.api.perf.TimeLexerSpeed,void main(String[]),"public static void main(String[] args) throws Exception {
    RuntimeMXBean runtimeMxBean = ManagementFactory.getRuntimeMXBean();
    List<String> vmArgs = runtimeMxBean.getInputArguments();
    System.out.print(""Java VM args: "");
    for (String vmArg : vmArgs) {
        if (!vmArg.startsWith(""-D"")) {
            System.out.print(vmArg + "" "");
        }
    }
    System.out.println();
    // System.out.println(VM.current().details());
    TimeLexerSpeed tests = new TimeLexerSpeed();
    tests.compilerWarmUp(100);
    int n = 3500;
    tests.load_legacy_java_ascii_file(Parser_java_file, n);
    tests.load_legacy_java_ascii_file(RuleContext_java_file, n);
    tests.load_legacy_java_ascii(Parser_java_file, n);
    tests.load_legacy_java_ascii(RuleContext_java_file, n);
    tests.load_legacy_java_utf8(Parser_java_file, n);
    tests.load_legacy_java_utf8(PerfDir + ""/udhr_hin.txt"", n);
    tests.load_new_utf8(Parser_java_file, n);
    tests.load_new_utf8(RuleContext_java_file, n);
    tests.load_new_utf8(PerfDir + ""/udhr_hin.txt"", n);
    System.out.println();
    n = 2000;
    tests.lex_legacy_java_utf8(n, false);
    tests.lex_legacy_java_utf8(n, true);
    tests.lex_new_java_utf8(n, false);
    tests.lex_new_java_utf8(n, true);
    System.out.println();
    n = 400;
    tests.lex_legacy_grapheme_utf8(""udhr_kor.txt"", n, false);
    tests.lex_legacy_grapheme_utf8(""udhr_kor.txt"", n, true);
    tests.lex_legacy_grapheme_utf8(""udhr_hin.txt"", n, false);
    tests.lex_legacy_grapheme_utf8(""udhr_hin.txt"", n, true);
    // legacy can't handle the emoji (32 bit stuff)
    tests.lex_new_grapheme_utf8(""udhr_kor.txt"", n, false);
    tests.lex_new_grapheme_utf8(""udhr_kor.txt"", n, true);
    tests.lex_new_grapheme_utf8(""udhr_hin.txt"", n, false);
    tests.lex_new_grapheme_utf8(""udhr_hin.txt"", n, true);
    tests.lex_new_grapheme_utf8(""emoji.txt"", n, false);
    tests.lex_new_grapheme_utf8(""emoji.txt"", n, true);
    for (String streamFootprint : tests.streamFootprints) {
        System.out.print(streamFootprint);
    }
}", ,"// System.out.println(VM.current().details());
[[SEP]]// legacy can't handle the emoji (32 bit stuff)
",// System.out.println(VM.current().details());[[SEP]]// legacy can't handle the emoji (32 bit stuff),177,229,[0],0,"[0, 0]",0,"[0, 0]",0,0,0,0,main(String[]),org.antlr.v4.test.runtime.java.api.perf.TimeLexerSpeed,main/1[java.lang.String[]],False,177,1,10,0,10,4,14,44,0,4,1,14,9,9,2,0,0,0,15,4,6,3,2,0,0,0,22,9,0,False
65,..\projects\antlr4-4.11.0\runtime-testsuite\test\org\antlr\v4\test\runtime\java\api\perf\TimeLexerSpeed.java,org.antlr.v4.test.runtime.java.api.perf.TimeLexerSpeed,"void load_legacy_java_ascii_file(String, int)","public void load_legacy_java_ascii_file(String resourceName, int n) throws Exception {
    URL sampleJavaFile = TimeLexerSpeed.class.getClassLoader().getResource(resourceName);
    if (sampleJavaFile == null) {
        System.err.println(""Can't run load_legacy_java_ascii_file from jar (or can't find "" + resourceName + "")"");
        // cannot find resource
        return;
    }
    if (!new File(sampleJavaFile.getFile()).exists()) {
        System.err.println(""Can't run load_legacy_java_ascii_file from jar (or can't find "" + resourceName + "")"");
        return;
    }
    long start = System.nanoTime();
    // keep refs around so we can average memory
    CharStream[] input = new CharStream[n];
    for (int i = 0; i < n; i++) {
        input[i] = new ANTLRFileStream(sampleJavaFile.getFile());
    }
    long stop = System.nanoTime();
    long tus = (stop - start) / 1000;
    int size = input[0].size();
    String currentMethodName = new Exception().getStackTrace()[0].getMethodName();
    GraphLayout olayout = GraphLayout.parseInstance((Object) input[0]);
    long streamSize = olayout.totalSize();
    streamFootprints.add(basename(resourceName) + "" ("" + size + "" char): "" + olayout.toFootprint());
    if (output)
        System.out.printf(""%27s average time %5dus size %6db over %4d loads of %5d symbols from %s\n"", currentMethodName, tus / n, streamSize, n, size, basename(resourceName));
}", ,"// cannot find resource
[[SEP]]// keep refs around so we can average memory
",// cannot find resource[[SEP]]// keep refs around so we can average memory,246,275,[0],0,"[0, 0]",0,"[0, 0]",0,0,1,0,"load_legacy_java_ascii_file(String, int)",org.antlr.v4.test.runtime.java.api.perf.TimeLexerSpeed,"load_legacy_java_ascii_file/2[java.lang.String,int]",False,246,5,4,1,3,5,15,24,2,10,2,15,1,2,1,1,0,1,7,5,11,6,1,0,0,0,47,1,0,False
66,..\projects\antlr4-4.11.0\runtime-testsuite\test\org\antlr\v4\test\runtime\java\api\perf\TimeLexerSpeed.java,org.antlr.v4.test.runtime.java.api.perf.TimeLexerSpeed,"void load_legacy_java_ascii(String, int)","public void load_legacy_java_ascii(String resourceName, int n) throws Exception {
    // keep refs around so we can average memory
    CharStream[] input = new CharStream[n];
    ClassLoader loader = TimeLexerSpeed.class.getClassLoader();
    InputStream[] streams = new InputStream[n];
    for (int i = 0; i < n; i++) {
        streams[i] = loader.getResourceAsStream(resourceName);
    }
    // track only time to suck data out of stream
    long start = System.nanoTime();
    for (int i = 0; i < n; i++) {
        try (InputStream is = streams[i]) {
            input[i] = new ANTLRInputStream(is);
        }
    }
    long stop = System.nanoTime();
    long tus = (stop - start) / 1000;
    int size = input[0].size();
    long streamSize = GraphLayout.parseInstance((Object) input[0]).totalSize();
    streamFootprints.add(basename(resourceName) + "" ("" + size + "" char): "" + GraphLayout.parseInstance((Object) input[0]).toFootprint());
    String currentMethodName = new Exception().getStackTrace()[0].getMethodName();
    if (output)
        System.out.printf(""%27s average time %5dus size %6db over %4d loads of %5d symbols from %s\n"", currentMethodName, tus / n, streamSize, n, size, basename(resourceName));
}", ,"// keep refs around so we can average memory
[[SEP]]// track only time to suck data out of stream
",// keep refs around so we can average memory[[SEP]]// track only time to suck data out of stream,277,303,[0],0,"[0, 0]",0,"[0, 0]",0,0,1,0,"load_legacy_java_ascii(String, int)",org.antlr.v4.test.runtime.java.api.perf.TimeLexerSpeed,"load_legacy_java_ascii/2[java.lang.String,int]",False,277,4,4,1,3,4,12,21,0,12,2,12,1,2,2,0,1,1,3,7,14,4,2,0,0,0,40,1,0,False
67,..\projects\antlr4-4.11.0\runtime-testsuite\test\org\antlr\v4\test\runtime\java\api\perf\TimeLexerSpeed.java,org.antlr.v4.test.runtime.java.api.perf.TimeLexerSpeed,"void load_legacy_java_utf8(String, int)","public void load_legacy_java_utf8(String resourceName, int n) throws Exception {
    // keep refs around so we can average memory
    CharStream[] input = new CharStream[n];
    ClassLoader loader = TimeLexerSpeed.class.getClassLoader();
    InputStream[] streams = new InputStream[n];
    for (int i = 0; i < n; i++) {
        streams[i] = loader.getResourceAsStream(resourceName);
    }
    // track only time to suck data out of stream
    long start = System.nanoTime();
    for (int i = 0; i < n; i++) {
        try (InputStream is = streams[i];
            InputStreamReader isr = new InputStreamReader(is, StandardCharsets.UTF_8);
            BufferedReader br = new BufferedReader(isr)) {
            input[i] = new ANTLRInputStream(br);
        }
    }
    long stop = System.nanoTime();
    long tus = (stop - start) / 1000;
    int size = input[0].size();
    long streamSize = GraphLayout.parseInstance((Object) input[0]).totalSize();
    streamFootprints.add(basename(resourceName) + "" ("" + size + "" char): "" + GraphLayout.parseInstance((Object) input[0]).toFootprint());
    String currentMethodName = new Exception().getStackTrace()[0].getMethodName();
    if (output)
        System.out.printf(""%27s average time %5dus size %6db over %4d loads of %5d symbols from %s\n"", currentMethodName, tus / n, streamSize, n, size, basename(resourceName));
}", ,"// keep refs around so we can average memory
[[SEP]]// track only time to suck data out of stream
",// keep refs around so we can average memory[[SEP]]// track only time to suck data out of stream,305,333,[0],0,"[0, 0]",0,"[0, 0]",0,0,1,0,"load_legacy_java_utf8(String, int)",org.antlr.v4.test.runtime.java.api.perf.TimeLexerSpeed,"load_legacy_java_utf8/2[java.lang.String,int]",False,305,4,4,1,3,4,12,21,0,14,2,12,1,2,2,0,1,1,3,7,16,4,2,0,0,0,44,1,0,False
68,..\projects\antlr4-4.11.0\runtime-testsuite\test\org\antlr\v4\test\runtime\java\api\perf\TimeLexerSpeed.java,org.antlr.v4.test.runtime.java.api.perf.TimeLexerSpeed,"void load_new_utf8(String, int)","public void load_new_utf8(String resourceName, int n) throws Exception {
    // keep refs around so we can average memory
    CharStream[] input = new CharStream[n];
    ClassLoader loader = TimeLexerSpeed.class.getClassLoader();
    InputStream[] streams = new InputStream[n];
    for (int i = 0; i < n; i++) {
        streams[i] = loader.getResourceAsStream(resourceName);
    }
    URLConnection uc = null;
    long streamLength = getResourceSize(loader, resourceName);
    // track only time to suck data out of stream
    long start = System.nanoTime();
    for (int i = 0; i < n; i++) {
        try (InputStream is = streams[i]) {
            input[i] = CharStreams.fromStream(is, StandardCharsets.UTF_8, streamLength);
        }
    }
    long stop = System.nanoTime();
    long tus = (stop - start) / 1000;
    int size = input[0].size();
    long streamSize = GraphLayout.parseInstance((Object) input[0]).totalSize();
    streamFootprints.add(basename(resourceName) + "" ("" + size + "" char): "" + GraphLayout.parseInstance((Object) input[0]).toFootprint());
    String currentMethodName = new Exception().getStackTrace()[0].getMethodName();
    if (output)
        System.out.printf(""%27s average time %5dus size %6db over %4d loads of %5d symbols from %s\n"", currentMethodName, tus / n, streamSize, n, size, basename(resourceName));
}", ,"// keep refs around so we can average memory
[[SEP]]// track only time to suck data out of stream
",// keep refs around so we can average memory[[SEP]]// track only time to suck data out of stream,335,363,[0],0,"[0, 0]",0,"[0, 0]",0,0,1,0,"load_new_utf8(String, int)",org.antlr.v4.test.runtime.java.api.perf.TimeLexerSpeed,"load_new_utf8/2[java.lang.String,int]",False,335,4,5,1,4,4,14,23,0,14,2,14,2,2,2,0,1,1,3,7,16,4,2,0,0,0,43,1,0,False
69,..\projects\antlr4-4.11.0\runtime-testsuite\test\org\antlr\v4\test\runtime\java\api\perf\TimeLexerSpeed.java,org.antlr.v4.test.runtime.java.api.perf.TimeLexerSpeed,"double tokenize(Lexer, int, boolean)","public double tokenize(Lexer lexer, int n, boolean clearLexerDFACache) {
    // always wipe the DFA before we begin tests so previous tests
    // don't affect this run!
    lexer.getInterpreter().clearDFA();
    long[] times = new long[n];
    for (int i = 0; i < n; i++) {
        lexer.reset();
        if (clearLexerDFACache) {
            lexer.getInterpreter().clearDFA();
        }
        long start = System.nanoTime();
        CommonTokenStream tokens = new CommonTokenStream(lexer);
        // lex whole file.
        tokens.fill();
        // int size = lexer.getInputStream().size();
        long stop = System.nanoTime();
        times[i] = (stop - start) / 1000;
        // if ( output ) System.out.printf(""Tokenized %d char in %dus\n"", size, times[i]);
    }
    Arrays.sort(times);
    // drop highest 20% of times
    times = Arrays.copyOfRange(times, 0, times.length - (int) (n * .2));
    return avg(times);
}", ,"// always wipe the DFA before we begin tests so previous tests
[[SEP]]// don't affect this run!
[[SEP]]// if ( output ) System.out.printf(""Tokenized %d char in %dus\n"", size, times[i]);
[[SEP]]// lex whole file.
[[SEP]]// int size = lexer.getInputStream().size();
[[SEP]]// drop highest 20% of times
","// always wipe the DFA before we begin tests so previous tests// don't affect this run![[SEP]]// lex whole file.[[SEP]]// int size = lexer.getInputStream().size();[[SEP]]// if ( output ) System.out.printf(""Tokenized %d char in %dus\n"", size, times[i]);[[SEP]]// drop highest 20% of times",436,457,[0],0,"[0, 0, 0, 0, 0, 0]",0,"[0, 0, 0, 0, 0]",0,0,0,0,"tokenize(Lexer, int, boolean)",org.antlr.v4.test.runtime.java.api.perf.TimeLexerSpeed,"tokenize/3[org.antlr.v4.runtime.Lexer,int,boolean]",False,436,7,10,4,6,3,8,18,1,5,3,8,1,1,1,0,0,2,0,4,7,4,2,0,0,0,18,1,0,False
70,..\projects\antlr4-4.11.0\runtime-testsuite\test\org\antlr\v4\test\runtime\java\api\perf\TimeLexerSpeed.java,org.antlr.v4.test.runtime.java.api.perf.TimeLexerSpeed,"double std(double, List<Long>)","public double std(double mean, List<Long> values) {
    // unbiased std dev
    double sum = 0.0;
    for (Long v : values) {
        sum += (v - mean) * (v - mean);
    }
    return Math.sqrt(sum / (values.size() - 1));
}", ,"// unbiased std dev
",// unbiased std dev,467,473,[0],0,[0],0,[0],0,0,0,0,"std(double, List<Long>)",org.antlr.v4.test.runtime.java.api.perf.TimeLexerSpeed,"std/2[double,java.util.List<java.lang.Long>]",False,467,0,0,0,0,2,2,7,1,1,2,2,0,0,1,0,0,3,0,2,2,5,1,0,0,0,6,1,0,False
71,..\projects\antlr4-4.11.0\runtime-testsuite\test\org\antlr\v4\test\runtime\java\api\perf\TimeLexerSpeed.java,org.antlr.v4.test.runtime.java.api.perf.TimeLexerSpeed,"long getResourceSize(ClassLoader, String)","public static long getResourceSize(ClassLoader loader, String resourceName) throws IOException {
    URLConnection uc = null;
    try {
        // Sadly, URLConnection is not AutoCloseable, but it leaks resources if
        // we don't close its stream.
        uc = loader.getResource(resourceName).openConnection();
        return uc.getContentLengthLong();
    } finally {
        if (uc != null) {
            uc.getInputStream().close();
        }
    }
}", ,"// Sadly, URLConnection is not AutoCloseable, but it leaks resources if
[[SEP]]// we don't close its stream.
","// Sadly, URLConnection is not AutoCloseable, but it leaks resources if// we don't close its stream.",493,505,[0],0,"[0, 0]",0,[0],0,0,0,0,"getResourceSize(ClassLoader, String)",org.antlr.v4.test.runtime.java.api.perf.TimeLexerSpeed,"getResourceSize/2[java.lang.ClassLoader,java.lang.String]",False,493,0,3,3,0,2,5,12,1,1,2,5,0,0,0,1,1,0,0,0,2,0,2,0,0,0,16,9,0,False
72,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\ANTLRErrorListener.java,org.antlr.v4.runtime.ANTLRErrorListener,"void syntaxError(Recognizer<?, ?>, Object, int, int, String, RecognitionException)","/**
 * Upon syntax error, notify any interested parties. This is not how to
 * recover from errors or compute error messages. {@link ANTLRErrorStrategy}
 * specifies how to recover from syntax errors and how to compute error
 * messages. This listener's job is simply to emit a computed message,
 * though it has enough information to create its own message in many cases.
 *
 * <p>The {@link RecognitionException} is non-null for all syntax errors except
 * when we discover mismatched token errors that we can recover from
 * in-line, without returning from the surrounding rule (via the single
 * token insertion and deletion mechanism).</p>
 *
 * @param recognizer
 *        What parser got the error. From this
 * 		  object, you can access the context as well
 * 		  as the input stream.
 * @param offendingSymbol
 *        The offending token in the input token
 * 		  stream, unless recognizer is a lexer (then it's null). If
 * 		  no viable alternative error, {@code e} has token at which we
 * 		  started production for the decision.
 * @param line
 * 		  The line number in the input where the error occurred.
 * @param charPositionInLine
 * 		  The character position within that line where the error occurred.
 * @param msg
 * 		  The message to emit.
 * @param e
 *        The exception generated by the parser that led to
 *        the reporting of an error. It is null in the case where
 *        the parser was able to recover in line without exiting the
 *        surrounding rule.
 */
public void syntaxError(Recognizer<?, ?> recognizer, Object offendingSymbol, int line, int charPositionInLine, String msg, RecognitionException e);","/**
 * Upon syntax error, notify any interested parties. This is not how to
 * recover from errors or compute error messages. {@link ANTLRErrorStrategy}
 * specifies how to recover from syntax errors and how to compute error
 * messages. This listener's job is simply to emit a computed message,
 * though it has enough information to create its own message in many cases.
 *
 * <p>The {@link RecognitionException} is non-null for all syntax errors except
 * when we discover mismatched token errors that we can recover from
 * in-line, without returning from the surrounding rule (via the single
 * token insertion and deletion mechanism).</p>
 *
 * @param recognizer
 *        What parser got the error. From this
 * 		  object, you can access the context as well
 * 		  as the input stream.
 * @param offendingSymbol
 *        The offending token in the input token
 * 		  stream, unless recognizer is a lexer (then it's null). If
 * 		  no viable alternative error, {@code e} has token at which we
 * 		  started production for the decision.
 * @param line
 * 		  The line number in the input where the error occurred.
 * @param charPositionInLine
 * 		  The character position within that line where the error occurred.
 * @param msg
 * 		  The message to emit.
 * @param e
 *        The exception generated by the parser that led to
 *        the reporting of an error. It is null in the case where
 *        the parser was able to recover in line without exiting the
 *        surrounding rule.
 */
", ,"/** * Upon syntax error, notify any interested parties. This is not how to * recover from errors or compute error messages. {@link ANTLRErrorStrategy} * specifies how to recover from syntax errors and how to compute error * messages. This listener's job is simply to emit a computed message, * though it has enough information to create its own message in many cases. * * <p>The {@link RecognitionException} is non-null for all syntax errors except * when we discover mismatched token errors that we can recover from * in-line, without returning from the surrounding rule (via the single * token insertion and deletion mechanism).</p> * * @param recognizer *        What parser got the error. From this * 		  object, you can access the context as well * 		  as the input stream. * @param offendingSymbol *        The offending token in the input token * 		  stream, unless recognizer is a lexer (then it's null). If * 		  no viable alternative error, {@code e} has token at which we * 		  started production for the decision. * @param line * 		  The line number in the input where the error occurred. * @param charPositionInLine * 		  The character position within that line where the error occurred. * @param msg * 		  The message to emit. * @param e *        The exception generated by the parser that led to *        the reporting of an error. It is null in the case where *        the parser was able to recover in line without exiting the *        surrounding rule. */",52,57,[0],0,[0],0,[0],0,0,0,0,"syntaxError(Recognizer<?, ?>, Object, int, int, String, RecognitionException)",org.antlr.v4.runtime.ANTLRErrorListener,"syntaxError/6[org.antlr.v4.runtime.Recognizer<?,?>,java.lang.Object,int,int,java.lang.String,org.antlr.v4.runtime.RecognitionException]",False,19,2,3,3,0,1,0,1,0,0,6,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,112,1,0,True
73,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\ANTLRErrorListener.java,org.antlr.v4.runtime.ANTLRErrorListener,"void reportAmbiguity(Parser, DFA, int, int, boolean, BitSet, ATNConfigSet)","/**
 * This method is called by the parser when a full-context prediction
 * results in an ambiguity.
 *
 * <p>Each full-context prediction which does not result in a syntax error
 * will call either {@link #reportContextSensitivity} or
 * {@link #reportAmbiguity}.</p>
 *
 * <p>When {@code ambigAlts} is not null, it contains the set of potentially
 * viable alternatives identified by the prediction algorithm. When
 * {@code ambigAlts} is null, use {@link ATNConfigSet#getAlts} to obtain the
 * represented alternatives from the {@code configs} argument.</p>
 *
 * <p>When {@code exact} is {@code true}, <em>all</em> of the potentially
 * viable alternatives are truly viable, i.e. this is reporting an exact
 * ambiguity. When {@code exact} is {@code false}, <em>at least two</em> of
 * the potentially viable alternatives are viable for the current input, but
 * the prediction algorithm terminated as soon as it determined that at
 * least the <em>minimum</em> potentially viable alternative is truly
 * viable.</p>
 *
 * <p>When the {@link PredictionMode#LL_EXACT_AMBIG_DETECTION} prediction
 * mode is used, the parser is required to identify exact ambiguities so
 * {@code exact} will always be {@code true}.</p>
 *
 * <p>This method is not used by lexers.</p>
 *
 * @param recognizer the parser instance
 * @param dfa the DFA for the current decision
 * @param startIndex the input index where the decision started
 * @param stopIndex the input input where the ambiguity was identified
 * @param exact {@code true} if the ambiguity is exactly known, otherwise
 * {@code false}. This is always {@code true} when
 * {@link PredictionMode#LL_EXACT_AMBIG_DETECTION} is used.
 * @param ambigAlts the potentially ambiguous alternatives, or {@code null}
 * to indicate that the potentially ambiguous alternatives are the complete
 * set of represented alternatives in {@code configs}
 * @param configs the ATN configuration set where the ambiguity was
 * identified
 */
void reportAmbiguity(Parser recognizer, DFA dfa, int startIndex, int stopIndex, boolean exact, BitSet ambigAlts, ATNConfigSet configs);","/**
 * This method is called by the parser when a full-context prediction
 * results in an ambiguity.
 *
 * <p>Each full-context prediction which does not result in a syntax error
 * will call either {@link #reportContextSensitivity} or
 * {@link #reportAmbiguity}.</p>
 *
 * <p>When {@code ambigAlts} is not null, it contains the set of potentially
 * viable alternatives identified by the prediction algorithm. When
 * {@code ambigAlts} is null, use {@link ATNConfigSet#getAlts} to obtain the
 * represented alternatives from the {@code configs} argument.</p>
 *
 * <p>When {@code exact} is {@code true}, <em>all</em> of the potentially
 * viable alternatives are truly viable, i.e. this is reporting an exact
 * ambiguity. When {@code exact} is {@code false}, <em>at least two</em> of
 * the potentially viable alternatives are viable for the current input, but
 * the prediction algorithm terminated as soon as it determined that at
 * least the <em>minimum</em> potentially viable alternative is truly
 * viable.</p>
 *
 * <p>When the {@link PredictionMode#LL_EXACT_AMBIG_DETECTION} prediction
 * mode is used, the parser is required to identify exact ambiguities so
 * {@code exact} will always be {@code true}.</p>
 *
 * <p>This method is not used by lexers.</p>
 *
 * @param recognizer the parser instance
 * @param dfa the DFA for the current decision
 * @param startIndex the input index where the decision started
 * @param stopIndex the input input where the ambiguity was identified
 * @param exact {@code true} if the ambiguity is exactly known, otherwise
 * {@code false}. This is always {@code true} when
 * {@link PredictionMode#LL_EXACT_AMBIG_DETECTION} is used.
 * @param ambigAlts the potentially ambiguous alternatives, or {@code null}
 * to indicate that the potentially ambiguous alternatives are the complete
 * set of represented alternatives in {@code configs}
 * @param configs the ATN configuration set where the ambiguity was
 * identified
 */
", ,"/** * This method is called by the parser when a full-context prediction * results in an ambiguity. * * <p>Each full-context prediction which does not result in a syntax error * will call either {@link #reportContextSensitivity} or * {@link #reportAmbiguity}.</p> * * <p>When {@code ambigAlts} is not null, it contains the set of potentially * viable alternatives identified by the prediction algorithm. When * {@code ambigAlts} is null, use {@link ATNConfigSet#getAlts} to obtain the * represented alternatives from the {@code configs} argument.</p> * * <p>When {@code exact} is {@code true}, <em>all</em> of the potentially * viable alternatives are truly viable, i.e. this is reporting an exact * ambiguity. When {@code exact} is {@code false}, <em>at least two</em> of * the potentially viable alternatives are viable for the current input, but * the prediction algorithm terminated as soon as it determined that at * least the <em>minimum</em> potentially viable alternative is truly * viable.</p> * * <p>When the {@link PredictionMode#LL_EXACT_AMBIG_DETECTION} prediction * mode is used, the parser is required to identify exact ambiguities so * {@code exact} will always be {@code true}.</p> * * <p>This method is not used by lexers.</p> * * @param recognizer the parser instance * @param dfa the DFA for the current decision * @param startIndex the input index where the decision started * @param stopIndex the input input where the ambiguity was identified * @param exact {@code true} if the ambiguity is exactly known, otherwise * {@code false}. This is always {@code true} when * {@link PredictionMode#LL_EXACT_AMBIG_DETECTION} is used. * @param ambigAlts the potentially ambiguous alternatives, or {@code null} * to indicate that the potentially ambiguous alternatives are the complete * set of represented alternatives in {@code configs} * @param configs the ATN configuration set where the ambiguity was * identified */",99,105,[0],0,[0],0,[0],0,0,0,0,"reportAmbiguity(Parser, DFA, int, int, boolean, BitSet, ATNConfigSet)",org.antlr.v4.runtime.ANTLRErrorListener,"reportAmbiguity/7[org.antlr.v4.runtime.Parser,org.antlr.v4.runtime.dfa.DFA,int,int,boolean,java.util.BitSet,org.antlr.v4.runtime.atn.ATNConfigSet]",False,59,3,2,2,0,1,0,1,0,0,7,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,101,0,0,True
74,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\ANTLRErrorListener.java,org.antlr.v4.runtime.ANTLRErrorListener,"void reportAttemptingFullContext(Parser, DFA, int, int, BitSet, ATNConfigSet)","/**
 * This method is called when an SLL conflict occurs and the parser is about
 * to use the full context information to make an LL decision.
 *
 * <p>If one or more configurations in {@code configs} contains a semantic
 * predicate, the predicates are evaluated before this method is called. The
 * subset of alternatives which are still viable after predicates are
 * evaluated is reported in {@code conflictingAlts}.</p>
 *
 * <p>This method is not used by lexers.</p>
 *
 * @param recognizer the parser instance
 * @param dfa the DFA for the current decision
 * @param startIndex the input index where the decision started
 * @param stopIndex the input index where the SLL conflict occurred
 * @param conflictingAlts The specific conflicting alternatives. If this is
 * {@code null}, the conflicting alternatives are all alternatives
 * represented in {@code configs}. At the moment, conflictingAlts is non-null
 * (for the reference implementation, but Sam's optimized version can see this
 * as null).
 * @param configs the ATN configuration set where the SLL conflict was
 * detected
 */
void reportAttemptingFullContext(Parser recognizer, DFA dfa, int startIndex, int stopIndex, BitSet conflictingAlts, ATNConfigSet configs);","/**
 * This method is called when an SLL conflict occurs and the parser is about
 * to use the full context information to make an LL decision.
 *
 * <p>If one or more configurations in {@code configs} contains a semantic
 * predicate, the predicates are evaluated before this method is called. The
 * subset of alternatives which are still viable after predicates are
 * evaluated is reported in {@code conflictingAlts}.</p>
 *
 * <p>This method is not used by lexers.</p>
 *
 * @param recognizer the parser instance
 * @param dfa the DFA for the current decision
 * @param startIndex the input index where the decision started
 * @param stopIndex the input index where the SLL conflict occurred
 * @param conflictingAlts The specific conflicting alternatives. If this is
 * {@code null}, the conflicting alternatives are all alternatives
 * represented in {@code configs}. At the moment, conflictingAlts is non-null
 * (for the reference implementation, but Sam's optimized version can see this
 * as null).
 * @param configs the ATN configuration set where the SLL conflict was
 * detected
 */
", ,"/** * This method is called when an SLL conflict occurs and the parser is about * to use the full context information to make an LL decision. * * <p>If one or more configurations in {@code configs} contains a semantic * predicate, the predicates are evaluated before this method is called. The * subset of alternatives which are still viable after predicates are * evaluated is reported in {@code conflictingAlts}.</p> * * <p>This method is not used by lexers.</p> * * @param recognizer the parser instance * @param dfa the DFA for the current decision * @param startIndex the input index where the decision started * @param stopIndex the input index where the SLL conflict occurred * @param conflictingAlts The specific conflicting alternatives. If this is * {@code null}, the conflicting alternatives are all alternatives * represented in {@code configs}. At the moment, conflictingAlts is non-null * (for the reference implementation, but Sam's optimized version can see this * as null). * @param configs the ATN configuration set where the SLL conflict was * detected */",130,135,[0],0,[0],0,[0],0,0,0,0,"reportAttemptingFullContext(Parser, DFA, int, int, BitSet, ATNConfigSet)",org.antlr.v4.runtime.ANTLRErrorListener,"reportAttemptingFullContext/6[org.antlr.v4.runtime.Parser,org.antlr.v4.runtime.dfa.DFA,int,int,java.util.BitSet,org.antlr.v4.runtime.atn.ATNConfigSet]",False,107,3,2,2,0,1,0,1,0,0,6,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,87,0,0,True
75,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\ANTLRErrorListener.java,org.antlr.v4.runtime.ANTLRErrorListener,"void reportContextSensitivity(Parser, DFA, int, int, int, ATNConfigSet)","/**
 * This method is called by the parser when a full-context prediction has a
 * unique result.
 *
 * <p>Each full-context prediction which does not result in a syntax error
 * will call either {@link #reportContextSensitivity} or
 * {@link #reportAmbiguity}.</p>
 *
 * <p>For prediction implementations that only evaluate full-context
 * predictions when an SLL conflict is found (including the default
 * {@link ParserATNSimulator} implementation), this method reports cases
 * where SLL conflicts were resolved to unique full-context predictions,
 * i.e. the decision was context-sensitive. This report does not necessarily
 * indicate a problem, and it may appear even in completely unambiguous
 * grammars.</p>
 *
 * <p>{@code configs} may have more than one represented alternative if the
 * full-context prediction algorithm does not evaluate predicates before
 * beginning the full-context prediction. In all cases, the final prediction
 * is passed as the {@code prediction} argument.</p>
 *
 * <p>Note that the definition of ""context sensitivity"" in this method
 * differs from the concept in {@link DecisionInfo#contextSensitivities}.
 * This method reports all instances where an SLL conflict occurred but LL
 * parsing produced a unique result, whether or not that unique result
 * matches the minimum alternative in the SLL conflicting set.</p>
 *
 * <p>This method is not used by lexers.</p>
 *
 * @param recognizer the parser instance
 * @param dfa the DFA for the current decision
 * @param startIndex the input index where the decision started
 * @param stopIndex the input index where the context sensitivity was
 * finally determined
 * @param prediction the unambiguous result of the full-context prediction
 * @param configs the ATN configuration set where the unambiguous prediction
 * was determined
 */
void reportContextSensitivity(Parser recognizer, DFA dfa, int startIndex, int stopIndex, int prediction, ATNConfigSet configs);","/**
 * This method is called by the parser when a full-context prediction has a
 * unique result.
 *
 * <p>Each full-context prediction which does not result in a syntax error
 * will call either {@link #reportContextSensitivity} or
 * {@link #reportAmbiguity}.</p>
 *
 * <p>For prediction implementations that only evaluate full-context
 * predictions when an SLL conflict is found (including the default
 * {@link ParserATNSimulator} implementation), this method reports cases
 * where SLL conflicts were resolved to unique full-context predictions,
 * i.e. the decision was context-sensitive. This report does not necessarily
 * indicate a problem, and it may appear even in completely unambiguous
 * grammars.</p>
 *
 * <p>{@code configs} may have more than one represented alternative if the
 * full-context prediction algorithm does not evaluate predicates before
 * beginning the full-context prediction. In all cases, the final prediction
 * is passed as the {@code prediction} argument.</p>
 *
 * <p>Note that the definition of ""context sensitivity"" in this method
 * differs from the concept in {@link DecisionInfo#contextSensitivities}.
 * This method reports all instances where an SLL conflict occurred but LL
 * parsing produced a unique result, whether or not that unique result
 * matches the minimum alternative in the SLL conflicting set.</p>
 *
 * <p>This method is not used by lexers.</p>
 *
 * @param recognizer the parser instance
 * @param dfa the DFA for the current decision
 * @param startIndex the input index where the decision started
 * @param stopIndex the input index where the context sensitivity was
 * finally determined
 * @param prediction the unambiguous result of the full-context prediction
 * @param configs the ATN configuration set where the unambiguous prediction
 * was determined
 */
", ,"/** * This method is called by the parser when a full-context prediction has a * unique result. * * <p>Each full-context prediction which does not result in a syntax error * will call either {@link #reportContextSensitivity} or * {@link #reportAmbiguity}.</p> * * <p>For prediction implementations that only evaluate full-context * predictions when an SLL conflict is found (including the default * {@link ParserATNSimulator} implementation), this method reports cases * where SLL conflicts were resolved to unique full-context predictions, * i.e. the decision was context-sensitive. This report does not necessarily * indicate a problem, and it may appear even in completely unambiguous * grammars.</p> * * <p>{@code configs} may have more than one represented alternative if the * full-context prediction algorithm does not evaluate predicates before * beginning the full-context prediction. In all cases, the final prediction * is passed as the {@code prediction} argument.</p> * * <p>Note that the definition of ""context sensitivity"" in this method * differs from the concept in {@link DecisionInfo#contextSensitivities}. * This method reports all instances where an SLL conflict occurred but LL * parsing produced a unique result, whether or not that unique result * matches the minimum alternative in the SLL conflicting set.</p> * * <p>This method is not used by lexers.</p> * * @param recognizer the parser instance * @param dfa the DFA for the current decision * @param startIndex the input index where the decision started * @param stopIndex the input index where the context sensitivity was * finally determined * @param prediction the unambiguous result of the full-context prediction * @param configs the ATN configuration set where the unambiguous prediction * was determined */",175,180,[0],0,[0],0,[0],0,0,0,0,"reportContextSensitivity(Parser, DFA, int, int, int, ATNConfigSet)",org.antlr.v4.runtime.ANTLRErrorListener,"reportContextSensitivity/6[org.antlr.v4.runtime.Parser,org.antlr.v4.runtime.dfa.DFA,int,int,int,org.antlr.v4.runtime.atn.ATNConfigSet]",False,137,3,2,2,0,1,0,1,0,0,6,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,116,0,0,True
76,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\ANTLRErrorStrategy.java,org.antlr.v4.runtime.ANTLRErrorStrategy,void reset(Parser),"/**
 * Reset the error handler state for the specified {@code recognizer}.
 * @param recognizer the parser instance
 */
void reset(Parser recognizer);","/**
 * Reset the error handler state for the specified {@code recognizer}.
 * @param recognizer the parser instance
 */
", ,/** * Reset the error handler state for the specified {@code recognizer}. * @param recognizer the parser instance */,33,33,[0],0,[0],0,[0],0,0,0,0,reset(Parser),org.antlr.v4.runtime.ANTLRErrorStrategy,reset/1[org.antlr.v4.runtime.Parser],False,29,1,1,1,0,1,0,1,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,11,0,0,True
77,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\ANTLRErrorStrategy.java,org.antlr.v4.runtime.ANTLRErrorStrategy,Token recoverInline(Parser),"/**
 * This method is called when an unexpected symbol is encountered during an
 * inline match operation, such as {@link Parser#match}. If the error
 * strategy successfully recovers from the match failure, this method
 * returns the {@link Token} instance which should be treated as the
 * successful result of the match.
 *
 * <p>This method handles the consumption of any tokens - the caller should
 * <b>not</b> call {@link Parser#consume} after a successful recovery.</p>
 *
 * <p>Note that the calling code will not report an error if this method
 * returns successfully. The error strategy implementation is responsible
 * for calling {@link Parser#notifyErrorListeners} as appropriate.</p>
 *
 * @param recognizer the parser instance
 * @throws RecognitionException if the error strategy was not able to
 * recover from the unexpected input symbol
 */
Token recoverInline(Parser recognizer) throws RecognitionException;","/**
 * This method is called when an unexpected symbol is encountered during an
 * inline match operation, such as {@link Parser#match}. If the error
 * strategy successfully recovers from the match failure, this method
 * returns the {@link Token} instance which should be treated as the
 * successful result of the match.
 *
 * <p>This method handles the consumption of any tokens - the caller should
 * <b>not</b> call {@link Parser#consume} after a successful recovery.</p>
 *
 * <p>Note that the calling code will not report an error if this method
 * returns successfully. The error strategy implementation is responsible
 * for calling {@link Parser#notifyErrorListeners} as appropriate.</p>
 *
 * @param recognizer the parser instance
 * @throws RecognitionException if the error strategy was not able to
 * recover from the unexpected input symbol
 */
", ,"/** * This method is called when an unexpected symbol is encountered during an * inline match operation, such as {@link Parser#match}. If the error * strategy successfully recovers from the match failure, this method * returns the {@link Token} instance which should be treated as the * successful result of the match. * * <p>This method handles the consumption of any tokens - the caller should * <b>not</b> call {@link Parser#consume} after a successful recovery.</p> * * <p>Note that the calling code will not report an error if this method * returns successfully. The error strategy implementation is responsible * for calling {@link Parser#notifyErrorListeners} as appropriate.</p> * * @param recognizer the parser instance * @throws RecognitionException if the error strategy was not able to * recover from the unexpected input symbol */",53,53,[0],0,[0],0,[0],0,0,0,0,recoverInline(Parser),org.antlr.v4.runtime.ANTLRErrorStrategy,recoverInline/1[org.antlr.v4.runtime.Parser],False,35,2,3,3,0,1,0,1,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,63,0,0,True
78,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\ANTLRErrorStrategy.java,org.antlr.v4.runtime.ANTLRErrorStrategy,"void recover(Parser, RecognitionException)","/**
 * This method is called to recover from exception {@code e}. This method is
 * called after {@link #reportError} by the default exception handler
 * generated for a rule method.
 *
 * @see #reportError
 *
 * @param recognizer the parser instance
 * @param e the recognition exception to recover from
 * @throws RecognitionException if the error strategy could not recover from
 * the recognition exception
 */
void recover(Parser recognizer, RecognitionException e) throws RecognitionException;","/**
 * This method is called to recover from exception {@code e}. This method is
 * called after {@link #reportError} by the default exception handler
 * generated for a rule method.
 *
 * @see #reportError
 *
 * @param recognizer the parser instance
 * @param e the recognition exception to recover from
 * @throws RecognitionException if the error strategy could not recover from
 * the recognition exception
 */
", ,/** * This method is called to recover from exception {@code e}. This method is * called after {@link #reportError} by the default exception handler * generated for a rule method. * * @see #reportError * * @param recognizer the parser instance * @param e the recognition exception to recover from * @throws RecognitionException if the error strategy could not recover from * the recognition exception */,67,67,[0],0,[0],0,[0],0,0,0,0,"recover(Parser, RecognitionException)",org.antlr.v4.runtime.ANTLRErrorStrategy,"recover/2[org.antlr.v4.runtime.Parser,org.antlr.v4.runtime.RecognitionException]",False,55,2,1,1,0,1,0,1,0,0,2,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,27,0,0,True
79,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\ANTLRErrorStrategy.java,org.antlr.v4.runtime.ANTLRErrorStrategy,void sync(Parser),"/**
 * This method provides the error handler with an opportunity to handle
 * syntactic or semantic errors in the input stream before they result in a
 * {@link RecognitionException}.
 *
 * <p>The generated code currently contains calls to {@link #sync} after
 * entering the decision state of a closure block ({@code (...)*} or
 * {@code (...)+}).</p>
 *
 * <p>For an implementation based on Jim Idle's ""magic sync"" mechanism, see
 * {@link DefaultErrorStrategy#sync}.</p>
 *
 * @see DefaultErrorStrategy#sync
 *
 * @param recognizer the parser instance
 * @throws RecognitionException if an error is detected by the error
 * strategy but cannot be automatically recovered at the current state in
 * the parsing process
 */
void sync(Parser recognizer) throws RecognitionException;","/**
 * This method provides the error handler with an opportunity to handle
 * syntactic or semantic errors in the input stream before they result in a
 * {@link RecognitionException}.
 *
 * <p>The generated code currently contains calls to {@link #sync} after
 * entering the decision state of a closure block ({@code (...)*} or
 * {@code (...)+}).</p>
 *
 * <p>For an implementation based on Jim Idle's ""magic sync"" mechanism, see
 * {@link DefaultErrorStrategy#sync}.</p>
 *
 * @see DefaultErrorStrategy#sync
 *
 * @param recognizer the parser instance
 * @throws RecognitionException if an error is detected by the error
 * strategy but cannot be automatically recovered at the current state in
 * the parsing process
 */
", ,"/** * This method provides the error handler with an opportunity to handle * syntactic or semantic errors in the input stream before they result in a * {@link RecognitionException}. * * <p>The generated code currently contains calls to {@link #sync} after * entering the decision state of a closure block ({@code (...)*} or * {@code (...)+}).</p> * * <p>For an implementation based on Jim Idle's ""magic sync"" mechanism, see * {@link DefaultErrorStrategy#sync}.</p> * * @see DefaultErrorStrategy#sync * * @param recognizer the parser instance * @throws RecognitionException if an error is detected by the error * strategy but cannot be automatically recovered at the current state in * the parsing process */",88,88,[0],0,[0],0,[0],0,0,0,0,sync(Parser),org.antlr.v4.runtime.ANTLRErrorStrategy,sync/1[org.antlr.v4.runtime.Parser],False,69,1,1,1,0,1,0,1,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,61,0,0,True
80,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\ANTLRErrorStrategy.java,org.antlr.v4.runtime.ANTLRErrorStrategy,boolean inErrorRecoveryMode(Parser),"/**
 * Tests whether or not {@code recognizer} is in the process of recovering
 * from an error. In error recovery mode, {@link Parser#consume} adds
 * symbols to the parse tree by calling
 * {@link Parser#createErrorNode(ParserRuleContext, Token)} then
 * {@link ParserRuleContext#addErrorNode(ErrorNode)} instead of
 * {@link Parser#createTerminalNode(ParserRuleContext, Token)}.
 *
 * @param recognizer the parser instance
 * @return {@code true} if the parser is currently recovering from a parse
 * error, otherwise {@code false}
 */
boolean inErrorRecoveryMode(Parser recognizer);","/**
 * Tests whether or not {@code recognizer} is in the process of recovering
 * from an error. In error recovery mode, {@link Parser#consume} adds
 * symbols to the parse tree by calling
 * {@link Parser#createErrorNode(ParserRuleContext, Token)} then
 * {@link ParserRuleContext#addErrorNode(ErrorNode)} instead of
 * {@link Parser#createTerminalNode(ParserRuleContext, Token)}.
 *
 * @param recognizer the parser instance
 * @return {@code true} if the parser is currently recovering from a parse
 * error, otherwise {@code false}
 */
", ,"/** * Tests whether or not {@code recognizer} is in the process of recovering * from an error. In error recovery mode, {@link Parser#consume} adds * symbols to the parse tree by calling * {@link Parser#createErrorNode(ParserRuleContext, Token)} then * {@link ParserRuleContext#addErrorNode(ErrorNode)} instead of * {@link Parser#createTerminalNode(ParserRuleContext, Token)}. * * @param recognizer the parser instance * @return {@code true} if the parser is currently recovering from a parse * error, otherwise {@code false} */",102,102,[0],0,[0],0,[0],0,0,0,0,inErrorRecoveryMode(Parser),org.antlr.v4.runtime.ANTLRErrorStrategy,inErrorRecoveryMode/1[org.antlr.v4.runtime.Parser],False,90,1,1,1,0,1,0,1,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,37,0,0,True
81,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\ANTLRErrorStrategy.java,org.antlr.v4.runtime.ANTLRErrorStrategy,void reportMatch(Parser),"/**
 * This method is called by when the parser successfully matches an input
 * symbol.
 *
 * @param recognizer the parser instance
 */
void reportMatch(Parser recognizer);","/**
 * This method is called by when the parser successfully matches an input
 * symbol.
 *
 * @param recognizer the parser instance
 */
", ,/** * This method is called by when the parser successfully matches an input * symbol. * * @param recognizer the parser instance */,110,110,[0],0,[0],0,[0],0,0,0,0,reportMatch(Parser),org.antlr.v4.runtime.ANTLRErrorStrategy,reportMatch/1[org.antlr.v4.runtime.Parser],False,104,1,2,2,0,1,0,1,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,17,0,0,True
82,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\ANTLRErrorStrategy.java,org.antlr.v4.runtime.ANTLRErrorStrategy,"void reportError(Parser, RecognitionException)","/**
 * Report any kind of {@link RecognitionException}. This method is called by
 * the default exception handler generated for a rule method.
 *
 * @param recognizer the parser instance
 * @param e the recognition exception to report
 */
void reportError(Parser recognizer, RecognitionException e);","/**
 * Report any kind of {@link RecognitionException}. This method is called by
 * the default exception handler generated for a rule method.
 *
 * @param recognizer the parser instance
 * @param e the recognition exception to report
 */
", ,/** * Report any kind of {@link RecognitionException}. This method is called by * the default exception handler generated for a rule method. * * @param recognizer the parser instance * @param e the recognition exception to report */,119,119,[0],0,[0],0,[0],0,0,0,0,"reportError(Parser, RecognitionException)",org.antlr.v4.runtime.ANTLRErrorStrategy,"reportError/2[org.antlr.v4.runtime.Parser,org.antlr.v4.runtime.RecognitionException]",False,112,2,1,1,0,1,0,1,0,0,2,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,26,0,0,True
83,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\ANTLRInputStream.java,org.antlr.v4.runtime.ANTLRInputStream,"void load(Reader, int, int)","public void load(Reader r, int size, int readChunkSize) throws IOException {
    if (r == null) {
        return;
    }
    if (size <= 0) {
        size = INITIAL_BUFFER_SIZE;
    }
    if (readChunkSize <= 0) {
        readChunkSize = READ_BUFFER_SIZE;
    }
    // System.out.println(""load ""+size+"" in chunks of ""+readChunkSize);
    try {
        // alloc initial buffer size.
        data = new char[size];
        // read all the data in chunks of readChunkSize
        int numRead = 0;
        int p = 0;
        do {
            if (p + readChunkSize > data.length) {
                // overflow?
                // System.out.println(""### overflow p=""+p+"", data.length=""+data.length);
                data = Arrays.copyOf(data, data.length * 2);
            }
            numRead = r.read(data, p, readChunkSize);
            // System.out.println(""read ""+numRead+"" chars; p was ""+p+"" is now ""+(p+numRead));
            p += numRead;
        } while (// while not EOF
        numRead != -1);
        // set the actual size of the data available;
        // EOF subtracted one above in p+=numRead; add one back
        n = p + 1;
        // System.out.println(""n=""+n);
    } finally {
        r.close();
    }
}", ,"// System.out.println(""load ""+size+"" in chunks of ""+readChunkSize);
[[SEP]]// set the actual size of the data available;
[[SEP]]// System.out.println(""n=""+n);
[[SEP]]// alloc initial buffer size.
[[SEP]]// read all the data in chunks of readChunkSize
[[SEP]]// overflow?
[[SEP]]// System.out.println(""### overflow p=""+p+"", data.length=""+data.length);
[[SEP]]// System.out.println(""read ""+numRead+"" chars; p was ""+p+"" is now ""+(p+numRead));
[[SEP]]// while not EOF
[[SEP]]// EOF subtracted one above in p+=numRead; add one back
","// System.out.println(""load ""+size+"" in chunks of ""+readChunkSize);[[SEP]]// alloc initial buffer size.[[SEP]]// read all the data in chunks of readChunkSize[[SEP]]// overflow?// System.out.println(""### overflow p=""+p+"", data.length=""+data.length);[[SEP]]// System.out.println(""read ""+numRead+"" chars; p was ""+p+"" is now ""+(p+numRead));[[SEP]]// while not EOF[[SEP]]// set the actual size of the data available;// EOF subtracted one above in p+=numRead; add one back[[SEP]]// System.out.println(""n=""+n);",80,116,[0],0,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]",0,"[0, 0, 0, 0, 0, 0, 0, 0]",0,0,0,0,"load(Reader, int, int)",org.antlr.v4.runtime.ANTLRInputStream,"load/3[java.io.Reader,int,int]",False,82,1,1,1,0,6,3,28,1,2,3,3,0,0,1,2,1,0,0,7,9,3,3,0,0,0,29,1,0,False
84,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\ANTLRInputStream.java,org.antlr.v4.runtime.ANTLRInputStream,void reset(),"/**
 * Reset the stream so that it's in the same state it was
 *  when the object was created *except* the data array is not
 *  touched.
 */
public void reset() {
    p = 0;
}","/**
 * Reset the stream so that it's in the same state it was
 *  when the object was created *except* the data array is not
 *  touched.
 */
", ,/** * Reset the stream so that it's in the same state it was *  when the object was created *except* the data array is not *  touched. */,122,124,[0],0,[0],0,[0],0,0,0,0,reset(),org.antlr.v4.runtime.ANTLRInputStream,reset/0,False,122,0,0,0,0,1,0,3,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0,0,0,20,1,0,True
85,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\ANTLRInputStream.java,org.antlr.v4.runtime.ANTLRInputStream,void consume(),"@Override
public void consume() {
    if (p >= n) {
        assert LA(1) == IntStream.EOF;
        throw new IllegalStateException(""cannot consume EOF"");
    }
    // System.out.println(""prev p=""+p+"", c=""+(char)data[p]);
    if (p < n) {
        p++;
        // System.out.println(""p moves to ""+p+"" (c='""+(char)data[p]+""')"");
    }
}", ,"// System.out.println(""prev p=""+p+"", c=""+(char)data[p]);
[[SEP]]// System.out.println(""p moves to ""+p+"" (c='""+(char)data[p]+""')"");
","// System.out.println(""prev p=""+p+"", c=""+(char)data[p]);[[SEP]]// System.out.println(""p moves to ""+p+"" (c='""+(char)data[p]+""')"");",126,138,[0],0,"[0, 0]",0,"[0, 0]",0,0,0,0,consume(),org.antlr.v4.runtime.ANTLRInputStream,consume/0,False,127,1,2,1,1,3,1,9,0,0,0,1,1,1,0,1,0,0,1,1,0,0,1,0,0,0,9,1,0,False
86,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\ANTLRInputStream.java,org.antlr.v4.runtime.ANTLRInputStream,int LA(int),"@Override
public int LA(int i) {
    if (i == 0) {
        // undefined
        return 0;
    }
    if (i < 0) {
        // e.g., translate LA(-1) to use offset i=0; then data[p+0-1]
        i++;
        if ((p + i - 1) < 0) {
            // invalid; no char before first char
            return IntStream.EOF;
        }
    }
    if ((p + i - 1) >= n) {
        // System.out.println(""char LA(""+i+"")=EOF; p=""+p);
        return IntStream.EOF;
    }
    // System.out.println(""char LA(""+i+"")=""+(char)data[p+i-1]+""; p=""+p);
    // System.out.println(""LA(""+i+""); p=""+p+"" n=""+n+"" data.length=""+data.length);
    return data[p + i - 1];
}", ,"// System.out.println(""char LA(""+i+"")=""+(char)data[p+i-1]+""; p=""+p);
[[SEP]]// undefined
[[SEP]]// e.g., translate LA(-1) to use offset i=0; then data[p+0-1]
[[SEP]]// invalid; no char before first char
[[SEP]]// System.out.println(""char LA(""+i+"")=EOF; p=""+p);
[[SEP]]// System.out.println(""LA(""+i+""); p=""+p+"" n=""+n+"" data.length=""+data.length);
","// undefined[[SEP]]// e.g., translate LA(-1) to use offset i=0; then data[p+0-1][[SEP]]// invalid; no char before first char[[SEP]]// System.out.println(""char LA(""+i+"")=EOF; p=""+p);[[SEP]]// System.out.println(""char LA(""+i+"")=""+(char)data[p+i-1]+""; p=""+p);// System.out.println(""LA(""+i+""); p=""+p+"" n=""+n+"" data.length=""+data.length);",140,159,[0],0,"[0, 0, 0, 0, 0, 0]",0,"[0, 0, 0, 0, 0]",0,0,0,0,LA(int),org.antlr.v4.runtime.ANTLRInputStream,LA/1[int],False,141,0,2,2,0,5,0,15,4,0,1,0,0,0,0,1,0,2,0,7,0,6,2,0,0,0,5,1,0,False
87,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\ANTLRInputStream.java,org.antlr.v4.runtime.ANTLRInputStream,int index(),"/**
 * Return the current input symbol index 0..n where n indicates the
 *  last symbol has been read.  The index is the index of char to
 *  be returned from LA(1).
 */
@Override
public int index() {
    return p;
}","/**
 * Return the current input symbol index 0..n where n indicates the
 *  last symbol has been read.  The index is the index of char to
 *  be returned from LA(1).
 */
", ,/** * Return the current input symbol index 0..n where n indicates the *  last symbol has been read.  The index is the index of char to *  be returned from LA(1). */,169,172,[0],0,[0],0,[0],0,0,0,0,index(),org.antlr.v4.runtime.ANTLRInputStream,index/0,False,170,0,0,0,0,1,0,3,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,22,1,0,True
88,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\ANTLRInputStream.java,org.antlr.v4.runtime.ANTLRInputStream,int mark(),"/**
 * mark/release do nothing; we have entire buffer
 */
@Override
public int mark() {
    return -1;
}","/**
 * mark/release do nothing; we have entire buffer
 */
", ,/** * mark/release do nothing; we have entire buffer */,180,183,[0],0,[0],0,[0],0,0,0,0,mark(),org.antlr.v4.runtime.ANTLRInputStream,mark/0,False,181,0,0,0,0,1,0,3,1,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,7,1,0,True
89,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\ANTLRInputStream.java,org.antlr.v4.runtime.ANTLRInputStream,void seek(int),"/**
 * consume() ahead until p==index; can't just set p=index as we must
 *  update line and charPositionInLine. If we seek backwards, just set p
 */
@Override
public void seek(int index) {
    if (index <= p) {
        // just jump; don't update stream state (line, ...)
        p = index;
        return;
    }
    // seek forward, consume until p hits index or n (whichever comes first)
    index = Math.min(index, n);
    while (p < index) {
        consume();
    }
}","/**
 * consume() ahead until p==index; can't just set p=index as we must
 *  update line and charPositionInLine. If we seek backwards, just set p
 */
","// just jump; don't update stream state (line, ...)
[[SEP]]// seek forward, consume until p hits index or n (whichever comes first)
","/** * consume() ahead until p==index; can't just set p=index as we must *  update line and charPositionInLine. If we seek backwards, just set p */[[SEP]]// just jump; don't update stream state (line, ...)[[SEP]]// seek forward, consume until p hits index or n (whichever comes first)",192,203,[0],0,"[0, 0]",0,"[0, 0, 0]",0,0,0,0,seek(int),org.antlr.v4.runtime.ANTLRInputStream,seek/1[int],False,193,1,1,0,1,3,2,10,1,0,1,2,1,2,1,0,0,0,0,0,2,0,1,0,0,0,15,1,0,True
90,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\ANTLRInputStream.java,org.antlr.v4.runtime.ANTLRInputStream,String getText(Interval),"@Override
public String getText(Interval interval) {
    int start = interval.a;
    int stop = interval.b;
    if (stop >= n)
        stop = n - 1;
    int count = stop - start + 1;
    if (start >= n)
        return """";
    // System.err.println(""data: ""+Arrays.toString(data)+"", n=""+n+
    // "", start=""+start+
    // "", stop=""+stop);
    return new String(data, start, count);
}", ,"// System.err.println(""data: ""+Arrays.toString(data)+"", n=""+n+
[[SEP]]// "", start=""+start+
[[SEP]]// "", stop=""+stop);
","// System.err.println(""data: ""+Arrays.toString(data)+"", n=""+n+// "", start=""+start+// "", stop=""+stop);",205,216,[0],0,"[0, 0, 0]",0,[0],0,0,0,0,getText(Interval),org.antlr.v4.runtime.ANTLRInputStream,getText/1[org.antlr.v4.runtime.misc.Interval],False,206,1,0,0,0,3,0,8,2,3,1,0,0,0,0,0,0,0,1,2,4,3,1,0,0,0,8,1,0,False
91,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\BailErrorStrategy.java,org.antlr.v4.runtime.BailErrorStrategy,"void recover(Parser, RecognitionException)","/**
 * Instead of recovering from exception {@code e}, re-throw it wrapped
 *  in a {@link ParseCancellationException} so it is not caught by the
 *  rule function catches.  Use {@link Exception#getCause()} to get the
 *  original {@link RecognitionException}.
 */
@Override
public void recover(Parser recognizer, RecognitionException e) {
    for (ParserRuleContext context = recognizer.getContext(); context != null; context = context.getParent()) {
        context.exception = e;
    }
    throw new ParseCancellationException(e);
}","/**
 * Instead of recovering from exception {@code e}, re-throw it wrapped
 *  in a {@link ParseCancellationException} so it is not caught by the
 *  rule function catches.  Use {@link Exception#getCause()} to get the
 *  original {@link RecognitionException}.
 */
", ,"/** * Instead of recovering from exception {@code e}, re-throw it wrapped *  in a {@link ParseCancellationException} so it is not caught by the *  rule function catches.  Use {@link Exception#getCause()} to get the *  original {@link RecognitionException}. */",45,52,[0],0,[0],0,[0],0,0,0,0,"recover(Parser, RecognitionException)",org.antlr.v4.runtime.BailErrorStrategy,"recover/2[org.antlr.v4.runtime.Parser,org.antlr.v4.runtime.RecognitionException]",False,46,4,3,0,3,2,2,6,0,1,2,2,0,0,1,1,0,0,0,0,3,0,1,0,0,0,32,1,0,True
92,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\BailErrorStrategy.java,org.antlr.v4.runtime.BailErrorStrategy,Token recoverInline(Parser),"/**
 * Make sure we don't attempt to recover inline; if the parser
 *  successfully recovers, it won't throw an exception.
 */
@Override
public Token recoverInline(Parser recognizer) throws RecognitionException {
    InputMismatchException e = new InputMismatchException(recognizer);
    for (ParserRuleContext context = recognizer.getContext(); context != null; context = context.getParent()) {
        context.exception = e;
    }
    throw new ParseCancellationException(e);
}","/**
 * Make sure we don't attempt to recover inline; if the parser
 *  successfully recovers, it won't throw an exception.
 */
", ,"/** * Make sure we don't attempt to recover inline; if the parser *  successfully recovers, it won't throw an exception. */",57,67,[0],0,[0],0,[0],0,0,0,0,recoverInline(Parser),org.antlr.v4.runtime.BailErrorStrategy,recoverInline/1[org.antlr.v4.runtime.Parser],False,60,5,4,0,4,2,2,7,0,2,1,2,0,0,1,1,0,0,0,0,4,0,1,0,0,0,27,1,0,True
93,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\BailErrorStrategy.java,org.antlr.v4.runtime.BailErrorStrategy,void sync(Parser),"/**
 * Make sure we don't attempt to recover from problems in subrules.
 */
@Override
public void sync(Parser recognizer) {
}","/**
 * Make sure we don't attempt to recover from problems in subrules.
 */
", ,/** * Make sure we don't attempt to recover from problems in subrules. */,70,71,[0],0,[0],0,[0],0,0,0,0,sync(Parser),org.antlr.v4.runtime.BailErrorStrategy,sync/1[org.antlr.v4.runtime.Parser],False,71,1,0,0,0,1,0,2,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,12,1,0,True
94,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\BufferedTokenStream.java,org.antlr.v4.runtime.BufferedTokenStream,void release(int),"@Override
public void release(int marker) {
    // no resources to release
}", ,"// no resources to release
",// no resources to release,87,90,[0],0,[0],0,[0],0,0,0,0,release(int),org.antlr.v4.runtime.BufferedTokenStream,release/1[int],False,88,0,0,0,0,1,0,2,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,1,0,False
95,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\BufferedTokenStream.java,org.antlr.v4.runtime.BufferedTokenStream,void reset(),"/**
 * This method resets the token stream back to the first token in the
 * buffer. It is equivalent to calling {@link #seek}{@code (0)}.
 *
 * @see #setTokenSource(TokenSource)
 * @deprecated Use {@code seek(0)} instead.
 */
@Deprecated
public void reset() {
    seek(0);
}","/**
 * This method resets the token stream back to the first token in the
 * buffer. It is equivalent to calling {@link #seek}{@code (0)}.
 *
 * @see #setTokenSource(TokenSource)
 * @deprecated Use {@code seek(0)} instead.
 */
", ,/** * This method resets the token stream back to the first token in the * buffer. It is equivalent to calling {@link #seek}{@code (0)}. * * @see #setTokenSource(TokenSource) * @deprecated Use {@code seek(0)} instead. */,99,102,[1],1,[0],0,[1],1,0,0,0,reset(),org.antlr.v4.runtime.BufferedTokenStream,reset/0,False,100,1,1,0,1,1,1,3,0,0,0,1,1,5,0,0,0,0,0,1,0,0,0,0,0,0,19,1,0,True
96,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\BufferedTokenStream.java,org.antlr.v4.runtime.BufferedTokenStream,void consume(),"@Override
public void consume() {
    boolean skipEofCheck;
    if (p >= 0) {
        if (fetchedEOF) {
            // the last token in tokens is EOF. skip check if p indexes any
            // fetched token except the last.
            skipEofCheck = p < tokens.size() - 1;
        } else {
            // no EOF token in tokens. skip check if p indexes a fetched token.
            skipEofCheck = p < tokens.size();
        }
    } else {
        // not yet initialized
        skipEofCheck = false;
    }
    if (!skipEofCheck && LA(1) == EOF) {
        throw new IllegalStateException(""cannot consume EOF"");
    }
    if (sync(p + 1)) {
        p = adjustSeekIndex(p + 1);
    }
}", ,"// the last token in tokens is EOF. skip check if p indexes any
[[SEP]]// fetched token except the last.
[[SEP]]// no EOF token in tokens. skip check if p indexes a fetched token.
[[SEP]]// not yet initialized
",// the last token in tokens is EOF. skip check if p indexes any// fetched token except the last.[[SEP]]// no EOF token in tokens. skip check if p indexes a fetched token.[[SEP]]// not yet initialized,113,139,[0],0,"[0, 0, 0, 0]",0,"[0, 0, 0]",0,0,0,0,consume(),org.antlr.v4.runtime.BufferedTokenStream,consume/0,False,114,1,3,0,3,6,4,20,0,1,0,4,3,6,0,1,0,0,1,5,4,3,2,0,0,0,19,1,0,False
97,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\BufferedTokenStream.java,org.antlr.v4.runtime.BufferedTokenStream,boolean sync(int),"/**
 * Make sure index {@code i} in tokens has a token.
 *
 * @return {@code true} if a token is located at index {@code i}, otherwise
 *    {@code false}.
 * @see #get(int i)
 */
protected boolean sync(int i) {
    assert i >= 0;
    // how many more elements we need?
    int n = i - tokens.size() + 1;
    // System.out.println(""sync(""+i+"") needs ""+n);
    if (n > 0) {
        int fetched = fetch(n);
        return fetched >= n;
    }
    return true;
}","/**
 * Make sure index {@code i} in tokens has a token.
 *
 * @return {@code true} if a token is located at index {@code i}, otherwise
 *    {@code false}.
 * @see #get(int i)
 */
","// how many more elements we need?
[[SEP]]// System.out.println(""sync(""+i+"") needs ""+n);
","/** * Make sure index {@code i} in tokens has a token. * * @return {@code true} if a token is located at index {@code i}, otherwise *    {@code false}. * @see #get(int i) */[[SEP]]// how many more elements we need?[[SEP]]// System.out.println(""sync(""+i+"") needs ""+n);",147,157,[0],0,"[0, 0]",0,"[0, 0, 0]",0,0,1,0,sync(int),org.antlr.v4.runtime.BufferedTokenStream,sync/1[int],False,147,1,8,7,1,3,2,9,2,2,1,2,1,1,0,0,0,0,0,3,2,2,1,0,0,0,20,4,0,True
98,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\BufferedTokenStream.java,org.antlr.v4.runtime.BufferedTokenStream,int fetch(int),"/**
 * Add {@code n} elements to buffer.
 *
 * @return The actual number of elements added to the buffer.
 */
protected int fetch(int n) {
    if (fetchedEOF) {
        return 0;
    }
    for (int i = 0; i < n; i++) {
        Token t = tokenSource.nextToken();
        if (t instanceof WritableToken) {
            ((WritableToken) t).setTokenIndex(tokens.size());
        }
        tokens.add(t);
        if (t.getType() == Token.EOF) {
            fetchedEOF = true;
            return i + 1;
        }
    }
    return n;
}","/**
 * Add {@code n} elements to buffer.
 *
 * @return The actual number of elements added to the buffer.
 */
", ,/** * Add {@code n} elements to buffer. * * @return The actual number of elements added to the buffer. */,163,181,[0],0,[0],0,[0],0,0,0,0,fetch(int),org.antlr.v4.runtime.BufferedTokenStream,fetch/1[int],False,163,3,5,2,3,5,5,17,3,2,1,5,0,0,1,1,0,1,0,3,3,1,2,0,0,0,20,4,0,True
99,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\BufferedTokenStream.java,org.antlr.v4.runtime.BufferedTokenStream,"List<Token> get(int, int)","/**
 * Get all tokens from start..stop inclusively
 */
public List<Token> get(int start, int stop) {
    if (start < 0 || stop < 0)
        return null;
    lazyInit();
    List<Token> subset = new ArrayList<Token>();
    if (stop >= tokens.size())
        stop = tokens.size() - 1;
    for (int i = start; i <= stop; i++) {
        Token t = tokens.get(i);
        if (t.getType() == Token.EOF)
            break;
        subset.add(t);
    }
    return subset;
}","/**
 * Get all tokens from start..stop inclusively
 */
", ,/** * Get all tokens from start..stop inclusively */,192,203,[0],0,[0],0,[0],0,0,0,0,"get(int, int)",org.antlr.v4.runtime.BufferedTokenStream,"get/2[int,int]",False,192,2,2,0,2,6,5,12,2,3,2,5,1,4,1,1,0,0,0,3,4,1,2,0,0,0,15,1,0,True
100,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\BufferedTokenStream.java,org.antlr.v4.runtime.BufferedTokenStream,Token LT(int),"@Override
public Token LT(int k) {
    lazyInit();
    if (k == 0)
        return null;
    if (k < 0)
        return LB(-k);
    int i = p + k - 1;
    sync(i);
    if (i >= tokens.size()) {
        // return EOF token
        // EOF must be last token
        return tokens.get(tokens.size() - 1);
    }
    // if ( i>range ) range = i;
    return tokens.get(i);
}", ,"// return EOF token
[[SEP]]// EOF must be last token
[[SEP]]// if ( i>range ) range = i;
",// return EOF token// EOF must be last token[[SEP]]// if ( i>range ) range = i;,214,228,[0],0,"[0, 0, 0]",0,"[0, 0]",0,0,0,0,LT(int),org.antlr.v4.runtime.BufferedTokenStream,LT/1[int],False,215,2,4,1,3,4,5,11,4,1,1,5,3,4,0,1,0,0,0,4,1,3,1,0,0,0,11,1,0,False
101,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\BufferedTokenStream.java,org.antlr.v4.runtime.BufferedTokenStream,int adjustSeekIndex(int),"/**
 * Allowed derived classes to modify the behavior of operations which change
 * the current stream position by adjusting the target token index of a seek
 * operation. The default implementation simply returns {@code i}. If an
 * exception is thrown in this method, the current stream index should not be
 * changed.
 *
 * <p>For example, {@link CommonTokenStream} overrides this method to ensure that
 * the seek target is always an on-channel token.</p>
 *
 * @param i The target token index.
 * @return The adjusted target token index.
 */
protected int adjustSeekIndex(int i) {
    return i;
}","/**
 * Allowed derived classes to modify the behavior of operations which change
 * the current stream position by adjusting the target token index of a seek
 * operation. The default implementation simply returns {@code i}. If an
 * exception is thrown in this method, the current stream index should not be
 * changed.
 *
 * <p>For example, {@link CommonTokenStream} overrides this method to ensure that
 * the seek target is always an on-channel token.</p>
 *
 * @param i The target token index.
 * @return The adjusted target token index.
 */
", ,"/** * Allowed derived classes to modify the behavior of operations which change * the current stream position by adjusting the target token index of a seek * operation. The default implementation simply returns {@code i}. If an * exception is thrown in this method, the current stream index should not be * changed. * * <p>For example, {@link CommonTokenStream} overrides this method to ensure that * the seek target is always an on-channel token.</p> * * @param i The target token index. * @return The adjusted target token index. */",243,245,[0],0,[0],0,[0],0,0,0,0,adjustSeekIndex(int),org.antlr.v4.runtime.BufferedTokenStream,adjustSeekIndex/1[int],False,243,0,3,3,0,1,0,3,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,51,4,0,True
102,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\BufferedTokenStream.java,org.antlr.v4.runtime.BufferedTokenStream,void setTokenSource(TokenSource),"/**
 * Reset this token stream by setting its token source.
 */
public void setTokenSource(TokenSource tokenSource) {
    this.tokenSource = tokenSource;
    tokens.clear();
    p = -1;
    fetchedEOF = false;
}","/**
 * Reset this token stream by setting its token source.
 */
", ,/** * Reset this token stream by setting its token source. */,259,264,[0],0,[0],0,[0],0,0,0,0,setTokenSource(TokenSource),org.antlr.v4.runtime.BufferedTokenStream,setTokenSource/1[org.antlr.v4.runtime.TokenSource],False,259,1,1,1,0,1,1,6,0,0,1,1,0,0,0,0,0,0,0,1,3,0,0,0,0,0,15,1,0,True
103,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\BufferedTokenStream.java,org.antlr.v4.runtime.BufferedTokenStream,"List<Token> getTokens(int, int, Set<Integer>)","/**
 * Given a start and stop index, return a List of all tokens in
 *  the token type BitSet.  Return null if no tokens were found.  This
 *  method looks at both on and off channel tokens.
 */
public List<Token> getTokens(int start, int stop, Set<Integer> types) {
    lazyInit();
    if (start < 0 || stop >= tokens.size() || stop < 0 || start >= tokens.size()) {
        throw new IndexOutOfBoundsException(""start "" + start + "" or stop "" + stop + "" not in 0.."" + (tokens.size() - 1));
    }
    if (start > stop)
        return null;
    // list = tokens[start:stop]:{T t, t.getType() in types}
    List<Token> filteredTokens = new ArrayList<Token>();
    for (int i = start; i <= stop; i++) {
        Token t = tokens.get(i);
        if (types == null || types.contains(t.getType())) {
            filteredTokens.add(t);
        }
    }
    if (filteredTokens.isEmpty()) {
        filteredTokens = null;
    }
    return filteredTokens;
}","/**
 * Given a start and stop index, return a List of all tokens in
 *  the token type BitSet.  Return null if no tokens were found.  This
 *  method looks at both on and off channel tokens.
 */
","// list = tokens[start:stop]:{T t, t.getType() in types}
","/** * Given a start and stop index, return a List of all tokens in *  the token type BitSet.  Return null if no tokens were found.  This *  method looks at both on and off channel tokens. */[[SEP]]// list = tokens[start:stop]:{T t, t.getType() in types}",276,298,[0],0,[0],0,"[0, 0]",0,0,0,0,"getTokens(int, int, Set<Integer>)",org.antlr.v4.runtime.BufferedTokenStream,"getTokens/3[int,int,java.util.Set<java.lang.Integer>]",False,276,2,4,2,2,10,7,18,2,3,3,7,1,4,1,1,0,1,3,3,4,2,2,0,0,0,41,1,0,True
104,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\BufferedTokenStream.java,org.antlr.v4.runtime.BufferedTokenStream,"int nextTokenOnChannel(int, int)","/**
 * Given a starting index, return the index of the next token on channel.
 * Return {@code i} if {@code tokens[i]} is on channel. Return the index of
 * the EOF token if there are no tokens on channel between {@code i} and
 * EOF.
 */
protected int nextTokenOnChannel(int i, int channel) {
    sync(i);
    if (i >= size()) {
        return size() - 1;
    }
    Token token = tokens.get(i);
    while (token.getChannel() != channel) {
        if (token.getType() == Token.EOF) {
            return i;
        }
        i++;
        sync(i);
        token = tokens.get(i);
    }
    return i;
}","/**
 * Given a starting index, return the index of the next token on channel.
 * Return {@code i} if {@code tokens[i]} is on channel. Return the index of
 * the EOF token if there are no tokens on channel between {@code i} and
 * EOF.
 */
", ,"/** * Given a starting index, return the index of the next token on channel. * Return {@code i} if {@code tokens[i]} is on channel. Return the index of * the EOF token if there are no tokens on channel between {@code i} and * EOF. */",312,330,[0],0,[0],0,[0],0,0,0,0,"nextTokenOnChannel(int, int)",org.antlr.v4.runtime.BufferedTokenStream,"nextTokenOnChannel/2[int,int]",False,312,2,7,3,4,4,5,16,3,1,2,5,2,2,1,2,0,0,0,1,2,1,2,0,0,0,27,4,0,True
105,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\BufferedTokenStream.java,org.antlr.v4.runtime.BufferedTokenStream,"int previousTokenOnChannel(int, int)","/**
 * Given a starting index, return the index of the previous token on
 * channel. Return {@code i} if {@code tokens[i]} is on channel. Return -1
 * if there are no tokens on channel between {@code i} and 0.
 *
 * <p>
 * If {@code i} specifies an index at or after the EOF token, the EOF token
 * index is returned. This is due to the fact that the EOF token is treated
 * as though it were on every channel.</p>
 */
protected int previousTokenOnChannel(int i, int channel) {
    sync(i);
    if (i >= size()) {
        // the EOF token is on every channel
        return size() - 1;
    }
    while (i >= 0) {
        Token token = tokens.get(i);
        if (token.getType() == Token.EOF || token.getChannel() == channel) {
            return i;
        }
        i--;
    }
    return i;
}","/**
 * Given a starting index, return the index of the previous token on
 * channel. Return {@code i} if {@code tokens[i]} is on channel. Return -1
 * if there are no tokens on channel between {@code i} and 0.
 *
 * <p>
 * If {@code i} specifies an index at or after the EOF token, the EOF token
 * index is returned. This is due to the fact that the EOF token is treated
 * as though it were on every channel.</p>
 */
","// the EOF token is on every channel
","/** * Given a starting index, return the index of the previous token on * channel. Return {@code i} if {@code tokens[i]} is on channel. Return -1 * if there are no tokens on channel between {@code i} and 0. * * <p> * If {@code i} specifies an index at or after the EOF token, the EOF token * index is returned. This is due to the fact that the EOF token is treated * as though it were on every channel.</p> */[[SEP]]// the EOF token is on every channel",342,359,[0],0,[0],0,"[0, 0]",0,0,0,0,"previousTokenOnChannel(int, int)",org.antlr.v4.runtime.BufferedTokenStream,"previousTokenOnChannel/2[int,int]",False,342,2,6,2,4,5,5,14,3,1,2,5,2,2,1,2,0,0,0,2,1,1,2,0,0,0,47,4,0,True
106,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\BufferedTokenStream.java,org.antlr.v4.runtime.BufferedTokenStream,"List<Token> getHiddenTokensToRight(int, int)","/**
 * Collect all tokens on specified channel to the right of
 *  the current token up until we see a token on DEFAULT_TOKEN_CHANNEL or
 *  EOF. If channel is -1, find any non default channel token.
 */
public List<Token> getHiddenTokensToRight(int tokenIndex, int channel) {
    lazyInit();
    if (tokenIndex < 0 || tokenIndex >= tokens.size()) {
        throw new IndexOutOfBoundsException(tokenIndex + "" not in 0.."" + (tokens.size() - 1));
    }
    int nextOnChannel = nextTokenOnChannel(tokenIndex + 1, Lexer.DEFAULT_TOKEN_CHANNEL);
    int to;
    int from = tokenIndex + 1;
    // if none onchannel to right, nextOnChannel=-1 so set to = last token
    if (nextOnChannel == -1)
        to = size() - 1;
    else
        to = nextOnChannel;
    return filterForChannel(from, to, channel);
}","/**
 * Collect all tokens on specified channel to the right of
 *  the current token up until we see a token on DEFAULT_TOKEN_CHANNEL or
 *  EOF. If channel is -1, find any non default channel token.
 */
","// if none onchannel to right, nextOnChannel=-1 so set to = last token
","/** * Collect all tokens on specified channel to the right of *  the current token up until we see a token on DEFAULT_TOKEN_CHANNEL or *  EOF. If channel is -1, find any non default channel token. */[[SEP]]// if none onchannel to right, nextOnChannel=-1 so set to = last token",365,380,[0],0,[0],0,"[0, 0]",0,0,0,0,"getHiddenTokensToRight(int, int)",org.antlr.v4.runtime.BufferedTokenStream,"getHiddenTokensToRight/2[int,int]",False,365,2,5,1,4,4,5,12,1,3,2,5,4,5,0,1,0,1,1,6,4,5,1,0,0,0,58,1,0,True
107,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\BufferedTokenStream.java,org.antlr.v4.runtime.BufferedTokenStream,List<Token> getHiddenTokensToRight(int),"/**
 * Collect all hidden tokens (any off-default channel) to the right of
 *  the current token up until we see a token on DEFAULT_TOKEN_CHANNEL
 *  or EOF.
 */
public List<Token> getHiddenTokensToRight(int tokenIndex) {
    return getHiddenTokensToRight(tokenIndex, -1);
}","/**
 * Collect all hidden tokens (any off-default channel) to the right of
 *  the current token up until we see a token on DEFAULT_TOKEN_CHANNEL
 *  or EOF.
 */
", ,/** * Collect all hidden tokens (any off-default channel) to the right of *  the current token up until we see a token on DEFAULT_TOKEN_CHANNEL *  or EOF. */,386,388,[0],0,[0],0,[0],0,0,0,0,getHiddenTokensToRight(int),org.antlr.v4.runtime.BufferedTokenStream,getHiddenTokensToRight/1[int],False,386,2,1,0,1,1,1,3,1,0,1,1,1,6,0,0,0,0,0,1,0,0,0,0,0,0,39,1,0,True
108,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\BufferedTokenStream.java,org.antlr.v4.runtime.BufferedTokenStream,"List<Token> getHiddenTokensToLeft(int, int)","/**
 * Collect all tokens on specified channel to the left of
 *  the current token up until we see a token on DEFAULT_TOKEN_CHANNEL.
 *  If channel is -1, find any non default channel token.
 */
public List<Token> getHiddenTokensToLeft(int tokenIndex, int channel) {
    lazyInit();
    if (tokenIndex < 0 || tokenIndex >= tokens.size()) {
        throw new IndexOutOfBoundsException(tokenIndex + "" not in 0.."" + (tokens.size() - 1));
    }
    if (tokenIndex == 0) {
        // obviously no tokens can appear before the first token
        return null;
    }
    int prevOnChannel = previousTokenOnChannel(tokenIndex - 1, Lexer.DEFAULT_TOKEN_CHANNEL);
    if (prevOnChannel == tokenIndex - 1)
        return null;
    // if none onchannel to left, prevOnChannel=-1 then from=0
    int from = prevOnChannel + 1;
    int to = tokenIndex - 1;
    return filterForChannel(from, to, channel);
}","/**
 * Collect all tokens on specified channel to the left of
 *  the current token up until we see a token on DEFAULT_TOKEN_CHANNEL.
 *  If channel is -1, find any non default channel token.
 */
","// obviously no tokens can appear before the first token
[[SEP]]// if none onchannel to left, prevOnChannel=-1 then from=0
","/** * Collect all tokens on specified channel to the left of *  the current token up until we see a token on DEFAULT_TOKEN_CHANNEL. *  If channel is -1, find any non default channel token. */[[SEP]]// obviously no tokens can appear before the first token[[SEP]]// if none onchannel to left, prevOnChannel=-1 then from=0",394,413,[0],0,"[0, 0]",0,"[0, 0, 0]",0,0,0,0,"getHiddenTokensToLeft(int, int)",org.antlr.v4.runtime.BufferedTokenStream,"getHiddenTokensToLeft/2[int,int]",False,394,2,4,1,3,5,4,14,3,3,2,4,3,5,0,2,0,1,1,7,3,6,1,0,0,0,45,1,0,True
109,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\BufferedTokenStream.java,org.antlr.v4.runtime.BufferedTokenStream,List<Token> getHiddenTokensToLeft(int),"/**
 * Collect all hidden tokens (any off-default channel) to the left of
 *  the current token up until we see a token on DEFAULT_TOKEN_CHANNEL.
 */
public List<Token> getHiddenTokensToLeft(int tokenIndex) {
    return getHiddenTokensToLeft(tokenIndex, -1);
}","/**
 * Collect all hidden tokens (any off-default channel) to the left of
 *  the current token up until we see a token on DEFAULT_TOKEN_CHANNEL.
 */
", ,/** * Collect all hidden tokens (any off-default channel) to the left of *  the current token up until we see a token on DEFAULT_TOKEN_CHANNEL. */,418,420,[0],0,[0],0,[0],0,0,0,0,getHiddenTokensToLeft(int),org.antlr.v4.runtime.BufferedTokenStream,getHiddenTokensToLeft/1[int],False,418,2,1,0,1,1,1,3,1,0,1,1,1,6,0,0,0,0,0,1,0,0,0,0,0,0,25,1,0,True
110,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\BufferedTokenStream.java,org.antlr.v4.runtime.BufferedTokenStream,void fill(),"/**
 * Get all tokens from lexer until EOF
 */
public void fill() {
    lazyInit();
    final int blockSize = 1000;
    while (true) {
        int fetched = fetch(blockSize);
        if (fetched < blockSize) {
            return;
        }
    }
}","/**
 * Get all tokens from lexer until EOF
 */
", ,/** * Get all tokens from lexer until EOF */,481,490,[0],0,[0],0,[0],0,0,0,0,fill(),org.antlr.v4.runtime.BufferedTokenStream,fill/0,False,481,1,51,49,2,3,2,10,1,2,0,2,2,4,1,0,0,0,0,1,2,0,2,0,0,0,17,1,0,True
111,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\CharStream.java,org.antlr.v4.runtime.CharStream,String getText(Interval),"/**
 * This method returns the text for a range of characters within this input
 * stream. This method is guaranteed to not throw an exception if the
 * specified {@code interval} lies entirely within a marked range. For more
 * information about marked ranges, see {@link IntStream#mark}.
 *
 * @param interval an interval within the stream
 * @return the text of the specified interval
 *
 * @throws NullPointerException if {@code interval} is {@code null}
 * @throws IllegalArgumentException if {@code interval.a < 0}, or if
 * {@code interval.b < interval.a - 1}, or if {@code interval.b} lies at or
 * past the end of the stream
 * @throws UnsupportedOperationException if the stream does not support
 * getting the text of the specified interval
 */
public String getText(Interval interval);","/**
 * This method returns the text for a range of characters within this input
 * stream. This method is guaranteed to not throw an exception if the
 * specified {@code interval} lies entirely within a marked range. For more
 * information about marked ranges, see {@link IntStream#mark}.
 *
 * @param interval an interval within the stream
 * @return the text of the specified interval
 *
 * @throws NullPointerException if {@code interval} is {@code null}
 * @throws IllegalArgumentException if {@code interval.a < 0}, or if
 * {@code interval.b < interval.a - 1}, or if {@code interval.b} lies at or
 * past the end of the stream
 * @throws UnsupportedOperationException if the stream does not support
 * getting the text of the specified interval
 */
", ,"/** * This method returns the text for a range of characters within this input * stream. This method is guaranteed to not throw an exception if the * specified {@code interval} lies entirely within a marked range. For more * information about marked ranges, see {@link IntStream#mark}. * * @param interval an interval within the stream * @return the text of the specified interval * * @throws NullPointerException if {@code interval} is {@code null} * @throws IllegalArgumentException if {@code interval.a < 0}, or if * {@code interval.b < interval.a - 1}, or if {@code interval.b} lies at or * past the end of the stream * @throws UnsupportedOperationException if the stream does not support * getting the text of the specified interval */",29,29,[0],0,[0],0,[0],0,0,0,0,getText(Interval),org.antlr.v4.runtime.CharStream,getText/1[org.antlr.v4.runtime.misc.Interval],False,13,1,11,11,0,1,0,1,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,44,1,0,True
112,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\CharStreams.java,org.antlr.v4.runtime.CharStreams,CharStream fromPath(Path),"/**
 * Creates a {@link CharStream} given a path to a UTF-8
 * encoded file on disk.
 *
 * Reads the entire contents of the file into the result before returning.
 */
public static CharStream fromPath(Path path) throws IOException {
    return fromPath(path, StandardCharsets.UTF_8);
}","/**
 * Creates a {@link CharStream} given a path to a UTF-8
 * encoded file on disk.
 *
 * Reads the entire contents of the file into the result before returning.
 */
", ,/** * Creates a {@link CharStream} given a path to a UTF-8 * encoded file on disk. * * Reads the entire contents of the file into the result before returning. */,75,77,[0],0,[0],0,[0],0,0,0,0,fromPath(Path),org.antlr.v4.runtime.CharStreams,fromPath/1[java.nio.file.Path],False,75,2,3,2,1,1,1,3,1,0,1,1,1,2,0,0,0,0,0,0,0,0,0,0,0,0,26,9,0,True
113,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\CharStreams.java,org.antlr.v4.runtime.CharStreams,"CharStream fromPath(Path, Charset)","/**
 * Creates a {@link CharStream} given a path to a file on disk and the
 * charset of the bytes contained in the file.
 *
 * Reads the entire contents of the file into the result before returning.
 */
public static CharStream fromPath(Path path, Charset charset) throws IOException {
    long size = Files.size(path);
    try (ReadableByteChannel channel = Files.newByteChannel(path)) {
        return fromChannel(channel, charset, DEFAULT_BUFFER_SIZE, CodingErrorAction.REPLACE, path.toString(), size);
    }
}","/**
 * Creates a {@link CharStream} given a path to a file on disk and the
 * charset of the bytes contained in the file.
 *
 * Reads the entire contents of the file into the result before returning.
 */
", ,/** * Creates a {@link CharStream} given a path to a file on disk and the * charset of the bytes contained in the file. * * Reads the entire contents of the file into the result before returning. */,85,96,[0],0,[0],0,[0],0,0,0,0,"fromPath(Path, Charset)",org.antlr.v4.runtime.CharStreams,"fromPath/2[java.nio.file.Path,java.nio.charset.Charset]",False,85,3,8,7,1,1,4,6,1,2,2,4,1,1,0,0,1,0,0,0,2,0,1,0,0,0,34,9,0,True
114,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\CharStreams.java,org.antlr.v4.runtime.CharStreams,CharStream fromFileName(String),"/**
 * Creates a {@link CharStream} given a string containing a
 * path to a UTF-8 file on disk.
 *
 * Reads the entire contents of the file into the result before returning.
 */
public static CharStream fromFileName(String fileName) throws IOException {
    return fromPath(Paths.get(fileName), StandardCharsets.UTF_8);
}","/**
 * Creates a {@link CharStream} given a string containing a
 * path to a UTF-8 file on disk.
 *
 * Reads the entire contents of the file into the result before returning.
 */
", ,/** * Creates a {@link CharStream} given a string containing a * path to a UTF-8 file on disk. * * Reads the entire contents of the file into the result before returning. */,104,106,[0],0,[0],0,[0],0,0,0,0,fromFileName(String),org.antlr.v4.runtime.CharStreams,fromFileName/1[java.lang.String],False,104,2,2,1,1,1,2,3,1,0,1,2,1,2,0,0,0,0,0,0,0,0,0,0,0,0,29,9,0,True
115,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\CharStreams.java,org.antlr.v4.runtime.CharStreams,"CharStream fromFileName(String, Charset)","/**
 * Creates a {@link CharStream} given a string containing a
 * path to a file on disk and the charset of the bytes
 * contained in the file.
 *
 * Reads the entire contents of the file into the result before returning.
 */
public static CharStream fromFileName(String fileName, Charset charset) throws IOException {
    return fromPath(Paths.get(fileName), charset);
}","/**
 * Creates a {@link CharStream} given a string containing a
 * path to a file on disk and the charset of the bytes
 * contained in the file.
 *
 * Reads the entire contents of the file into the result before returning.
 */
", ,/** * Creates a {@link CharStream} given a string containing a * path to a file on disk and the charset of the bytes * contained in the file. * * Reads the entire contents of the file into the result before returning. */,115,117,[0],0,[0],0,[0],0,0,0,0,"fromFileName(String, Charset)",org.antlr.v4.runtime.CharStreams,"fromFileName/2[java.lang.String,java.nio.charset.Charset]",False,115,2,2,1,1,1,2,3,1,0,2,2,1,2,0,0,0,0,0,0,0,0,0,0,0,0,32,9,0,True
116,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\CharStreams.java,org.antlr.v4.runtime.CharStreams,CharStream fromStream(InputStream),"/**
 * Creates a {@link CharStream} given an opened {@link InputStream}
 * containing UTF-8 bytes.
 *
 * Reads the entire contents of the {@code InputStream} into
 * the result before returning, then closes the {@code InputStream}.
 */
public static CharStream fromStream(InputStream is) throws IOException {
    return fromStream(is, StandardCharsets.UTF_8);
}","/**
 * Creates a {@link CharStream} given an opened {@link InputStream}
 * containing UTF-8 bytes.
 *
 * Reads the entire contents of the {@code InputStream} into
 * the result before returning, then closes the {@code InputStream}.
 */
", ,"/** * Creates a {@link CharStream} given an opened {@link InputStream} * containing UTF-8 bytes. * * Reads the entire contents of the {@code InputStream} into * the result before returning, then closes the {@code InputStream}. */",127,129,[0],0,[0],0,[0],0,0,0,0,fromStream(InputStream),org.antlr.v4.runtime.CharStreams,fromStream/1[java.io.InputStream],False,127,2,3,2,1,1,1,3,1,0,1,1,1,3,0,0,0,0,0,0,0,0,0,0,0,0,27,9,0,True
117,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\CharStreams.java,org.antlr.v4.runtime.CharStreams,"CharStream fromStream(InputStream, Charset)","/**
 * Creates a {@link CharStream} given an opened {@link InputStream} and the
 * charset of the bytes contained in the stream.
 *
 * Reads the entire contents of the {@code InputStream} into
 * the result before returning, then closes the {@code InputStream}.
 */
public static CharStream fromStream(InputStream is, Charset charset) throws IOException {
    return fromStream(is, charset, -1);
}","/**
 * Creates a {@link CharStream} given an opened {@link InputStream} and the
 * charset of the bytes contained in the stream.
 *
 * Reads the entire contents of the {@code InputStream} into
 * the result before returning, then closes the {@code InputStream}.
 */
", ,"/** * Creates a {@link CharStream} given an opened {@link InputStream} and the * charset of the bytes contained in the stream. * * Reads the entire contents of the {@code InputStream} into * the result before returning, then closes the {@code InputStream}. */",138,140,[0],0,[0],0,[0],0,0,0,0,"fromStream(InputStream, Charset)",org.antlr.v4.runtime.CharStreams,"fromStream/2[java.io.InputStream,java.nio.charset.Charset]",False,138,2,4,3,1,1,1,3,1,0,2,1,1,2,0,0,0,0,0,1,0,0,0,0,0,0,28,9,0,True
118,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\CharStreams.java,org.antlr.v4.runtime.CharStreams,CharStream fromChannel(ReadableByteChannel),"/**
 * Creates a {@link CharStream} given an opened {@link ReadableByteChannel}
 * containing UTF-8 bytes.
 *
 * Reads the entire contents of the {@code channel} into
 * the result before returning, then closes the {@code channel}.
 */
public static CharStream fromChannel(ReadableByteChannel channel) throws IOException {
    return fromChannel(channel, StandardCharsets.UTF_8);
}","/**
 * Creates a {@link CharStream} given an opened {@link ReadableByteChannel}
 * containing UTF-8 bytes.
 *
 * Reads the entire contents of the {@code channel} into
 * the result before returning, then closes the {@code channel}.
 */
", ,"/** * Creates a {@link CharStream} given an opened {@link ReadableByteChannel} * containing UTF-8 bytes. * * Reads the entire contents of the {@code channel} into * the result before returning, then closes the {@code channel}. */",161,163,[0],0,[0],0,[0],0,0,0,0,fromChannel(ReadableByteChannel),org.antlr.v4.runtime.CharStreams,fromChannel/1[java.nio.channels.ReadableByteChannel],False,161,2,1,0,1,1,1,3,1,0,1,1,1,3,0,0,0,0,0,0,0,0,0,0,0,0,29,9,0,True
119,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\CharStreams.java,org.antlr.v4.runtime.CharStreams,"CharStream fromChannel(ReadableByteChannel, Charset)","/**
 * Creates a {@link CharStream} given an opened {@link ReadableByteChannel} and the
 * charset of the bytes contained in the channel.
 *
 * Reads the entire contents of the {@code channel} into
 * the result before returning, then closes the {@code channel}.
 */
public static CharStream fromChannel(ReadableByteChannel channel, Charset charset) throws IOException {
    return fromChannel(channel, DEFAULT_BUFFER_SIZE, CodingErrorAction.REPLACE, IntStream.UNKNOWN_SOURCE_NAME);
}","/**
 * Creates a {@link CharStream} given an opened {@link ReadableByteChannel} and the
 * charset of the bytes contained in the channel.
 *
 * Reads the entire contents of the {@code channel} into
 * the result before returning, then closes the {@code channel}.
 */
", ,"/** * Creates a {@link CharStream} given an opened {@link ReadableByteChannel} and the * charset of the bytes contained in the channel. * * Reads the entire contents of the {@code channel} into * the result before returning, then closes the {@code channel}. */",172,178,[0],0,[0],0,[0],0,0,0,0,"fromChannel(ReadableByteChannel, Charset)",org.antlr.v4.runtime.CharStreams,"fromChannel/2[java.nio.channels.ReadableByteChannel,java.nio.charset.Charset]",False,172,3,2,1,1,1,1,3,1,0,2,1,1,2,0,0,0,0,0,0,0,0,0,0,0,0,31,9,0,True
120,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\CharStreams.java,org.antlr.v4.runtime.CharStreams,CodePointCharStream fromReader(Reader),"/**
 * Creates a {@link CharStream} given a {@link Reader}. Closes
 * the reader before returning.
 */
public static CodePointCharStream fromReader(Reader r) throws IOException {
    return fromReader(r, IntStream.UNKNOWN_SOURCE_NAME);
}","/**
 * Creates a {@link CharStream} given a {@link Reader}. Closes
 * the reader before returning.
 */
", ,/** * Creates a {@link CharStream} given a {@link Reader}. Closes * the reader before returning. */,184,186,[0],0,[0],0,[0],0,0,0,0,fromReader(Reader),org.antlr.v4.runtime.CharStreams,fromReader/1[java.io.Reader],False,184,2,2,1,1,1,1,3,1,0,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,17,9,0,True
121,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\CharStreams.java,org.antlr.v4.runtime.CharStreams,"CodePointCharStream fromReader(Reader, String)","/**
 * Creates a {@link CharStream} given a {@link Reader} and its
 * source name. Closes the reader before returning.
 */
public static CodePointCharStream fromReader(Reader r, String sourceName) throws IOException {
    try {
        CodePointBuffer.Builder codePointBufferBuilder = CodePointBuffer.builder(DEFAULT_BUFFER_SIZE);
        CharBuffer charBuffer = CharBuffer.allocate(DEFAULT_BUFFER_SIZE);
        while ((r.read(charBuffer)) != -1) {
            charBuffer.flip();
            codePointBufferBuilder.append(charBuffer);
            charBuffer.compact();
        }
        return CodePointCharStream.fromBuffer(codePointBufferBuilder.build(), sourceName);
    } finally {
        r.close();
    }
}","/**
 * Creates a {@link CharStream} given a {@link Reader} and its
 * source name. Closes the reader before returning.
 */
", ,/** * Creates a {@link CharStream} given a {@link Reader} and its * source name. Closes the reader before returning. */,192,206,[0],0,[0],0,[0],0,0,0,0,"fromReader(Reader, String)",org.antlr.v4.runtime.CharStreams,"fromReader/2[java.io.Reader,java.lang.String]",False,192,3,5,1,4,2,9,15,1,2,2,9,0,0,1,1,1,1,0,1,2,0,2,0,0,0,36,9,0,True
122,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\CharStreams.java,org.antlr.v4.runtime.CharStreams,CodePointCharStream fromString(String),"/**
 * Creates a {@link CharStream} given a {@link String}.
 */
public static CodePointCharStream fromString(String s) {
    return fromString(s, IntStream.UNKNOWN_SOURCE_NAME);
}","/**
 * Creates a {@link CharStream} given a {@link String}.
 */
", ,/** * Creates a {@link CharStream} given a {@link String}. */,211,213,[0],0,[0],0,[0],0,0,0,0,fromString(String),org.antlr.v4.runtime.CharStreams,fromString/1[java.lang.String],False,211,2,40,39,1,1,1,3,1,0,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,10,9,0,True
123,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\CharStreams.java,org.antlr.v4.runtime.CharStreams,"CodePointCharStream fromString(String, String)","/**
 * Creates a {@link CharStream} given a {@link String} and the {@code sourceName}
 * from which it came.
 */
public static CodePointCharStream fromString(String s, String sourceName) {
    // Initial guess assumes no code points > U+FFFF: one code
    // point for each code unit in the string
    CodePointBuffer.Builder codePointBufferBuilder = CodePointBuffer.builder(s.length());
    // TODO: CharBuffer.wrap(String) rightfully returns a read-only buffer
    // which doesn't expose its array, so we make a copy.
    CharBuffer cb = CharBuffer.allocate(s.length());
    cb.put(s);
    cb.flip();
    codePointBufferBuilder.append(cb);
    return CodePointCharStream.fromBuffer(codePointBufferBuilder.build(), sourceName);
}","/**
 * Creates a {@link CharStream} given a {@link String} and the {@code sourceName}
 * from which it came.
 */
","// Initial guess assumes no code points > U+FFFF: one code
[[SEP]]// TODO: CharBuffer.wrap(String) rightfully returns a read-only buffer
[[SEP]]// point for each code unit in the string
[[SEP]]// which doesn't expose its array, so we make a copy.
","/** * Creates a {@link CharStream} given a {@link String} and the {@code sourceName} * from which it came. */[[SEP]]// Initial guess assumes no code points > U+FFFF: one code// point for each code unit in the string[[SEP]]// TODO: CharBuffer.wrap(String) rightfully returns a read-only buffer// which doesn't expose its array, so we make a copy.",219,230,[0],0,"[0, 1, 0, 0]",1,"[0, 0, 1]",1,1,1,1,"fromString(String, String)",org.antlr.v4.runtime.CharStreams,"fromString/2[java.lang.String,java.lang.String]",False,219,3,5,1,4,1,8,8,1,2,2,8,0,0,0,0,0,0,0,0,2,0,0,0,0,0,20,9,0,True
124,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\CharStreams.java,org.antlr.v4.runtime.CharStreams,"CodePointCharStream fromChannel(ReadableByteChannel, int, CodingErrorAction, String)","/**
 * Creates a {@link CharStream} given an opened {@link ReadableByteChannel}
 * containing UTF-8 bytes.
 *
 * Reads the entire contents of the {@code channel} into
 * the result before returning, then closes the {@code channel}.
 */
public static CodePointCharStream fromChannel(ReadableByteChannel channel, int bufferSize, CodingErrorAction decodingErrorAction, String sourceName) throws IOException {
    return fromChannel(channel, StandardCharsets.UTF_8, bufferSize, decodingErrorAction, sourceName, -1);
}","/**
 * Creates a {@link CharStream} given an opened {@link ReadableByteChannel}
 * containing UTF-8 bytes.
 *
 * Reads the entire contents of the {@code channel} into
 * the result before returning, then closes the {@code channel}.
 */
", ,"/** * Creates a {@link CharStream} given an opened {@link ReadableByteChannel} * containing UTF-8 bytes. * * Reads the entire contents of the {@code channel} into * the result before returning, then closes the {@code channel}. */",239,247,[0],0,[0],0,[0],0,0,0,0,"fromChannel(ReadableByteChannel, int, CodingErrorAction, String)",org.antlr.v4.runtime.CharStreams,"fromChannel/4[java.nio.channels.ReadableByteChannel,int,java.nio.charset.CodingErrorAction,java.lang.String]",False,245,2,6,5,1,1,1,3,1,0,4,1,1,1,0,0,0,0,0,1,0,0,0,0,0,0,33,9,0,True
125,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\CharStreams.java,org.antlr.v4.runtime.CharStreams,"CodePointCharStream fromChannel(ReadableByteChannel, Charset, int, CodingErrorAction, String, long)","public static CodePointCharStream fromChannel(ReadableByteChannel channel, Charset charset, int bufferSize, CodingErrorAction decodingErrorAction, String sourceName, long inputSize) throws IOException {
    try {
        ByteBuffer utf8BytesIn = ByteBuffer.allocate(bufferSize);
        CharBuffer utf16CodeUnitsOut = CharBuffer.allocate(bufferSize);
        if (inputSize == -1) {
            inputSize = bufferSize;
        } else if (inputSize > Integer.MAX_VALUE) {
            // ByteBuffer et al don't support long sizes
            throw new IOException(String.format(""inputSize %d larger than max %d"", inputSize, Integer.MAX_VALUE));
        }
        CodePointBuffer.Builder codePointBufferBuilder = CodePointBuffer.builder((int) inputSize);
        CharsetDecoder decoder = charset.newDecoder().onMalformedInput(decodingErrorAction).onUnmappableCharacter(decodingErrorAction);
        boolean endOfInput = false;
        while (!endOfInput) {
            int bytesRead = channel.read(utf8BytesIn);
            endOfInput = (bytesRead == -1);
            utf8BytesIn.flip();
            CoderResult result = decoder.decode(utf8BytesIn, utf16CodeUnitsOut, endOfInput);
            if (result.isError() && decodingErrorAction.equals(CodingErrorAction.REPORT)) {
                result.throwException();
            }
            utf16CodeUnitsOut.flip();
            codePointBufferBuilder.append(utf16CodeUnitsOut);
            utf8BytesIn.compact();
            utf16CodeUnitsOut.compact();
        }
        // Handle any bytes at the end of the file which need to
        // be represented as errors or substitution characters.
        CoderResult flushResult = decoder.flush(utf16CodeUnitsOut);
        if (flushResult.isError() && decodingErrorAction.equals(CodingErrorAction.REPORT)) {
            flushResult.throwException();
        }
        utf16CodeUnitsOut.flip();
        codePointBufferBuilder.append(utf16CodeUnitsOut);
        CodePointBuffer codePointBuffer = codePointBufferBuilder.build();
        return CodePointCharStream.fromBuffer(codePointBuffer, sourceName);
    } finally {
        channel.close();
    }
}", ,"// Handle any bytes at the end of the file which need to
[[SEP]]// ByteBuffer et al don't support long sizes
[[SEP]]// be represented as errors or substitution characters.
",// ByteBuffer et al don't support long sizes[[SEP]]// Handle any bytes at the end of the file which need to// be represented as errors or substitution characters.,249,305,[0],0,"[0, 0, 0]",0,"[0, 0]",0,0,0,0,"fromChannel(ReadableByteChannel, Charset, int, CodingErrorAction, String, long)",org.antlr.v4.runtime.CharStreams,"fromChannel/6[java.nio.channels.ReadableByteChannel,java.nio.charset.Charset,int,java.nio.charset.CodingErrorAction,java.lang.String,long]",False,257,3,7,3,4,8,21,39,1,9,6,21,0,0,1,2,1,1,1,2,11,0,3,0,0,0,42,9,0,False
126,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\CodePointBuffer.java,org.antlr.v4.runtime.CodePointBuffer.Builder,void append(CharBuffer),"public void append(CharBuffer utf16In) {
    ensureRemaining(utf16In.remaining());
    if (utf16In.hasArray()) {
        appendArray(utf16In);
    } else {
        // TODO
        throw new UnsupportedOperationException(""TODO"");
    }
}", ,"// TODO
",// TODO,217,225,[0],0,[1],1,[1],1,1,0,1,append(CharBuffer),org.antlr.v4.runtime.CodePointBuffer$Builder,append/1[java.nio.CharBuffer],False,217,1,5,3,2,2,4,9,0,0,1,4,2,5,0,0,0,0,1,0,0,0,1,0,0,0,11,1,0,False
127,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\CodePointBuffer.java,org.antlr.v4.runtime.CodePointBuffer.Builder,void appendArrayInt(CharBuffer),"private void appendArrayInt(CharBuffer utf16In) {
    char[] in = utf16In.array();
    int inOffset = utf16In.arrayOffset() + utf16In.position();
    int inLimit = utf16In.arrayOffset() + utf16In.limit();
    int[] outInt = intBuffer.array();
    int outOffset = intBuffer.arrayOffset() + intBuffer.position();
    while (inOffset < inLimit) {
        char c = in[inOffset];
        inOffset++;
        if (prevHighSurrogate != -1) {
            if (Character.isLowSurrogate(c)) {
                outInt[outOffset] = Character.toCodePoint((char) prevHighSurrogate, c);
                outOffset++;
                prevHighSurrogate = -1;
            } else {
                // Dangling high surrogate
                outInt[outOffset] = prevHighSurrogate;
                outOffset++;
                if (Character.isHighSurrogate(c)) {
                    prevHighSurrogate = c & 0xFFFF;
                } else {
                    outInt[outOffset] = c & 0xFFFF;
                    outOffset++;
                    prevHighSurrogate = -1;
                }
            }
        } else if (Character.isHighSurrogate(c)) {
            prevHighSurrogate = c & 0xFFFF;
        } else {
            outInt[outOffset] = c & 0xFFFF;
            outOffset++;
        }
    }
    if (prevHighSurrogate != -1) {
        // Dangling high surrogate
        outInt[outOffset] = prevHighSurrogate & 0xFFFF;
        outOffset++;
    }
    utf16In.position(inOffset - utf16In.arrayOffset());
    intBuffer.position(outOffset - intBuffer.arrayOffset());
}", ,"// Dangling high surrogate
[[SEP]]// Dangling high surrogate
",// Dangling high surrogate[[SEP]]// Dangling high surrogate,307,351,[0],0,"[0, 0]",0,"[0, 0]",0,0,0,0,appendArrayInt(CharBuffer),org.antlr.v4.runtime.CodePointBuffer$Builder,appendArrayInt/1[java.nio.CharBuffer],False,307,2,3,3,0,7,11,43,0,6,1,11,0,0,1,2,0,0,0,9,15,5,4,0,0,0,17,2,0,False
128,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\CodePointBuffer.java,org.antlr.v4.runtime.CodePointBuffer.Builder,void byteToCharBuffer(int),"private void byteToCharBuffer(int toAppend) {
    byteBuffer.flip();
    // CharBuffers hold twice as much per unit as ByteBuffers, so start with half the capacity.
    CharBuffer newBuffer = CharBuffer.allocate(Math.max(byteBuffer.remaining() + toAppend, byteBuffer.capacity() / 2));
    while (byteBuffer.hasRemaining()) {
        newBuffer.put((char) (byteBuffer.get() & 0xFF));
    }
    type = Type.CHAR;
    byteBuffer = null;
    charBuffer = newBuffer;
}", ,"// CharBuffers hold twice as much per unit as ByteBuffers, so start with half the capacity.
","// CharBuffers hold twice as much per unit as ByteBuffers, so start with half the capacity.",353,363,[0],0,[0],0,[0],0,0,0,0,byteToCharBuffer(int),org.antlr.v4.runtime.CodePointBuffer$Builder,byteToCharBuffer/1[int],False,353,0,1,1,0,2,8,10,0,1,1,8,0,0,1,0,0,1,0,2,4,2,1,0,0,0,12,2,0,False
129,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\CodePointBuffer.java,org.antlr.v4.runtime.CodePointBuffer.Builder,void byteToIntBuffer(int),"private void byteToIntBuffer(int toAppend) {
    byteBuffer.flip();
    // IntBuffers hold four times as much per unit as ByteBuffers, so start with one quarter the capacity.
    IntBuffer newBuffer = IntBuffer.allocate(Math.max(byteBuffer.remaining() + toAppend, byteBuffer.capacity() / 4));
    while (byteBuffer.hasRemaining()) {
        newBuffer.put(byteBuffer.get() & 0xFF);
    }
    type = Type.INT;
    byteBuffer = null;
    intBuffer = newBuffer;
}", ,"// IntBuffers hold four times as much per unit as ByteBuffers, so start with one quarter the capacity.
","// IntBuffers hold four times as much per unit as ByteBuffers, so start with one quarter the capacity.",365,375,[0],0,[0],0,[0],0,0,0,0,byteToIntBuffer(int),org.antlr.v4.runtime.CodePointBuffer$Builder,byteToIntBuffer/1[int],False,365,0,1,1,0,2,8,10,0,1,1,8,0,0,1,0,0,0,0,2,4,2,1,0,0,0,12,2,0,False
130,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\CodePointBuffer.java,org.antlr.v4.runtime.CodePointBuffer.Builder,void charToIntBuffer(int),"private void charToIntBuffer(int toAppend) {
    charBuffer.flip();
    // IntBuffers hold two times as much per unit as ByteBuffers, so start with one half the capacity.
    IntBuffer newBuffer = IntBuffer.allocate(Math.max(charBuffer.remaining() + toAppend, charBuffer.capacity() / 2));
    while (charBuffer.hasRemaining()) {
        newBuffer.put(charBuffer.get() & 0xFFFF);
    }
    type = Type.INT;
    charBuffer = null;
    intBuffer = newBuffer;
}", ,"// IntBuffers hold two times as much per unit as ByteBuffers, so start with one half the capacity.
","// IntBuffers hold two times as much per unit as ByteBuffers, so start with one half the capacity.",377,387,[0],0,[0],0,[0],0,0,0,0,charToIntBuffer(int),org.antlr.v4.runtime.CodePointBuffer$Builder,charToIntBuffer/1[int],False,377,0,1,1,0,2,8,10,0,1,1,8,0,0,1,0,0,0,0,2,4,2,1,0,0,0,12,2,0,False
131,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\CodePointCharStream.java,org.antlr.v4.runtime.CodePointCharStream,Object getInternalStorage(),"// Visible for testing.
abstract Object getInternalStorage();","// Visible for testing.
", ,// Visible for testing.,41,41,[0],0,[0],0,[0],0,0,0,0,getInternalStorage(),org.antlr.v4.runtime.CodePointCharStream,getInternalStorage/0,False,41,0,3,3,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,4,1024,0,False
132,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\CodePointCharStream.java,org.antlr.v4.runtime.CodePointCharStream,CodePointCharStream fromBuffer(CodePointBuffer),"/**
 * Constructs a {@link CodePointCharStream} which provides access
 * to the Unicode code points stored in {@code codePointBuffer}.
 */
public static CodePointCharStream fromBuffer(CodePointBuffer codePointBuffer) {
    return fromBuffer(codePointBuffer, UNKNOWN_SOURCE_NAME);
}","/**
 * Constructs a {@link CodePointCharStream} which provides access
 * to the Unicode code points stored in {@code codePointBuffer}.
 */
", ,/** * Constructs a {@link CodePointCharStream} which provides access * to the Unicode code points stored in {@code codePointBuffer}. */,47,49,[0],0,[0],0,[0],0,0,0,0,fromBuffer(CodePointBuffer),org.antlr.v4.runtime.CodePointCharStream,fromBuffer/1[org.antlr.v4.runtime.CodePointBuffer],False,47,2,1,0,1,1,1,3,1,0,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,17,9,0,True
133,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\CodePointCharStream.java,org.antlr.v4.runtime.CodePointCharStream,"CodePointCharStream fromBuffer(CodePointBuffer, String)","/**
 * Constructs a named {@link CodePointCharStream} which provides access
 * to the Unicode code points stored in {@code codePointBuffer}.
 */
public static CodePointCharStream fromBuffer(CodePointBuffer codePointBuffer, String name) {
    // Java lacks generics on primitive types.
    // 
    // To avoid lots of calls to virtual methods in the
    // very hot codepath of LA() below, we construct one
    // of three concrete subclasses.
    // 
    // The concrete subclasses directly access the code
    // points stored in the underlying array (byte[],
    // char[], or int[]), so we can avoid lots of virtual
    // method calls to ByteBuffer.get(offset).
    switch(codePointBuffer.getType()) {
        case BYTE:
            return new CodePoint8BitCharStream(codePointBuffer.position(), codePointBuffer.remaining(), name, codePointBuffer.byteArray(), codePointBuffer.arrayOffset());
        case CHAR:
            return new CodePoint16BitCharStream(codePointBuffer.position(), codePointBuffer.remaining(), name, codePointBuffer.charArray(), codePointBuffer.arrayOffset());
        case INT:
            return new CodePoint32BitCharStream(codePointBuffer.position(), codePointBuffer.remaining(), name, codePointBuffer.intArray(), codePointBuffer.arrayOffset());
    }
    throw new UnsupportedOperationException(""Not reached"");
}","/**
 * Constructs a named {@link CodePointCharStream} which provides access
 * to the Unicode code points stored in {@code codePointBuffer}.
 */
","// Java lacks generics on primitive types.
[[SEP]]// 
[[SEP]]// To avoid lots of calls to virtual methods in the
[[SEP]]// very hot codepath of LA() below, we construct one
[[SEP]]// of three concrete subclasses.
[[SEP]]// 
[[SEP]]// The concrete subclasses directly access the code
[[SEP]]// points stored in the underlying array (byte[],
[[SEP]]// char[], or int[]), so we can avoid lots of virtual
[[SEP]]// method calls to ByteBuffer.get(offset).
","/** * Constructs a named {@link CodePointCharStream} which provides access * to the Unicode code points stored in {@code codePointBuffer}. */[[SEP]]// Java lacks generics on primitive types.//// To avoid lots of calls to virtual methods in the// very hot codepath of LA() below, we construct one// of three concrete subclasses.//// The concrete subclasses directly access the code// points stored in the underlying array (byte[],// char[], or int[]), so we can avoid lots of virtual// method calls to ByteBuffer.get(offset).",55,90,[0],0,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]",0,"[0, 0]",0,0,0,0,"fromBuffer(CodePointBuffer, String)",org.antlr.v4.runtime.CodePointCharStream,"fromBuffer/2[org.antlr.v4.runtime.CodePointBuffer,java.lang.String]",False,55,5,14,4,10,4,7,11,3,0,2,7,0,0,0,0,0,0,1,0,0,0,1,0,0,0,26,9,0,True
134,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\CodePointCharStream.java,org.antlr.v4.runtime.CodePointCharStream,int mark(),"/**
 * mark/release do nothing; we have entire buffer
 */
@Override
public final int mark() {
    return -1;
}","/**
 * mark/release do nothing; we have entire buffer
 */
", ,/** * mark/release do nothing; we have entire buffer */,112,115,[0],0,[0],0,[0],0,0,0,0,mark(),org.antlr.v4.runtime.CodePointCharStream,mark/0,False,113,0,0,0,0,1,0,3,1,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,7,17,0,True
135,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\CodePointCharStream.java,org.antlr.v4.runtime.CodePointCharStream.CodePoint8BitCharStream,String getText(Interval),"/**
 * Return the UTF-16 encoded string for the given interval
 */
@Override
public String getText(Interval interval) {
    int startIdx = Math.min(interval.a, size);
    int len = Math.min(interval.b - interval.a + 1, size - startIdx);
    // We know the maximum code point in byteArray is U+00FF,
    // so we can treat this as if it were ISO-8859-1, aka Latin-1,
    // which shares the same code points up to 0xFF.
    return new String(byteArray, startIdx, len, StandardCharsets.ISO_8859_1);
}","/**
 * Return the UTF-16 encoded string for the given interval
 */
","// We know the maximum code point in byteArray is U+00FF,
[[SEP]]// so we can treat this as if it were ISO-8859-1, aka Latin-1,
[[SEP]]// which shares the same code points up to 0xFF.
","/** * Return the UTF-16 encoded string for the given interval */[[SEP]]// We know the maximum code point in byteArray is U+00FF,// so we can treat this as if it were ISO-8859-1, aka Latin-1,// which shares the same code points up to 0xFF.",152,161,[0],0,"[0, 0, 0]",0,"[0, 0]",0,0,0,0,getText(Interval),org.antlr.v4.runtime.CodePointCharStream$CodePoint8BitCharStream,getText/1[org.antlr.v4.runtime.misc.Interval],False,153,1,0,0,0,1,1,5,1,2,1,1,0,0,0,0,0,0,0,1,2,3,0,0,0,0,15,1,0,True
136,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\CodePointCharStream.java,org.antlr.v4.runtime.CodePointCharStream.CodePoint8BitCharStream,int LA(int),"@Override
public int LA(int i) {
    int offset;
    switch(Integer.signum(i)) {
        case -1:
            offset = position + i;
            if (offset < 0) {
                return IntStream.EOF;
            }
            return byteArray[offset] & 0xFF;
        case 0:
            // Undefined
            return 0;
        case 1:
            offset = position + i - 1;
            if (offset >= size) {
                return IntStream.EOF;
            }
            return byteArray[offset] & 0xFF;
    }
    throw new UnsupportedOperationException(""Not reached"");
}", ,"// Undefined
",// Undefined,163,184,[0],0,[0],0,[0],0,0,0,0,LA(int),org.antlr.v4.runtime.CodePointCharStream$CodePoint8BitCharStream,LA/1[int],False,164,0,0,0,0,6,1,20,5,1,1,1,0,0,0,0,0,0,1,8,2,3,2,0,0,0,11,1,0,False
137,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\CodePointCharStream.java,org.antlr.v4.runtime.CodePointCharStream.CodePoint16BitCharStream,String getText(Interval),"/**
 * Return the UTF-16 encoded string for the given interval
 */
@Override
public String getText(Interval interval) {
    int startIdx = Math.min(interval.a, size);
    int len = Math.min(interval.b - interval.a + 1, size - startIdx);
    // We know there are no surrogates in this
    // array, since otherwise we would be given a
    // 32-bit int[] array.
    // 
    // So, it's safe to treat this as if it were
    // UTF-16.
    return new String(charArray, startIdx, len);
}","/**
 * Return the UTF-16 encoded string for the given interval
 */
","// We know there are no surrogates in this
[[SEP]]// array, since otherwise we would be given a
[[SEP]]// 32-bit int[] array.
[[SEP]]// 
[[SEP]]// So, it's safe to treat this as if it were
[[SEP]]// UTF-16.
","/** * Return the UTF-16 encoded string for the given interval */[[SEP]]// We know there are no surrogates in this// array, since otherwise we would be given a// 32-bit int[] array.//// So, it's safe to treat this as if it were// UTF-16.",204,216,[0],0,"[0, 0, 0, 0, 0, 0]",0,"[0, 0]",0,0,0,0,getText(Interval),org.antlr.v4.runtime.CodePointCharStream$CodePoint16BitCharStream,getText/1[org.antlr.v4.runtime.misc.Interval],False,205,1,0,0,0,1,1,5,1,2,1,1,0,0,0,0,0,0,0,1,2,3,0,0,0,0,15,1,0,True
138,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\CodePointCharStream.java,org.antlr.v4.runtime.CodePointCharStream.CodePoint16BitCharStream,int LA(int),"@Override
public int LA(int i) {
    int offset;
    switch(Integer.signum(i)) {
        case -1:
            offset = position + i;
            if (offset < 0) {
                return IntStream.EOF;
            }
            return charArray[offset] & 0xFFFF;
        case 0:
            // Undefined
            return 0;
        case 1:
            offset = position + i - 1;
            if (offset >= size) {
                return IntStream.EOF;
            }
            return charArray[offset] & 0xFFFF;
    }
    throw new UnsupportedOperationException(""Not reached"");
}", ,"// Undefined
",// Undefined,218,239,[0],0,[0],0,[0],0,0,0,0,LA(int),org.antlr.v4.runtime.CodePointCharStream$CodePoint16BitCharStream,LA/1[int],False,219,0,0,0,0,6,1,20,5,1,1,1,0,0,0,0,0,0,1,8,2,3,2,0,0,0,11,1,0,False
139,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\CodePointCharStream.java,org.antlr.v4.runtime.CodePointCharStream.CodePoint32BitCharStream,String getText(Interval),"/**
 * Return the UTF-16 encoded string for the given interval
 */
@Override
public String getText(Interval interval) {
    int startIdx = Math.min(interval.a, size);
    int len = Math.min(interval.b - interval.a + 1, size - startIdx);
    // Note that we pass the int[] code points to the String constructor --
    // this is supported, and the constructor will convert to UTF-16 internally.
    return new String(intArray, startIdx, len);
}","/**
 * Return the UTF-16 encoded string for the given interval
 */
","// Note that we pass the int[] code points to the String constructor --
[[SEP]]// this is supported, and the constructor will convert to UTF-16 internally.
","/** * Return the UTF-16 encoded string for the given interval */[[SEP]]// Note that we pass the int[] code points to the String constructor --// this is supported, and the constructor will convert to UTF-16 internally.",259,267,[0],0,"[0, 0]",0,"[0, 0]",0,0,0,0,getText(Interval),org.antlr.v4.runtime.CodePointCharStream$CodePoint32BitCharStream,getText/1[org.antlr.v4.runtime.misc.Interval],False,260,1,0,0,0,1,1,5,1,2,1,1,0,0,0,0,0,0,0,1,2,3,0,0,0,0,15,1,0,True
140,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\CodePointCharStream.java,org.antlr.v4.runtime.CodePointCharStream.CodePoint32BitCharStream,int LA(int),"@Override
public int LA(int i) {
    int offset;
    switch(Integer.signum(i)) {
        case -1:
            offset = position + i;
            if (offset < 0) {
                return IntStream.EOF;
            }
            return intArray[offset];
        case 0:
            // Undefined
            return 0;
        case 1:
            offset = position + i - 1;
            if (offset >= size) {
                return IntStream.EOF;
            }
            return intArray[offset];
    }
    throw new UnsupportedOperationException(""Not reached"");
}", ,"// Undefined
",// Undefined,269,290,[0],0,[0],0,[0],0,0,0,0,LA(int),org.antlr.v4.runtime.CodePointCharStream$CodePoint32BitCharStream,LA/1[int],False,270,0,0,0,0,6,1,20,5,1,1,1,0,0,0,0,0,0,1,6,2,3,2,0,0,0,9,1,0,False
141,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\CommonToken.java,org.antlr.v4.runtime.CommonToken,void setText(String),"/**
 * Explicitly set the text for this token. If {code text} is not
 * {@code null}, then {@link #getText} will return this value rather than
 * extracting the text from the input.
 *
 * @param text The explicit text of the token, or {@code null} if the text
 * should be obtained from the input along with the start and stop indexes
 * of the token.
 */
@Override
public void setText(String text) {
    this.text = text;
}","/**
 * Explicitly set the text for this token. If {code text} is not
 * {@code null}, then {@link #getText} will return this value rather than
 * extracting the text from the input.
 *
 * @param text The explicit text of the token, or {@code null} if the text
 * should be obtained from the input along with the start and stop indexes
 * of the token.
 */
", ,"/** * Explicitly set the text for this token. If {code text} is not * {@code null}, then {@link #getText} will return this value rather than * extracting the text from the input. * * @param text The explicit text of the token, or {@code null} if the text * should be obtained from the input along with the start and stop indexes * of the token. */",186,189,[0],0,[0],0,[0],0,0,0,0,setText(String),org.antlr.v4.runtime.CommonToken,setText/1[java.lang.String],False,187,0,1,1,0,1,0,3,0,0,1,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,30,1,0,True
142,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\CommonTokenStream.java,org.antlr.v4.runtime.CommonTokenStream,Token LB(int),"@Override
protected Token LB(int k) {
    if (k == 0 || (p - k) < 0)
        return null;
    int i = p;
    int n = 1;
    // find k good tokens looking backwards
    while (n <= k && i > 0) {
        // skip off-channel tokens
        i = previousTokenOnChannel(i - 1, channel);
        n++;
    }
    if (i < 0)
        return null;
    return tokens.get(i);
}", ,"// find k good tokens looking backwards
[[SEP]]// skip off-channel tokens
",// find k good tokens looking backwards[[SEP]]// skip off-channel tokens,73,87,[0],0,"[0, 0]",0,"[0, 0]",0,0,0,0,LB(int),org.antlr.v4.runtime.CommonTokenStream,LB/1[int],False,74,2,2,1,1,6,2,11,3,2,1,2,0,0,1,1,0,1,0,6,3,2,1,0,0,0,11,4,0,False
143,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\CommonTokenStream.java,org.antlr.v4.runtime.CommonTokenStream,Token LT(int),"@Override
public Token LT(int k) {
    // System.out.println(""enter LT(""+k+"")"");
    lazyInit();
    if (k == 0)
        return null;
    if (k < 0)
        return LB(-k);
    int i = p;
    // we know tokens[p] is a good one
    int n = 1;
    // find k good tokens
    while (n < k) {
        // skip off-channel tokens, but make sure to not look past EOF
        if (sync(i + 1)) {
            i = nextTokenOnChannel(i + 1, channel);
        }
        n++;
    }
    // if ( i>range ) range = i;
    return tokens.get(i);
}", ,"// System.out.println(""enter LT(""+k+"")"");
[[SEP]]// we know tokens[p] is a good one
[[SEP]]// find k good tokens
[[SEP]]// skip off-channel tokens, but make sure to not look past EOF
[[SEP]]// if ( i>range ) range = i;
","// System.out.println(""enter LT(""+k+"")"");[[SEP]]// we know tokens[p] is a good one[[SEP]]// find k good tokens[[SEP]]// skip off-channel tokens, but make sure to not look past EOF[[SEP]]// if ( i>range ) range = i;",89,107,[0],0,"[0, 0, 0, 0, 0]",0,"[0, 0, 0, 0, 0]",0,0,0,0,LT(int),org.antlr.v4.runtime.CommonTokenStream,LT/1[int],False,90,3,4,0,4,5,5,14,3,2,1,5,1,1,1,1,0,0,0,5,3,2,2,0,0,0,15,1,0,False
144,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\CommonTokenStream.java,org.antlr.v4.runtime.CommonTokenStream,int getNumberOfOnChannelTokens(),"/**
 * Count EOF just once.
 */
public int getNumberOfOnChannelTokens() {
    int n = 0;
    fill();
    for (int i = 0; i < tokens.size(); i++) {
        Token t = tokens.get(i);
        if (t.getChannel() == channel)
            n++;
        if (t.getType() == Token.EOF)
            break;
    }
    return n;
}","/**
 * Count EOF just once.
 */
", ,/** * Count EOF just once. */,110,119,[0],0,[0],0,[0],0,0,0,0,getNumberOfOnChannelTokens(),org.antlr.v4.runtime.CommonTokenStream,getNumberOfOnChannelTokens/0,False,110,2,3,0,3,4,5,10,1,3,0,5,0,0,1,2,0,0,0,2,3,0,2,0,0,0,17,1,0,True
145,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\ConsoleErrorListener.java,org.antlr.v4.runtime.ConsoleErrorListener,"void syntaxError(Recognizer<?, ?>, Object, int, int, String, RecognitionException)","/**
 * {@inheritDoc}
 *
 * <p>
 * This implementation prints messages to {@link System#err} containing the
 * values of {@code line}, {@code charPositionInLine}, and {@code msg} using
 * the following format.</p>
 *
 * <pre>
 * line <em>line</em>:<em>charPositionInLine</em> <em>msg</em>
 * </pre>
 */
@Override
public void syntaxError(Recognizer<?, ?> recognizer, Object offendingSymbol, int line, int charPositionInLine, String msg, RecognitionException e) {
    System.err.println(""line "" + line + "":"" + charPositionInLine + "" "" + msg);
}","/**
 * {@inheritDoc}
 *
 * <p>
 * This implementation prints messages to {@link System#err} containing the
 * values of {@code line}, {@code charPositionInLine}, and {@code msg} using
 * the following format.</p>
 *
 * <pre>
 * line <em>line</em>:<em>charPositionInLine</em> <em>msg</em>
 * </pre>
 */
", ,"/** * {@inheritDoc} * * <p> * This implementation prints messages to {@link System#err} containing the * values of {@code line}, {@code charPositionInLine}, and {@code msg} using * the following format.</p> * * <pre> * line <em>line</em>:<em>charPositionInLine</em> <em>msg</em> * </pre> */",30,39,[0],0,[0],0,[0],0,0,0,0,"syntaxError(Recognizer<?, ?>, Object, int, int, String, RecognitionException)",org.antlr.v4.runtime.ConsoleErrorListener,"syntaxError/6[org.antlr.v4.runtime.Recognizer<?,?>,java.lang.Object,int,int,java.lang.String,org.antlr.v4.runtime.RecognitionException]",False,37,2,0,0,0,1,1,3,0,0,6,1,0,0,0,0,0,0,3,0,0,1,0,0,0,0,23,1,0,True
146,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\DefaultErrorStrategy.java,org.antlr.v4.runtime.DefaultErrorStrategy,void reset(Parser),"/**
 * {@inheritDoc}
 *
 * <p>The default implementation simply calls {@link #endErrorCondition} to
 * ensure that the handler is not in error recovery mode.</p>
 */
@Override
public void reset(Parser recognizer) {
    endErrorCondition(recognizer);
}","/**
 * {@inheritDoc}
 *
 * <p>The default implementation simply calls {@link #endErrorCondition} to
 * ensure that the handler is not in error recovery mode.</p>
 */
", ,/** * {@inheritDoc} * * <p>The default implementation simply calls {@link #endErrorCondition} to * ensure that the handler is not in error recovery mode.</p> */,60,63,[0],0,[0],0,[0],0,0,0,0,reset(Parser),org.antlr.v4.runtime.DefaultErrorStrategy,reset/1[org.antlr.v4.runtime.Parser],False,61,2,1,0,1,1,1,3,0,0,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,20,1,0,True
147,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\DefaultErrorStrategy.java,org.antlr.v4.runtime.DefaultErrorStrategy,void beginErrorCondition(Parser),"/**
 * This method is called to enter error recovery mode when a recognition
 * exception is reported.
 *
 * @param recognizer the parser instance
 */
protected void beginErrorCondition(Parser recognizer) {
    errorRecoveryMode = true;
}","/**
 * This method is called to enter error recovery mode when a recognition
 * exception is reported.
 *
 * @param recognizer the parser instance
 */
", ,/** * This method is called to enter error recovery mode when a recognition * exception is reported. * * @param recognizer the parser instance */,71,73,[0],0,[0],0,[0],0,0,0,0,beginErrorCondition(Parser),org.antlr.v4.runtime.DefaultErrorStrategy,beginErrorCondition/1[org.antlr.v4.runtime.Parser],False,71,1,3,3,0,1,0,3,0,0,1,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,24,4,0,True
148,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\DefaultErrorStrategy.java,org.antlr.v4.runtime.DefaultErrorStrategy,boolean inErrorRecoveryMode(Parser),"/**
 * {@inheritDoc}
 */
@Override
public boolean inErrorRecoveryMode(Parser recognizer) {
    return errorRecoveryMode;
}","/**
 * {@inheritDoc}
 */
", ,/** * {@inheritDoc} */,78,81,[0],0,[0],0,[0],0,0,0,0,inErrorRecoveryMode(Parser),org.antlr.v4.runtime.DefaultErrorStrategy,inErrorRecoveryMode/1[org.antlr.v4.runtime.Parser],False,79,1,4,4,0,1,0,3,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,7,1,0,True
149,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\DefaultErrorStrategy.java,org.antlr.v4.runtime.DefaultErrorStrategy,void endErrorCondition(Parser),"/**
 * This method is called to leave error recovery mode after recovering from
 * a recognition exception.
 *
 * @param recognizer
 */
protected void endErrorCondition(Parser recognizer) {
    errorRecoveryMode = false;
    lastErrorStates = null;
    lastErrorIndex = -1;
}","/**
 * This method is called to leave error recovery mode after recovering from
 * a recognition exception.
 *
 * @param recognizer
 */
", ,/** * This method is called to leave error recovery mode after recovering from * a recognition exception. * * @param recognizer */,89,93,[0],0,[0],0,[0],0,0,0,0,endErrorCondition(Parser),org.antlr.v4.runtime.DefaultErrorStrategy,endErrorCondition/1[org.antlr.v4.runtime.Parser],False,89,1,2,2,0,1,0,5,0,0,1,0,0,0,0,0,0,0,0,1,3,0,0,0,0,0,26,4,0,True
150,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\DefaultErrorStrategy.java,org.antlr.v4.runtime.DefaultErrorStrategy,void reportMatch(Parser),"/**
 * {@inheritDoc}
 *
 * <p>The default implementation simply calls {@link #endErrorCondition}.</p>
 */
@Override
public void reportMatch(Parser recognizer) {
    endErrorCondition(recognizer);
}","/**
 * {@inheritDoc}
 *
 * <p>The default implementation simply calls {@link #endErrorCondition}.</p>
 */
", ,/** * {@inheritDoc} * * <p>The default implementation simply calls {@link #endErrorCondition}.</p> */,100,103,[0],0,[0],0,[0],0,0,0,0,reportMatch(Parser),org.antlr.v4.runtime.DefaultErrorStrategy,reportMatch/1[org.antlr.v4.runtime.Parser],False,101,2,2,1,1,1,1,3,0,0,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,12,1,0,True
151,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\DefaultErrorStrategy.java,org.antlr.v4.runtime.DefaultErrorStrategy,"void reportError(Parser, RecognitionException)","/**
 * {@inheritDoc}
 *
 * <p>The default implementation returns immediately if the handler is already
 * in error recovery mode. Otherwise, it calls {@link #beginErrorCondition}
 * and dispatches the reporting task based on the runtime type of {@code e}
 * according to the following table.</p>
 *
 * <ul>
 * <li>{@link NoViableAltException}: Dispatches the call to
 * {@link #reportNoViableAlternative}</li>
 * <li>{@link InputMismatchException}: Dispatches the call to
 * {@link #reportInputMismatch}</li>
 * <li>{@link FailedPredicateException}: Dispatches the call to
 * {@link #reportFailedPredicate}</li>
 * <li>All other types: calls {@link Parser#notifyErrorListeners} to report
 * the exception</li>
 * </ul>
 */
@Override
public void reportError(Parser recognizer, RecognitionException e) {
    // if we've already reported an error and have not matched a token
    // yet successfully, don't report any errors.
    if (inErrorRecoveryMode(recognizer)) {
        // System.err.print(""[SPURIOUS] "");
        // don't report spurious errors
        return;
    }
    beginErrorCondition(recognizer);
    if (e instanceof NoViableAltException) {
        reportNoViableAlternative(recognizer, (NoViableAltException) e);
    } else if (e instanceof InputMismatchException) {
        reportInputMismatch(recognizer, (InputMismatchException) e);
    } else if (e instanceof FailedPredicateException) {
        reportFailedPredicate(recognizer, (FailedPredicateException) e);
    } else {
        System.err.println(""unknown recognition error type: "" + e.getClass().getName());
        recognizer.notifyErrorListeners(e.getOffendingToken(), e.getMessage(), e);
    }
}","/**
 * {@inheritDoc}
 *
 * <p>The default implementation returns immediately if the handler is already
 * in error recovery mode. Otherwise, it calls {@link #beginErrorCondition}
 * and dispatches the reporting task based on the runtime type of {@code e}
 * according to the following table.</p>
 *
 * <ul>
 * <li>{@link NoViableAltException}: Dispatches the call to
 * {@link #reportNoViableAlternative}</li>
 * <li>{@link InputMismatchException}: Dispatches the call to
 * {@link #reportInputMismatch}</li>
 * <li>{@link FailedPredicateException}: Dispatches the call to
 * {@link #reportFailedPredicate}</li>
 * <li>All other types: calls {@link Parser#notifyErrorListeners} to report
 * the exception</li>
 * </ul>
 */
","// if we've already reported an error and have not matched a token
[[SEP]]// yet successfully, don't report any errors.
[[SEP]]// System.err.print(""[SPURIOUS] "");
[[SEP]]// don't report spurious errors
","/** * {@inheritDoc} * * <p>The default implementation returns immediately if the handler is already * in error recovery mode. Otherwise, it calls {@link #beginErrorCondition} * and dispatches the reporting task based on the runtime type of {@code e} * according to the following table.</p> * * <ul> * <li>{@link NoViableAltException}: Dispatches the call to * {@link #reportNoViableAlternative}</li> * <li>{@link InputMismatchException}: Dispatches the call to * {@link #reportInputMismatch}</li> * <li>{@link FailedPredicateException}: Dispatches the call to * {@link #reportFailedPredicate}</li> * <li>All other types: calls {@link Parser#notifyErrorListeners} to report * the exception</li> * </ul> */[[SEP]]// if we've already reported an error and have not matched a token// yet successfully, don't report any errors.[[SEP]]// System.err.print(""[SPURIOUS] "");// don't report spurious errors",124,148,[0],0,"[0, 0, 0, 0]",0,"[0, 0, 0]",0,0,0,0,"reportError(Parser, RecognitionException)",org.antlr.v4.runtime.DefaultErrorStrategy,"reportError/2[org.antlr.v4.runtime.Parser,org.antlr.v4.runtime.RecognitionException]",False,127,6,7,0,7,5,11,19,1,0,2,11,5,4,0,0,0,0,1,0,0,1,1,0,0,0,52,1,0,True
152,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\DefaultErrorStrategy.java,org.antlr.v4.runtime.DefaultErrorStrategy,"void recover(Parser, RecognitionException)","/**
 * {@inheritDoc}
 *
 * <p>The default implementation resynchronizes the parser by consuming tokens
 * until we find one in the resynchronization set--loosely the set of tokens
 * that can follow the current rule.</p>
 */
@Override
public void recover(Parser recognizer, RecognitionException e) {
    // System.out.println(""recover in ""+recognizer.getRuleInvocationStack()+
    // "" index=""+recognizer.getInputStream().index()+
    // "", lastErrorIndex=""+
    // lastErrorIndex+
    // "", states=""+lastErrorStates);
    if (lastErrorIndex == recognizer.getInputStream().index() && lastErrorStates != null && lastErrorStates.contains(recognizer.getState())) {
        // uh oh, another error at same token index and previously-visited
        // state in ATN; must be a case where LT(1) is in the recovery
        // token set so nothing got consumed. Consume a single token
        // at least to prevent an infinite loop; this is a failsafe.
        // System.err.println(""seen error condition before index=""+
        // lastErrorIndex+"", states=""+lastErrorStates);
        // System.err.println(""FAILSAFE consumes ""+recognizer.getTokenNames()[recognizer.getInputStream().LA(1)]);
        recognizer.consume();
    }
    lastErrorIndex = recognizer.getInputStream().index();
    if (lastErrorStates == null)
        lastErrorStates = new IntervalSet();
    lastErrorStates.add(recognizer.getState());
    IntervalSet followSet = getErrorRecoverySet(recognizer);
    consumeUntil(recognizer, followSet);
}","/**
 * {@inheritDoc}
 *
 * <p>The default implementation resynchronizes the parser by consuming tokens
 * until we find one in the resynchronization set--loosely the set of tokens
 * that can follow the current rule.</p>
 */
","// System.out.println(""recover in ""+recognizer.getRuleInvocationStack()+
[[SEP]]// "" index=""+recognizer.getInputStream().index()+
[[SEP]]// "", lastErrorIndex=""+
[[SEP]]// lastErrorIndex+
[[SEP]]// "", states=""+lastErrorStates);
[[SEP]]// uh oh, another error at same token index and previously-visited
[[SEP]]// state in ATN; must be a case where LT(1) is in the recovery
[[SEP]]// token set so nothing got consumed. Consume a single token
[[SEP]]// at least to prevent an infinite loop; this is a failsafe.
[[SEP]]// System.err.println(""seen error condition before index=""+
[[SEP]]// lastErrorIndex+"", states=""+lastErrorStates);
[[SEP]]// System.err.println(""FAILSAFE consumes ""+recognizer.getTokenNames()[recognizer.getInputStream().LA(1)]);
","/** * {@inheritDoc} * * <p>The default implementation resynchronizes the parser by consuming tokens * until we find one in the resynchronization set--loosely the set of tokens * that can follow the current rule.</p> */[[SEP]]// System.out.println(""recover in ""+recognizer.getRuleInvocationStack()+// "" index=""+recognizer.getInputStream().index()+// "", lastErrorIndex=""+// lastErrorIndex+// "", states=""+lastErrorStates);[[SEP]]// uh oh, another error at same token index and previously-visited// state in ATN; must be a case where LT(1) is in the recovery// token set so nothing got consumed. Consume a single token// at least to prevent an infinite loop; this is a failsafe.// System.err.println(""seen error condition before index=""+// lastErrorIndex+"", states=""+lastErrorStates);// System.err.println(""FAILSAFE consumes ""+recognizer.getTokenNames()[recognizer.getInputStream().LA(1)]);",157,181,[0],0,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]",0,"[0, 0, 0]",0,0,0,0,"recover(Parser, RecognitionException)",org.antlr.v4.runtime.DefaultErrorStrategy,"recover/2[org.antlr.v4.runtime.Parser,org.antlr.v4.runtime.RecognitionException]",False,158,6,9,0,9,5,8,10,0,1,2,8,2,1,0,3,0,0,0,0,3,0,1,0,0,0,37,1,0,True
153,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\DefaultErrorStrategy.java,org.antlr.v4.runtime.DefaultErrorStrategy,void sync(Parser),"/**
 * The default implementation of {@link ANTLRErrorStrategy#sync} makes sure
 * that the current lookahead symbol is consistent with what were expecting
 * at this point in the ATN. You can call this anytime but ANTLR only
 * generates code to check before subrules/loops and each iteration.
 *
 * <p>Implements Jim Idle's magic sync mechanism in closures and optional
 * subrules. E.g.,</p>
 *
 * <pre>
 * a : sync ( stuff sync )* ;
 * sync : {consume to what can follow sync} ;
 * </pre>
 *
 * At the start of a sub rule upon error, {@link #sync} performs single
 * token deletion, if possible. If it can't do that, it bails on the current
 * rule and uses the default error recovery, which consumes until the
 * resynchronization set of the current rule.
 *
 * <p>If the sub rule is optional ({@code (...)?}, {@code (...)*}, or block
 * with an empty alternative), then the expected set includes what follows
 * the subrule.</p>
 *
 * <p>During loop iteration, it consumes until it sees a token that can start a
 * sub rule or what follows loop. Yes, that is pretty aggressive. We opt to
 * stay in the loop as long as possible.</p>
 *
 * <p><strong>ORIGINS</strong></p>
 *
 * <p>Previous versions of ANTLR did a poor job of their recovery within loops.
 * A single mismatch token or missing token would force the parser to bail
 * out of the entire rules surrounding the loop. So, for rule</p>
 *
 * <pre>
 * classDef : 'class' ID '{' member* '}'
 * </pre>
 *
 * input with an extra token between members would force the parser to
 * consume until it found the next class definition rather than the next
 * member definition of the current class.
 *
 * <p>This functionality cost a little bit of effort because the parser has to
 * compare token set at the start of the loop and at each iteration. If for
 * some reason speed is suffering for you, you can turn off this
 * functionality by simply overriding this method as a blank { }.</p>
 */
@Override
public void sync(Parser recognizer) throws RecognitionException {
    ATNState s = recognizer.getInterpreter().atn.states.get(recognizer.getState());
    // System.err.println(""sync @ ""+s.stateNumber+""=""+s.getClass().getSimpleName());
    // If already recovering, don't try to sync
    if (inErrorRecoveryMode(recognizer)) {
        return;
    }
    TokenStream tokens = recognizer.getInputStream();
    int la = tokens.LA(1);
    // try cheaper subset first; might get lucky. seems to shave a wee bit off
    IntervalSet nextTokens = recognizer.getATN().nextTokens(s);
    if (nextTokens.contains(la)) {
        // We are sure the token matches
        nextTokensContext = null;
        nextTokensState = ATNState.INVALID_STATE_NUMBER;
        return;
    }
    if (nextTokens.contains(Token.EPSILON)) {
        if (nextTokensContext == null) {
            // It's possible the next token won't match; information tracked
            // by sync is restricted for performance.
            nextTokensContext = recognizer.getContext();
            nextTokensState = recognizer.getState();
        }
        return;
    }
    switch(s.getStateType()) {
        case ATNState.BLOCK_START:
        case ATNState.STAR_BLOCK_START:
        case ATNState.PLUS_BLOCK_START:
        case ATNState.STAR_LOOP_ENTRY:
            // report error and recover if possible
            if (singleTokenDeletion(recognizer) != null) {
                return;
            }
            throw new InputMismatchException(recognizer);
        case ATNState.PLUS_LOOP_BACK:
        case ATNState.STAR_LOOP_BACK:
            // System.err.println(""at loop back: ""+s.getClass().getSimpleName());
            reportUnwantedToken(recognizer);
            IntervalSet expecting = recognizer.getExpectedTokens();
            IntervalSet whatFollowsLoopIterationOrRule = expecting.or(getErrorRecoverySet(recognizer));
            consumeUntil(recognizer, whatFollowsLoopIterationOrRule);
            break;
        default:
            // do nothing if we can't identify the exact kind of ATN state
            break;
    }
}","/**
 * The default implementation of {@link ANTLRErrorStrategy#sync} makes sure
 * that the current lookahead symbol is consistent with what were expecting
 * at this point in the ATN. You can call this anytime but ANTLR only
 * generates code to check before subrules/loops and each iteration.
 *
 * <p>Implements Jim Idle's magic sync mechanism in closures and optional
 * subrules. E.g.,</p>
 *
 * <pre>
 * a : sync ( stuff sync )* ;
 * sync : {consume to what can follow sync} ;
 * </pre>
 *
 * At the start of a sub rule upon error, {@link #sync} performs single
 * token deletion, if possible. If it can't do that, it bails on the current
 * rule and uses the default error recovery, which consumes until the
 * resynchronization set of the current rule.
 *
 * <p>If the sub rule is optional ({@code (...)?}, {@code (...)*}, or block
 * with an empty alternative), then the expected set includes what follows
 * the subrule.</p>
 *
 * <p>During loop iteration, it consumes until it sees a token that can start a
 * sub rule or what follows loop. Yes, that is pretty aggressive. We opt to
 * stay in the loop as long as possible.</p>
 *
 * <p><strong>ORIGINS</strong></p>
 *
 * <p>Previous versions of ANTLR did a poor job of their recovery within loops.
 * A single mismatch token or missing token would force the parser to bail
 * out of the entire rules surrounding the loop. So, for rule</p>
 *
 * <pre>
 * classDef : 'class' ID '{' member* '}'
 * </pre>
 *
 * input with an extra token between members would force the parser to
 * consume until it found the next class definition rather than the next
 * member definition of the current class.
 *
 * <p>This functionality cost a little bit of effort because the parser has to
 * compare token set at the start of the loop and at each iteration. If for
 * some reason speed is suffering for you, you can turn off this
 * functionality by simply overriding this method as a blank { }.</p>
 */
","// System.err.println(""sync @ ""+s.stateNumber+""=""+s.getClass().getSimpleName());
[[SEP]]// If already recovering, don't try to sync
[[SEP]]// try cheaper subset first; might get lucky. seems to shave a wee bit off
[[SEP]]// We are sure the token matches
[[SEP]]// It's possible the next token won't match; information tracked
[[SEP]]// by sync is restricted for performance.
[[SEP]]// report error and recover if possible
[[SEP]]// System.err.println(""at loop back: ""+s.getClass().getSimpleName());
[[SEP]]// do nothing if we can't identify the exact kind of ATN state
","/** * The default implementation of {@link ANTLRErrorStrategy#sync} makes sure * that the current lookahead symbol is consistent with what were expecting * at this point in the ATN. You can call this anytime but ANTLR only * generates code to check before subrules/loops and each iteration. * * <p>Implements Jim Idle's magic sync mechanism in closures and optional * subrules. E.g.,</p> * * <pre> * a : sync ( stuff sync )* ; * sync : {consume to what can follow sync} ; * </pre> * * At the start of a sub rule upon error, {@link #sync} performs single * token deletion, if possible. If it can't do that, it bails on the current * rule and uses the default error recovery, which consumes until the * resynchronization set of the current rule. * * <p>If the sub rule is optional ({@code (...)?}, {@code (...)*}, or block * with an empty alternative), then the expected set includes what follows * the subrule.</p> * * <p>During loop iteration, it consumes until it sees a token that can start a * sub rule or what follows loop. Yes, that is pretty aggressive. We opt to * stay in the loop as long as possible.</p> * * <p><strong>ORIGINS</strong></p> * * <p>Previous versions of ANTLR did a poor job of their recovery within loops. * A single mismatch token or missing token would force the parser to bail * out of the entire rules surrounding the loop. So, for rule</p> * * <pre> * classDef : 'class' ID '{' member* '}' * </pre> * * input with an extra token between members would force the parser to * consume until it found the next class definition rather than the next * member definition of the current class. * * <p>This functionality cost a little bit of effort because the parser has to * compare token set at the start of the loop and at each iteration. If for * some reason speed is suffering for you, you can turn off this * functionality by simply overriding this method as a blank { }.</p> */[[SEP]]// System.err.println(""sync @ ""+s.stateNumber+""=""+s.getClass().getSimpleName());// If already recovering, don't try to sync[[SEP]]// try cheaper subset first; might get lucky. seems to shave a wee bit off[[SEP]]// We are sure the token matches[[SEP]]// It's possible the next token won't match; information tracked// by sync is restricted for performance.[[SEP]]// report error and recover if possible[[SEP]]// System.err.println(""at loop back: ""+s.getClass().getSimpleName());[[SEP]]// do nothing if we can't identify the exact kind of ATN state",229,286,[0],0,"[0, 0, 0, 0, 0, 0, 0, 0, 0]",0,"[0, 0, 0, 0, 0, 0, 0, 0]",0,0,1,0,sync(Parser),org.antlr.v4.runtime.DefaultErrorStrategy,sync/1[org.antlr.v4.runtime.Parser],False,230,9,17,0,17,12,17,40,4,6,1,17,5,5,0,2,0,0,0,1,10,0,2,0,0,0,173,1,0,True
154,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\DefaultErrorStrategy.java,org.antlr.v4.runtime.DefaultErrorStrategy,"void reportNoViableAlternative(Parser, NoViableAltException)","/**
 * This is called by {@link #reportError} when the exception is a
 * {@link NoViableAltException}.
 *
 * @see #reportError
 *
 * @param recognizer the parser instance
 * @param e the recognition exception
 */
protected void reportNoViableAlternative(Parser recognizer, NoViableAltException e) {
    TokenStream tokens = recognizer.getInputStream();
    String input;
    if (tokens != null) {
        if (e.getStartToken().getType() == Token.EOF)
            input = ""<EOF>"";
        else
            input = tokens.getText(e.getStartToken(), e.getOffendingToken());
    } else {
        input = ""<unknown input>"";
    }
    String msg = ""no viable alternative at input "" + escapeWSAndQuote(input);
    recognizer.notifyErrorListeners(e.getOffendingToken(), msg, e);
}","/**
 * This is called by {@link #reportError} when the exception is a
 * {@link NoViableAltException}.
 *
 * @see #reportError
 *
 * @param recognizer the parser instance
 * @param e the recognition exception
 */
", ,/** * This is called by {@link #reportError} when the exception is a * {@link NoViableAltException}. * * @see #reportError * * @param recognizer the parser instance * @param e the recognition exception */,297,311,[0],0,[0],0,[0],0,0,0,0,"reportNoViableAlternative(Parser, NoViableAltException)",org.antlr.v4.runtime.DefaultErrorStrategy,"reportNoViableAlternative/2[org.antlr.v4.runtime.Parser,org.antlr.v4.runtime.NoViableAltException]",False,299,6,8,1,7,3,7,13,0,3,2,7,1,1,0,2,0,0,3,0,5,1,2,0,0,0,34,4,0,True
155,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\DefaultErrorStrategy.java,org.antlr.v4.runtime.DefaultErrorStrategy,"void reportInputMismatch(Parser, InputMismatchException)","/**
 * This is called by {@link #reportError} when the exception is an
 * {@link InputMismatchException}.
 *
 * @see #reportError
 *
 * @param recognizer the parser instance
 * @param e the recognition exception
 */
protected void reportInputMismatch(Parser recognizer, InputMismatchException e) {
    String msg = ""mismatched input "" + getTokenErrorDisplay(e.getOffendingToken()) + "" expecting "" + e.getExpectedTokens().toString(recognizer.getVocabulary());
    recognizer.notifyErrorListeners(e.getOffendingToken(), msg, e);
}","/**
 * This is called by {@link #reportError} when the exception is an
 * {@link InputMismatchException}.
 *
 * @see #reportError
 *
 * @param recognizer the parser instance
 * @param e the recognition exception
 */
", ,/** * This is called by {@link #reportError} when the exception is an * {@link InputMismatchException}. * * @see #reportError * * @param recognizer the parser instance * @param e the recognition exception */,322,328,[0],0,[0],0,[0],0,0,0,0,"reportInputMismatch(Parser, InputMismatchException)",org.antlr.v4.runtime.DefaultErrorStrategy,"reportInputMismatch/2[org.antlr.v4.runtime.Parser,org.antlr.v4.runtime.InputMismatchException]",False,324,6,7,1,6,1,6,4,0,1,2,6,1,2,0,0,0,0,2,0,1,1,0,0,0,0,25,4,0,True
156,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\DefaultErrorStrategy.java,org.antlr.v4.runtime.DefaultErrorStrategy,"void reportFailedPredicate(Parser, FailedPredicateException)","/**
 * This is called by {@link #reportError} when the exception is a
 * {@link FailedPredicateException}.
 *
 * @see #reportError
 *
 * @param recognizer the parser instance
 * @param e the recognition exception
 */
protected void reportFailedPredicate(Parser recognizer, FailedPredicateException e) {
    String ruleName = recognizer.getRuleNames()[recognizer._ctx.getRuleIndex()];
    String msg = ""rule "" + ruleName + "" "" + e.getMessage();
    recognizer.notifyErrorListeners(e.getOffendingToken(), msg, e);
}","/**
 * This is called by {@link #reportError} when the exception is a
 * {@link FailedPredicateException}.
 *
 * @see #reportError
 *
 * @param recognizer the parser instance
 * @param e the recognition exception
 */
", ,/** * This is called by {@link #reportError} when the exception is a * {@link FailedPredicateException}. * * @see #reportError * * @param recognizer the parser instance * @param e the recognition exception */,339,345,[0],0,[0],0,[0],0,0,0,0,"reportFailedPredicate(Parser, FailedPredicateException)",org.antlr.v4.runtime.DefaultErrorStrategy,"reportFailedPredicate/2[org.antlr.v4.runtime.Parser,org.antlr.v4.runtime.FailedPredicateException]",False,341,5,5,1,4,1,5,5,0,2,2,5,0,0,0,0,0,0,2,0,2,1,0,0,0,0,21,4,0,True
157,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\DefaultErrorStrategy.java,org.antlr.v4.runtime.DefaultErrorStrategy,void reportUnwantedToken(Parser),"/**
 * This method is called to report a syntax error which requires the removal
 * of a token from the input stream. At the time this method is called, the
 * erroneous symbol is current {@code LT(1)} symbol and has not yet been
 * removed from the input stream. When this method returns,
 * {@code recognizer} is in error recovery mode.
 *
 * <p>This method is called when {@link #singleTokenDeletion} identifies
 * single-token deletion as a viable recovery strategy for a mismatched
 * input error.</p>
 *
 * <p>The default implementation simply returns if the handler is already in
 * error recovery mode. Otherwise, it calls {@link #beginErrorCondition} to
 * enter error recovery mode, followed by calling
 * {@link Parser#notifyErrorListeners}.</p>
 *
 * @param recognizer the parser instance
 */
protected void reportUnwantedToken(Parser recognizer) {
    if (inErrorRecoveryMode(recognizer)) {
        return;
    }
    beginErrorCondition(recognizer);
    Token t = recognizer.getCurrentToken();
    String tokenName = getTokenErrorDisplay(t);
    IntervalSet expecting = getExpectedTokens(recognizer);
    String msg = ""extraneous input "" + tokenName + "" expecting "" + expecting.toString(recognizer.getVocabulary());
    recognizer.notifyErrorListeners(t, msg, null);
}","/**
 * This method is called to report a syntax error which requires the removal
 * of a token from the input stream. At the time this method is called, the
 * erroneous symbol is current {@code LT(1)} symbol and has not yet been
 * removed from the input stream. When this method returns,
 * {@code recognizer} is in error recovery mode.
 *
 * <p>This method is called when {@link #singleTokenDeletion} identifies
 * single-token deletion as a viable recovery strategy for a mismatched
 * input error.</p>
 *
 * <p>The default implementation simply returns if the handler is already in
 * error recovery mode. Otherwise, it calls {@link #beginErrorCondition} to
 * enter error recovery mode, followed by calling
 * {@link Parser#notifyErrorListeners}.</p>
 *
 * @param recognizer the parser instance
 */
", ,"/** * This method is called to report a syntax error which requires the removal * of a token from the input stream. At the time this method is called, the * erroneous symbol is current {@code LT(1)} symbol and has not yet been * removed from the input stream. When this method returns, * {@code recognizer} is in error recovery mode. * * <p>This method is called when {@link #singleTokenDeletion} identifies * single-token deletion as a viable recovery strategy for a mismatched * input error.</p> * * <p>The default implementation simply returns if the handler is already in * error recovery mode. Otherwise, it calls {@link #beginErrorCondition} to * enter error recovery mode, followed by calling * {@link Parser#notifyErrorListeners}.</p> * * @param recognizer the parser instance */",365,378,[0],0,[0],0,[0],0,0,0,0,reportUnwantedToken(Parser),org.antlr.v4.runtime.DefaultErrorStrategy,reportUnwantedToken/1[org.antlr.v4.runtime.Parser],False,365,5,10,2,8,2,8,11,1,4,1,8,4,2,0,0,0,0,2,0,4,1,1,0,0,0,73,4,0,True
158,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\DefaultErrorStrategy.java,org.antlr.v4.runtime.DefaultErrorStrategy,void reportMissingToken(Parser),"/**
 * This method is called to report a syntax error which requires the
 * insertion of a missing token into the input stream. At the time this
 * method is called, the missing token has not yet been inserted. When this
 * method returns, {@code recognizer} is in error recovery mode.
 *
 * <p>This method is called when {@link #singleTokenInsertion} identifies
 * single-token insertion as a viable recovery strategy for a mismatched
 * input error.</p>
 *
 * <p>The default implementation simply returns if the handler is already in
 * error recovery mode. Otherwise, it calls {@link #beginErrorCondition} to
 * enter error recovery mode, followed by calling
 * {@link Parser#notifyErrorListeners}.</p>
 *
 * @param recognizer the parser instance
 */
protected void reportMissingToken(Parser recognizer) {
    if (inErrorRecoveryMode(recognizer)) {
        return;
    }
    beginErrorCondition(recognizer);
    Token t = recognizer.getCurrentToken();
    IntervalSet expecting = getExpectedTokens(recognizer);
    String msg = ""missing "" + expecting.toString(recognizer.getVocabulary()) + "" at "" + getTokenErrorDisplay(t);
    recognizer.notifyErrorListeners(t, msg, null);
}","/**
 * This method is called to report a syntax error which requires the
 * insertion of a missing token into the input stream. At the time this
 * method is called, the missing token has not yet been inserted. When this
 * method returns, {@code recognizer} is in error recovery mode.
 *
 * <p>This method is called when {@link #singleTokenInsertion} identifies
 * single-token insertion as a viable recovery strategy for a mismatched
 * input error.</p>
 *
 * <p>The default implementation simply returns if the handler is already in
 * error recovery mode. Otherwise, it calls {@link #beginErrorCondition} to
 * enter error recovery mode, followed by calling
 * {@link Parser#notifyErrorListeners}.</p>
 *
 * @param recognizer the parser instance
 */
", ,"/** * This method is called to report a syntax error which requires the * insertion of a missing token into the input stream. At the time this * method is called, the missing token has not yet been inserted. When this * method returns, {@code recognizer} is in error recovery mode. * * <p>This method is called when {@link #singleTokenInsertion} identifies * single-token insertion as a viable recovery strategy for a mismatched * input error.</p> * * <p>The default implementation simply returns if the handler is already in * error recovery mode. Otherwise, it calls {@link #beginErrorCondition} to * enter error recovery mode, followed by calling * {@link Parser#notifyErrorListeners}.</p> * * @param recognizer the parser instance */",397,410,[0],0,[0],0,[0],0,0,0,0,reportMissingToken(Parser),org.antlr.v4.runtime.DefaultErrorStrategy,reportMissingToken/1[org.antlr.v4.runtime.Parser],False,397,5,9,1,8,2,8,10,1,3,1,8,4,2,0,0,0,0,2,0,3,1,1,0,0,0,67,4,0,True
159,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\DefaultErrorStrategy.java,org.antlr.v4.runtime.DefaultErrorStrategy,Token recoverInline(Parser),"/**
 * {@inheritDoc}
 *
 * <p>The default implementation attempts to recover from the mismatched input
 * by using single token insertion and deletion as described below. If the
 * recovery attempt fails, this method throws an
 * {@link InputMismatchException}.</p>
 *
 * <p><strong>EXTRA TOKEN</strong> (single token deletion)</p>
 *
 * <p>{@code LA(1)} is not what we are looking for. If {@code LA(2)} has the
 * right token, however, then assume {@code LA(1)} is some extra spurious
 * token and delete it. Then consume and return the next token (which was
 * the {@code LA(2)} token) as the successful result of the match operation.</p>
 *
 * <p>This recovery strategy is implemented by {@link #singleTokenDeletion}.</p>
 *
 * <p><strong>MISSING TOKEN</strong> (single token insertion)</p>
 *
 * <p>If current token (at {@code LA(1)}) is consistent with what could come
 * after the expected {@code LA(1)} token, then assume the token is missing
 * and use the parser's {@link TokenFactory} to create it on the fly. The
 * ""insertion"" is performed by returning the created token as the successful
 * result of the match operation.</p>
 *
 * <p>This recovery strategy is implemented by {@link #singleTokenInsertion}.</p>
 *
 * <p><strong>EXAMPLE</strong></p>
 *
 * <p>For example, Input {@code i=(3;} is clearly missing the {@code ')'}. When
 * the parser returns from the nested call to {@code expr}, it will have
 * call chain:</p>
 *
 * <pre>
 * stat &rarr; expr &rarr; atom
 * </pre>
 *
 * and it will be trying to match the {@code ')'} at this point in the
 * derivation:
 *
 * <pre>
 * =&gt; ID '=' '(' INT ')' ('+' atom)* ';'
 *                    ^
 * </pre>
 *
 * The attempt to match {@code ')'} will fail when it sees {@code ';'} and
 * call {@link #recoverInline}. To recover, it sees that {@code LA(1)==';'}
 * is in the set of tokens that can follow the {@code ')'} token reference
 * in rule {@code atom}. It can assume that you forgot the {@code ')'}.
 */
@Override
public Token recoverInline(Parser recognizer) throws RecognitionException {
    // SINGLE TOKEN DELETION
    Token matchedSymbol = singleTokenDeletion(recognizer);
    if (matchedSymbol != null) {
        // we have deleted the extra token.
        // now, move past ttype token as if all were ok
        recognizer.consume();
        return matchedSymbol;
    }
    // SINGLE TOKEN INSERTION
    if (singleTokenInsertion(recognizer)) {
        return getMissingSymbol(recognizer);
    }
    // even that didn't work; must throw the exception
    InputMismatchException e;
    if (nextTokensContext == null) {
        e = new InputMismatchException(recognizer);
    } else {
        e = new InputMismatchException(recognizer, nextTokensState, nextTokensContext);
    }
    throw e;
}","/**
 * {@inheritDoc}
 *
 * <p>The default implementation attempts to recover from the mismatched input
 * by using single token insertion and deletion as described below. If the
 * recovery attempt fails, this method throws an
 * {@link InputMismatchException}.</p>
 *
 * <p><strong>EXTRA TOKEN</strong> (single token deletion)</p>
 *
 * <p>{@code LA(1)} is not what we are looking for. If {@code LA(2)} has the
 * right token, however, then assume {@code LA(1)} is some extra spurious
 * token and delete it. Then consume and return the next token (which was
 * the {@code LA(2)} token) as the successful result of the match operation.</p>
 *
 * <p>This recovery strategy is implemented by {@link #singleTokenDeletion}.</p>
 *
 * <p><strong>MISSING TOKEN</strong> (single token insertion)</p>
 *
 * <p>If current token (at {@code LA(1)}) is consistent with what could come
 * after the expected {@code LA(1)} token, then assume the token is missing
 * and use the parser's {@link TokenFactory} to create it on the fly. The
 * ""insertion"" is performed by returning the created token as the successful
 * result of the match operation.</p>
 *
 * <p>This recovery strategy is implemented by {@link #singleTokenInsertion}.</p>
 *
 * <p><strong>EXAMPLE</strong></p>
 *
 * <p>For example, Input {@code i=(3;} is clearly missing the {@code ')'}. When
 * the parser returns from the nested call to {@code expr}, it will have
 * call chain:</p>
 *
 * <pre>
 * stat &rarr; expr &rarr; atom
 * </pre>
 *
 * and it will be trying to match the {@code ')'} at this point in the
 * derivation:
 *
 * <pre>
 * =&gt; ID '=' '(' INT ')' ('+' atom)* ';'
 *                    ^
 * </pre>
 *
 * The attempt to match {@code ')'} will fail when it sees {@code ';'} and
 * call {@link #recoverInline}. To recover, it sees that {@code LA(1)==';'}
 * is in the set of tokens that can follow the {@code ')'} token reference
 * in rule {@code atom}. It can assume that you forgot the {@code ')'}.
 */
","// SINGLE TOKEN DELETION
[[SEP]]// we have deleted the extra token.
[[SEP]]// now, move past ttype token as if all were ok
[[SEP]]// SINGLE TOKEN INSERTION
[[SEP]]// even that didn't work; must throw the exception
","/** * {@inheritDoc} * * <p>The default implementation attempts to recover from the mismatched input * by using single token insertion and deletion as described below. If the * recovery attempt fails, this method throws an * {@link InputMismatchException}.</p> * * <p><strong>EXTRA TOKEN</strong> (single token deletion)</p> * * <p>{@code LA(1)} is not what we are looking for. If {@code LA(2)} has the * right token, however, then assume {@code LA(1)} is some extra spurious * token and delete it. Then consume and return the next token (which was * the {@code LA(2)} token) as the successful result of the match operation.</p> * * <p>This recovery strategy is implemented by {@link #singleTokenDeletion}.</p> * * <p><strong>MISSING TOKEN</strong> (single token insertion)</p> * * <p>If current token (at {@code LA(1)}) is consistent with what could come * after the expected {@code LA(1)} token, then assume the token is missing * and use the parser's {@link TokenFactory} to create it on the fly. The * ""insertion"" is performed by returning the created token as the successful * result of the match operation.</p> * * <p>This recovery strategy is implemented by {@link #singleTokenInsertion}.</p> * * <p><strong>EXAMPLE</strong></p> * * <p>For example, Input {@code i=(3;} is clearly missing the {@code ')'}. When * the parser returns from the nested call to {@code expr}, it will have * call chain:</p> * * <pre> * stat &rarr; expr &rarr; atom * </pre> * * and it will be trying to match the {@code ')'} at this point in the * derivation: * * <pre> * =&gt; ID '=' '(' INT ')' ('+' atom)* ';' *                    ^ * </pre> * * The attempt to match {@code ')'} will fail when it sees {@code ';'} and * call {@link #recoverInline}. To recover, it sees that {@code LA(1)==';'} * is in the set of tokens that can follow the {@code ')'} token reference * in rule {@code atom}. It can assume that you forgot the {@code ')'}. */[[SEP]]// SINGLE TOKEN DELETION[[SEP]]// we have deleted the extra token.// now, move past ttype token as if all were ok[[SEP]]// SINGLE TOKEN INSERTION[[SEP]]// even that didn't work; must throw the exception",462,489,[0],0,"[0, 0, 0, 0, 0]",0,"[0, 0, 0, 0, 0]",0,0,0,0,recoverInline(Parser),org.antlr.v4.runtime.DefaultErrorStrategy,recoverInline/1[org.antlr.v4.runtime.Parser],False,465,4,6,0,6,4,4,18,2,2,1,4,3,8,0,2,0,0,0,0,3,0,1,0,0,0,134,1,0,True
160,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\DefaultErrorStrategy.java,org.antlr.v4.runtime.DefaultErrorStrategy,boolean singleTokenInsertion(Parser),"/**
 * This method implements the single-token insertion inline error recovery
 * strategy. It is called by {@link #recoverInline} if the single-token
 * deletion strategy fails to recover from the mismatched input. If this
 * method returns {@code true}, {@code recognizer} will be in error recovery
 * mode.
 *
 * <p>This method determines whether or not single-token insertion is viable by
 * checking if the {@code LA(1)} input symbol could be successfully matched
 * if it were instead the {@code LA(2)} symbol. If this method returns
 * {@code true}, the caller is responsible for creating and inserting a
 * token with the correct type to produce this behavior.</p>
 *
 * @param recognizer the parser instance
 * @return {@code true} if single-token insertion is a viable recovery
 * strategy for the current mismatched input, otherwise {@code false}
 */
protected boolean singleTokenInsertion(Parser recognizer) {
    int currentSymbolType = recognizer.getInputStream().LA(1);
    // if current token is consistent with what could come after current
    // ATN state, then we know we're missing a token; error recovery
    // is free to conjure up and insert the missing token
    ATNState currentState = recognizer.getInterpreter().atn.states.get(recognizer.getState());
    ATNState next = currentState.transition(0).target;
    ATN atn = recognizer.getInterpreter().atn;
    IntervalSet expectingAtLL2 = atn.nextTokens(next, recognizer._ctx);
    // System.out.println(""LT(2) set=""+expectingAtLL2.toString(recognizer.getTokenNames()));
    if (expectingAtLL2.contains(currentSymbolType)) {
        reportMissingToken(recognizer);
        return true;
    }
    return false;
}","/**
 * This method implements the single-token insertion inline error recovery
 * strategy. It is called by {@link #recoverInline} if the single-token
 * deletion strategy fails to recover from the mismatched input. If this
 * method returns {@code true}, {@code recognizer} will be in error recovery
 * mode.
 *
 * <p>This method determines whether or not single-token insertion is viable by
 * checking if the {@code LA(1)} input symbol could be successfully matched
 * if it were instead the {@code LA(2)} symbol. If this method returns
 * {@code true}, the caller is responsible for creating and inserting a
 * token with the correct type to produce this behavior.</p>
 *
 * @param recognizer the parser instance
 * @return {@code true} if single-token insertion is a viable recovery
 * strategy for the current mismatched input, otherwise {@code false}
 */
","// if current token is consistent with what could come after current
[[SEP]]// ATN state, then we know we're missing a token; error recovery
[[SEP]]// is free to conjure up and insert the missing token
[[SEP]]// System.out.println(""LT(2) set=""+expectingAtLL2.toString(recognizer.getTokenNames()));
","/** * This method implements the single-token insertion inline error recovery * strategy. It is called by {@link #recoverInline} if the single-token * deletion strategy fails to recover from the mismatched input. If this * method returns {@code true}, {@code recognizer} will be in error recovery * mode. * * <p>This method determines whether or not single-token insertion is viable by * checking if the {@code LA(1)} input symbol could be successfully matched * if it were instead the {@code LA(2)} symbol. If this method returns * {@code true}, the caller is responsible for creating and inserting a * token with the correct type to produce this behavior.</p> * * @param recognizer the parser instance * @return {@code true} if single-token insertion is a viable recovery * strategy for the current mismatched input, otherwise {@code false} */[[SEP]]// if current token is consistent with what could come after current// ATN state, then we know we're missing a token; error recovery// is free to conjure up and insert the missing token[[SEP]]// System.out.println(""LT(2) set=""+expectingAtLL2.toString(recognizer.getTokenNames()));",508,523,[0],0,"[0, 0, 0, 0]",0,"[0, 0, 0]",0,0,0,0,singleTokenInsertion(Parser),org.antlr.v4.runtime.DefaultErrorStrategy,singleTokenInsertion/1[org.antlr.v4.runtime.Parser],False,508,7,9,1,8,2,9,12,2,5,1,9,1,3,0,0,0,0,0,2,5,0,1,0,0,0,77,4,0,True
161,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\DefaultErrorStrategy.java,org.antlr.v4.runtime.DefaultErrorStrategy,Token singleTokenDeletion(Parser),"/**
 * This method implements the single-token deletion inline error recovery
 * strategy. It is called by {@link #recoverInline} to attempt to recover
 * from mismatched input. If this method returns null, the parser and error
 * handler state will not have changed. If this method returns non-null,
 * {@code recognizer} will <em>not</em> be in error recovery mode since the
 * returned token was a successful match.
 *
 * <p>If the single-token deletion is successful, this method calls
 * {@link #reportUnwantedToken} to report the error, followed by
 * {@link Parser#consume} to actually ""delete"" the extraneous token. Then,
 * before returning {@link #reportMatch} is called to signal a successful
 * match.</p>
 *
 * @param recognizer the parser instance
 * @return the successfully matched {@link Token} instance if single-token
 * deletion successfully recovers from the mismatched input, otherwise
 * {@code null}
 */
protected Token singleTokenDeletion(Parser recognizer) {
    int nextTokenType = recognizer.getInputStream().LA(2);
    IntervalSet expecting = getExpectedTokens(recognizer);
    if (expecting.contains(nextTokenType)) {
        reportUnwantedToken(recognizer);
        /*
			System.err.println(""recoverFromMismatchedToken deleting ""+
							   ((TokenStream)recognizer.getInputStream()).LT(1)+
							   "" since ""+((TokenStream)recognizer.getInputStream()).LT(2)+
							   "" is what we want"");
			*/
        // simply delete extra token
        recognizer.consume();
        // we want to return the token we're actually matching
        Token matchedSymbol = recognizer.getCurrentToken();
        // we know current token is correct
        reportMatch(recognizer);
        return matchedSymbol;
    }
    return null;
}","/**
 * This method implements the single-token deletion inline error recovery
 * strategy. It is called by {@link #recoverInline} to attempt to recover
 * from mismatched input. If this method returns null, the parser and error
 * handler state will not have changed. If this method returns non-null,
 * {@code recognizer} will <em>not</em> be in error recovery mode since the
 * returned token was a successful match.
 *
 * <p>If the single-token deletion is successful, this method calls
 * {@link #reportUnwantedToken} to report the error, followed by
 * {@link Parser#consume} to actually ""delete"" the extraneous token. Then,
 * before returning {@link #reportMatch} is called to signal a successful
 * match.</p>
 *
 * @param recognizer the parser instance
 * @return the successfully matched {@link Token} instance if single-token
 * deletion successfully recovers from the mismatched input, otherwise
 * {@code null}
 */
","/*
			System.err.println(""recoverFromMismatchedToken deleting ""+
							   ((TokenStream)recognizer.getInputStream()).LT(1)+
							   "" since ""+((TokenStream)recognizer.getInputStream()).LT(2)+
							   "" is what we want"");
			*/
[[SEP]]// simply delete extra token
[[SEP]]// we want to return the token we're actually matching
[[SEP]]// we know current token is correct
","/** * This method implements the single-token deletion inline error recovery * strategy. It is called by {@link #recoverInline} to attempt to recover * from mismatched input. If this method returns null, the parser and error * handler state will not have changed. If this method returns non-null, * {@code recognizer} will <em>not</em> be in error recovery mode since the * returned token was a successful match. * * <p>If the single-token deletion is successful, this method calls * {@link #reportUnwantedToken} to report the error, followed by * {@link Parser#consume} to actually ""delete"" the extraneous token. Then, * before returning {@link #reportMatch} is called to signal a successful * match.</p> * * @param recognizer the parser instance * @return the successfully matched {@link Token} instance if single-token * deletion successfully recovers from the mismatched input, otherwise * {@code null} */[[SEP]]/*			System.err.println(""recoverFromMismatchedToken deleting ""+							   ((TokenStream)recognizer.getInputStream()).LT(1)+							   "" since ""+((TokenStream)recognizer.getInputStream()).LT(2)+							   "" is what we want"");			*/[[SEP]]// simply delete extra token[[SEP]]// we want to return the token we're actually matching[[SEP]]// we know current token is correct",544,562,[0],0,"[0, 0, 0, 0]",0,"[0, 0, 0, 0, 0]",0,0,0,0,singleTokenDeletion(Parser),org.antlr.v4.runtime.DefaultErrorStrategy,singleTokenDeletion/1[org.antlr.v4.runtime.Parser],False,544,5,10,2,8,2,8,12,2,3,1,8,3,4,0,0,0,0,0,1,3,0,1,0,0,0,67,4,0,True
162,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\DefaultErrorStrategy.java,org.antlr.v4.runtime.DefaultErrorStrategy,Token getMissingSymbol(Parser),"/**
 * Conjure up a missing token during error recovery.
 *
 *  The recognizer attempts to recover from single missing
 *  symbols. But, actions might refer to that missing symbol.
 *  For example, x=ID {f($x);}. The action clearly assumes
 *  that there has been an identifier matched previously and that
 *  $x points at that token. If that token is missing, but
 *  the next token in the stream is what we want we assume that
 *  this token is missing and we keep going. Because we
 *  have to return some token to replace the missing token,
 *  we have to conjure one up. This method gives the user control
 *  over the tokens returned for missing tokens. Mostly,
 *  you will want to create something special for identifier
 *  tokens. For literals such as '{' and ',', the default
 *  action in the parser or tree parser works. It simply creates
 *  a CommonToken of the appropriate type. The text will be the token.
 *  If you change what tokens must be created by the lexer,
 *  override this method to create the appropriate tokens.
 */
protected Token getMissingSymbol(Parser recognizer) {
    Token currentSymbol = recognizer.getCurrentToken();
    IntervalSet expecting = getExpectedTokens(recognizer);
    int expectedTokenType = Token.INVALID_TYPE;
    if (!expecting.isNil()) {
        // get any element
        expectedTokenType = expecting.getMinElement();
    }
    String tokenText;
    if (expectedTokenType == Token.EOF)
        tokenText = ""<missing EOF>"";
    else
        tokenText = ""<missing "" + recognizer.getVocabulary().getDisplayName(expectedTokenType) + "">"";
    Token current = currentSymbol;
    Token lookback = recognizer.getInputStream().LT(-1);
    if (current.getType() == Token.EOF && lookback != null) {
        current = lookback;
    }
    return recognizer.getTokenFactory().create(new Pair<TokenSource, CharStream>(current.getTokenSource(), current.getTokenSource().getInputStream()), expectedTokenType, tokenText, Token.DEFAULT_CHANNEL, -1, -1, current.getLine(), current.getCharPositionInLine());
}","/**
 * Conjure up a missing token during error recovery.
 *
 *  The recognizer attempts to recover from single missing
 *  symbols. But, actions might refer to that missing symbol.
 *  For example, x=ID {f($x);}. The action clearly assumes
 *  that there has been an identifier matched previously and that
 *  $x points at that token. If that token is missing, but
 *  the next token in the stream is what we want we assume that
 *  this token is missing and we keep going. Because we
 *  have to return some token to replace the missing token,
 *  we have to conjure one up. This method gives the user control
 *  over the tokens returned for missing tokens. Mostly,
 *  you will want to create something special for identifier
 *  tokens. For literals such as '{' and ',', the default
 *  action in the parser or tree parser works. It simply creates
 *  a CommonToken of the appropriate type. The text will be the token.
 *  If you change what tokens must be created by the lexer,
 *  override this method to create the appropriate tokens.
 */
","// get any element
","/** * Conjure up a missing token during error recovery. * *  The recognizer attempts to recover from single missing *  symbols. But, actions might refer to that missing symbol. *  For example, x=ID {f($x);}. The action clearly assumes *  that there has been an identifier matched previously and that *  $x points at that token. If that token is missing, but *  the next token in the stream is what we want we assume that *  this token is missing and we keep going. Because we *  have to return some token to replace the missing token, *  we have to conjure one up. This method gives the user control *  over the tokens returned for missing tokens. Mostly, *  you will want to create something special for identifier *  tokens. For literals such as '{' and ',', the default *  action in the parser or tree parser works. It simply creates *  a CommonToken of the appropriate type. The text will be the token. *  If you change what tokens must be created by the lexer, *  override this method to create the appropriate tokens. */[[SEP]]// get any element",583,603,[0],0,[0],0,"[0, 0]",0,0,0,0,getMissingSymbol(Parser),org.antlr.v4.runtime.DefaultErrorStrategy,getMissingSymbol/1[org.antlr.v4.runtime.Parser],False,583,12,17,1,16,5,15,17,1,6,1,15,1,1,0,3,0,0,3,3,9,1,1,0,0,0,105,4,0,True
163,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\DefaultErrorStrategy.java,org.antlr.v4.runtime.DefaultErrorStrategy,String getTokenErrorDisplay(Token),"/**
 * How should a token be displayed in an error message? The default
 *  is to display just the text, but during development you might
 *  want to have a lot of information spit out.  Override in that case
 *  to use t.toString() (which, for CommonToken, dumps everything about
 *  the token). This is better than forcing you to override a method in
 *  your token objects because you don't have to go modify your lexer
 *  so that it creates a new Java type.
 */
protected String getTokenErrorDisplay(Token t) {
    if (t == null)
        return ""<no token>"";
    String s = getSymbolText(t);
    if (s == null) {
        if (getSymbolType(t) == Token.EOF) {
            s = ""<EOF>"";
        } else {
            s = ""<"" + getSymbolType(t) + "">"";
        }
    }
    return escapeWSAndQuote(s);
}","/**
 * How should a token be displayed in an error message? The default
 *  is to display just the text, but during development you might
 *  want to have a lot of information spit out.  Override in that case
 *  to use t.toString() (which, for CommonToken, dumps everything about
 *  the token). This is better than forcing you to override a method in
 *  your token objects because you don't have to go modify your lexer
 *  so that it creates a new Java type.
 */
", ,"/** * How should a token be displayed in an error message? The default *  is to display just the text, but during development you might *  want to have a lot of information spit out.  Override in that case *  to use t.toString() (which, for CommonToken, dumps everything about *  the token). This is better than forcing you to override a method in *  your token objects because you don't have to go modify your lexer *  so that it creates a new Java type. */",618,630,[0],0,[0],0,[0],0,0,0,0,getTokenErrorDisplay(Token),org.antlr.v4.runtime.DefaultErrorStrategy,getTokenErrorDisplay/1[org.antlr.v4.runtime.Token],False,618,2,6,3,3,4,3,13,2,1,1,3,3,1,0,3,0,0,4,0,3,1,2,0,0,0,63,4,0,True
164,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\DefaultErrorStrategy.java,org.antlr.v4.runtime.DefaultErrorStrategy,String escapeWSAndQuote(String),"protected String escapeWSAndQuote(String s) {
    // if ( s==null ) return s;
    s = s.replace(""\n"", ""\\n"");
    s = s.replace(""\r"", ""\\r"");
    s = s.replace(""\t"", ""\\t"");
    return ""'"" + s + ""'"";
}", ,"// if ( s==null ) return s;
",// if ( s==null ) return s;,641,647,[0],0,[0],0,[0],0,0,0,0,escapeWSAndQuote(String),org.antlr.v4.runtime.DefaultErrorStrategy,escapeWSAndQuote/1[java.lang.String],False,641,0,2,2,0,1,1,6,1,0,1,1,0,0,0,0,0,0,8,0,3,1,0,0,0,0,6,4,0,False
165,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\DefaultErrorStrategy.java,org.antlr.v4.runtime.DefaultErrorStrategy,IntervalSet getErrorRecoverySet(Parser),"/*  Compute the error recovery set for the current rule.  During
	 *  rule invocation, the parser pushes the set of tokens that can
	 *  follow that rule reference on the stack; this amounts to
	 *  computing FIRST of what follows the rule reference in the
	 *  enclosing rule. See LinearApproximator.FIRST().
	 *  This local follow set only includes tokens
	 *  from within the rule; i.e., the FIRST computation done by
	 *  ANTLR stops at the end of a rule.
	 *
	 *  EXAMPLE
	 *
	 *  When you find a ""no viable alt exception"", the input is not
	 *  consistent with any of the alternatives for rule r.  The best
	 *  thing to do is to consume tokens until you see something that
	 *  can legally follow a call to r *or* any rule that called r.
	 *  You don't want the exact set of viable next tokens because the
	 *  input might just be missing a token--you might consume the
	 *  rest of the input looking for one of the missing tokens.
	 *
	 *  Consider grammar:
	 *
	 *  a : '[' b ']'
	 *    | '(' b ')'
	 *    ;
	 *  b : c '^' INT ;
	 *  c : ID
	 *    | INT
	 *    ;
	 *
	 *  At each rule invocation, the set of tokens that could follow
	 *  that rule is pushed on a stack.  Here are the various
	 *  context-sensitive follow sets:
	 *
	 *  FOLLOW(b1_in_a) = FIRST(']') = ']'
	 *  FOLLOW(b2_in_a) = FIRST(')') = ')'
	 *  FOLLOW(c_in_b) = FIRST('^') = '^'
	 *
	 *  Upon erroneous input ""[]"", the call chain is
	 *
	 *  a -> b -> c
	 *
	 *  and, hence, the follow context stack is:
	 *
	 *  depth     follow set       start of rule execution
	 *    0         <EOF>                    a (from main())
	 *    1          ']'                     b
	 *    2          '^'                     c
	 *
	 *  Notice that ')' is not included, because b would have to have
	 *  been called from a different context in rule a for ')' to be
	 *  included.
	 *
	 *  For error recovery, we cannot consider FOLLOW(c)
	 *  (context-sensitive or otherwise).  We need the combined set of
	 *  all context-sensitive FOLLOW sets--the set of all tokens that
	 *  could follow any reference in the call chain.  We need to
	 *  resync to one of those tokens.  Note that FOLLOW(c)='^' and if
	 *  we resync'd to that token, we'd consume until EOF.  We need to
	 *  sync to context-sensitive FOLLOWs for a, b, and c: {']','^'}.
	 *  In this case, for input ""[]"", LA(1) is ']' and in the set, so we would
	 *  not consume anything. After printing an error, rule c would
	 *  return normally.  Rule b would not find the required '^' though.
	 *  At this point, it gets a mismatched token error and throws an
	 *  exception (since LA(1) is not in the viable following token
	 *  set).  The rule exception handler tries to recover, but finds
	 *  the same recovery set and doesn't consume anything.  Rule b
	 *  exits normally returning to rule a.  Now it finds the ']' (and
	 *  with the successful match exits errorRecovery mode).
	 *
	 *  So, you can see that the parser walks up the call chain looking
	 *  for the token that was a member of the recovery set.
	 *
	 *  Errors are not generated in errorRecovery mode.
	 *
	 *  ANTLR's error recovery mechanism is based upon original ideas:
	 *
	 *  ""Algorithms + Data Structures = Programs"" by Niklaus Wirth
	 *
	 *  and
	 *
	 *  ""A note on error recovery in recursive descent parsers"":
	 *  http://portal.acm.org/citation.cfm?id=947902.947905
	 *
	 *  Later, Josef Grosch had some good ideas:
	 *
	 *  ""Efficient and Comfortable Error Recovery in Recursive Descent
	 *  Parsers"":
	 *  ftp://www.cocolab.com/products/cocktail/doca4.ps/ell.ps.zip
	 *
	 *  Like Grosch I implement context-sensitive FOLLOW sets that are combined
	 *  at run-time upon error to avoid overhead during parsing.
	 */
protected IntervalSet getErrorRecoverySet(Parser recognizer) {
    ATN atn = recognizer.getInterpreter().atn;
    RuleContext ctx = recognizer._ctx;
    IntervalSet recoverSet = new IntervalSet();
    while (ctx != null && ctx.invokingState >= 0) {
        // compute what follows who invoked us
        ATNState invokingState = atn.states.get(ctx.invokingState);
        RuleTransition rt = (RuleTransition) invokingState.transition(0);
        IntervalSet follow = atn.nextTokens(rt.followState);
        recoverSet.addAll(follow);
        ctx = ctx.parent;
    }
    recoverSet.remove(Token.EPSILON);
    // System.out.println(""recover set ""+recoverSet.toString(recognizer.getTokenNames()));
    return recoverSet;
}","/*  Compute the error recovery set for the current rule.  During
	 *  rule invocation, the parser pushes the set of tokens that can
	 *  follow that rule reference on the stack; this amounts to
	 *  computing FIRST of what follows the rule reference in the
	 *  enclosing rule. See LinearApproximator.FIRST().
	 *  This local follow set only includes tokens
	 *  from within the rule; i.e., the FIRST computation done by
	 *  ANTLR stops at the end of a rule.
	 *
	 *  EXAMPLE
	 *
	 *  When you find a ""no viable alt exception"", the input is not
	 *  consistent with any of the alternatives for rule r.  The best
	 *  thing to do is to consume tokens until you see something that
	 *  can legally follow a call to r *or* any rule that called r.
	 *  You don't want the exact set of viable next tokens because the
	 *  input might just be missing a token--you might consume the
	 *  rest of the input looking for one of the missing tokens.
	 *
	 *  Consider grammar:
	 *
	 *  a : '[' b ']'
	 *    | '(' b ')'
	 *    ;
	 *  b : c '^' INT ;
	 *  c : ID
	 *    | INT
	 *    ;
	 *
	 *  At each rule invocation, the set of tokens that could follow
	 *  that rule is pushed on a stack.  Here are the various
	 *  context-sensitive follow sets:
	 *
	 *  FOLLOW(b1_in_a) = FIRST(']') = ']'
	 *  FOLLOW(b2_in_a) = FIRST(')') = ')'
	 *  FOLLOW(c_in_b) = FIRST('^') = '^'
	 *
	 *  Upon erroneous input ""[]"", the call chain is
	 *
	 *  a -> b -> c
	 *
	 *  and, hence, the follow context stack is:
	 *
	 *  depth     follow set       start of rule execution
	 *    0         <EOF>                    a (from main())
	 *    1          ']'                     b
	 *    2          '^'                     c
	 *
	 *  Notice that ')' is not included, because b would have to have
	 *  been called from a different context in rule a for ')' to be
	 *  included.
	 *
	 *  For error recovery, we cannot consider FOLLOW(c)
	 *  (context-sensitive or otherwise).  We need the combined set of
	 *  all context-sensitive FOLLOW sets--the set of all tokens that
	 *  could follow any reference in the call chain.  We need to
	 *  resync to one of those tokens.  Note that FOLLOW(c)='^' and if
	 *  we resync'd to that token, we'd consume until EOF.  We need to
	 *  sync to context-sensitive FOLLOWs for a, b, and c: {']','^'}.
	 *  In this case, for input ""[]"", LA(1) is ']' and in the set, so we would
	 *  not consume anything. After printing an error, rule c would
	 *  return normally.  Rule b would not find the required '^' though.
	 *  At this point, it gets a mismatched token error and throws an
	 *  exception (since LA(1) is not in the viable following token
	 *  set).  The rule exception handler tries to recover, but finds
	 *  the same recovery set and doesn't consume anything.  Rule b
	 *  exits normally returning to rule a.  Now it finds the ']' (and
	 *  with the successful match exits errorRecovery mode).
	 *
	 *  So, you can see that the parser walks up the call chain looking
	 *  for the token that was a member of the recovery set.
	 *
	 *  Errors are not generated in errorRecovery mode.
	 *
	 *  ANTLR's error recovery mechanism is based upon original ideas:
	 *
	 *  ""Algorithms + Data Structures = Programs"" by Niklaus Wirth
	 *
	 *  and
	 *
	 *  ""A note on error recovery in recursive descent parsers"":
	 *  http://portal.acm.org/citation.cfm?id=947902.947905
	 *
	 *  Later, Josef Grosch had some good ideas:
	 *
	 *  ""Efficient and Comfortable Error Recovery in Recursive Descent
	 *  Parsers"":
	 *  ftp://www.cocolab.com/products/cocktail/doca4.ps/ell.ps.zip
	 *
	 *  Like Grosch I implement context-sensitive FOLLOW sets that are combined
	 *  at run-time upon error to avoid overhead during parsing.
	 */
","// compute what follows who invoked us
[[SEP]]// System.out.println(""recover set ""+recoverSet.toString(recognizer.getTokenNames()));
","/*  Compute the error recovery set for the current rule.  During	 *  rule invocation, the parser pushes the set of tokens that can	 *  follow that rule reference on the stack; this amounts to	 *  computing FIRST of what follows the rule reference in the	 *  enclosing rule. See LinearApproximator.FIRST().	 *  This local follow set only includes tokens	 *  from within the rule; i.e., the FIRST computation done by	 *  ANTLR stops at the end of a rule.	 *	 *  EXAMPLE	 *	 *  When you find a ""no viable alt exception"", the input is not	 *  consistent with any of the alternatives for rule r.  The best	 *  thing to do is to consume tokens until you see something that	 *  can legally follow a call to r *or* any rule that called r.	 *  You don't want the exact set of viable next tokens because the	 *  input might just be missing a token--you might consume the	 *  rest of the input looking for one of the missing tokens.	 *	 *  Consider grammar:	 *	 *  a : '[' b ']'	 *    | '(' b ')'	 *    ;	 *  b : c '^' INT ;	 *  c : ID	 *    | INT	 *    ;	 *	 *  At each rule invocation, the set of tokens that could follow	 *  that rule is pushed on a stack.  Here are the various	 *  context-sensitive follow sets:	 *	 *  FOLLOW(b1_in_a) = FIRST(']') = ']'	 *  FOLLOW(b2_in_a) = FIRST(')') = ')'	 *  FOLLOW(c_in_b) = FIRST('^') = '^'	 *	 *  Upon erroneous input ""[]"", the call chain is	 *	 *  a -> b -> c	 *	 *  and, hence, the follow context stack is:	 *	 *  depth     follow set       start of rule execution	 *    0         <EOF>                    a (from main())	 *    1          ']'                     b	 *    2          '^'                     c	 *	 *  Notice that ')' is not included, because b would have to have	 *  been called from a different context in rule a for ')' to be	 *  included.	 *	 *  For error recovery, we cannot consider FOLLOW(c)	 *  (context-sensitive or otherwise).  We need the combined set of	 *  all context-sensitive FOLLOW sets--the set of all tokens that	 *  could follow any reference in the call chain.  We need to	 *  resync to one of those tokens.  Note that FOLLOW(c)='^' and if	 *  we resync'd to that token, we'd consume until EOF.  We need to	 *  sync to context-sensitive FOLLOWs for a, b, and c: {']','^'}.	 *  In this case, for input ""[]"", LA(1) is ']' and in the set, so we would	 *  not consume anything. After printing an error, rule c would	 *  return normally.  Rule b would not find the required '^' though.	 *  At this point, it gets a mismatched token error and throws an	 *  exception (since LA(1) is not in the viable following token	 *  set).  The rule exception handler tries to recover, but finds	 *  the same recovery set and doesn't consume anything.  Rule b	 *  exits normally returning to rule a.  Now it finds the ']' (and	 *  with the successful match exits errorRecovery mode).	 *	 *  So, you can see that the parser walks up the call chain looking	 *  for the token that was a member of the recovery set.	 *	 *  Errors are not generated in errorRecovery mode.	 *	 *  ANTLR's error recovery mechanism is based upon original ideas:	 *	 *  ""Algorithms + Data Structures = Programs"" by Niklaus Wirth	 *	 *  and	 *	 *  ""A note on error recovery in recursive descent parsers"":	 *  http://portal.acm.org/citation.cfm?id=947902.947905	 *	 *  Later, Josef Grosch had some good ideas:	 *	 *  ""Efficient and Comfortable Error Recovery in Recursive Descent	 *  Parsers"":	 *  ftp://www.cocolab.com/products/cocktail/doca4.ps/ell.ps.zip	 *	 *  Like Grosch I implement context-sensitive FOLLOW sets that are combined	 *  at run-time upon error to avoid overhead during parsing.	 */[[SEP]]// compute what follows who invoked us[[SEP]]// System.out.println(""recover set ""+recoverSet.toString(recognizer.getTokenNames()));",741,756,[0],0,"[0, 0]",0,"[0, 0, 0]",0,0,0,1,getErrorRecoverySet(Parser),org.antlr.v4.runtime.DefaultErrorStrategy,getErrorRecoverySet/1[org.antlr.v4.runtime.Parser],False,741,7,8,2,6,3,6,14,1,6,1,6,0,0,1,1,0,0,0,2,7,0,1,0,0,0,21,4,0,False
166,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\DefaultErrorStrategy.java,org.antlr.v4.runtime.DefaultErrorStrategy,"void consumeUntil(Parser, IntervalSet)","/**
 * Consume tokens until one matches the given token set.
 */
protected void consumeUntil(Parser recognizer, IntervalSet set) {
    // System.err.println(""consumeUntil(""+set.toString(recognizer.getTokenNames())+"")"");
    int ttype = recognizer.getInputStream().LA(1);
    while (ttype != Token.EOF && !set.contains(ttype)) {
        // System.out.println(""consume during recover LA(1)=""+getTokenNames()[input.LA(1)]);
        // recognizer.getInputStream().consume();
        recognizer.consume();
        ttype = recognizer.getInputStream().LA(1);
    }
}","/**
 * Consume tokens until one matches the given token set.
 */
","// System.err.println(""consumeUntil(""+set.toString(recognizer.getTokenNames())+"")"");
[[SEP]]// System.out.println(""consume during recover LA(1)=""+getTokenNames()[input.LA(1)]);
[[SEP]]// recognizer.getInputStream().consume();
","/** * Consume tokens until one matches the given token set. */[[SEP]]// System.err.println(""consumeUntil(""+set.toString(recognizer.getTokenNames())+"")"");[[SEP]]// System.out.println(""consume during recover LA(1)=""+getTokenNames()[input.LA(1)]);// recognizer.getInputStream().consume();",759,768,[0],0,"[0, 0, 0]",0,"[0, 0, 0]",0,0,0,0,"consumeUntil(Parser, IntervalSet)",org.antlr.v4.runtime.DefaultErrorStrategy,"consumeUntil/2[org.antlr.v4.runtime.Parser,org.antlr.v4.runtime.misc.IntervalSet]",False,759,3,6,2,4,3,4,7,0,1,2,4,0,0,1,1,0,0,0,2,2,0,1,0,0,0,13,4,0,True
167,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\DiagnosticErrorListener.java,org.antlr.v4.runtime.DiagnosticErrorListener,"BitSet getConflictingAlts(BitSet, ATNConfigSet)","/**
 * Computes the set of conflicting or ambiguous alternatives from a
 * configuration set, if that information was not already provided by the
 * parser.
 *
 * @param reportedAlts The set of conflicting or ambiguous alternatives, as
 * reported by the parser.
 * @param configs The conflicting or ambiguous configuration set.
 * @return Returns {@code reportedAlts} if it is not {@code null}, otherwise
 * returns the set of alternatives represented in {@code configs}.
 */
protected BitSet getConflictingAlts(BitSet reportedAlts, ATNConfigSet configs) {
    if (reportedAlts != null) {
        return reportedAlts;
    }
    BitSet result = new BitSet();
    for (ATNConfig config : configs) {
        result.set(config.alt);
    }
    return result;
}","/**
 * Computes the set of conflicting or ambiguous alternatives from a
 * configuration set, if that information was not already provided by the
 * parser.
 *
 * @param reportedAlts The set of conflicting or ambiguous alternatives, as
 * reported by the parser.
 * @param configs The conflicting or ambiguous configuration set.
 * @return Returns {@code reportedAlts} if it is not {@code null}, otherwise
 * returns the set of alternatives represented in {@code configs}.
 */
", ,"/** * Computes the set of conflicting or ambiguous alternatives from a * configuration set, if that information was not already provided by the * parser. * * @param reportedAlts The set of conflicting or ambiguous alternatives, as * reported by the parser. * @param configs The conflicting or ambiguous configuration set. * @return Returns {@code reportedAlts} if it is not {@code null}, otherwise * returns the set of alternatives represented in {@code configs}. */",141,152,[0],0,[0],0,[0],0,0,0,0,"getConflictingAlts(BitSet, ATNConfigSet)",org.antlr.v4.runtime.DiagnosticErrorListener,"getConflictingAlts/2[java.util.BitSet,org.antlr.v4.runtime.atn.ATNConfigSet]",False,141,1,1,1,0,3,1,10,2,1,2,1,0,0,1,1,0,0,0,0,1,0,1,0,0,0,41,4,0,True
168,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\IntStream.java,org.antlr.v4.runtime.IntStream,void consume(),"/**
 *  Consumes the current symbol in the stream. This method has the following
 *  effects:
 *
 *  <ul>
 *    <li><strong>Forward movement:</strong> The value of {@link #index index()}
 * 		before calling this method is less than the value of {@code index()}
 * 		after calling this method.</li>
 *    <li><strong>Ordered lookahead:</strong> The value of {@code LA(1)} before
 * 		calling this method becomes the value of {@code LA(-1)} after calling
 * 		this method.</li>
 *  </ul>
 *
 *  Note that calling this method does not guarantee that {@code index()} is
 *  incremented by exactly 1, as that would preclude the ability to implement
 *  filtering streams (e.g. {@link CommonTokenStream} which distinguishes
 *  between ""on-channel"" and ""off-channel"" tokens).
 *
 *  @throws IllegalStateException if an attempt is made to consume the
 *  end of the stream (i.e. if {@code LA(1)==}{@link #EOF EOF} before calling
 *  {@code consume}).
 */
void consume();","/**
 *  Consumes the current symbol in the stream. This method has the following
 *  effects:
 *
 *  <ul>
 *    <li><strong>Forward movement:</strong> The value of {@link #index index()}
 * 		before calling this method is less than the value of {@code index()}
 * 		after calling this method.</li>
 *    <li><strong>Ordered lookahead:</strong> The value of {@code LA(1)} before
 * 		calling this method becomes the value of {@code LA(-1)} after calling
 * 		this method.</li>
 *  </ul>
 *
 *  Note that calling this method does not guarantee that {@code index()} is
 *  incremented by exactly 1, as that would preclude the ability to implement
 *  filtering streams (e.g. {@link CommonTokenStream} which distinguishes
 *  between ""on-channel"" and ""off-channel"" tokens).
 *
 *  @throws IllegalStateException if an attempt is made to consume the
 *  end of the stream (i.e. if {@code LA(1)==}{@link #EOF EOF} before calling
 *  {@code consume}).
 */
", ,"/** *  Consumes the current symbol in the stream. This method has the following *  effects: * *  <ul> *    <li><strong>Forward movement:</strong> The value of {@link #index index()} * 		before calling this method is less than the value of {@code index()} * 		after calling this method.</li> *    <li><strong>Ordered lookahead:</strong> The value of {@code LA(1)} before * 		calling this method becomes the value of {@code LA(-1)} after calling * 		this method.</li> *  </ul> * *  Note that calling this method does not guarantee that {@code index()} is *  incremented by exactly 1, as that would preclude the ability to implement *  filtering streams (e.g. {@link CommonTokenStream} which distinguishes *  between ""on-channel"" and ""off-channel"" tokens). * *  @throws IllegalStateException if an attempt is made to consume the *  end of the stream (i.e. if {@code LA(1)==}{@link #EOF EOF} before calling *  {@code consume}). */",60,60,[0],0,[0],0,[0],0,0,0,0,consume(),org.antlr.v4.runtime.IntStream,consume/0,False,38,0,6,6,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,64,0,0,True
169,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\IntStream.java,org.antlr.v4.runtime.IntStream,int LA(int),"/**
 * Gets the value of the symbol at offset {@code i} from the current
 * position. When {@code i==1}, this method returns the value of the current
 * symbol in the stream (which is the next symbol to be consumed). When
 * {@code i==-1}, this method returns the value of the previously read
 * symbol in the stream. It is not valid to call this method with
 * {@code i==0}, but the specific behavior is unspecified because this
 * method is frequently called from performance-critical code.
 *
 * <p>This method is guaranteed to succeed if any of the following are true:</p>
 *
 * <ul>
 *   <li>{@code i>0}</li>
 *   <li>{@code i==-1} and {@link #index index()} returns a value greater
 *     than the value of {@code index()} after the stream was constructed
 *     and {@code LA(1)} was called in that order. Specifying the current
 *     {@code index()} relative to the index after the stream was created
 *     allows for filtering implementations that do not return every symbol
 *     from the underlying source. Specifying the call to {@code LA(1)}
 *     allows for lazily initialized streams.</li>
 *   <li>{@code LA(i)} refers to a symbol consumed within a marked region
 *     that has not yet been released.</li>
 * </ul>
 *
 * <p>If {@code i} represents a position at or beyond the end of the stream,
 * this method returns {@link #EOF}.</p>
 *
 * <p>The return value is unspecified if {@code i<0} and fewer than {@code -i}
 * calls to {@link #consume consume()} have occurred from the beginning of
 * the stream before calling this method.</p>
 *
 * @throws UnsupportedOperationException if the stream does not support
 * retrieving the value of the specified symbol
 */
int LA(int i);","/**
 * Gets the value of the symbol at offset {@code i} from the current
 * position. When {@code i==1}, this method returns the value of the current
 * symbol in the stream (which is the next symbol to be consumed). When
 * {@code i==-1}, this method returns the value of the previously read
 * symbol in the stream. It is not valid to call this method with
 * {@code i==0}, but the specific behavior is unspecified because this
 * method is frequently called from performance-critical code.
 *
 * <p>This method is guaranteed to succeed if any of the following are true:</p>
 *
 * <ul>
 *   <li>{@code i>0}</li>
 *   <li>{@code i==-1} and {@link #index index()} returns a value greater
 *     than the value of {@code index()} after the stream was constructed
 *     and {@code LA(1)} was called in that order. Specifying the current
 *     {@code index()} relative to the index after the stream was created
 *     allows for filtering implementations that do not return every symbol
 *     from the underlying source. Specifying the call to {@code LA(1)}
 *     allows for lazily initialized streams.</li>
 *   <li>{@code LA(i)} refers to a symbol consumed within a marked region
 *     that has not yet been released.</li>
 * </ul>
 *
 * <p>If {@code i} represents a position at or beyond the end of the stream,
 * this method returns {@link #EOF}.</p>
 *
 * <p>The return value is unspecified if {@code i<0} and fewer than {@code -i}
 * calls to {@link #consume consume()} have occurred from the beginning of
 * the stream before calling this method.</p>
 *
 * @throws UnsupportedOperationException if the stream does not support
 * retrieving the value of the specified symbol
 */
", ,"/** * Gets the value of the symbol at offset {@code i} from the current * position. When {@code i==1}, this method returns the value of the current * symbol in the stream (which is the next symbol to be consumed). When * {@code i==-1}, this method returns the value of the previously read * symbol in the stream. It is not valid to call this method with * {@code i==0}, but the specific behavior is unspecified because this * method is frequently called from performance-critical code. * * <p>This method is guaranteed to succeed if any of the following are true:</p> * * <ul> *   <li>{@code i>0}</li> *   <li>{@code i==-1} and {@link #index index()} returns a value greater *     than the value of {@code index()} after the stream was constructed *     and {@code LA(1)} was called in that order. Specifying the current *     {@code index()} relative to the index after the stream was created *     allows for filtering implementations that do not return every symbol *     from the underlying source. Specifying the call to {@code LA(1)} *     allows for lazily initialized streams.</li> *   <li>{@code LA(i)} refers to a symbol consumed within a marked region *     that has not yet been released.</li> * </ul> * * <p>If {@code i} represents a position at or beyond the end of the stream, * this method returns {@link #EOF}.</p> * * <p>The return value is unspecified if {@code i<0} and fewer than {@code -i} * calls to {@link #consume consume()} have occurred from the beginning of * the stream before calling this method.</p> * * @throws UnsupportedOperationException if the stream does not support * retrieving the value of the specified symbol */",96,96,[0],0,[0],0,[0],0,0,0,0,LA(int),org.antlr.v4.runtime.IntStream,LA/1[int],False,62,0,34,34,0,1,0,1,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,96,0,0,True
170,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\IntStream.java,org.antlr.v4.runtime.IntStream,int mark(),"/**
 * A mark provides a guarantee that {@link #seek seek()} operations will be
 * valid over a ""marked range"" extending from the index where {@code mark()}
 * was called to the current {@link #index index()}. This allows the use of
 * streaming input sources by specifying the minimum buffering requirements
 * to support arbitrary lookahead during prediction.
 *
 * <p>The returned mark is an opaque handle (type {@code int}) which is passed
 * to {@link #release release()} when the guarantees provided by the marked
 * range are no longer necessary. When calls to
 * {@code mark()}/{@code release()} are nested, the marks must be released
 * in reverse order of which they were obtained. Since marked regions are
 * used during performance-critical sections of prediction, the specific
 * behavior of invalid usage is unspecified (i.e. a mark is not released, or
 * a mark is released twice, or marks are not released in reverse order from
 * which they were created).</p>
 *
 * <p>The behavior of this method is unspecified if no call to an
 * {@link IntStream initializing method} has occurred after this stream was
 * constructed.</p>
 *
 * <p>This method does not change the current position in the input stream.</p>
 *
 * <p>The following example shows the use of {@link #mark mark()},
 * {@link #release release(mark)}, {@link #index index()}, and
 * {@link #seek seek(index)} as part of an operation to safely work within a
 * marked region, then restore the stream position to its original value and
 * release the mark.</p>
 * <pre>
 * IntStream stream = ...;
 * int index = -1;
 * int mark = stream.mark();
 * try {
 *   index = stream.index();
 *   // perform work here...
 * } finally {
 *   if (index != -1) {
 *     stream.seek(index);
 *   }
 *   stream.release(mark);
 * }
 * </pre>
 *
 * @return An opaque marker which should be passed to
 * {@link #release release()} when the marked range is no longer required.
 */
int mark();","/**
 * A mark provides a guarantee that {@link #seek seek()} operations will be
 * valid over a ""marked range"" extending from the index where {@code mark()}
 * was called to the current {@link #index index()}. This allows the use of
 * streaming input sources by specifying the minimum buffering requirements
 * to support arbitrary lookahead during prediction.
 *
 * <p>The returned mark is an opaque handle (type {@code int}) which is passed
 * to {@link #release release()} when the guarantees provided by the marked
 * range are no longer necessary. When calls to
 * {@code mark()}/{@code release()} are nested, the marks must be released
 * in reverse order of which they were obtained. Since marked regions are
 * used during performance-critical sections of prediction, the specific
 * behavior of invalid usage is unspecified (i.e. a mark is not released, or
 * a mark is released twice, or marks are not released in reverse order from
 * which they were created).</p>
 *
 * <p>The behavior of this method is unspecified if no call to an
 * {@link IntStream initializing method} has occurred after this stream was
 * constructed.</p>
 *
 * <p>This method does not change the current position in the input stream.</p>
 *
 * <p>The following example shows the use of {@link #mark mark()},
 * {@link #release release(mark)}, {@link #index index()}, and
 * {@link #seek seek(index)} as part of an operation to safely work within a
 * marked region, then restore the stream position to its original value and
 * release the mark.</p>
 * <pre>
 * IntStream stream = ...;
 * int index = -1;
 * int mark = stream.mark();
 * try {
 *   index = stream.index();
 *   // perform work here...
 * } finally {
 *   if (index != -1) {
 *     stream.seek(index);
 *   }
 *   stream.release(mark);
 * }
 * </pre>
 *
 * @return An opaque marker which should be passed to
 * {@link #release release()} when the marked range is no longer required.
 */
", ,"/** * A mark provides a guarantee that {@link #seek seek()} operations will be * valid over a ""marked range"" extending from the index where {@code mark()} * was called to the current {@link #index index()}. This allows the use of * streaming input sources by specifying the minimum buffering requirements * to support arbitrary lookahead during prediction. * * <p>The returned mark is an opaque handle (type {@code int}) which is passed * to {@link #release release()} when the guarantees provided by the marked * range are no longer necessary. When calls to * {@code mark()}/{@code release()} are nested, the marks must be released * in reverse order of which they were obtained. Since marked regions are * used during performance-critical sections of prediction, the specific * behavior of invalid usage is unspecified (i.e. a mark is not released, or * a mark is released twice, or marks are not released in reverse order from * which they were created).</p> * * <p>The behavior of this method is unspecified if no call to an * {@link IntStream initializing method} has occurred after this stream was * constructed.</p> * * <p>This method does not change the current position in the input stream.</p> * * <p>The following example shows the use of {@link #mark mark()}, * {@link #release release(mark)}, {@link #index index()}, and * {@link #seek seek(index)} as part of an operation to safely work within a * marked region, then restore the stream position to its original value and * release the mark.</p> * <pre> * IntStream stream = ...; * int index = -1; * int mark = stream.mark(); * try { *   index = stream.index(); *   // perform work here... * } finally { *   if (index != -1) { *     stream.seek(index); *   } *   stream.release(mark); * } * </pre> * * @return An opaque marker which should be passed to * {@link #release release()} when the marked range is no longer required. */",144,144,[0],0,[0],0,[0],0,0,0,0,mark(),org.antlr.v4.runtime.IntStream,mark/0,False,98,0,4,4,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,115,0,0,True
171,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\IntStream.java,org.antlr.v4.runtime.IntStream,void release(int),"/**
 * This method releases a marked range created by a call to
 * {@link #mark mark()}. Calls to {@code release()} must appear in the
 * reverse order of the corresponding calls to {@code mark()}. If a mark is
 * released twice, or if marks are not released in reverse order of the
 * corresponding calls to {@code mark()}, the behavior is unspecified.
 *
 * <p>For more information and an example, see {@link #mark}.</p>
 *
 * @param marker A marker returned by a call to {@code mark()}.
 * @see #mark
 */
void release(int marker);","/**
 * This method releases a marked range created by a call to
 * {@link #mark mark()}. Calls to {@code release()} must appear in the
 * reverse order of the corresponding calls to {@code mark()}. If a mark is
 * released twice, or if marks are not released in reverse order of the
 * corresponding calls to {@code mark()}, the behavior is unspecified.
 *
 * <p>For more information and an example, see {@link #mark}.</p>
 *
 * @param marker A marker returned by a call to {@code mark()}.
 * @see #mark
 */
", ,"/** * This method releases a marked range created by a call to * {@link #mark mark()}. Calls to {@code release()} must appear in the * reverse order of the corresponding calls to {@code mark()}. If a mark is * released twice, or if marks are not released in reverse order of the * corresponding calls to {@code mark()}, the behavior is unspecified. * * <p>For more information and an example, see {@link #mark}.</p> * * @param marker A marker returned by a call to {@code mark()}. * @see #mark */",158,158,[0],0,[0],0,[0],0,0,0,0,release(int),org.antlr.v4.runtime.IntStream,release/1[int],False,146,0,4,4,0,1,0,1,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,41,0,0,True
172,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\IntStream.java,org.antlr.v4.runtime.IntStream,int index(),"/**
 * Return the index into the stream of the input symbol referred to by
 * {@code LA(1)}.
 *
 * <p>The behavior of this method is unspecified if no call to an
 * {@link IntStream initializing method} has occurred after this stream was
 * constructed.</p>
 */
int index();","/**
 * Return the index into the stream of the input symbol referred to by
 * {@code LA(1)}.
 *
 * <p>The behavior of this method is unspecified if no call to an
 * {@link IntStream initializing method} has occurred after this stream was
 * constructed.</p>
 */
", ,/** * Return the index into the stream of the input symbol referred to by * {@code LA(1)}. * * <p>The behavior of this method is unspecified if no call to an * {@link IntStream initializing method} has occurred after this stream was * constructed.</p> */,168,168,[0],0,[0],0,[0],0,0,0,0,index(),org.antlr.v4.runtime.IntStream,index/0,False,160,0,39,39,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,28,0,0,True
173,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\IntStream.java,org.antlr.v4.runtime.IntStream,void seek(int),"/**
 * Set the input cursor to the position indicated by {@code index}. If the
 * specified index lies past the end of the stream, the operation behaves as
 * though {@code index} was the index of the EOF symbol. After this method
 * returns without throwing an exception, then at least one of the following
 * will be true.
 *
 * <ul>
 *   <li>{@link #index index()} will return the index of the first symbol
 *     appearing at or after the specified {@code index}. Specifically,
 *     implementations which filter their sources should automatically
 *     adjust {@code index} forward the minimum amount required for the
 *     operation to target a non-ignored symbol.</li>
 *   <li>{@code LA(1)} returns {@link #EOF}</li>
 * </ul>
 *
 * This operation is guaranteed to not throw an exception if {@code index}
 * lies within a marked region. For more information on marked regions, see
 * {@link #mark}. The behavior of this method is unspecified if no call to
 * an {@link IntStream initializing method} has occurred after this stream
 * was constructed.
 *
 * @param index The absolute index to seek to.
 *
 * @throws IllegalArgumentException if {@code index} is less than 0
 * @throws UnsupportedOperationException if the stream does not support
 * seeking to the specified index
 */
void seek(int index);","/**
 * Set the input cursor to the position indicated by {@code index}. If the
 * specified index lies past the end of the stream, the operation behaves as
 * though {@code index} was the index of the EOF symbol. After this method
 * returns without throwing an exception, then at least one of the following
 * will be true.
 *
 * <ul>
 *   <li>{@link #index index()} will return the index of the first symbol
 *     appearing at or after the specified {@code index}. Specifically,
 *     implementations which filter their sources should automatically
 *     adjust {@code index} forward the minimum amount required for the
 *     operation to target a non-ignored symbol.</li>
 *   <li>{@code LA(1)} returns {@link #EOF}</li>
 * </ul>
 *
 * This operation is guaranteed to not throw an exception if {@code index}
 * lies within a marked region. For more information on marked regions, see
 * {@link #mark}. The behavior of this method is unspecified if no call to
 * an {@link IntStream initializing method} has occurred after this stream
 * was constructed.
 *
 * @param index The absolute index to seek to.
 *
 * @throws IllegalArgumentException if {@code index} is less than 0
 * @throws UnsupportedOperationException if the stream does not support
 * seeking to the specified index
 */
", ,"/** * Set the input cursor to the position indicated by {@code index}. If the * specified index lies past the end of the stream, the operation behaves as * though {@code index} was the index of the EOF symbol. After this method * returns without throwing an exception, then at least one of the following * will be true. * * <ul> *   <li>{@link #index index()} will return the index of the first symbol *     appearing at or after the specified {@code index}. Specifically, *     implementations which filter their sources should automatically *     adjust {@code index} forward the minimum amount required for the *     operation to target a non-ignored symbol.</li> *   <li>{@code LA(1)} returns {@link #EOF}</li> * </ul> * * This operation is guaranteed to not throw an exception if {@code index} * lies within a marked region. For more information on marked regions, see * {@link #mark}. The behavior of this method is unspecified if no call to * an {@link IntStream initializing method} has occurred after this stream * was constructed. * * @param index The absolute index to seek to. * * @throws IllegalArgumentException if {@code index} is less than 0 * @throws UnsupportedOperationException if the stream does not support * seeking to the specified index */",198,198,[0],0,[0],0,[0],0,0,0,0,seek(int),org.antlr.v4.runtime.IntStream,seek/1[int],False,170,0,10,10,0,1,0,1,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,97,0,0,True
174,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\IntStream.java,org.antlr.v4.runtime.IntStream,int size(),"/**
 * Returns the total number of symbols in the stream, including a single EOF
 * symbol.
 *
 * @throws UnsupportedOperationException if the size of the stream is
 * unknown.
 */
int size();","/**
 * Returns the total number of symbols in the stream, including a single EOF
 * symbol.
 *
 * @throws UnsupportedOperationException if the size of the stream is
 * unknown.
 */
", ,"/** * Returns the total number of symbols in the stream, including a single EOF * symbol. * * @throws UnsupportedOperationException if the size of the stream is * unknown. */",207,207,[0],0,[0],0,[0],0,0,0,0,size(),org.antlr.v4.runtime.IntStream,size/0,False,200,0,29,29,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,18,0,0,True
175,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\Lexer.java,org.antlr.v4.runtime.Lexer,void reset(),"public void reset() {
    // wack Lexer state variables
    if (_input != null) {
        // rewind the input
        _input.seek(0);
    }
    _token = null;
    _type = Token.INVALID_TYPE;
    _channel = Token.DEFAULT_CHANNEL;
    _tokenStartCharIndex = -1;
    _tokenStartCharPositionInLine = -1;
    _tokenStartLine = -1;
    _text = null;
    _hitEOF = false;
    _mode = Lexer.DEFAULT_MODE;
    _modeStack.clear();
    getInterpreter().reset();
}", ,"// wack Lexer state variables
[[SEP]]// rewind the input
",// wack Lexer state variables[[SEP]]// rewind the input,88,106,[0],0,"[0, 0]",0,"[0, 0]",0,0,0,0,reset(),org.antlr.v4.runtime.Lexer,reset/0,False,88,4,6,2,4,2,4,16,0,0,0,4,0,0,0,1,0,0,0,4,9,0,1,0,0,0,21,1,0,False
176,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\Lexer.java,org.antlr.v4.runtime.Lexer,Token nextToken(),"/**
 * Return a token from this source; i.e., match a token on the char
 *  stream.
 */
@Override
public Token nextToken() {
    if (_input == null) {
        throw new IllegalStateException(""nextToken requires a non-null input stream."");
    }
    // Mark start location in char stream so unbuffered streams are
    // guaranteed at least have text of current token
    int tokenStartMarker = _input.mark();
    try {
        outer: while (true) {
            if (_hitEOF) {
                emitEOF();
                return _token;
            }
            _token = null;
            _channel = Token.DEFAULT_CHANNEL;
            _tokenStartCharIndex = _input.index();
            _tokenStartCharPositionInLine = getInterpreter().getCharPositionInLine();
            _tokenStartLine = getInterpreter().getLine();
            _text = null;
            do {
                _type = Token.INVALID_TYPE;
                // System.out.println(""nextToken line ""+tokenStartLine+"" at ""+((char)input.LA(1))+
                // "" in mode ""+mode+
                // "" at index ""+input.index());
                int ttype;
                try {
                    ttype = getInterpreter().match(_input, _mode);
                } catch (LexerNoViableAltException e) {
                    // report error
                    notifyListeners(e);
                    recover(e);
                    ttype = SKIP;
                }
                if (_input.LA(1) == IntStream.EOF) {
                    _hitEOF = true;
                }
                if (_type == Token.INVALID_TYPE)
                    _type = ttype;
                if (_type == SKIP) {
                    continue outer;
                }
            } while (_type == MORE);
            if (_token == null)
                emit();
            return _token;
        }
    } finally {
        // make sure we release marker after match or
        // unbuffered char stream will keep buffering
        _input.release(tokenStartMarker);
    }
}","/**
 * Return a token from this source; i.e., match a token on the char
 *  stream.
 */
","// Mark start location in char stream so unbuffered streams are
[[SEP]]// guaranteed at least have text of current token
[[SEP]]// System.out.println(""nextToken line ""+tokenStartLine+"" at ""+((char)input.LA(1))+
[[SEP]]// "" in mode ""+mode+
[[SEP]]// "" at index ""+input.index());
[[SEP]]// report error
[[SEP]]// make sure we release marker after match or
[[SEP]]// unbuffered char stream will keep buffering
","/** * Return a token from this source; i.e., match a token on the char *  stream. */[[SEP]]// Mark start location in char stream so unbuffered streams are// guaranteed at least have text of current token[[SEP]]// System.out.println(""nextToken line ""+tokenStartLine+"" at ""+((char)input.LA(1))+// "" in mode ""+mode+// "" at index ""+input.index());[[SEP]]// report error[[SEP]]// make sure we release marker after match or// unbuffered char stream will keep buffering",111,165,[0],0,"[0, 0, 0, 0, 0, 0, 0, 0]",0,"[0, 0, 0, 0, 0]",0,0,1,0,nextToken(),org.antlr.v4.runtime.Lexer,nextToken/0,False,112,5,14,2,12,10,12,45,2,2,0,12,4,5,2,6,2,0,1,1,12,0,4,0,0,0,53,1,0,True
177,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\Lexer.java,org.antlr.v4.runtime.Lexer,void skip(),"/**
 * Instruct the lexer to skip creating a token for current lexer rule
 *  and look for another token.  nextToken() knows to keep looking when
 *  a lexer rule finishes with token set to SKIP_TOKEN.  Recall that
 *  if token==null at end of any token rule, it creates one for you
 *  and emits it.
 */
public void skip() {
    _type = SKIP;
}","/**
 * Instruct the lexer to skip creating a token for current lexer rule
 *  and look for another token.  nextToken() knows to keep looking when
 *  a lexer rule finishes with token set to SKIP_TOKEN.  Recall that
 *  if token==null at end of any token rule, it creates one for you
 *  and emits it.
 */
", ,"/** * Instruct the lexer to skip creating a token for current lexer rule *  and look for another token.  nextToken() knows to keep looking when *  a lexer rule finishes with token set to SKIP_TOKEN.  Recall that *  if token==null at end of any token rule, it creates one for you *  and emits it. */",173,175,[0],0,[0],0,[0],0,0,0,0,skip(),org.antlr.v4.runtime.Lexer,skip/0,False,173,0,1,1,0,1,0,3,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,39,1,0,True
178,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\Lexer.java,org.antlr.v4.runtime.Lexer,void setInputStream(IntStream),"/**
 * Set the char stream and reset the lexer
 */
@Override
public void setInputStream(IntStream input) {
    this._input = null;
    this._tokenFactorySourcePair = new Pair<TokenSource, CharStream>(this, _input);
    reset();
    this._input = (CharStream) input;
    this._tokenFactorySourcePair = new Pair<TokenSource, CharStream>(this, _input);
}","/**
 * Set the char stream and reset the lexer
 */
", ,/** * Set the char stream and reset the lexer */,209,216,[0],0,[0],0,[0],0,0,0,0,setInputStream(IntStream),org.antlr.v4.runtime.Lexer,setInputStream/1[org.antlr.v4.runtime.IntStream],False,210,5,4,2,2,1,1,7,0,0,1,1,1,1,0,0,0,0,0,0,4,0,0,0,0,0,13,1,0,True
179,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\Lexer.java,org.antlr.v4.runtime.Lexer,void emit(Token),"/**
 * By default does not support multiple emits per nextToken invocation
 *  for efficiency reasons.  Subclass and override this method, nextToken,
 *  and getToken (to push tokens into a list and pull from that list
 *  rather than a single variable as this implementation does).
 */
public void emit(Token token) {
    // System.err.println(""emit ""+token);
    this._token = token;
}","/**
 * By default does not support multiple emits per nextToken invocation
 *  for efficiency reasons.  Subclass and override this method, nextToken,
 *  and getToken (to push tokens into a list and pull from that list
 *  rather than a single variable as this implementation does).
 */
","// System.err.println(""emit ""+token);
","/** * By default does not support multiple emits per nextToken invocation *  for efficiency reasons.  Subclass and override this method, nextToken, *  and getToken (to push tokens into a list and pull from that list *  rather than a single variable as this implementation does). */[[SEP]]// System.err.println(""emit ""+token);",233,236,[0],0,[0],0,"[0, 0]",0,0,0,1,emit(Token),org.antlr.v4.runtime.Lexer,emit/1[org.antlr.v4.runtime.Token],False,233,1,2,2,0,1,0,3,0,0,1,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,32,1,0,True
180,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\Lexer.java,org.antlr.v4.runtime.Lexer,Token emit(),"/**
 * The standard method called to automatically emit a token at the
 *  outermost lexical rule.  The token object should point into the
 *  char buffer start..stop.  If there is a text override in 'text',
 *  use that to set the token's text.  Override this method to emit
 *  custom Token objects or provide a new factory.
 */
public Token emit() {
    Token t = _factory.create(_tokenFactorySourcePair, _type, _text, _channel, _tokenStartCharIndex, getCharIndex() - 1, _tokenStartLine, _tokenStartCharPositionInLine);
    emit(t);
    return t;
}","/**
 * The standard method called to automatically emit a token at the
 *  outermost lexical rule.  The token object should point into the
 *  char buffer start..stop.  If there is a text override in 'text',
 *  use that to set the token's text.  Override this method to emit
 *  custom Token objects or provide a new factory.
 */
", ,"/** * The standard method called to automatically emit a token at the *  outermost lexical rule.  The token object should point into the *  char buffer start..stop.  If there is a text override in 'text', *  use that to set the token's text.  Override this method to emit *  custom Token objects or provide a new factory. */",244,249,[0],0,[0],0,[0],0,0,0,0,emit(),org.antlr.v4.runtime.Lexer,emit/0,False,244,3,4,1,3,1,3,5,1,1,0,3,2,1,0,0,0,0,0,1,1,1,0,0,0,0,34,1,0,True
181,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\Lexer.java,org.antlr.v4.runtime.Lexer,int getCharIndex(),"/**
 * What is the index of the current character of lookahead?
 */
public int getCharIndex() {
    return _input.index();
}","/**
 * What is the index of the current character of lookahead?
 */
", ,/** * What is the index of the current character of lookahead? */,279,281,[0],0,[0],0,[0],0,0,0,0,getCharIndex(),org.antlr.v4.runtime.Lexer,getCharIndex/0,False,279,1,2,1,1,1,1,3,1,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,10,1,0,True
182,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\Lexer.java,org.antlr.v4.runtime.Lexer,String getText(),"/**
 * Return the text matched so far for the current token or any
 *  text override.
 */
public String getText() {
    if (_text != null) {
        return _text;
    }
    return getInterpreter().getText(_input);
}","/**
 * Return the text matched so far for the current token or any
 *  text override.
 */
", ,/** * Return the text matched so far for the current token or any *  text override. */,286,291,[0],0,[0],0,[0],0,0,0,0,getText(),org.antlr.v4.runtime.Lexer,getText/0,False,286,2,2,0,2,2,2,6,2,0,0,2,0,0,0,1,0,0,0,0,0,0,1,0,0,0,16,1,0,True
183,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\Lexer.java,org.antlr.v4.runtime.Lexer,void setText(String),"/**
 * Set the complete text of this token; it wipes any previous
 *  changes to the text.
 */
public void setText(String text) {
    this._text = text;
}","/**
 * Set the complete text of this token; it wipes any previous
 *  changes to the text.
 */
", ,/** * Set the complete text of this token; it wipes any previous *  changes to the text. */,296,298,[0],0,[0],0,[0],0,0,0,0,setText(String),org.antlr.v4.runtime.Lexer,setText/1[java.lang.String],False,296,0,0,0,0,1,0,3,0,0,1,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,14,1,0,True
184,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\Lexer.java,org.antlr.v4.runtime.Lexer,Token getToken(),"/**
 * Override if emitting multiple tokens.
 */
public Token getToken() {
    return _token;
}","/**
 * Override if emitting multiple tokens.
 */
", ,/** * Override if emitting multiple tokens. */,301,301,[0],0,[0],0,[0],0,0,0,0,getToken(),org.antlr.v4.runtime.Lexer,getToken/0,False,301,1,0,0,0,1,0,3,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,6,1,0,True
185,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\Lexer.java,org.antlr.v4.runtime.Lexer,String[] getTokenNames(),"/**
 * Used to print out token names like ID during debugging and
 *  error reporting.  The generated parsers implement a method
 *  that overrides this to point to their String[] tokenNames.
 */
@Override
@Deprecated
public String[] getTokenNames() {
    return null;
}","/**
 * Used to print out token names like ID during debugging and
 *  error reporting.  The generated parsers implement a method
 *  that overrides this to point to their String[] tokenNames.
 */
", ,/** * Used to print out token names like ID during debugging and *  error reporting.  The generated parsers implement a method *  that overrides this to point to their String[] tokenNames. */,333,337,[0],0,[0],0,[0],0,0,0,0,getTokenNames(),org.antlr.v4.runtime.Lexer,getTokenNames/0,False,335,0,0,0,0,1,0,3,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,27,1,0,True
186,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\Lexer.java,org.antlr.v4.runtime.Lexer,List<? extends Token> getAllTokens(),"/**
 * Return a list of all Token objects in input char stream.
 *  Forces load of all tokens. Does not include EOF token.
 */
public List<? extends Token> getAllTokens() {
    List<Token> tokens = new ArrayList<Token>();
    Token t = nextToken();
    while (t.getType() != Token.EOF) {
        tokens.add(t);
        t = nextToken();
    }
    return tokens;
}","/**
 * Return a list of all Token objects in input char stream.
 *  Forces load of all tokens. Does not include EOF token.
 */
", ,/** * Return a list of all Token objects in input char stream. *  Forces load of all tokens. Does not include EOF token. */,342,350,[0],0,[0],0,[0],0,0,0,0,getAllTokens(),org.antlr.v4.runtime.Lexer,getAllTokens/0,False,342,2,2,0,2,2,3,9,1,2,0,3,1,6,1,1,0,0,0,0,3,0,1,0,0,0,23,1,0,True
187,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\Lexer.java,org.antlr.v4.runtime.Lexer,void recover(LexerNoViableAltException),"public void recover(LexerNoViableAltException e) {
    if (_input.LA(1) != IntStream.EOF) {
        // skip a char and try again
        getInterpreter().consume(_input);
    }
}", ,"// skip a char and try again
",// skip a char and try again,352,357,[0],0,[0],0,[0],0,0,0,0,recover(LexerNoViableAltException),org.antlr.v4.runtime.Lexer,recover/1[org.antlr.v4.runtime.LexerNoViableAltException],False,352,4,4,1,3,2,3,5,0,0,1,3,0,0,0,1,0,0,0,1,0,0,1,0,0,0,10,1,0,False
188,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\Lexer.java,org.antlr.v4.runtime.Lexer,void recover(RecognitionException),"/**
 * Lexers can normally match any char in it's vocabulary after matching
 *  a token, so do the easy thing and just kill a character and hope
 *  it all works out.  You can instead use the rule invocation stack
 *  to do sophisticated error recovery if you are in a fragment rule.
 */
public void recover(RecognitionException re) {
    // System.out.println(""consuming char ""+(char)input.LA(1)+"" during recovery"");
    // re.printStackTrace();
    // TODO: Do we lose character or line position information?
    _input.consume();
}","/**
 * Lexers can normally match any char in it's vocabulary after matching
 *  a token, so do the easy thing and just kill a character and hope
 *  it all works out.  You can instead use the rule invocation stack
 *  to do sophisticated error recovery if you are in a fragment rule.
 */
","// System.out.println(""consuming char ""+(char)input.LA(1)+"" during recovery"");
[[SEP]]// re.printStackTrace();
[[SEP]]// TODO: Do we lose character or line position information?
","/** * Lexers can normally match any char in it's vocabulary after matching *  a token, so do the easy thing and just kill a character and hope *  it all works out.  You can instead use the rule invocation stack *  to do sophisticated error recovery if you are in a fragment rule. */[[SEP]]// System.out.println(""consuming char ""+(char)input.LA(1)+"" during recovery"");// re.printStackTrace();// TODO: Do we lose character or line position information?",404,409,[0],0,"[0, 0, 1]",1,"[0, 1]",1,1,1,1,recover(RecognitionException),org.antlr.v4.runtime.Lexer,recover/1[org.antlr.v4.runtime.RecognitionException],False,404,2,1,0,1,1,1,3,0,0,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,39,1,0,True
189,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\ListTokenSource.java,org.antlr.v4.runtime.ListTokenSource,int getCharPositionInLine(),"/**
 * {@inheritDoc}
 */
@Override
public int getCharPositionInLine() {
    if (i < tokens.size()) {
        return tokens.get(i).getCharPositionInLine();
    } else if (eofToken != null) {
        return eofToken.getCharPositionInLine();
    } else if (tokens.size() > 0) {
        // have to calculate the result from the line/column of the previous
        // token, along with the text of the token.
        Token lastToken = tokens.get(tokens.size() - 1);
        String tokenText = lastToken.getText();
        if (tokenText != null) {
            int lastNewLine = tokenText.lastIndexOf('\n');
            if (lastNewLine >= 0) {
                return tokenText.length() - lastNewLine - 1;
            }
        }
        return lastToken.getCharPositionInLine() + lastToken.getStopIndex() - lastToken.getStartIndex() + 1;
    }
    // only reach this if tokens is empty, meaning EOF occurs at the first
    // position in the input
    return 0;
}","/**
 * {@inheritDoc}
 */
","// only reach this if tokens is empty, meaning EOF occurs at the first
[[SEP]]// have to calculate the result from the line/column of the previous
[[SEP]]// token, along with the text of the token.
[[SEP]]// position in the input
","/** * {@inheritDoc} */[[SEP]]// have to calculate the result from the line/column of the previous// token, along with the text of the token.[[SEP]]// only reach this if tokens is empty, meaning EOF occurs at the first// position in the input",90,116,[0],0,"[0, 0, 0, 0]",0,"[0, 0, 0]",0,0,0,0,getCharPositionInLine(),org.antlr.v4.runtime.ListTokenSource,getCharPositionInLine/0,False,91,1,5,1,4,6,8,20,5,3,0,8,0,0,0,2,0,0,0,6,3,5,3,0,0,0,13,1,0,True
190,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\ListTokenSource.java,org.antlr.v4.runtime.ListTokenSource,Token nextToken(),"/**
 * {@inheritDoc}
 */
@Override
public Token nextToken() {
    if (i >= tokens.size()) {
        if (eofToken == null) {
            int start = -1;
            if (tokens.size() > 0) {
                int previousStop = tokens.get(tokens.size() - 1).getStopIndex();
                if (previousStop != -1) {
                    start = previousStop + 1;
                }
            }
            int stop = Math.max(-1, start - 1);
            eofToken = _factory.create(new Pair<TokenSource, CharStream>(this, getInputStream()), Token.EOF, ""EOF"", Token.DEFAULT_CHANNEL, start, stop, getLine(), getCharPositionInLine());
        }
        return eofToken;
    }
    Token t = tokens.get(i);
    if (i == tokens.size() - 1 && t.getType() == Token.EOF) {
        eofToken = t;
    }
    i++;
    return t;
}","/**
 * {@inheritDoc}
 */
", ,/** * {@inheritDoc} */,121,147,[0],0,[0],0,[0],0,0,0,0,nextToken(),org.antlr.v4.runtime.ListTokenSource,nextToken/0,False,122,6,7,0,7,7,9,22,2,4,0,9,3,1,0,4,0,0,1,8,7,4,4,0,0,0,10,1,0,True
191,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\ListTokenSource.java,org.antlr.v4.runtime.ListTokenSource,int getLine(),"/**
 * {@inheritDoc}
 */
@Override
public int getLine() {
    if (i < tokens.size()) {
        return tokens.get(i).getLine();
    } else if (eofToken != null) {
        return eofToken.getLine();
    } else if (tokens.size() > 0) {
        // have to calculate the result from the line/column of the previous
        // token, along with the text of the token.
        Token lastToken = tokens.get(tokens.size() - 1);
        int line = lastToken.getLine();
        String tokenText = lastToken.getText();
        if (tokenText != null) {
            for (int i = 0; i < tokenText.length(); i++) {
                if (tokenText.charAt(i) == '\n') {
                    line++;
                }
            }
        }
        // if no text is available, assume the token did not contain any newline characters.
        return line;
    }
    // only reach this if tokens is empty, meaning EOF occurs at the first
    // position in the input
    return 1;
}","/**
 * {@inheritDoc}
 */
","// only reach this if tokens is empty, meaning EOF occurs at the first
[[SEP]]// have to calculate the result from the line/column of the previous
[[SEP]]// token, along with the text of the token.
[[SEP]]// if no text is available, assume the token did not contain any newline characters.
[[SEP]]// position in the input
","/** * {@inheritDoc} */[[SEP]]// have to calculate the result from the line/column of the previous// token, along with the text of the token.[[SEP]]// if no text is available, assume the token did not contain any newline characters.[[SEP]]// only reach this if tokens is empty, meaning EOF occurs at the first// position in the input",152,182,[0],0,"[0, 0, 0, 0, 0]",0,"[0, 0, 0, 0]",0,0,0,0,getLine(),org.antlr.v4.runtime.ListTokenSource,getLine/0,False,153,1,3,1,2,7,6,22,4,4,0,6,0,0,1,3,0,0,0,4,4,1,4,0,0,0,10,1,0,True
192,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\ListTokenSource.java,org.antlr.v4.runtime.ListTokenSource,CharStream getInputStream(),"/**
 * {@inheritDoc}
 */
@Override
public CharStream getInputStream() {
    if (i < tokens.size()) {
        return tokens.get(i).getInputStream();
    } else if (eofToken != null) {
        return eofToken.getInputStream();
    } else if (tokens.size() > 0) {
        return tokens.get(tokens.size() - 1).getInputStream();
    }
    // no input stream information is available
    return null;
}","/**
 * {@inheritDoc}
 */
","// no input stream information is available
",/** * {@inheritDoc} */[[SEP]]// no input stream information is available,187,201,[0],0,[0],0,"[0, 0]",0,0,0,0,getInputStream(),org.antlr.v4.runtime.ListTokenSource,getInputStream/0,False,188,2,3,2,1,4,3,12,4,0,0,3,0,0,0,1,0,0,0,2,0,1,1,0,0,0,8,1,0,True
193,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\ListTokenSource.java,org.antlr.v4.runtime.ListTokenSource,String getSourceName(),"/**
 * {@inheritDoc}
 */
@Override
public String getSourceName() {
    if (sourceName != null) {
        return sourceName;
    }
    CharStream inputStream = getInputStream();
    if (inputStream != null) {
        return inputStream.getSourceName();
    }
    return ""List"";
}","/**
 * {@inheritDoc}
 */
", ,/** * {@inheritDoc} */,206,218,[0],0,[0],0,[0],0,0,0,0,getSourceName(),org.antlr.v4.runtime.ListTokenSource,getSourceName/0,False,207,3,2,0,2,3,2,10,3,1,0,2,1,1,0,2,0,0,1,0,1,0,1,0,0,0,9,1,0,True
194,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\ListTokenSource.java,org.antlr.v4.runtime.ListTokenSource,void setTokenFactory(TokenFactory<?>),"/**
 * {@inheritDoc}
 */
@Override
public void setTokenFactory(TokenFactory<?> factory) {
    this._factory = factory;
}","/**
 * {@inheritDoc}
 */
", ,/** * {@inheritDoc} */,223,226,[0],0,[0],0,[0],0,0,0,0,setTokenFactory(TokenFactory<?>),org.antlr.v4.runtime.ListTokenSource,setTokenFactory/1[org.antlr.v4.runtime.TokenFactory<?>],False,224,1,0,0,0,1,0,3,0,0,1,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,4,1,0,True
195,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\ListTokenSource.java,org.antlr.v4.runtime.ListTokenSource,TokenFactory<?> getTokenFactory(),"/**
 * {@inheritDoc}
 */
@Override
public TokenFactory<?> getTokenFactory() {
    return _factory;
}","/**
 * {@inheritDoc}
 */
", ,/** * {@inheritDoc} */,231,234,[0],0,[0],0,[0],0,0,0,0,getTokenFactory(),org.antlr.v4.runtime.ListTokenSource,getTokenFactory/0,False,232,1,0,0,0,1,0,3,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,4,1,0,True
196,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\Parser.java,org.antlr.v4.runtime.Parser,void reset(),"/**
 * reset the parser's state
 */
public void reset() {
    if (getInputStream() != null)
        getInputStream().seek(0);
    _errHandler.reset(this);
    _ctx = null;
    _syntaxErrors = 0;
    matchedEOF = false;
    setTrace(false);
    _precedenceStack.clear();
    _precedenceStack.push(0);
    ATNSimulator interpreter = getInterpreter();
    if (interpreter != null) {
        interpreter.reset();
    }
}","/**
 * reset the parser's state
 */
", ,/** * reset the parser's state */,164,177,[0],0,[0],0,[0],0,0,0,0,reset(),org.antlr.v4.runtime.Parser,reset/0,False,164,7,9,1,8,3,8,14,0,1,0,8,2,3,0,2,0,0,0,3,4,0,1,0,0,0,23,1,0,True
197,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\Parser.java,org.antlr.v4.runtime.Parser,Token match(int),"/**
 * Match current input symbol against {@code ttype}. If the symbol type
 * matches, {@link ANTLRErrorStrategy#reportMatch} and {@link #consume} are
 * called to complete the match process.
 *
 * <p>If the symbol type does not match,
 * {@link ANTLRErrorStrategy#recoverInline} is called on the current error
 * strategy to attempt recovery. If {@link #getBuildParseTree} is
 * {@code true} and the token index of the symbol returned by
 * {@link ANTLRErrorStrategy#recoverInline} is -1, the symbol is added to
 * the parse tree by calling {@link #createErrorNode(ParserRuleContext, Token)} then
 * {@link ParserRuleContext#addErrorNode(ErrorNode)}.</p>
 *
 * @param ttype the token type to match
 * @return the matched symbol
 * @throws RecognitionException if the current input symbol did not match
 * {@code ttype} and the error strategy could not recover from the
 * mismatched symbol
 */
public Token match(int ttype) throws RecognitionException {
    Token t = getCurrentToken();
    if (t.getType() == ttype) {
        if (ttype == Token.EOF) {
            matchedEOF = true;
        }
        _errHandler.reportMatch(this);
        consume();
    } else {
        t = _errHandler.recoverInline(this);
        if (_buildParseTrees && t.getTokenIndex() == -1) {
            // we must have conjured up a new token during single token insertion
            // if it's not the current symbol
            _ctx.addErrorNode(createErrorNode(_ctx, t));
        }
    }
    return t;
}","/**
 * Match current input symbol against {@code ttype}. If the symbol type
 * matches, {@link ANTLRErrorStrategy#reportMatch} and {@link #consume} are
 * called to complete the match process.
 *
 * <p>If the symbol type does not match,
 * {@link ANTLRErrorStrategy#recoverInline} is called on the current error
 * strategy to attempt recovery. If {@link #getBuildParseTree} is
 * {@code true} and the token index of the symbol returned by
 * {@link ANTLRErrorStrategy#recoverInline} is -1, the symbol is added to
 * the parse tree by calling {@link #createErrorNode(ParserRuleContext, Token)} then
 * {@link ParserRuleContext#addErrorNode(ErrorNode)}.</p>
 *
 * @param ttype the token type to match
 * @return the matched symbol
 * @throws RecognitionException if the current input symbol did not match
 * {@code ttype} and the error strategy could not recover from the
 * mismatched symbol
 */
","// we must have conjured up a new token during single token insertion
[[SEP]]// if it's not the current symbol
","/** * Match current input symbol against {@code ttype}. If the symbol type * matches, {@link ANTLRErrorStrategy#reportMatch} and {@link #consume} are * called to complete the match process. * * <p>If the symbol type does not match, * {@link ANTLRErrorStrategy#recoverInline} is called on the current error * strategy to attempt recovery. If {@link #getBuildParseTree} is * {@code true} and the token index of the symbol returned by * {@link ANTLRErrorStrategy#recoverInline} is -1, the symbol is added to * the parse tree by calling {@link #createErrorNode(ParserRuleContext, Token)} then * {@link ParserRuleContext#addErrorNode(ErrorNode)}.</p> * * @param ttype the token type to match * @return the matched symbol * @throws RecognitionException if the current input symbol did not match * {@code ttype} and the error strategy could not recover from the * mismatched symbol */[[SEP]]// we must have conjured up a new token during single token insertion// if it's not the current symbol",198,216,[0],0,"[0, 0]",0,"[0, 0]",0,0,0,0,match(int),org.antlr.v4.runtime.Parser,match/1[int],False,198,4,9,1,8,5,8,17,1,1,1,8,3,3,0,3,0,0,0,1,3,0,2,0,0,0,58,1,0,True
198,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\Parser.java,org.antlr.v4.runtime.Parser,Token matchWildcard(),"/**
 * Match current input symbol as a wildcard. If the symbol type matches
 * (i.e. has a value greater than 0), {@link ANTLRErrorStrategy#reportMatch}
 * and {@link #consume} are called to complete the match process.
 *
 * <p>If the symbol type does not match,
 * {@link ANTLRErrorStrategy#recoverInline} is called on the current error
 * strategy to attempt recovery. If {@link #getBuildParseTree} is
 * {@code true} and the token index of the symbol returned by
 * {@link ANTLRErrorStrategy#recoverInline} is -1, the symbol is added to
 * the parse tree by calling {@link Parser#createErrorNode(ParserRuleContext, Token)}. then
 * {@link ParserRuleContext#addErrorNode(ErrorNode)}</p>
 *
 * @return the matched symbol
 * @throws RecognitionException if the current input symbol did not match
 * a wildcard and the error strategy could not recover from the mismatched
 * symbol
 */
public Token matchWildcard() throws RecognitionException {
    Token t = getCurrentToken();
    if (t.getType() > 0) {
        _errHandler.reportMatch(this);
        consume();
    } else {
        t = _errHandler.recoverInline(this);
        if (_buildParseTrees && t.getTokenIndex() == -1) {
            // we must have conjured up a new token during single token insertion
            // if it's not the current symbol
            _ctx.addErrorNode(createErrorNode(_ctx, t));
        }
    }
    return t;
}","/**
 * Match current input symbol as a wildcard. If the symbol type matches
 * (i.e. has a value greater than 0), {@link ANTLRErrorStrategy#reportMatch}
 * and {@link #consume} are called to complete the match process.
 *
 * <p>If the symbol type does not match,
 * {@link ANTLRErrorStrategy#recoverInline} is called on the current error
 * strategy to attempt recovery. If {@link #getBuildParseTree} is
 * {@code true} and the token index of the symbol returned by
 * {@link ANTLRErrorStrategy#recoverInline} is -1, the symbol is added to
 * the parse tree by calling {@link Parser#createErrorNode(ParserRuleContext, Token)}. then
 * {@link ParserRuleContext#addErrorNode(ErrorNode)}</p>
 *
 * @return the matched symbol
 * @throws RecognitionException if the current input symbol did not match
 * a wildcard and the error strategy could not recover from the mismatched
 * symbol
 */
","// we must have conjured up a new token during single token insertion
[[SEP]]// if it's not the current symbol
","/** * Match current input symbol as a wildcard. If the symbol type matches * (i.e. has a value greater than 0), {@link ANTLRErrorStrategy#reportMatch} * and {@link #consume} are called to complete the match process. * * <p>If the symbol type does not match, * {@link ANTLRErrorStrategy#recoverInline} is called on the current error * strategy to attempt recovery. If {@link #getBuildParseTree} is * {@code true} and the token index of the symbol returned by * {@link ANTLRErrorStrategy#recoverInline} is -1, the symbol is added to * the parse tree by calling {@link Parser#createErrorNode(ParserRuleContext, Token)}. then * {@link ParserRuleContext#addErrorNode(ErrorNode)}</p> * * @return the matched symbol * @throws RecognitionException if the current input symbol did not match * a wildcard and the error strategy could not recover from the mismatched * symbol */[[SEP]]// we must have conjured up a new token during single token insertion// if it's not the current symbol",236,252,[0],0,"[0, 0]",0,"[0, 0]",0,0,0,0,matchWildcard(),org.antlr.v4.runtime.Parser,matchWildcard/0,False,236,4,9,1,8,4,8,14,1,1,0,8,3,3,0,1,0,0,0,2,2,0,2,0,0,0,63,1,0,True
199,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\Parser.java,org.antlr.v4.runtime.Parser,void setBuildParseTree(boolean),"/**
 * Track the {@link ParserRuleContext} objects during the parse and hook
 * them up using the {@link ParserRuleContext#children} list so that it
 * forms a parse tree. The {@link ParserRuleContext} returned from the start
 * rule represents the root of the parse tree.
 *
 * <p>Note that if we are not building parse trees, rule contexts only point
 * upwards. When a rule exits, it returns the context but that gets garbage
 * collected if nobody holds a reference. It points upwards but nobody
 * points at it.</p>
 *
 * <p>When we build parse trees, we are adding all of these contexts to
 * {@link ParserRuleContext#children} list. Contexts are then not candidates
 * for garbage collection.</p>
 */
public void setBuildParseTree(boolean buildParseTrees) {
    this._buildParseTrees = buildParseTrees;
}","/**
 * Track the {@link ParserRuleContext} objects during the parse and hook
 * them up using the {@link ParserRuleContext#children} list so that it
 * forms a parse tree. The {@link ParserRuleContext} returned from the start
 * rule represents the root of the parse tree.
 *
 * <p>Note that if we are not building parse trees, rule contexts only point
 * upwards. When a rule exits, it returns the context but that gets garbage
 * collected if nobody holds a reference. It points upwards but nobody
 * points at it.</p>
 *
 * <p>When we build parse trees, we are adding all of these contexts to
 * {@link ParserRuleContext#children} list. Contexts are then not candidates
 * for garbage collection.</p>
 */
", ,"/** * Track the {@link ParserRuleContext} objects during the parse and hook * them up using the {@link ParserRuleContext#children} list so that it * forms a parse tree. The {@link ParserRuleContext} returned from the start * rule represents the root of the parse tree. * * <p>Note that if we are not building parse trees, rule contexts only point * upwards. When a rule exits, it returns the context but that gets garbage * collected if nobody holds a reference. It points upwards but nobody * points at it.</p> * * <p>When we build parse trees, we are adding all of these contexts to * {@link ParserRuleContext#children} list. Contexts are then not candidates * for garbage collection.</p> */",269,271,[0],0,[0],0,[0],0,0,0,0,setBuildParseTree(boolean),org.antlr.v4.runtime.Parser,setBuildParseTree/1[boolean],False,269,0,1,1,0,1,0,3,0,0,1,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,61,1,0,True
200,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\Parser.java,org.antlr.v4.runtime.Parser,boolean getBuildParseTree(),"/**
 * Gets whether or not a complete parse tree will be constructed while
 * parsing. This property is {@code true} for a newly constructed parser.
 *
 * @return {@code true} if a complete parse tree will be constructed while
 * parsing, otherwise {@code false}
 */
public boolean getBuildParseTree() {
    return _buildParseTrees;
}","/**
 * Gets whether or not a complete parse tree will be constructed while
 * parsing. This property is {@code true} for a newly constructed parser.
 *
 * @return {@code true} if a complete parse tree will be constructed while
 * parsing, otherwise {@code false}
 */
", ,"/** * Gets whether or not a complete parse tree will be constructed while * parsing. This property is {@code true} for a newly constructed parser. * * @return {@code true} if a complete parse tree will be constructed while * parsing, otherwise {@code false} */",280,282,[0],0,[0],0,[0],0,0,0,0,getBuildParseTree(),org.antlr.v4.runtime.Parser,getBuildParseTree/0,False,280,0,0,0,0,1,0,3,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,24,1,0,True
201,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\Parser.java,org.antlr.v4.runtime.Parser,void setTrimParseTree(boolean),"/**
 * Trim the internal lists of the parse tree during parsing to conserve memory.
 * This property is set to {@code false} by default for a newly constructed parser.
 *
 * @param trimParseTrees {@code true} to trim the capacity of the {@link ParserRuleContext#children}
 * list to its size after a rule is parsed.
 */
public void setTrimParseTree(boolean trimParseTrees) {
    if (trimParseTrees) {
        if (getTrimParseTree())
            return;
        addParseListener(TrimToSizeListener.INSTANCE);
    } else {
        removeParseListener(TrimToSizeListener.INSTANCE);
    }
}","/**
 * Trim the internal lists of the parse tree during parsing to conserve memory.
 * This property is set to {@code false} by default for a newly constructed parser.
 *
 * @param trimParseTrees {@code true} to trim the capacity of the {@link ParserRuleContext#children}
 * list to its size after a rule is parsed.
 */
", ,/** * Trim the internal lists of the parse tree during parsing to conserve memory. * This property is set to {@code false} by default for a newly constructed parser. * * @param trimParseTrees {@code true} to trim the capacity of the {@link ParserRuleContext#children} * list to its size after a rule is parsed. */,291,299,[0],0,[0],0,[0],0,0,0,0,setTrimParseTree(boolean),org.antlr.v4.runtime.Parser,setTrimParseTree/1[boolean],False,291,1,3,0,3,3,3,9,1,0,1,3,3,2,0,0,0,0,0,0,0,0,2,0,0,0,35,1,0,True
202,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\Parser.java,org.antlr.v4.runtime.Parser,boolean getTrimParseTree(),"/**
 * @return {@code true} if the {@link ParserRuleContext#children} list is trimmed
 * using the default {@link Parser.TrimToSizeListener} during the parse process.
 */
public boolean getTrimParseTree() {
    return getParseListeners().contains(TrimToSizeListener.INSTANCE);
}","/**
 * @return {@code true} if the {@link ParserRuleContext#children} list is trimmed
 * using the default {@link Parser.TrimToSizeListener} during the parse process.
 */
", ,/** * @return {@code true} if the {@link ParserRuleContext#children} list is trimmed * using the default {@link Parser.TrimToSizeListener} during the parse process. */,305,307,[0],0,[0],0,[0],0,0,0,0,getTrimParseTree(),org.antlr.v4.runtime.Parser,getTrimParseTree/0,False,305,1,2,1,1,1,2,3,1,0,0,2,1,1,0,0,0,0,0,0,0,0,0,0,0,0,12,1,0,True
203,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\Parser.java,org.antlr.v4.runtime.Parser,void addParseListener(ParseTreeListener),"/**
 * Registers {@code listener} to receive events during the parsing process.
 *
 * <p>To support output-preserving grammar transformations (including but not
 * limited to left-recursion removal, automated left-factoring, and
 * optimized code generation), calls to listener methods during the parse
 * may differ substantially from calls made by
 * {@link ParseTreeWalker#DEFAULT} used after the parse is complete. In
 * particular, rule entry and exit events may occur in a different order
 * during the parse than after the parser. In addition, calls to certain
 * rule entry methods may be omitted.</p>
 *
 * <p>With the following specific exceptions, calls to listener events are
 * <em>deterministic</em>, i.e. for identical input the calls to listener
 * methods will be the same.</p>
 *
 * <ul>
 * <li>Alterations to the grammar used to generate code may change the
 * behavior of the listener calls.</li>
 * <li>Alterations to the command line options passed to ANTLR 4 when
 * generating the parser may change the behavior of the listener calls.</li>
 * <li>Changing the version of the ANTLR Tool used to generate the parser
 * may change the behavior of the listener calls.</li>
 * </ul>
 *
 * @param listener the listener to add
 *
 * @throws NullPointerException if {@code} listener is {@code null}
 */
public void addParseListener(ParseTreeListener listener) {
    if (listener == null) {
        throw new NullPointerException(""listener"");
    }
    if (_parseListeners == null) {
        _parseListeners = new ArrayList<ParseTreeListener>();
    }
    this._parseListeners.add(listener);
}","/**
 * Registers {@code listener} to receive events during the parsing process.
 *
 * <p>To support output-preserving grammar transformations (including but not
 * limited to left-recursion removal, automated left-factoring, and
 * optimized code generation), calls to listener methods during the parse
 * may differ substantially from calls made by
 * {@link ParseTreeWalker#DEFAULT} used after the parse is complete. In
 * particular, rule entry and exit events may occur in a different order
 * during the parse than after the parser. In addition, calls to certain
 * rule entry methods may be omitted.</p>
 *
 * <p>With the following specific exceptions, calls to listener events are
 * <em>deterministic</em>, i.e. for identical input the calls to listener
 * methods will be the same.</p>
 *
 * <ul>
 * <li>Alterations to the grammar used to generate code may change the
 * behavior of the listener calls.</li>
 * <li>Alterations to the command line options passed to ANTLR 4 when
 * generating the parser may change the behavior of the listener calls.</li>
 * <li>Changing the version of the ANTLR Tool used to generate the parser
 * may change the behavior of the listener calls.</li>
 * </ul>
 *
 * @param listener the listener to add
 *
 * @throws NullPointerException if {@code} listener is {@code null}
 */
", ,"/** * Registers {@code listener} to receive events during the parsing process. * * <p>To support output-preserving grammar transformations (including but not * limited to left-recursion removal, automated left-factoring, and * optimized code generation), calls to listener methods during the parse * may differ substantially from calls made by * {@link ParseTreeWalker#DEFAULT} used after the parse is complete. In * particular, rule entry and exit events may occur in a different order * during the parse than after the parser. In addition, calls to certain * rule entry methods may be omitted.</p> * * <p>With the following specific exceptions, calls to listener events are * <em>deterministic</em>, i.e. for identical input the calls to listener * methods will be the same.</p> * * <ul> * <li>Alterations to the grammar used to generate code may change the * behavior of the listener calls.</li> * <li>Alterations to the command line options passed to ANTLR 4 when * generating the parser may change the behavior of the listener calls.</li> * <li>Changing the version of the ANTLR Tool used to generate the parser * may change the behavior of the listener calls.</li> * </ul> * * @param listener the listener to add * * @throws NullPointerException if {@code} listener is {@code null} */",348,358,[0],0,[0],0,[0],0,0,0,0,addParseListener(ParseTreeListener),org.antlr.v4.runtime.Parser,addParseListener/1[org.antlr.v4.runtime.tree.ParseTreeListener],False,348,1,2,2,0,3,1,9,0,0,1,1,0,0,0,2,0,0,1,0,1,0,1,0,0,0,90,1,0,True
204,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\Parser.java,org.antlr.v4.runtime.Parser,void removeParseListener(ParseTreeListener),"/**
 * Remove {@code listener} from the list of parse listeners.
 *
 * <p>If {@code listener} is {@code null} or has not been added as a parse
 * listener, this method does nothing.</p>
 *
 * @see #addParseListener
 *
 * @param listener the listener to remove
 */
public void removeParseListener(ParseTreeListener listener) {
    if (_parseListeners != null) {
        if (_parseListeners.remove(listener)) {
            if (_parseListeners.isEmpty()) {
                _parseListeners = null;
            }
        }
    }
}","/**
 * Remove {@code listener} from the list of parse listeners.
 *
 * <p>If {@code listener} is {@code null} or has not been added as a parse
 * listener, this method does nothing.</p>
 *
 * @see #addParseListener
 *
 * @param listener the listener to remove
 */
", ,"/** * Remove {@code listener} from the list of parse listeners. * * <p>If {@code listener} is {@code null} or has not been added as a parse * listener, this method does nothing.</p> * * @see #addParseListener * * @param listener the listener to remove */",370,378,[0],0,[0],0,[0],0,0,0,0,removeParseListener(ParseTreeListener),org.antlr.v4.runtime.Parser,removeParseListener/1[org.antlr.v4.runtime.tree.ParseTreeListener],False,370,1,2,2,0,4,2,9,0,0,1,2,0,0,0,1,0,0,0,0,1,0,3,0,0,0,27,1,0,True
205,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\Parser.java,org.antlr.v4.runtime.Parser,void removeParseListeners(),"/**
 * Remove all parse listeners.
 *
 * @see #addParseListener
 */
public void removeParseListeners() {
    _parseListeners = null;
}","/**
 * Remove all parse listeners.
 *
 * @see #addParseListener
 */
", ,/** * Remove all parse listeners. * * @see #addParseListener */,385,387,[0],0,[0],0,[0],0,0,0,0,removeParseListeners(),org.antlr.v4.runtime.Parser,removeParseListeners/0,False,385,0,0,0,0,1,0,3,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,8,1,0,True
206,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\Parser.java,org.antlr.v4.runtime.Parser,void triggerEnterRuleEvent(),"/**
 * Notify any parse listeners of an enter rule event.
 *
 * @see #addParseListener
 */
protected void triggerEnterRuleEvent() {
    for (ParseTreeListener listener : _parseListeners) {
        listener.enterEveryRule(_ctx);
        _ctx.enterRule(listener);
    }
}","/**
 * Notify any parse listeners of an enter rule event.
 *
 * @see #addParseListener
 */
", ,/** * Notify any parse listeners of an enter rule event. * * @see #addParseListener */,394,399,[0],0,[0],0,[0],0,0,0,0,triggerEnterRuleEvent(),org.antlr.v4.runtime.Parser,triggerEnterRuleEvent/0,False,394,2,5,3,2,2,2,6,0,0,0,2,0,0,1,0,0,0,0,0,0,0,1,0,0,0,19,4,0,True
207,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\Parser.java,org.antlr.v4.runtime.Parser,void triggerExitRuleEvent(),"/**
 * Notify any parse listeners of an exit rule event.
 *
 * @see #addParseListener
 */
protected void triggerExitRuleEvent() {
    // reverse order walk of listeners
    for (int i = _parseListeners.size() - 1; i >= 0; i--) {
        ParseTreeListener listener = _parseListeners.get(i);
        _ctx.exitRule(listener);
        listener.exitEveryRule(_ctx);
    }
}","/**
 * Notify any parse listeners of an exit rule event.
 *
 * @see #addParseListener
 */
","// reverse order walk of listeners
",/** * Notify any parse listeners of an exit rule event. * * @see #addParseListener */[[SEP]]// reverse order walk of listeners,406,413,[0],0,[0],0,"[0, 0]",0,0,0,0,triggerExitRuleEvent(),org.antlr.v4.runtime.Parser,triggerExitRuleEvent/0,False,406,2,4,2,2,2,4,7,0,2,0,4,0,0,1,0,0,0,0,2,2,1,1,0,0,0,18,4,0,True
208,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\Parser.java,org.antlr.v4.runtime.Parser,int getNumberOfSyntaxErrors(),"/**
 * Gets the number of syntax errors reported during parsing. This value is
 * incremented each time {@link #notifyErrorListeners} is called.
 *
 * @see #notifyErrorListeners
 */
public int getNumberOfSyntaxErrors() {
    return _syntaxErrors;
}","/**
 * Gets the number of syntax errors reported during parsing. This value is
 * incremented each time {@link #notifyErrorListeners} is called.
 *
 * @see #notifyErrorListeners
 */
", ,/** * Gets the number of syntax errors reported during parsing. This value is * incremented each time {@link #notifyErrorListeners} is called. * * @see #notifyErrorListeners */,421,423,[0],0,[0],0,[0],0,0,0,0,getNumberOfSyntaxErrors(),org.antlr.v4.runtime.Parser,getNumberOfSyntaxErrors/0,False,421,0,0,0,0,1,0,3,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,20,1,0,True
209,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\Parser.java,org.antlr.v4.runtime.Parser,void setTokenFactory(TokenFactory<?>),"/**
 * Tell our token source and error strategy about a new way to create tokens.
 */
@Override
public void setTokenFactory(TokenFactory<?> factory) {
    _input.getTokenSource().setTokenFactory(factory);
}","/**
 * Tell our token source and error strategy about a new way to create tokens.
 */
", ,/** * Tell our token source and error strategy about a new way to create tokens. */,431,434,[0],0,[0],0,[0],0,0,0,0,setTokenFactory(TokenFactory<?>),org.antlr.v4.runtime.Parser,setTokenFactory/1[org.antlr.v4.runtime.TokenFactory<?>],False,432,3,2,0,2,1,2,3,0,0,1,2,0,0,0,0,0,0,0,0,0,0,0,0,0,0,16,1,0,True
210,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\Parser.java,org.antlr.v4.runtime.Parser,"ParseTreePattern compileParseTreePattern(String, int)","/**
 * The preferred method of getting a tree pattern. For example, here's a
 * sample use:
 *
 * <pre>
 * ParseTree t = parser.expr();
 * ParseTreePattern p = parser.compileParseTreePattern(""&lt;ID&gt;+0"", MyParser.RULE_expr);
 * ParseTreeMatch m = p.match(t);
 * String id = m.get(""ID"");
 * </pre>
 */
public ParseTreePattern compileParseTreePattern(String pattern, int patternRuleIndex) {
    if (getTokenStream() != null) {
        TokenSource tokenSource = getTokenStream().getTokenSource();
        if (tokenSource instanceof Lexer) {
            Lexer lexer = (Lexer) tokenSource;
            return compileParseTreePattern(pattern, patternRuleIndex, lexer);
        }
    }
    throw new UnsupportedOperationException(""Parser can't discover a lexer to use"");
}","/**
 * The preferred method of getting a tree pattern. For example, here's a
 * sample use:
 *
 * <pre>
 * ParseTree t = parser.expr();
 * ParseTreePattern p = parser.compileParseTreePattern(""&lt;ID&gt;+0"", MyParser.RULE_expr);
 * ParseTreeMatch m = p.match(t);
 * String id = m.get(""ID"");
 * </pre>
 */
", ,"/** * The preferred method of getting a tree pattern. For example, here's a * sample use: * * <pre> * ParseTree t = parser.expr(); * ParseTreePattern p = parser.compileParseTreePattern(""&lt;ID&gt;+0"", MyParser.RULE_expr); * ParseTreeMatch m = p.match(t); * String id = m.get(""ID""); * </pre> */",472,481,[0],0,[0],0,[0],0,0,0,0,"compileParseTreePattern(String, int)",org.antlr.v4.runtime.Parser,"compileParseTreePattern/2[java.lang.String,int]",False,472,5,3,0,3,3,3,10,1,2,2,3,2,1,0,1,0,0,1,0,2,0,2,0,0,0,39,1,0,True
211,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\Parser.java,org.antlr.v4.runtime.Parser,"ParseTreePattern compileParseTreePattern(String, int, Lexer)","/**
 * The same as {@link #compileParseTreePattern(String, int)} but specify a
 * {@link Lexer} rather than trying to deduce it from this parser.
 */
public ParseTreePattern compileParseTreePattern(String pattern, int patternRuleIndex, Lexer lexer) {
    ParseTreePatternMatcher m = new ParseTreePatternMatcher(lexer, this);
    return m.compile(pattern, patternRuleIndex);
}","/**
 * The same as {@link #compileParseTreePattern(String, int)} but specify a
 * {@link Lexer} rather than trying to deduce it from this parser.
 */
", ,"/** * The same as {@link #compileParseTreePattern(String, int)} but specify a * {@link Lexer} rather than trying to deduce it from this parser. */",487,492,[0],0,[0],0,[0],0,0,0,0,"compileParseTreePattern(String, int, Lexer)",org.antlr.v4.runtime.Parser,"compileParseTreePattern/3[java.lang.String,int,org.antlr.v4.runtime.Lexer]",False,489,3,3,1,2,1,1,4,1,1,3,1,0,0,0,0,0,0,0,0,1,0,0,0,0,0,21,1,0,True
212,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\Parser.java,org.antlr.v4.runtime.Parser,void setTokenStream(TokenStream),"/**
 * Set the token stream and reset the parser.
 */
public void setTokenStream(TokenStream input) {
    this._input = null;
    reset();
    this._input = input;
}","/**
 * Set the token stream and reset the parser.
 */
", ,/** * Set the token stream and reset the parser. */,516,520,[0],0,[0],0,[0],0,0,0,0,setTokenStream(TokenStream),org.antlr.v4.runtime.Parser,setTokenStream/1[org.antlr.v4.runtime.TokenStream],False,516,2,3,2,1,1,1,5,0,0,1,1,1,4,0,0,0,0,0,0,2,0,0,0,0,0,11,1,0,True
213,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\Parser.java,org.antlr.v4.runtime.Parser,Token consume(),"/**
 * Consume and return the {@linkplain #getCurrentToken current symbol}.
 *
 * <p>E.g., given the following input with {@code A} being the current
 * lookahead symbol, this function moves the cursor to {@code B} and returns
 * {@code A}.</p>
 *
 * <pre>
 *  A B
 *  ^
 * </pre>
 *
 * If the parser is not in error recovery mode, the consumed symbol is added
 * to the parse tree using {@link ParserRuleContext#addChild(TerminalNode)}, and
 * {@link ParseTreeListener#visitTerminal} is called on any parse listeners.
 * If the parser <em>is</em> in error recovery mode, the consumed symbol is
 * added to the parse tree using {@link #createErrorNode(ParserRuleContext, Token)} then
 * {@link ParserRuleContext#addErrorNode(ErrorNode)} and
 * {@link ParseTreeListener#visitErrorNode} is called on any parse
 * listeners.
 */
public Token consume() {
    Token o = getCurrentToken();
    if (o.getType() != EOF) {
        getInputStream().consume();
    }
    boolean hasListener = _parseListeners != null && !_parseListeners.isEmpty();
    if (_buildParseTrees || hasListener) {
        if (_errHandler.inErrorRecoveryMode(this)) {
            ErrorNode node = _ctx.addErrorNode(createErrorNode(_ctx, o));
            if (_parseListeners != null) {
                for (ParseTreeListener listener : _parseListeners) {
                    listener.visitErrorNode(node);
                }
            }
        } else {
            TerminalNode node = _ctx.addChild(createTerminalNode(_ctx, o));
            if (_parseListeners != null) {
                for (ParseTreeListener listener : _parseListeners) {
                    listener.visitTerminal(node);
                }
            }
        }
    }
    return o;
}","/**
 * Consume and return the {@linkplain #getCurrentToken current symbol}.
 *
 * <p>E.g., given the following input with {@code A} being the current
 * lookahead symbol, this function moves the cursor to {@code B} and returns
 * {@code A}.</p>
 *
 * <pre>
 *  A B
 *  ^
 * </pre>
 *
 * If the parser is not in error recovery mode, the consumed symbol is added
 * to the parse tree using {@link ParserRuleContext#addChild(TerminalNode)}, and
 * {@link ParseTreeListener#visitTerminal} is called on any parse listeners.
 * If the parser <em>is</em> in error recovery mode, the consumed symbol is
 * added to the parse tree using {@link #createErrorNode(ParserRuleContext, Token)} then
 * {@link ParserRuleContext#addErrorNode(ErrorNode)} and
 * {@link ParseTreeListener#visitErrorNode} is called on any parse
 * listeners.
 */
", ,"/** * Consume and return the {@linkplain #getCurrentToken current symbol}. * * <p>E.g., given the following input with {@code A} being the current * lookahead symbol, this function moves the cursor to {@code B} and returns * {@code A}.</p> * * <pre> *  A B *  ^ * </pre> * * If the parser is not in error recovery mode, the consumed symbol is added * to the parse tree using {@link ParserRuleContext#addChild(TerminalNode)}, and * {@link ParseTreeListener#visitTerminal} is called on any parse listeners. * If the parser <em>is</em> in error recovery mode, the consumed symbol is * added to the parse tree using {@link #createErrorNode(ParserRuleContext, Token)} then * {@link ParserRuleContext#addErrorNode(ErrorNode)} and * {@link ParseTreeListener#visitErrorNode} is called on any parse * listeners. */",568,593,[0],0,[0],0,[0],0,0,0,0,consume(),org.antlr.v4.runtime.Parser,consume/0,False,568,8,17,6,11,10,12,26,1,4,0,12,4,2,2,4,0,0,0,0,4,0,4,0,0,0,62,1,0,True
214,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\Parser.java,org.antlr.v4.runtime.Parser,"TerminalNode createTerminalNode(ParserRuleContext, Token)","/**
 * How to create a token leaf node associated with a parent.
 *  Typically, the terminal node to create is not a function of the parent.
 *
 * @since 4.7
 */
public TerminalNode createTerminalNode(ParserRuleContext parent, Token t) {
    return new TerminalNodeImpl(t);
}","/**
 * How to create a token leaf node associated with a parent.
 *  Typically, the terminal node to create is not a function of the parent.
 *
 * @since 4.7
 */
", ,"/** * How to create a token leaf node associated with a parent. *  Typically, the terminal node to create is not a function of the parent. * * @since 4.7 */",600,602,[0],0,[0],0,[0],0,0,0,0,"createTerminalNode(ParserRuleContext, Token)",org.antlr.v4.runtime.Parser,"createTerminalNode/2[org.antlr.v4.runtime.ParserRuleContext,org.antlr.v4.runtime.Token]",False,600,4,2,1,1,1,0,3,1,0,2,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,22,1,0,True
215,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\Parser.java,org.antlr.v4.runtime.Parser,"ErrorNode createErrorNode(ParserRuleContext, Token)","/**
 * How to create an error node, given a token, associated with a parent.
 *  Typically, the error node to create is not a function of the parent.
 *
 * @since 4.7
 */
public ErrorNode createErrorNode(ParserRuleContext parent, Token t) {
    return new ErrorNodeImpl(t);
}","/**
 * How to create an error node, given a token, associated with a parent.
 *  Typically, the error node to create is not a function of the parent.
 *
 * @since 4.7
 */
", ,"/** * How to create an error node, given a token, associated with a parent. *  Typically, the error node to create is not a function of the parent. * * @since 4.7 */",609,611,[0],0,[0],0,[0],0,0,0,0,"createErrorNode(ParserRuleContext, Token)",org.antlr.v4.runtime.Parser,"createErrorNode/2[org.antlr.v4.runtime.ParserRuleContext,org.antlr.v4.runtime.Token]",False,609,4,5,4,1,1,0,3,1,0,2,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,22,1,0,True
216,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\Parser.java,org.antlr.v4.runtime.Parser,void addContextToParseTree(),"protected void addContextToParseTree() {
    ParserRuleContext parent = (ParserRuleContext) _ctx.parent;
    // add current context to parent if we have a parent
    if (parent != null) {
        parent.addChild(_ctx);
    }
}", ,"// add current context to parent if we have a parent
",// add current context to parent if we have a parent,613,619,[0],0,[0],0,[0],0,0,0,0,addContextToParseTree(),org.antlr.v4.runtime.Parser,addContextToParseTree/0,False,613,1,2,1,1,2,1,6,0,1,0,1,0,0,0,1,0,0,0,0,1,0,1,0,0,0,10,4,0,False
217,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\Parser.java,org.antlr.v4.runtime.Parser,"void enterRule(ParserRuleContext, int, int)","/**
 * Always called by generated parsers upon entry to a rule. Access field
 * {@link #_ctx} get the current context.
 */
public void enterRule(ParserRuleContext localctx, int state, int ruleIndex) {
    setState(state);
    _ctx = localctx;
    _ctx.start = _input.LT(1);
    if (_buildParseTrees)
        addContextToParseTree();
    if (_parseListeners != null)
        triggerEnterRuleEvent();
}","/**
 * Always called by generated parsers upon entry to a rule. Access field
 * {@link #_ctx} get the current context.
 */
", ,/** * Always called by generated parsers upon entry to a rule. Access field * {@link #_ctx} get the current context. */,625,631,[0],0,[0],0,[0],0,0,0,0,"enterRule(ParserRuleContext, int, int)",org.antlr.v4.runtime.Parser,"enterRule/3[org.antlr.v4.runtime.ParserRuleContext,int,int]",False,625,4,6,2,4,3,4,7,0,0,3,4,2,1,0,1,0,0,0,1,2,0,1,0,0,0,37,1,0,True
218,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\Parser.java,org.antlr.v4.runtime.Parser,void exitRule(),"public void exitRule() {
    if (matchedEOF) {
        // if we have matched EOF, it cannot consume past EOF so we use LT(1) here
        // LT(1) will be end of file
        _ctx.stop = _input.LT(1);
    } else {
        // stop node is what we just matched
        _ctx.stop = _input.LT(-1);
    }
    // trigger event on _ctx, before it reverts to parent
    if (_parseListeners != null)
        triggerExitRuleEvent();
    setState(_ctx.invokingState);
    _ctx = (ParserRuleContext) _ctx.parent;
}", ,"// if we have matched EOF, it cannot consume past EOF so we use LT(1) here
[[SEP]]// LT(1) will be end of file
[[SEP]]// stop node is what we just matched
[[SEP]]// trigger event on _ctx, before it reverts to parent
","// if we have matched EOF, it cannot consume past EOF so we use LT(1) here// LT(1) will be end of file[[SEP]]// stop node is what we just matched[[SEP]]// trigger event on _ctx, before it reverts to parent",633,645,[0],0,"[0, 0, 0, 0]",0,"[0, 0, 0]",0,0,0,0,exitRule(),org.antlr.v4.runtime.Parser,exitRule/0,False,633,4,5,2,3,3,3,11,0,0,0,3,1,1,0,1,0,0,0,2,3,0,1,0,0,0,17,1,0,False
219,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\Parser.java,org.antlr.v4.runtime.Parser,"void enterOuterAlt(ParserRuleContext, int)","public void enterOuterAlt(ParserRuleContext localctx, int altNum) {
    localctx.setAltNumber(altNum);
    // if we have new localctx, make sure we replace existing ctx
    // that is previous child of parse tree
    if (_buildParseTrees && _ctx != localctx) {
        ParserRuleContext parent = (ParserRuleContext) _ctx.parent;
        if (parent != null) {
            parent.removeLastChild();
            parent.addChild(localctx);
        }
    }
    _ctx = localctx;
}", ,"// if we have new localctx, make sure we replace existing ctx
[[SEP]]// that is previous child of parse tree
","// if we have new localctx, make sure we replace existing ctx// that is previous child of parse tree",647,659,[0],0,"[0, 0]",0,[0],0,0,0,0,"enterOuterAlt(ParserRuleContext, int)",org.antlr.v4.runtime.Parser,"enterOuterAlt/2[org.antlr.v4.runtime.ParserRuleContext,int]",False,647,2,3,0,3,4,3,11,0,1,2,3,0,0,0,2,0,0,0,0,2,0,2,0,0,0,15,1,0,False
220,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\Parser.java,org.antlr.v4.runtime.Parser,int getPrecedence(),"/**
 * Get the precedence level for the top-most precedence rule.
 *
 * @return The precedence level for the top-most precedence rule, or -1 if
 * the parser context is not nested within a precedence rule.
 */
public final int getPrecedence() {
    if (_precedenceStack.isEmpty()) {
        return -1;
    }
    return _precedenceStack.peek();
}","/**
 * Get the precedence level for the top-most precedence rule.
 *
 * @return The precedence level for the top-most precedence rule, or -1 if
 * the parser context is not nested within a precedence rule.
 */
", ,"/** * Get the precedence level for the top-most precedence rule. * * @return The precedence level for the top-most precedence rule, or -1 if * the parser context is not nested within a precedence rule. */",667,673,[0],0,[0],0,[0],0,0,0,0,getPrecedence(),org.antlr.v4.runtime.Parser,getPrecedence/0,False,667,2,3,1,2,2,2,6,2,0,0,2,0,0,0,0,0,0,0,1,0,0,1,0,0,0,18,17,0,True
221,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\Parser.java,org.antlr.v4.runtime.Parser,"void enterRecursionRule(ParserRuleContext, int)","/**
 * @deprecated Use
 * {@link #enterRecursionRule(ParserRuleContext, int, int, int)} instead.
 */
@Deprecated
public void enterRecursionRule(ParserRuleContext localctx, int ruleIndex) {
    enterRecursionRule(localctx, getATN().ruleToStartState[ruleIndex].stateNumber, ruleIndex, 0);
}","/**
 * @deprecated Use
 * {@link #enterRecursionRule(ParserRuleContext, int, int, int)} instead.
 */
", ,"/** * @deprecated Use * {@link #enterRecursionRule(ParserRuleContext, int, int, int)} instead. */",679,682,[1],1,[0],0,[1],1,0,0,0,"enterRecursionRule(ParserRuleContext, int)",org.antlr.v4.runtime.Parser,"enterRecursionRule/2[org.antlr.v4.runtime.ParserRuleContext,int]",False,680,3,2,0,2,1,2,3,0,0,2,2,1,2,0,0,0,0,0,1,0,0,0,0,0,0,8,1,0,True
222,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\Parser.java,org.antlr.v4.runtime.Parser,"void enterRecursionRule(ParserRuleContext, int, int, int)","public void enterRecursionRule(ParserRuleContext localctx, int state, int ruleIndex, int precedence) {
    setState(state);
    _precedenceStack.push(precedence);
    _ctx = localctx;
    _ctx.start = _input.LT(1);
    if (_parseListeners != null) {
        // simulates rule entry for left-recursive rules
        triggerEnterRuleEvent();
    }
}", ,"// simulates rule entry for left-recursive rules
",// simulates rule entry for left-recursive rules,684,692,[0],0,[0],0,[0],0,0,0,0,"enterRecursionRule(ParserRuleContext, int, int, int)",org.antlr.v4.runtime.Parser,"enterRecursionRule/4[org.antlr.v4.runtime.ParserRuleContext,int,int,int]",False,684,5,5,1,4,2,4,9,0,0,4,4,1,1,0,1,0,0,0,1,2,0,1,0,0,0,17,1,0,False
223,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\Parser.java,org.antlr.v4.runtime.Parser,"void pushNewRecursionContext(ParserRuleContext, int, int)","/**
 * Like {@link #enterRule} but for recursive rules.
 *  Make the current context the child of the incoming localctx.
 */
public void pushNewRecursionContext(ParserRuleContext localctx, int state, int ruleIndex) {
    ParserRuleContext previous = _ctx;
    previous.parent = localctx;
    previous.invokingState = state;
    previous.stop = _input.LT(-1);
    _ctx = localctx;
    _ctx.start = previous.start;
    if (_buildParseTrees) {
        _ctx.addChild(previous);
    }
    if (_parseListeners != null) {
        // simulates rule entry for left-recursive rules
        triggerEnterRuleEvent();
    }
}","/**
 * Like {@link #enterRule} but for recursive rules.
 *  Make the current context the child of the incoming localctx.
 */
","// simulates rule entry for left-recursive rules
",/** * Like {@link #enterRule} but for recursive rules. *  Make the current context the child of the incoming localctx. */[[SEP]]// simulates rule entry for left-recursive rules,697,712,[0],0,[0],0,"[0, 0]",0,0,0,0,"pushNewRecursionContext(ParserRuleContext, int, int)",org.antlr.v4.runtime.Parser,"pushNewRecursionContext/3[org.antlr.v4.runtime.ParserRuleContext,int,int]",False,697,3,4,1,3,3,3,14,0,1,3,3,1,1,0,1,0,0,0,1,6,0,1,0,0,0,30,1,0,True
224,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\Parser.java,org.antlr.v4.runtime.Parser,void unrollRecursionContexts(ParserRuleContext),"public void unrollRecursionContexts(ParserRuleContext _parentctx) {
    _precedenceStack.pop();
    _ctx.stop = _input.LT(-1);
    // save current ctx (return value)
    ParserRuleContext retctx = _ctx;
    // unroll so _ctx is as it was before call to recursive method
    if (_parseListeners != null) {
        while (_ctx != _parentctx) {
            triggerExitRuleEvent();
            _ctx = (ParserRuleContext) _ctx.parent;
        }
    } else {
        _ctx = _parentctx;
    }
    // hook into tree
    retctx.parent = _parentctx;
    if (_buildParseTrees && _parentctx != null) {
        // add return ctx into invoking rule's tree
        _parentctx.addChild(retctx);
    }
}", ,"// save current ctx (return value)
[[SEP]]// unroll so _ctx is as it was before call to recursive method
[[SEP]]// hook into tree
[[SEP]]// add return ctx into invoking rule's tree
",// save current ctx (return value)[[SEP]]// unroll so _ctx is as it was before call to recursive method[[SEP]]// hook into tree[[SEP]]// add return ctx into invoking rule's tree,714,737,[0],0,"[0, 0, 0, 0]",0,"[0, 0, 0, 0]",0,0,0,0,unrollRecursionContexts(ParserRuleContext),org.antlr.v4.runtime.Parser,unrollRecursionContexts/1[org.antlr.v4.runtime.ParserRuleContext],False,714,4,6,2,4,5,4,18,0,1,1,4,1,1,1,3,0,0,0,1,5,0,2,0,0,0,18,1,0,False
225,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\Parser.java,org.antlr.v4.runtime.Parser,boolean inContext(String),"public boolean inContext(String context) {
    // TODO: useful in parser?
    return false;
}", ,"// TODO: useful in parser?
",// TODO: useful in parser?,761,764,[0],0,[1],1,[1],1,1,1,1,inContext(String),org.antlr.v4.runtime.Parser,inContext/1[java.lang.String],False,761,0,0,0,0,1,0,3,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,4,1,0,False
226,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\Parser.java,org.antlr.v4.runtime.Parser,boolean isExpectedToken(int),"/**
 * Checks whether or not {@code symbol} can follow the current state in the
 * ATN. The behavior of this method is equivalent to the following, but is
 * implemented such that the complete context-sensitive follow set does not
 * need to be explicitly constructed.
 *
 * <pre>
 * return getExpectedTokens().contains(symbol);
 * </pre>
 *
 * @param symbol the symbol type to check
 * @return {@code true} if {@code symbol} can follow the current state in
 * the ATN, otherwise {@code false}.
 */
public boolean isExpectedToken(int symbol) {
    // return getInterpreter().atn.nextTokens(_ctx);
    ATN atn = getInterpreter().atn;
    ParserRuleContext ctx = _ctx;
    ATNState s = atn.states.get(getState());
    IntervalSet following = atn.nextTokens(s);
    if (following.contains(symbol)) {
        return true;
    }
    // System.out.println(""following ""+s+""=""+following);
    if (!following.contains(Token.EPSILON))
        return false;
    while (ctx != null && ctx.invokingState >= 0 && following.contains(Token.EPSILON)) {
        ATNState invokingState = atn.states.get(ctx.invokingState);
        RuleTransition rt = (RuleTransition) invokingState.transition(0);
        following = atn.nextTokens(rt.followState);
        if (following.contains(symbol)) {
            return true;
        }
        ctx = (ParserRuleContext) ctx.parent;
    }
    if (following.contains(Token.EPSILON) && symbol == Token.EOF) {
        return true;
    }
    return false;
}","/**
 * Checks whether or not {@code symbol} can follow the current state in the
 * ATN. The behavior of this method is equivalent to the following, but is
 * implemented such that the complete context-sensitive follow set does not
 * need to be explicitly constructed.
 *
 * <pre>
 * return getExpectedTokens().contains(symbol);
 * </pre>
 *
 * @param symbol the symbol type to check
 * @return {@code true} if {@code symbol} can follow the current state in
 * the ATN, otherwise {@code false}.
 */
","// return getInterpreter().atn.nextTokens(_ctx);
[[SEP]]// System.out.println(""following ""+s+""=""+following);
","/** * Checks whether or not {@code symbol} can follow the current state in the * ATN. The behavior of this method is equivalent to the following, but is * implemented such that the complete context-sensitive follow set does not * need to be explicitly constructed. * * <pre> * return getExpectedTokens().contains(symbol); * </pre> * * @param symbol the symbol type to check * @return {@code true} if {@code symbol} can follow the current state in * the ATN, otherwise {@code false}. */[[SEP]]// return getInterpreter().atn.nextTokens(_ctx);[[SEP]]// System.out.println(""following ""+s+""=""+following);",780,808,[0],0,"[0, 0]",0,"[0, 0, 0]",0,0,0,0,isExpectedToken(int),org.antlr.v4.runtime.Parser,isExpectedToken/1[int],False,780,6,5,0,5,9,6,23,5,6,1,6,0,0,1,2,0,0,0,2,8,0,2,0,0,0,60,1,0,True
227,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\Parser.java,org.antlr.v4.runtime.Parser,IntervalSet getExpectedTokens(),"/**
 * Computes the set of input symbols which could follow the current parser
 * state and context, as given by {@link #getState} and {@link #getContext},
 * respectively.
 *
 * @see ATN#getExpectedTokens(int, RuleContext)
 */
public IntervalSet getExpectedTokens() {
    return getATN().getExpectedTokens(getState(), getContext());
}","/**
 * Computes the set of input symbols which could follow the current parser
 * state and context, as given by {@link #getState} and {@link #getContext},
 * respectively.
 *
 * @see ATN#getExpectedTokens(int, RuleContext)
 */
", ,"/** * Computes the set of input symbols which could follow the current parser * state and context, as given by {@link #getState} and {@link #getContext}, * respectively. * * @see ATN#getExpectedTokens(int, RuleContext) */",821,823,[0],0,[0],0,[0],0,0,0,0,getExpectedTokens(),org.antlr.v4.runtime.Parser,getExpectedTokens/0,False,821,4,6,2,4,1,4,3,1,0,0,4,1,1,0,0,0,0,0,0,0,0,0,0,0,0,25,1,0,True
228,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\Parser.java,org.antlr.v4.runtime.Parser,int getRuleIndex(String),"/**
 * Get a rule's index (i.e., {@code RULE_ruleName} field) or -1 if not found.
 */
public int getRuleIndex(String ruleName) {
    Integer ruleIndex = getRuleIndexMap().get(ruleName);
    if (ruleIndex != null)
        return ruleIndex;
    return -1;
}","/**
 * Get a rule's index (i.e., {@code RULE_ruleName} field) or -1 if not found.
 */
", ,"/** * Get a rule's index (i.e., {@code RULE_ruleName} field) or -1 if not found. */",833,837,[0],0,[0],0,[0],0,0,0,0,getRuleIndex(String),org.antlr.v4.runtime.Parser,getRuleIndex/1[java.lang.String],False,833,1,3,2,1,2,2,5,2,1,1,2,0,0,0,1,0,0,0,1,1,0,1,0,0,0,18,1,0,True
229,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\Parser.java,org.antlr.v4.runtime.Parser,List<String> getRuleInvocationStack(),"/**
 * Return List&lt;String&gt; of the rule names in your parser instance
 *  leading up to a call to the current rule.  You could override if
 *  you want more details such as the file/line info of where
 *  in the ATN a rule is invoked.
 *
 *  This is very useful for error messages.
 */
public List<String> getRuleInvocationStack() {
    return getRuleInvocationStack(_ctx);
}","/**
 * Return List&lt;String&gt; of the rule names in your parser instance
 *  leading up to a call to the current rule.  You could override if
 *  you want more details such as the file/line info of where
 *  in the ATN a rule is invoked.
 *
 *  This is very useful for error messages.
 */
", ,/** * Return List&lt;String&gt; of the rule names in your parser instance *  leading up to a call to the current rule.  You could override if *  you want more details such as the file/line info of where *  in the ATN a rule is invoked. * *  This is very useful for error messages. */,848,850,[0],0,[0],0,[0],0,0,0,0,getRuleInvocationStack(),org.antlr.v4.runtime.Parser,getRuleInvocationStack/0,False,848,1,3,2,1,1,1,3,1,0,0,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,44,1,0,True
230,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\Parser.java,org.antlr.v4.runtime.Parser,List<String> getRuleInvocationStack(RuleContext),"public List<String> getRuleInvocationStack(RuleContext p) {
    String[] ruleNames = getRuleNames();
    List<String> stack = new ArrayList<String>();
    while (p != null) {
        // compute what follows who invoked us
        int ruleIndex = p.getRuleIndex();
        if (ruleIndex < 0)
            stack.add(""n/a"");
        else
            stack.add(ruleNames[ruleIndex]);
        p = p.parent;
    }
    return stack;
}", ,"// compute what follows who invoked us
",// compute what follows who invoked us,852,863,[0],0,[0],0,[0],0,0,0,0,getRuleInvocationStack(RuleContext),org.antlr.v4.runtime.Parser,getRuleInvocationStack/1[org.antlr.v4.runtime.RuleContext],False,852,2,4,2,2,3,3,11,1,3,1,3,0,0,1,1,0,0,1,1,4,0,2,0,0,0,11,1,0,False
231,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\Parser.java,org.antlr.v4.runtime.Parser,List<String> getDFAStrings(),"/**
 * For debugging and other purposes.
 */
public List<String> getDFAStrings() {
    synchronized (_interp.decisionToDFA) {
        List<String> s = new ArrayList<String>();
        for (int d = 0; d < _interp.decisionToDFA.length; d++) {
            DFA dfa = _interp.decisionToDFA[d];
            s.add(dfa.toString(getVocabulary()));
        }
        return s;
    }
}","/**
 * For debugging and other purposes.
 */
", ,/** * For debugging and other purposes. */,866,875,[0],0,[0],0,[0],0,0,0,0,getDFAStrings(),org.antlr.v4.runtime.Parser,getDFAStrings/0,False,866,2,2,0,2,2,3,10,1,3,0,3,0,0,1,0,0,0,0,1,3,0,2,0,0,0,13,1,0,True
232,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\Parser.java,org.antlr.v4.runtime.Parser,void dumpDFA(PrintStream),"/**
 * For debugging and other purposes.
 */
public void dumpDFA(PrintStream dumpStream) {
    synchronized (_interp.decisionToDFA) {
        boolean seenOne = false;
        for (int d = 0; d < _interp.decisionToDFA.length; d++) {
            DFA dfa = _interp.decisionToDFA[d];
            if (!dfa.states.isEmpty()) {
                if (seenOne)
                    dumpStream.println();
                dumpStream.println(""Decision "" + dfa.decision + "":"");
                dumpStream.print(dfa.toString(getVocabulary()));
                seenOne = true;
            }
        }
    }
}","/**
 * For debugging and other purposes.
 */
", ,/** * For debugging and other purposes. */,882,895,[0],0,[0],0,[0],0,0,0,0,dumpDFA(PrintStream),org.antlr.v4.runtime.Parser,dumpDFA/1[java.io.PrintStream],False,882,2,3,1,2,4,6,14,0,3,1,6,0,0,1,0,0,0,2,1,4,1,4,0,0,0,18,1,0,True
233,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\Parser.java,org.antlr.v4.runtime.Parser,void setProfile(boolean),"/**
 * @since 4.3
 */
public void setProfile(boolean profile) {
    ParserATNSimulator interp = getInterpreter();
    PredictionMode saveMode = interp.getPredictionMode();
    if (profile) {
        if (!(interp instanceof ProfilingATNSimulator)) {
            setInterpreter(new ProfilingATNSimulator(this));
        }
    } else if (interp instanceof ProfilingATNSimulator) {
        ParserATNSimulator sim = new ParserATNSimulator(this, getATN(), interp.decisionToDFA, interp.getSharedContextCache());
        setInterpreter(sim);
    }
    getInterpreter().setPredictionMode(saveMode);
}","/**
 * @since 4.3
 */
", ,/** * @since 4.3 */,913,927,[0],0,[0],0,[0],0,0,0,0,setProfile(boolean),org.antlr.v4.runtime.Parser,setProfile/1[boolean],False,913,5,8,0,8,4,6,14,0,3,1,6,0,0,0,0,0,1,0,0,3,0,2,0,0,0,16,1,0,True
234,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\Parser.java,org.antlr.v4.runtime.Parser,void setTrace(boolean),"/**
 * During a parse is sometimes useful to listen in on the rule entry and exit
 *  events as well as token matches. This is for quick and dirty debugging.
 */
public void setTrace(boolean trace) {
    if (!trace) {
        removeParseListener(_tracer);
        _tracer = null;
    } else {
        if (_tracer != null)
            removeParseListener(_tracer);
        else
            _tracer = new TraceListener();
        addParseListener(_tracer);
    }
}","/**
 * During a parse is sometimes useful to listen in on the rule entry and exit
 *  events as well as token matches. This is for quick and dirty debugging.
 */
", ,/** * During a parse is sometimes useful to listen in on the rule entry and exit *  events as well as token matches. This is for quick and dirty debugging. */,932,942,[0],0,[0],0,[0],0,0,0,0,setTrace(boolean),org.antlr.v4.runtime.Parser,setTrace/1[boolean],False,932,2,5,2,3,3,2,11,0,0,1,2,2,1,0,1,0,0,0,0,2,0,2,0,0,0,31,1,0,True
235,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\Parser.java,org.antlr.v4.runtime.Parser,boolean isTrace(),"/**
 * Gets whether a {@link TraceListener} is registered as a parse listener
 * for the parser.
 *
 * @see #setTrace(boolean)
 */
public boolean isTrace() {
    return _tracer != null;
}","/**
 * Gets whether a {@link TraceListener} is registered as a parse listener
 * for the parser.
 *
 * @see #setTrace(boolean)
 */
", ,/** * Gets whether a {@link TraceListener} is registered as a parse listener * for the parser. * * @see #setTrace(boolean) */,950,952,[0],0,[0],0,[0],0,0,0,0,isTrace(),org.antlr.v4.runtime.Parser,isTrace/0,False,950,0,0,0,0,2,0,3,1,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,13,1,0,True
236,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\ParserInterpreter.java,org.antlr.v4.runtime.ParserInterpreter,ParserRuleContext parse(int),"/**
 * Begin parsing at startRuleIndex
 */
public ParserRuleContext parse(int startRuleIndex) {
    RuleStartState startRuleStartState = atn.ruleToStartState[startRuleIndex];
    rootContext = createInterpreterRuleContext(null, ATNState.INVALID_STATE_NUMBER, startRuleIndex);
    if (startRuleStartState.isLeftRecursiveRule) {
        enterRecursionRule(rootContext, startRuleStartState.stateNumber, startRuleIndex, 0);
    } else {
        enterRule(rootContext, startRuleStartState.stateNumber, startRuleIndex);
    }
    while (true) {
        ATNState p = getATNState();
        switch(p.getStateType()) {
            case ATNState.RULE_STOP:
                // pop; return from rule
                if (_ctx.isEmpty()) {
                    if (startRuleStartState.isLeftRecursiveRule) {
                        ParserRuleContext result = _ctx;
                        Pair<ParserRuleContext, Integer> parentContext = _parentContextStack.pop();
                        unrollRecursionContexts(parentContext.a);
                        return result;
                    } else {
                        exitRule();
                        return rootContext;
                    }
                }
                visitRuleStopState(p);
                break;
            default:
                try {
                    visitState(p);
                } catch (RecognitionException e) {
                    setState(atn.ruleToStopState[p.ruleIndex].stateNumber);
                    getContext().exception = e;
                    getErrorHandler().reportError(this, e);
                    recover(e);
                }
                break;
        }
    }
}","/**
 * Begin parsing at startRuleIndex
 */
","// pop; return from rule
",/** * Begin parsing at startRuleIndex */[[SEP]]// pop; return from rule,160,206,[0],0,[0],0,"[0, 0]",0,0,0,0,parse(int),org.antlr.v4.runtime.ParserInterpreter,parse/1[int],False,160,10,16,1,15,7,16,41,2,4,1,16,6,2,1,0,1,0,0,1,6,0,4,0,0,0,37,1,0,True
237,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\ParserInterpreter.java,org.antlr.v4.runtime.ParserInterpreter,void visitState(ATNState),"protected void visitState(ATNState p) {
    // System.out.println(""visitState ""+p.stateNumber);
    int predictedAlt = 1;
    if (p instanceof DecisionState) {
        predictedAlt = visitDecisionState((DecisionState) p);
    }
    Transition transition = p.transition(predictedAlt - 1);
    switch(transition.getSerializationType()) {
        case Transition.EPSILON:
            if (p.getStateType() == ATNState.STAR_LOOP_ENTRY && ((StarLoopEntryState) p).isPrecedenceDecision && !(transition.target instanceof LoopEndState)) {
                // We are at the start of a left recursive rule's (...)* loop
                // and we're not taking the exit branch of loop.
                InterpreterRuleContext localctx = createInterpreterRuleContext(_parentContextStack.peek().a, _parentContextStack.peek().b, _ctx.getRuleIndex());
                pushNewRecursionContext(localctx, atn.ruleToStartState[p.ruleIndex].stateNumber, _ctx.getRuleIndex());
            }
            break;
        case Transition.ATOM:
            match(((AtomTransition) transition).label);
            break;
        case Transition.RANGE:
        case Transition.SET:
        case Transition.NOT_SET:
            if (!transition.matches(_input.LA(1), Token.MIN_USER_TOKEN_TYPE, 65535)) {
                recoverInline();
            }
            matchWildcard();
            break;
        case Transition.WILDCARD:
            matchWildcard();
            break;
        case Transition.RULE:
            RuleStartState ruleStartState = (RuleStartState) transition.target;
            int ruleIndex = ruleStartState.ruleIndex;
            InterpreterRuleContext newctx = createInterpreterRuleContext(_ctx, p.stateNumber, ruleIndex);
            if (ruleStartState.isLeftRecursiveRule) {
                enterRecursionRule(newctx, ruleStartState.stateNumber, ruleIndex, ((RuleTransition) transition).precedence);
            } else {
                enterRule(newctx, transition.target.stateNumber, ruleIndex);
            }
            break;
        case Transition.PREDICATE:
            PredicateTransition predicateTransition = (PredicateTransition) transition;
            if (!sempred(_ctx, predicateTransition.ruleIndex, predicateTransition.predIndex)) {
                throw new FailedPredicateException(this);
            }
            break;
        case Transition.ACTION:
            ActionTransition actionTransition = (ActionTransition) transition;
            action(_ctx, actionTransition.ruleIndex, actionTransition.actionIndex);
            break;
        case Transition.PRECEDENCE:
            if (!precpred(_ctx, ((PrecedencePredicateTransition) transition).precedence)) {
                throw new FailedPredicateException(this, String.format(""precpred(_ctx, %d)"", ((PrecedencePredicateTransition) transition).precedence));
            }
            break;
        default:
            throw new UnsupportedOperationException(""Unrecognized ATN transition type."");
    }
    setState(transition.target.stateNumber);
}", ,"// System.out.println(""visitState ""+p.stateNumber);
[[SEP]]// We are at the start of a left recursive rule's (...)* loop
[[SEP]]// and we're not taking the exit branch of loop.
","// System.out.println(""visitState ""+p.stateNumber);[[SEP]]// We are at the start of a left recursive rule's (...)* loop// and we're not taking the exit branch of loop.",219,298,[0],0,"[0, 0, 0]",0,"[0, 0]",0,0,0,0,visitState(ATNState),org.antlr.v4.runtime.ParserInterpreter,visitState/1[org.antlr.v4.runtime.atn.ATNState],False,219,18,21,1,20,19,20,58,0,8,1,20,4,1,0,1,0,6,2,4,9,1,2,0,0,0,45,4,0,False
238,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\ParserInterpreter.java,org.antlr.v4.runtime.ParserInterpreter,int visitDecisionState(DecisionState),"/**
 * Method visitDecisionState() is called when the interpreter reaches
 *  a decision state (instance of DecisionState). It gives an opportunity
 *  for subclasses to track interesting things.
 */
protected int visitDecisionState(DecisionState p) {
    int predictedAlt = 1;
    if (p.getNumberOfTransitions() > 1) {
        getErrorHandler().sync(this);
        int decision = p.decision;
        if (decision == overrideDecision && _input.index() == overrideDecisionInputIndex && !overrideDecisionReached) {
            predictedAlt = overrideDecisionAlt;
            overrideDecisionReached = true;
        } else {
            predictedAlt = getInterpreter().adaptivePredict(_input, decision, _ctx);
        }
    }
    return predictedAlt;
}","/**
 * Method visitDecisionState() is called when the interpreter reaches
 *  a decision state (instance of DecisionState). It gives an opportunity
 *  for subclasses to track interesting things.
 */
", ,/** * Method visitDecisionState() is called when the interpreter reaches *  a decision state (instance of DecisionState). It gives an opportunity *  for subclasses to track interesting things. */,304,320,[0],0,[0],0,[0],0,0,0,0,visitDecisionState(DecisionState),org.antlr.v4.runtime.ParserInterpreter,visitDecisionState/1[org.antlr.v4.runtime.atn.DecisionState],False,304,7,7,1,6,5,6,15,1,2,1,6,0,0,0,2,0,0,0,2,5,0,2,0,0,0,35,4,0,True
239,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\ParserInterpreter.java,org.antlr.v4.runtime.ParserInterpreter,"InterpreterRuleContext createInterpreterRuleContext(ParserRuleContext, int, int)","/**
 * Provide simple ""factory"" for InterpreterRuleContext's.
 *  @since 4.5.1
 */
protected InterpreterRuleContext createInterpreterRuleContext(ParserRuleContext parent, int invokingStateNumber, int ruleIndex) {
    return new InterpreterRuleContext(parent, invokingStateNumber, ruleIndex);
}","/**
 * Provide simple ""factory"" for InterpreterRuleContext's.
 *  @since 4.5.1
 */
", ,"/** * Provide simple ""factory"" for InterpreterRuleContext's. *  @since 4.5.1 */",325,331,[0],0,[0],0,[0],0,0,0,0,"createInterpreterRuleContext(ParserRuleContext, int, int)",org.antlr.v4.runtime.ParserInterpreter,"createInterpreterRuleContext/3[org.antlr.v4.runtime.ParserRuleContext,int,int]",False,329,2,3,2,1,1,0,3,1,0,3,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,9,4,0,True
240,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\ParserInterpreter.java,org.antlr.v4.runtime.ParserInterpreter,"void addDecisionOverride(int, int, int)","/**
 * Override this parser interpreters normal decision-making process
 *  at a particular decision and input token index. Instead of
 *  allowing the adaptive prediction mechanism to choose the
 *  first alternative within a block that leads to a successful parse,
 *  force it to take the alternative, 1..n for n alternatives.
 *
 *  As an implementation limitation right now, you can only specify one
 *  override. This is sufficient to allow construction of different
 *  parse trees for ambiguous input. It means re-parsing the entire input
 *  in general because you're never sure where an ambiguous sequence would
 *  live in the various parse trees. For example, in one interpretation,
 *  an ambiguous input sequence would be matched completely in expression
 *  but in another it could match all the way back to the root.
 *
 *  s : e '!'? ;
 *  e : ID
 *    | ID '!'
 *    ;
 *
 *  Here, x! can be matched as (s (e ID) !) or (s (e ID !)). In the first
 *  case, the ambiguous sequence is fully contained only by the root.
 *  In the second case, the ambiguous sequences fully contained within just
 *  e, as in: (e ID !).
 *
 *  Rather than trying to optimize this and make
 *  some intelligent decisions for optimization purposes, I settled on
 *  just re-parsing the whole input and then using
 *  {link Trees#getRootOfSubtreeEnclosingRegion} to find the minimal
 *  subtree that contains the ambiguous sequence. I originally tried to
 *  record the call stack at the point the parser detected and ambiguity but
 *  left recursive rules create a parse tree stack that does not reflect
 *  the actual call stack. That impedance mismatch was enough to make
 *  it it challenging to restart the parser at a deeply nested rule
 *  invocation.
 *
 *  Only parser interpreters can override decisions so as to avoid inserting
 *  override checking code in the critical ALL(*) prediction execution path.
 *
 *  @since 4.5.1
 */
public void addDecisionOverride(int decision, int tokenIndex, int forcedAlt) {
    overrideDecision = decision;
    overrideDecisionInputIndex = tokenIndex;
    overrideDecisionAlt = forcedAlt;
}","/**
 * Override this parser interpreters normal decision-making process
 *  at a particular decision and input token index. Instead of
 *  allowing the adaptive prediction mechanism to choose the
 *  first alternative within a block that leads to a successful parse,
 *  force it to take the alternative, 1..n for n alternatives.
 *
 *  As an implementation limitation right now, you can only specify one
 *  override. This is sufficient to allow construction of different
 *  parse trees for ambiguous input. It means re-parsing the entire input
 *  in general because you're never sure where an ambiguous sequence would
 *  live in the various parse trees. For example, in one interpretation,
 *  an ambiguous input sequence would be matched completely in expression
 *  but in another it could match all the way back to the root.
 *
 *  s : e '!'? ;
 *  e : ID
 *    | ID '!'
 *    ;
 *
 *  Here, x! can be matched as (s (e ID) !) or (s (e ID !)). In the first
 *  case, the ambiguous sequence is fully contained only by the root.
 *  In the second case, the ambiguous sequences fully contained within just
 *  e, as in: (e ID !).
 *
 *  Rather than trying to optimize this and make
 *  some intelligent decisions for optimization purposes, I settled on
 *  just re-parsing the whole input and then using
 *  {link Trees#getRootOfSubtreeEnclosingRegion} to find the minimal
 *  subtree that contains the ambiguous sequence. I originally tried to
 *  record the call stack at the point the parser detected and ambiguity but
 *  left recursive rules create a parse tree stack that does not reflect
 *  the actual call stack. That impedance mismatch was enough to make
 *  it it challenging to restart the parser at a deeply nested rule
 *  invocation.
 *
 *  Only parser interpreters can override decisions so as to avoid inserting
 *  override checking code in the critical ALL(*) prediction execution path.
 *
 *  @since 4.5.1
 */
", ,"/** * Override this parser interpreters normal decision-making process *  at a particular decision and input token index. Instead of *  allowing the adaptive prediction mechanism to choose the *  first alternative within a block that leads to a successful parse, *  force it to take the alternative, 1..n for n alternatives. * *  As an implementation limitation right now, you can only specify one *  override. This is sufficient to allow construction of different *  parse trees for ambiguous input. It means re-parsing the entire input *  in general because you're never sure where an ambiguous sequence would *  live in the various parse trees. For example, in one interpretation, *  an ambiguous input sequence would be matched completely in expression *  but in another it could match all the way back to the root. * *  s : e '!'? ; *  e : ID *    | ID '!' *    ; * *  Here, x! can be matched as (s (e ID) !) or (s (e ID !)). In the first *  case, the ambiguous sequence is fully contained only by the root. *  In the second case, the ambiguous sequences fully contained within just *  e, as in: (e ID !). * *  Rather than trying to optimize this and make *  some intelligent decisions for optimization purposes, I settled on *  just re-parsing the whole input and then using *  {link Trees#getRootOfSubtreeEnclosingRegion} to find the minimal *  subtree that contains the ambiguous sequence. I originally tried to *  record the call stack at the point the parser detected and ambiguity but *  left recursive rules create a parse tree stack that does not reflect *  the actual call stack. That impedance mismatch was enough to make *  it it challenging to restart the parser at a deeply nested rule *  invocation. * *  Only parser interpreters can override decisions so as to avoid inserting *  override checking code in the critical ALL(*) prediction execution path. * *  @since 4.5.1 */",388,392,[0],0,[0],0,[0],0,0,0,1,"addDecisionOverride(int, int, int)",org.antlr.v4.runtime.ParserInterpreter,"addDecisionOverride/3[int,int,int]",False,388,0,0,0,0,1,0,5,0,0,3,0,0,0,0,0,0,0,0,0,3,0,0,0,0,0,156,1,0,True
241,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\ParserInterpreter.java,org.antlr.v4.runtime.ParserInterpreter,void recover(RecognitionException),"/**
 * Rely on the error handler for this parser but, if no tokens are consumed
 *  to recover, add an error node. Otherwise, nothing is seen in the parse
 *  tree.
 */
protected void recover(RecognitionException e) {
    int i = _input.index();
    getErrorHandler().recover(this, e);
    if (_input.index() == i) {
        // no input consumed, better add an error node
        if (e instanceof InputMismatchException) {
            InputMismatchException ime = (InputMismatchException) e;
            Token tok = e.getOffendingToken();
            int expectedTokenType = Token.INVALID_TYPE;
            if (!ime.getExpectedTokens().isNil()) {
                // get any element
                expectedTokenType = ime.getExpectedTokens().getMinElement();
            }
            Token errToken = getTokenFactory().create(new Pair<TokenSource, CharStream>(tok.getTokenSource(), tok.getTokenSource().getInputStream()), expectedTokenType, tok.getText(), Token.DEFAULT_CHANNEL, // invalid start/stop
            -1, // invalid start/stop
            -1, tok.getLine(), tok.getCharPositionInLine());
            _ctx.addErrorNode(createErrorNode(_ctx, errToken));
        } else {
            // NoViableAlt
            Token tok = e.getOffendingToken();
            Token errToken = getTokenFactory().create(new Pair<TokenSource, CharStream>(tok.getTokenSource(), tok.getTokenSource().getInputStream()), Token.INVALID_TYPE, tok.getText(), Token.DEFAULT_CHANNEL, // invalid start/stop
            -1, // invalid start/stop
            -1, tok.getLine(), tok.getCharPositionInLine());
            _ctx.addErrorNode(createErrorNode(_ctx, errToken));
        }
    }
}","/**
 * Rely on the error handler for this parser but, if no tokens are consumed
 *  to recover, add an error node. Otherwise, nothing is seen in the parse
 *  tree.
 */
","// no input consumed, better add an error node
[[SEP]]// get any element
[[SEP]]// invalid start/stop
[[SEP]]// invalid start/stop
[[SEP]]// NoViableAlt
[[SEP]]// invalid start/stop
[[SEP]]// invalid start/stop
","/** * Rely on the error handler for this parser but, if no tokens are consumed *  to recover, add an error node. Otherwise, nothing is seen in the parse *  tree. */[[SEP]]// no input consumed, better add an error node[[SEP]]// get any element[[SEP]]// invalid start/stop[[SEP]]// invalid start/stop[[SEP]]// NoViableAlt[[SEP]]// invalid start/stop[[SEP]]// invalid start/stop",402,433,[0],0,"[0, 0, 0, 0, 0, 0, 0]",0,"[0, 0, 0, 0, 0, 0, 0, 0]",0,0,0,0,recover(RecognitionException),org.antlr.v4.runtime.ParserInterpreter,recover/1[org.antlr.v4.runtime.RecognitionException],False,402,12,18,1,17,4,16,21,0,7,1,16,0,0,0,1,0,0,0,4,8,0,3,0,0,0,37,4,0,True
242,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\ParserInterpreter.java,org.antlr.v4.runtime.ParserInterpreter,InterpreterRuleContext getRootContext(),"/**
 * Return the root of the parse, which can be useful if the parser
 *  bails out. You still can access the top node. Note that,
 *  because of the way left recursive rules add children, it's possible
 *  that the root will not have any children if the start rule immediately
 *  called and left recursive rule that fails.
 *
 * @since 4.5.1
 */
public InterpreterRuleContext getRootContext() {
    return rootContext;
}","/**
 * Return the root of the parse, which can be useful if the parser
 *  bails out. You still can access the top node. Note that,
 *  because of the way left recursive rules add children, it's possible
 *  that the root will not have any children if the start rule immediately
 *  called and left recursive rule that fails.
 *
 * @since 4.5.1
 */
", ,"/** * Return the root of the parse, which can be useful if the parser *  bails out. You still can access the top node. Note that, *  because of the way left recursive rules add children, it's possible *  that the root will not have any children if the start rule immediately *  called and left recursive rule that fails. * * @since 4.5.1 */",447,449,[0],0,[0],0,[0],0,0,0,0,getRootContext(),org.antlr.v4.runtime.ParserInterpreter,getRootContext/0,False,447,1,0,0,0,1,0,3,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,38,1,0,True
243,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\ParserRuleContext.java,org.antlr.v4.runtime.ParserRuleContext,void copyFrom(ParserRuleContext),"/**
 * COPY a ctx (I'm deliberately not using copy constructor) to avoid
 *  confusion with creating node with parent. Does not copy children
 *  (except error leaves).
 *
 *  This is used in the generated parser code to flip a generic XContext
 *  node for rule X to a YContext for alt label Y. In that sense, it is
 *  not really a generic copy function.
 *
 *  If we do an error sync() at start of a rule, we might add error nodes
 *  to the generic XContext so this function must copy those nodes to
 *  the YContext as well else they are lost!
 */
public void copyFrom(ParserRuleContext ctx) {
    this.parent = ctx.parent;
    this.invokingState = ctx.invokingState;
    this.start = ctx.start;
    this.stop = ctx.stop;
    // copy any error nodes to alt label node
    if (ctx.children != null) {
        this.children = new ArrayList<>();
        // reset parent pointer for any error nodes
        for (ParseTree child : ctx.children) {
            if (child instanceof ErrorNode) {
                addChild((ErrorNode) child);
            }
        }
    }
}","/**
 * COPY a ctx (I'm deliberately not using copy constructor) to avoid
 *  confusion with creating node with parent. Does not copy children
 *  (except error leaves).
 *
 *  This is used in the generated parser code to flip a generic XContext
 *  node for rule X to a YContext for alt label Y. In that sense, it is
 *  not really a generic copy function.
 *
 *  If we do an error sync() at start of a rule, we might add error nodes
 *  to the generic XContext so this function must copy those nodes to
 *  the YContext as well else they are lost!
 */
","// copy any error nodes to alt label node
[[SEP]]// reset parent pointer for any error nodes
","/** * COPY a ctx (I'm deliberately not using copy constructor) to avoid *  confusion with creating node with parent. Does not copy children *  (except error leaves). * *  This is used in the generated parser code to flip a generic XContext *  node for rule X to a YContext for alt label Y. In that sense, it is *  not really a generic copy function. * *  If we do an error sync() at start of a rule, we might add error nodes *  to the generic XContext so this function must copy those nodes to *  the YContext as well else they are lost! */[[SEP]]// copy any error nodes to alt label node[[SEP]]// reset parent pointer for any error nodes",95,112,[0],0,"[0, 0]",0,"[0, 0, 0]",0,0,0,0,copyFrom(ParserRuleContext),org.antlr.v4.runtime.ParserRuleContext,copyFrom/1[org.antlr.v4.runtime.ParserRuleContext],False,95,3,1,0,1,4,1,14,0,0,1,1,1,1,1,1,0,0,0,0,5,0,3,0,0,0,70,1,0,True
244,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\ParserRuleContext.java,org.antlr.v4.runtime.ParserRuleContext,T addAnyChild(T),"/**
 * Add a parse tree node to this as a child.  Works for
 *  internal and leaf nodes. Does not set parent link;
 *  other add methods must do that. Other addChild methods
 *  call this.
 *
 *  We cannot set the parent pointer of the incoming node
 *  because the existing interfaces do not have a setParent()
 *  method and I don't want to break backward compatibility for this.
 *
 *  @since 4.7
 */
public <T extends ParseTree> T addAnyChild(T t) {
    if (children == null)
        children = new ArrayList<>();
    children.add(t);
    return t;
}","/**
 * Add a parse tree node to this as a child.  Works for
 *  internal and leaf nodes. Does not set parent link;
 *  other add methods must do that. Other addChild methods
 *  call this.
 *
 *  We cannot set the parent pointer of the incoming node
 *  because the existing interfaces do not have a setParent()
 *  method and I don't want to break backward compatibility for this.
 *
 *  @since 4.7
 */
", ,/** * Add a parse tree node to this as a child.  Works for *  internal and leaf nodes. Does not set parent link; *  other add methods must do that. Other addChild methods *  call this. * *  We cannot set the parent pointer of the incoming node *  because the existing interfaces do not have a setParent() *  method and I don't want to break backward compatibility for this. * *  @since 4.7 */,134,138,[0],0,[0],0,[0],0,0,0,0,addAnyChild(T),org.antlr.v4.runtime.ParserRuleContext,addAnyChild/1[T],False,134,2,0,0,0,2,1,5,1,0,1,1,0,0,0,1,0,0,0,0,1,0,1,0,0,0,46,1,0,True
245,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\ParserRuleContext.java,org.antlr.v4.runtime.ParserRuleContext,TerminalNode addChild(TerminalNode),"/**
 * Add a token leaf node child and force its parent to be this node.
 */
public TerminalNode addChild(TerminalNode t) {
    t.setParent(this);
    return addAnyChild(t);
}","/**
 * Add a token leaf node child and force its parent to be this node.
 */
", ,/** * Add a token leaf node child and force its parent to be this node. */,145,148,[0],0,[0],0,[0],0,0,0,0,addChild(TerminalNode),org.antlr.v4.runtime.ParserRuleContext,addChild/1[org.antlr.v4.runtime.tree.TerminalNode],False,145,3,4,2,2,1,2,4,1,0,1,2,0,0,0,0,0,0,0,0,0,0,0,0,0,0,18,1,0,True
246,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\ParserRuleContext.java,org.antlr.v4.runtime.ParserRuleContext,ErrorNode addErrorNode(ErrorNode),"/**
 * Add an error node child and force its parent to be this node.
 *
 * @since 4.7
 */
public ErrorNode addErrorNode(ErrorNode errorNode) {
    errorNode.setParent(this);
    return addAnyChild(errorNode);
}","/**
 * Add an error node child and force its parent to be this node.
 *
 * @since 4.7
 */
", ,/** * Add an error node child and force its parent to be this node. * * @since 4.7 */,154,157,[0],0,[0],0,[0],0,0,0,0,addErrorNode(ErrorNode),org.antlr.v4.runtime.ParserRuleContext,addErrorNode/1[org.antlr.v4.runtime.tree.ErrorNode],False,154,3,6,4,2,1,2,4,1,0,1,2,0,0,0,0,0,0,0,0,0,0,0,0,0,0,16,1,0,True
247,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\ParserRuleContext.java,org.antlr.v4.runtime.ParserRuleContext,TerminalNode addChild(Token),"/**
 * Add a child to this node based upon matchedToken. It
 *  creates a TerminalNodeImpl rather than using
 *  {@link Parser#createTerminalNode(ParserRuleContext, Token)}. I'm leaving this
 *  in for compatibility but the parser doesn't use this anymore.
 */
@Deprecated
public TerminalNode addChild(Token matchedToken) {
    TerminalNodeImpl t = new TerminalNodeImpl(matchedToken);
    addAnyChild(t);
    t.setParent(this);
    return t;
}","/**
 * Add a child to this node based upon matchedToken. It
 *  creates a TerminalNodeImpl rather than using
 *  {@link Parser#createTerminalNode(ParserRuleContext, Token)}. I'm leaving this
 *  in for compatibility but the parser doesn't use this anymore.
 */
", ,"/** * Add a child to this node based upon matchedToken. It *  creates a TerminalNodeImpl rather than using *  {@link Parser#createTerminalNode(ParserRuleContext, Token)}. I'm leaving this *  in for compatibility but the parser doesn't use this anymore. */",164,170,[0],0,[0],0,[0],0,0,0,0,addChild(Token),org.antlr.v4.runtime.ParserRuleContext,addChild/1[org.antlr.v4.runtime.Token],False,165,4,3,0,3,1,2,6,1,1,1,2,0,0,0,0,0,0,0,0,1,0,0,0,0,0,28,1,0,True
248,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\ParserRuleContext.java,org.antlr.v4.runtime.ParserRuleContext,ErrorNode addErrorNode(Token),"/**
 * Add a child to this node based upon badToken.  It
 *  creates a ErrorNodeImpl rather than using
 *  {@link Parser#createErrorNode(ParserRuleContext, Token)}. I'm leaving this
 *  in for compatibility but the parser doesn't use this anymore.
 */
@Deprecated
public ErrorNode addErrorNode(Token badToken) {
    ErrorNodeImpl t = new ErrorNodeImpl(badToken);
    addAnyChild(t);
    t.setParent(this);
    return t;
}","/**
 * Add a child to this node based upon badToken.  It
 *  creates a ErrorNodeImpl rather than using
 *  {@link Parser#createErrorNode(ParserRuleContext, Token)}. I'm leaving this
 *  in for compatibility but the parser doesn't use this anymore.
 */
", ,"/** * Add a child to this node based upon badToken.  It *  creates a ErrorNodeImpl rather than using *  {@link Parser#createErrorNode(ParserRuleContext, Token)}. I'm leaving this *  in for compatibility but the parser doesn't use this anymore. */",177,183,[0],0,[0],0,[0],0,0,0,0,addErrorNode(Token),org.antlr.v4.runtime.ParserRuleContext,addErrorNode/1[org.antlr.v4.runtime.Token],False,178,5,3,0,3,1,2,6,1,1,1,2,0,0,0,0,0,0,0,0,1,0,0,0,0,0,28,1,0,True
249,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\ParserRuleContext.java,org.antlr.v4.runtime.ParserRuleContext,void removeLastChild(),"// public void trace(int s) {
// if ( states==null ) states = new ArrayList<Integer>();
// states.add(s);
// }
/**
 * Used by enterOuterAlt to toss out a RuleContext previously added as
 *  we entered a rule. If we have # label, we will need to remove
 *  generic ruleContext object.
 */
public void removeLastChild() {
    if (children != null) {
        children.remove(children.size() - 1);
    }
}","/**
 * Used by enterOuterAlt to toss out a RuleContext previously added as
 *  we entered a rule. If we have # label, we will need to remove
 *  generic ruleContext object.
 */
", ,"// public void trace(int s) {// if ( states==null ) states = new ArrayList<Integer>();// states.add(s);// }[[SEP]]/** * Used by enterOuterAlt to toss out a RuleContext previously added as *  we entered a rule. If we have # label, we will need to remove *  generic ruleContext object. */",194,198,[0],0,[0],0,"[0, 0]",0,0,0,0,removeLastChild(),org.antlr.v4.runtime.ParserRuleContext,removeLastChild/0,False,194,0,1,1,0,2,2,5,0,0,0,2,0,0,0,1,0,0,0,1,0,1,1,0,0,0,27,1,0,True
250,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\ParserRuleContext.java,org.antlr.v4.runtime.ParserRuleContext,ParserRuleContext getParent(),"@Override
public /**
 * Override to make type more specific
 */
ParserRuleContext getParent() {
    return (ParserRuleContext) super.getParent();
}", ,"/**
 * Override to make type more specific
 */
",/** * Override to make type more specific */,200,204,[0],0,[0],0,[0],0,0,0,0,getParent(),org.antlr.v4.runtime.ParserRuleContext,getParent/0,False,202,1,2,2,0,1,1,3,1,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,5,1,0,False
251,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\ParserRuleContext.java,org.antlr.v4.runtime.ParserRuleContext,"T getChild(Class<? extends T>, int)","public <T extends ParseTree> T getChild(Class<? extends T> ctxType, int i) {
    if (children == null || i < 0 || i >= children.size()) {
        return null;
    }
    // what element have we found with ctxType?
    int j = -1;
    for (ParseTree o : children) {
        if (ctxType.isInstance(o)) {
            j++;
            if (j == i) {
                return ctxType.cast(o);
            }
        }
    }
    return null;
}", ,"// what element have we found with ctxType?
",// what element have we found with ctxType?,211,226,[0],0,[0],0,[0],0,0,0,0,"getChild(Class<?T>, int)",org.antlr.v4.runtime.ParserRuleContext,"getChild/2[java.lang.Class<? extends T>,int]",False,211,2,0,0,0,7,3,15,3,1,2,3,0,0,1,2,0,0,0,2,1,0,3,0,0,0,10,1,0,False
252,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\ParserRuleContext.java,org.antlr.v4.runtime.ParserRuleContext,"TerminalNode getToken(int, int)","public TerminalNode getToken(int ttype, int i) {
    if (children == null || i < 0 || i >= children.size()) {
        return null;
    }
    // what token with ttype have we found?
    int j = -1;
    for (ParseTree o : children) {
        if (o instanceof TerminalNode) {
            TerminalNode tnode = (TerminalNode) o;
            Token symbol = tnode.getSymbol();
            if (symbol.getType() == ttype) {
                j++;
                if (j == i) {
                    return tnode;
                }
            }
        }
    }
    return null;
}", ,"// what token with ttype have we found?
",// what token with ttype have we found?,228,248,[0],0,[0],0,[0],0,0,0,0,"getToken(int, int)",org.antlr.v4.runtime.ParserRuleContext,"getToken/2[int,int]",False,228,3,2,0,2,8,3,19,3,3,2,3,0,0,1,3,0,0,0,2,3,0,4,0,0,0,14,1,0,False
253,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\ParserRuleContext.java,org.antlr.v4.runtime.ParserRuleContext,Interval getSourceInterval(),"@Override
public Interval getSourceInterval() {
    if (start == null) {
        return Interval.INVALID;
    }
    if (stop == null || stop.getTokenIndex() < start.getTokenIndex()) {
        // empty
        return Interval.of(start.getTokenIndex(), start.getTokenIndex() - 1);
    }
    return Interval.of(start.getTokenIndex(), stop.getTokenIndex());
}", ,"// empty
",// empty,306,315,[0],0,[0],0,[0],0,0,0,0,getSourceInterval(),org.antlr.v4.runtime.ParserRuleContext,getSourceInterval/0,False,307,2,2,0,2,4,2,9,3,0,0,2,0,0,0,2,0,0,0,1,0,1,1,0,0,0,6,1,0,False
254,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\ParserRuleContext.java,org.antlr.v4.runtime.ParserRuleContext,Token getStart(),"/**
 * Get the initial token in this context.
 * Note that the range from start to stop is inclusive, so for rules that do not consume anything
 * (for example, zero length or error productions) this token may exceed stop.
 */
public Token getStart() {
    return start;
}","/**
 * Get the initial token in this context.
 * Note that the range from start to stop is inclusive, so for rules that do not consume anything
 * (for example, zero length or error productions) this token may exceed stop.
 */
", ,"/** * Get the initial token in this context. * Note that the range from start to stop is inclusive, so for rules that do not consume anything * (for example, zero length or error productions) this token may exceed stop. */",322,322,[0],0,[0],0,[0],0,0,0,0,getStart(),org.antlr.v4.runtime.ParserRuleContext,getStart/0,False,322,1,1,1,0,1,0,3,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,28,1,0,True
255,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\ParserRuleContext.java,org.antlr.v4.runtime.ParserRuleContext,Token getStop(),"/**
 * Get the final token in this context.
 * Note that the range from start to stop is inclusive, so for rules that do not consume anything
 * (for example, zero length or error productions) this token may precede start.
 */
public Token getStop() {
    return stop;
}","/**
 * Get the final token in this context.
 * Note that the range from start to stop is inclusive, so for rules that do not consume anything
 * (for example, zero length or error productions) this token may precede start.
 */
", ,"/** * Get the final token in this context. * Note that the range from start to stop is inclusive, so for rules that do not consume anything * (for example, zero length or error productions) this token may precede start. */",328,328,[0],0,[0],0,[0],0,0,0,0,getStop(),org.antlr.v4.runtime.ParserRuleContext,getStop/0,False,328,1,1,1,0,1,0,3,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,27,1,0,True
256,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\ParserRuleContext.java,org.antlr.v4.runtime.ParserRuleContext,String toInfoString(Parser),"/**
 * Used for rule context info debugging during parse-time, not so much for ATN debugging
 */
public String toInfoString(Parser recognizer) {
    List<String> rules = recognizer.getRuleInvocationStack(this);
    Collections.reverse(rules);
    return ""ParserRuleContext"" + rules + ""{"" + ""start="" + start + "", stop="" + stop + '}';
}","/**
 * Used for rule context info debugging during parse-time, not so much for ATN debugging
 */
", ,"/** * Used for rule context info debugging during parse-time, not so much for ATN debugging */",331,338,[0],0,[0],0,[0],0,0,0,0,toInfoString(Parser),org.antlr.v4.runtime.ParserRuleContext,toInfoString/1[org.antlr.v4.runtime.Parser],False,331,1,1,0,1,1,2,5,1,1,1,2,0,0,0,0,0,0,4,0,1,1,0,0,0,0,21,1,0,True
257,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\RecognitionException.java,org.antlr.v4.runtime.RecognitionException,int getOffendingState(),"/**
 * Get the ATN state number the parser was in at the time the error
 * occurred. For {@link NoViableAltException} and
 * {@link LexerNoViableAltException} exceptions, this is the
 * {@link DecisionState} number. For others, it is the state whose outgoing
 * edge we couldn't match.
 *
 * <p>If the state number is not known, this method returns -1.</p>
 */
public int getOffendingState() {
    return offendingState;
}","/**
 * Get the ATN state number the parser was in at the time the error
 * occurred. For {@link NoViableAltException} and
 * {@link LexerNoViableAltException} exceptions, this is the
 * {@link DecisionState} number. For others, it is the state whose outgoing
 * edge we couldn't match.
 *
 * <p>If the state number is not known, this method returns -1.</p>
 */
", ,"/** * Get the ATN state number the parser was in at the time the error * occurred. For {@link NoViableAltException} and * {@link LexerNoViableAltException} exceptions, this is the * {@link DecisionState} number. For others, it is the state whose outgoing * edge we couldn't match. * * <p>If the state number is not known, this method returns -1.</p> */",65,67,[0],0,[0],0,[0],0,0,0,0,getOffendingState(),org.antlr.v4.runtime.RecognitionException,getOffendingState/0,False,65,0,0,0,0,1,0,3,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,35,1,0,True
258,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\RecognitionException.java,org.antlr.v4.runtime.RecognitionException,IntervalSet getExpectedTokens(),"/**
 * Gets the set of input symbols which could potentially follow the
 * previously matched symbol at the time this exception was thrown.
 *
 * <p>If the set of expected tokens is not known and could not be computed,
 * this method returns {@code null}.</p>
 *
 * @return The set of token types that could potentially follow the current
 * state in the ATN, or {@code null} if the information is not available.
 */
public IntervalSet getExpectedTokens() {
    if (recognizer != null) {
        return recognizer.getATN().getExpectedTokens(offendingState, ctx);
    }
    return null;
}","/**
 * Gets the set of input symbols which could potentially follow the
 * previously matched symbol at the time this exception was thrown.
 *
 * <p>If the set of expected tokens is not known and could not be computed,
 * this method returns {@code null}.</p>
 *
 * @return The set of token types that could potentially follow the current
 * state in the ATN, or {@code null} if the information is not available.
 */
", ,"/** * Gets the set of input symbols which could potentially follow the * previously matched symbol at the time this exception was thrown. * * <p>If the set of expected tokens is not known and could not be computed, * this method returns {@code null}.</p> * * @return The set of token types that could potentially follow the current * state in the ATN, or {@code null} if the information is not available. */",83,89,[0],0,[0],0,[0],0,0,0,0,getExpectedTokens(),org.antlr.v4.runtime.RecognitionException,getExpectedTokens/0,False,83,3,4,2,2,2,2,6,2,0,0,2,0,0,0,1,0,0,0,0,0,0,1,0,0,0,43,1,0,True
259,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\RecognitionException.java,org.antlr.v4.runtime.RecognitionException,RuleContext getCtx(),"/**
 * Gets the {@link RuleContext} at the time this exception was thrown.
 *
 * <p>If the context is not available, this method returns {@code null}.</p>
 *
 * @return The {@link RuleContext} at the time this exception was thrown.
 * If the context is not available, this method returns {@code null}.
 */
public RuleContext getCtx() {
    return ctx;
}","/**
 * Gets the {@link RuleContext} at the time this exception was thrown.
 *
 * <p>If the context is not available, this method returns {@code null}.</p>
 *
 * @return The {@link RuleContext} at the time this exception was thrown.
 * If the context is not available, this method returns {@code null}.
 */
", ,"/** * Gets the {@link RuleContext} at the time this exception was thrown. * * <p>If the context is not available, this method returns {@code null}.</p> * * @return The {@link RuleContext} at the time this exception was thrown. * If the context is not available, this method returns {@code null}. */",99,101,[0],0,[0],0,[0],0,0,0,0,getCtx(),org.antlr.v4.runtime.RecognitionException,getCtx/0,False,99,1,0,0,0,1,0,3,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,20,1,0,True
260,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\RecognitionException.java,org.antlr.v4.runtime.RecognitionException,IntStream getInputStream(),"/**
 * Gets the input stream which is the symbol source for the recognizer where
 * this exception was thrown.
 *
 * <p>If the input stream is not available, this method returns {@code null}.</p>
 *
 * @return The input stream which is the symbol source for the recognizer
 * where this exception was thrown, or {@code null} if the stream is not
 * available.
 */
public IntStream getInputStream() {
    return input;
}","/**
 * Gets the input stream which is the symbol source for the recognizer where
 * this exception was thrown.
 *
 * <p>If the input stream is not available, this method returns {@code null}.</p>
 *
 * @return The input stream which is the symbol source for the recognizer
 * where this exception was thrown, or {@code null} if the stream is not
 * available.
 */
", ,"/** * Gets the input stream which is the symbol source for the recognizer where * this exception was thrown. * * <p>If the input stream is not available, this method returns {@code null}.</p> * * @return The input stream which is the symbol source for the recognizer * where this exception was thrown, or {@code null} if the stream is not * available. */",113,115,[0],0,[0],0,[0],0,0,0,0,getInputStream(),org.antlr.v4.runtime.RecognitionException,getInputStream/0,False,113,1,0,0,0,1,0,3,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,25,1,0,True
261,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\RecognitionException.java,org.antlr.v4.runtime.RecognitionException,"Recognizer<?, ?> getRecognizer()","/**
 * Gets the {@link Recognizer} where this exception occurred.
 *
 * <p>If the recognizer is not available, this method returns {@code null}.</p>
 *
 * @return The recognizer where this exception occurred, or {@code null} if
 * the recognizer is not available.
 */
public Recognizer<?, ?> getRecognizer() {
    return recognizer;
}","/**
 * Gets the {@link Recognizer} where this exception occurred.
 *
 * <p>If the recognizer is not available, this method returns {@code null}.</p>
 *
 * @return The recognizer where this exception occurred, or {@code null} if
 * the recognizer is not available.
 */
", ,"/** * Gets the {@link Recognizer} where this exception occurred. * * <p>If the recognizer is not available, this method returns {@code null}.</p> * * @return The recognizer where this exception occurred, or {@code null} if * the recognizer is not available. */",134,136,[0],0,[0],0,[0],0,0,0,0,getRecognizer(),org.antlr.v4.runtime.RecognitionException,getRecognizer/0,False,134,1,0,0,0,1,0,3,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,17,1,0,True
262,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\Recognizer.java,org.antlr.v4.runtime.Recognizer,String[] getTokenNames(),"/**
 * Used to print out token names like ID during debugging and
 *  error reporting.  The generated parsers implement a method
 *  that overrides this to point to their String[] tokenNames.
 *
 * @deprecated Use {@link #getVocabulary()} instead.
 */
@Deprecated
public abstract String[] getTokenNames();","/**
 * Used to print out token names like ID during debugging and
 *  error reporting.  The generated parsers implement a method
 *  that overrides this to point to their String[] tokenNames.
 *
 * @deprecated Use {@link #getVocabulary()} instead.
 */
", ,/** * Used to print out token names like ID during debugging and *  error reporting.  The generated parsers implement a method *  that overrides this to point to their String[] tokenNames. * * @deprecated Use {@link #getVocabulary()} instead. */,45,46,[1],1,[0],0,[1],1,0,0,0,getTokenNames(),org.antlr.v4.runtime.Recognizer,getTokenNames/0,False,39,0,0,0,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,27,1025,0,True
263,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\Recognizer.java,org.antlr.v4.runtime.Recognizer,Vocabulary getVocabulary(),"/**
 * Get the vocabulary used by the recognizer.
 *
 * @return A {@link Vocabulary} instance providing information about the
 * vocabulary used by the grammar.
 */
@SuppressWarnings(""deprecation"")
public Vocabulary getVocabulary() {
    return VocabularyImpl.fromTokenNames(getTokenNames());
}","/**
 * Get the vocabulary used by the recognizer.
 *
 * @return A {@link Vocabulary} instance providing information about the
 * vocabulary used by the grammar.
 */
", ,/** * Get the vocabulary used by the recognizer. * * @return A {@link Vocabulary} instance providing information about the * vocabulary used by the grammar. */,56,59,[0],0,[0],0,[0],0,0,0,0,getVocabulary(),org.antlr.v4.runtime.Recognizer,getVocabulary/0,False,57,3,2,0,2,1,2,3,1,0,0,2,0,0,0,0,0,0,1,0,0,0,0,0,0,0,15,1,0,True
264,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\Recognizer.java,org.antlr.v4.runtime.Recognizer,"Map<String, Integer> getTokenTypeMap()","/**
 * Get a map from token names to token types.
 *
 * <p>Used for XPath and tree pattern compilation.</p>
 */
public Map<String, Integer> getTokenTypeMap() {
    Vocabulary vocabulary = getVocabulary();
    synchronized (tokenTypeMapCache) {
        Map<String, Integer> result = tokenTypeMapCache.get(vocabulary);
        if (result == null) {
            result = new HashMap<String, Integer>();
            for (int i = 0; i <= getATN().maxTokenType; i++) {
                String literalName = vocabulary.getLiteralName(i);
                if (literalName != null) {
                    result.put(literalName, i);
                }
                String symbolicName = vocabulary.getSymbolicName(i);
                if (symbolicName != null) {
                    result.put(symbolicName, i);
                }
            }
            result.put(""EOF"", Token.EOF);
            result = Collections.unmodifiableMap(result);
            tokenTypeMapCache.put(vocabulary, result);
        }
        return result;
    }
}","/**
 * Get a map from token names to token types.
 *
 * <p>Used for XPath and tree pattern compilation.</p>
 */
", ,/** * Get a map from token names to token types. * * <p>Used for XPath and tree pattern compilation.</p> */,66,91,[0],0,[0],0,[0],0,0,0,0,getTokenTypeMap(),org.antlr.v4.runtime.Recognizer,getTokenTypeMap/0,False,66,2,4,0,4,5,8,23,1,5,0,8,0,0,1,3,0,0,1,1,7,0,4,0,0,0,30,1,0,True
265,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\Recognizer.java,org.antlr.v4.runtime.Recognizer,"Map<String, Integer> getRuleIndexMap()","/**
 * Get a map from rule names to rule indexes.
 *
 * <p>Used for XPath and tree pattern compilation.</p>
 */
public Map<String, Integer> getRuleIndexMap() {
    String[] ruleNames = getRuleNames();
    if (ruleNames == null) {
        throw new UnsupportedOperationException(""The current recognizer does not provide a list of rule names."");
    }
    synchronized (ruleIndexMapCache) {
        Map<String, Integer> result = ruleIndexMapCache.get(ruleNames);
        if (result == null) {
            result = Collections.unmodifiableMap(Utils.toMap(ruleNames));
            ruleIndexMapCache.put(ruleNames, result);
        }
        return result;
    }
}","/**
 * Get a map from rule names to rule indexes.
 *
 * <p>Used for XPath and tree pattern compilation.</p>
 */
", ,/** * Get a map from rule names to rule indexes. * * <p>Used for XPath and tree pattern compilation.</p> */,98,113,[0],0,[0],0,[0],0,0,0,0,getRuleIndexMap(),org.antlr.v4.runtime.Recognizer,getRuleIndexMap/0,False,98,2,2,0,2,3,5,14,1,2,0,5,0,0,0,2,0,0,1,0,3,0,2,0,0,0,32,1,0,True
266,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\Recognizer.java,org.antlr.v4.runtime.Recognizer,String getSerializedATN(),"/**
 * If this recognizer was generated, it will have a serialized ATN
 * representation of the grammar.
 *
 * <p>For interpreters, we don't know their serialized ATN despite having
 * created the interpreter from it.</p>
 */
public String getSerializedATN() {
    throw new UnsupportedOperationException(""there is no serialized ATN"");
}","/**
 * If this recognizer was generated, it will have a serialized ATN
 * representation of the grammar.
 *
 * <p>For interpreters, we don't know their serialized ATN despite having
 * created the interpreter from it.</p>
 */
", ,"/** * If this recognizer was generated, it will have a serialized ATN * representation of the grammar. * * <p>For interpreters, we don't know their serialized ATN despite having * created the interpreter from it.</p> */",128,130,[0],0,[0],0,[0],0,0,0,0,getSerializedATN(),org.antlr.v4.runtime.Recognizer,getSerializedATN/0,False,128,0,0,0,0,1,0,3,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,31,1,0,True
267,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\Recognizer.java,org.antlr.v4.runtime.Recognizer,String getGrammarFileName(),"/**
 * For debugging and other purposes, might want the grammar name.
 *  Have ANTLR generate an implementation for this method.
 */
public abstract String getGrammarFileName();","/**
 * For debugging and other purposes, might want the grammar name.
 *  Have ANTLR generate an implementation for this method.
 */
", ,"/** * For debugging and other purposes, might want the grammar name. *  Have ANTLR generate an implementation for this method. */",135,135,[0],0,[0],0,[0],0,0,0,0,getGrammarFileName(),org.antlr.v4.runtime.Recognizer,getGrammarFileName/0,False,132,0,0,0,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,21,1025,0,True
268,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\Recognizer.java,org.antlr.v4.runtime.Recognizer,ATN getATN(),"/**
 * Get the {@link ATN} used by the recognizer for prediction.
 *
 * @return The {@link ATN} used by the recognizer for prediction.
 */
public abstract ATN getATN();","/**
 * Get the {@link ATN} used by the recognizer for prediction.
 *
 * @return The {@link ATN} used by the recognizer for prediction.
 */
", ,/** * Get the {@link ATN} used by the recognizer for prediction. * * @return The {@link ATN} used by the recognizer for prediction. */,142,142,[0],0,[0],0,[0],0,0,0,0,getATN(),org.antlr.v4.runtime.Recognizer,getATN/0,False,137,1,0,0,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,10,1025,0,True
269,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\Recognizer.java,org.antlr.v4.runtime.Recognizer,ATNInterpreter getInterpreter(),"/**
 * Get the ATN interpreter used by the recognizer for prediction.
 *
 * @return The ATN interpreter used by the recognizer for prediction.
 */
public ATNInterpreter getInterpreter() {
    return _interp;
}","/**
 * Get the ATN interpreter used by the recognizer for prediction.
 *
 * @return The ATN interpreter used by the recognizer for prediction.
 */
", ,/** * Get the ATN interpreter used by the recognizer for prediction. * * @return The ATN interpreter used by the recognizer for prediction. */,149,151,[0],0,[0],0,[0],0,0,0,0,getInterpreter(),org.antlr.v4.runtime.Recognizer,getInterpreter/0,False,149,1,0,0,0,1,0,3,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,13,1,0,True
270,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\Recognizer.java,org.antlr.v4.runtime.Recognizer,ParseInfo getParseInfo(),"/**
 * If profiling during the parse/lex, this will return DecisionInfo records
 *  for each decision in recognizer in a ParseInfo object.
 *
 * @since 4.3
 */
public ParseInfo getParseInfo() {
    return null;
}","/**
 * If profiling during the parse/lex, this will return DecisionInfo records
 *  for each decision in recognizer in a ParseInfo object.
 *
 * @since 4.3
 */
", ,"/** * If profiling during the parse/lex, this will return DecisionInfo records *  for each decision in recognizer in a ParseInfo object. * * @since 4.3 */",158,160,[0],0,[0],0,[0],0,0,0,0,getParseInfo(),org.antlr.v4.runtime.Recognizer,getParseInfo/0,False,158,1,0,0,0,1,0,3,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,17,1,0,True
271,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\Recognizer.java,org.antlr.v4.runtime.Recognizer,void setInterpreter(ATNInterpreter),"/**
 * Set the ATN interpreter used by the recognizer for prediction.
 *
 * @param interpreter The ATN interpreter used by the recognizer for
 * prediction.
 */
public void setInterpreter(ATNInterpreter interpreter) {
    _interp = interpreter;
}","/**
 * Set the ATN interpreter used by the recognizer for prediction.
 *
 * @param interpreter The ATN interpreter used by the recognizer for
 * prediction.
 */
", ,/** * Set the ATN interpreter used by the recognizer for prediction. * * @param interpreter The ATN interpreter used by the recognizer for * prediction. */,168,170,[0],0,[0],0,[0],0,0,0,0,setInterpreter(ATNInterpreter),org.antlr.v4.runtime.Recognizer,setInterpreter/1[ATNInterpreter],False,168,1,0,0,0,1,0,3,0,0,1,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,13,1,0,True
272,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\Recognizer.java,org.antlr.v4.runtime.Recognizer,String getErrorHeader(RecognitionException),"/**
 * What is the error header, normally line/character position information?
 */
public String getErrorHeader(RecognitionException e) {
    int line = e.getOffendingToken().getLine();
    int charPositionInLine = e.getOffendingToken().getCharPositionInLine();
    return ""line "" + line + "":"" + charPositionInLine;
}","/**
 * What is the error header, normally line/character position information?
 */
", ,"/** * What is the error header, normally line/character position information? */",173,177,[0],0,[0],0,[0],0,0,0,0,getErrorHeader(RecognitionException),org.antlr.v4.runtime.Recognizer,getErrorHeader/1[org.antlr.v4.runtime.RecognitionException],False,173,2,3,0,3,1,3,5,1,2,1,3,0,0,0,0,0,0,2,0,2,1,0,0,0,0,18,1,0,True
273,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\Recognizer.java,org.antlr.v4.runtime.Recognizer,String getTokenErrorDisplay(Token),"/**
 * How should a token be displayed in an error message? The default
 *  is to display just the text, but during development you might
 *  want to have a lot of information spit out.  Override in that case
 *  to use t.toString() (which, for CommonToken, dumps everything about
 *  the token). This is better than forcing you to override a method in
 *  your token objects because you don't have to go modify your lexer
 *  so that it creates a new Java type.
 *
 * @deprecated This method is not called by the ANTLR 4 Runtime. Specific
 * implementations of {@link ANTLRErrorStrategy} may provide a similar
 * feature when necessary. For example, see
 * {@link DefaultErrorStrategy#getTokenErrorDisplay}.
 */
@Deprecated
public String getTokenErrorDisplay(Token t) {
    if (t == null)
        return ""<no token>"";
    String s = t.getText();
    if (s == null) {
        if (t.getType() == Token.EOF) {
            s = ""<EOF>"";
        } else {
            s = ""<"" + t.getType() + "">"";
        }
    }
    s = s.replace(""\n"", ""\\n"");
    s = s.replace(""\r"", ""\\r"");
    s = s.replace(""\t"", ""\\t"");
    return ""'"" + s + ""'"";
}","/**
 * How should a token be displayed in an error message? The default
 *  is to display just the text, but during development you might
 *  want to have a lot of information spit out.  Override in that case
 *  to use t.toString() (which, for CommonToken, dumps everything about
 *  the token). This is better than forcing you to override a method in
 *  your token objects because you don't have to go modify your lexer
 *  so that it creates a new Java type.
 *
 * @deprecated This method is not called by the ANTLR 4 Runtime. Specific
 * implementations of {@link ANTLRErrorStrategy} may provide a similar
 * feature when necessary. For example, see
 * {@link DefaultErrorStrategy#getTokenErrorDisplay}.
 */
", ,"/** * How should a token be displayed in an error message? The default *  is to display just the text, but during development you might *  want to have a lot of information spit out.  Override in that case *  to use t.toString() (which, for CommonToken, dumps everything about *  the token). This is better than forcing you to override a method in *  your token objects because you don't have to go modify your lexer *  so that it creates a new Java type. * * @deprecated This method is not called by the ANTLR 4 Runtime. Specific * implementations of {@link ANTLRErrorStrategy} may provide a similar * feature when necessary. For example, see * {@link DefaultErrorStrategy#getTokenErrorDisplay}. */",192,208,[1],1,[0],0,[1],1,0,0,0,getTokenErrorDisplay(Token),org.antlr.v4.runtime.Recognizer,getTokenErrorDisplay/1[org.antlr.v4.runtime.Token],False,193,1,2,0,2,4,3,16,2,1,1,3,0,0,0,3,0,0,12,0,6,2,2,0,0,0,71,1,0,True
274,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\Recognizer.java,org.antlr.v4.runtime.Recognizer,void addErrorListener(ANTLRErrorListener),"/**
 * @exception NullPointerException if {@code listener} is {@code null}.
 */
public void addErrorListener(ANTLRErrorListener listener) {
    if (listener == null) {
        throw new NullPointerException(""listener cannot be null."");
    }
    _listeners.add(listener);
}","/**
 * @exception NullPointerException if {@code listener} is {@code null}.
 */
", ,/** * @exception NullPointerException if {@code listener} is {@code null}. */,213,219,[0],0,[0],0,[0],0,0,0,0,addErrorListener(ANTLRErrorListener),org.antlr.v4.runtime.Recognizer,addErrorListener/1[org.antlr.v4.runtime.ANTLRErrorListener],False,213,1,0,0,0,2,1,6,0,0,1,1,0,0,0,1,0,0,1,0,0,0,1,0,0,0,16,1,0,True
275,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\Recognizer.java,org.antlr.v4.runtime.Recognizer,"boolean sempred(RuleContext, int, int)","// subclass needs to override these if there are sempreds or actions
// that the ATN interp needs to execute
public boolean sempred(RuleContext _localctx, int ruleIndex, int actionIndex) {
    return true;
}","// that the ATN interp needs to execute
", ,// subclass needs to override these if there are sempreds or actions// that the ATN interp needs to execute,240,242,[0],0,[0],0,[0],0,0,0,0,"sempred(RuleContext, int, int)",org.antlr.v4.runtime.Recognizer,"sempred/3[org.antlr.v4.runtime.RuleContext,int,int]",False,240,1,0,0,0,1,0,3,1,0,3,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,6,1,0,False
276,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\Recognizer.java,org.antlr.v4.runtime.Recognizer,void setState(int),"/**
 * Indicate that the recognizer has changed internal state that is
 *  consistent with the ATN state passed in.  This way we always know
 *  where we are in the ATN as the parser goes along. The rule
 *  context objects form a stack that lets us see the stack of
 *  invoking rules. Combine this and we have complete ATN
 *  configuration information.
 */
public final void setState(int atnState) {
    // System.err.println(""setState ""+atnState);
    _stateNumber = atnState;
    // if ( traceATNStates ) _ctx.trace(atnState);
}","/**
 * Indicate that the recognizer has changed internal state that is
 *  consistent with the ATN state passed in.  This way we always know
 *  where we are in the ATN as the parser goes along. The rule
 *  context objects form a stack that lets us see the stack of
 *  invoking rules. Combine this and we have complete ATN
 *  configuration information.
 */
","// if ( traceATNStates ) _ctx.trace(atnState);
[[SEP]]// System.err.println(""setState ""+atnState);
","/** * Indicate that the recognizer has changed internal state that is *  consistent with the ATN state passed in.  This way we always know *  where we are in the ATN as the parser goes along. The rule *  context objects form a stack that lets us see the stack of *  invoking rules. Combine this and we have complete ATN *  configuration information. */[[SEP]]// System.err.println(""setState ""+atnState);[[SEP]]// if ( traceATNStates ) _ctx.trace(atnState);",262,266,[0],0,"[0, 0]",0,"[0, 0, 0]",0,0,0,0,setState(int),org.antlr.v4.runtime.Recognizer,setState/1[int],False,262,0,0,0,0,1,0,3,0,0,1,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,48,17,0,True
277,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\RuleContext.java,org.antlr.v4.runtime.RuleContext,boolean isEmpty(),"/**
 * A context is empty if there is no invoking state; meaning nobody called
 *  current context.
 */
public boolean isEmpty() {
    return invokingState == -1;
}","/**
 * A context is empty if there is no invoking state; meaning nobody called
 *  current context.
 */
", ,/** * A context is empty if there is no invoking state; meaning nobody called *  current context. */,100,102,[0],0,[0],0,[0],0,0,0,0,isEmpty(),org.antlr.v4.runtime.RuleContext,isEmpty/0,False,100,0,2,2,0,2,0,3,1,0,0,0,0,0,0,1,0,0,0,1,0,0,0,0,0,0,14,1,0,True
278,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\RuleContext.java,org.antlr.v4.runtime.RuleContext,String getText(),"/**
 * Return the combined text of all child nodes. This method only considers
 *  tokens which have been added to the parse tree.
 *  <p>
 *  Since tokens on hidden channels (e.g. whitespace or comments) are not
 *  added to the parse trees, they will not appear in the output of this
 *  method.
 */
@Override
public String getText() {
    if (getChildCount() == 0) {
        return """";
    }
    StringBuilder builder = new StringBuilder();
    for (int i = 0; i < getChildCount(); i++) {
        builder.append(getChild(i).getText());
    }
    return builder.toString();
}","/**
 * Return the combined text of all child nodes. This method only considers
 *  tokens which have been added to the parse tree.
 *  <p>
 *  Since tokens on hidden channels (e.g. whitespace or comments) are not
 *  added to the parse trees, they will not appear in the output of this
 *  method.
 */
", ,"/** * Return the combined text of all child nodes. This method only considers *  tokens which have been added to the parse tree. *  <p> *  Since tokens on hidden channels (e.g. whitespace or comments) are not *  added to the parse trees, they will not appear in the output of this *  method. */",127,139,[0],0,[0],0,[0],0,0,0,0,getText(),org.antlr.v4.runtime.RuleContext,getText/0,False,128,2,3,0,3,3,5,10,2,2,0,5,2,1,1,1,0,0,1,2,2,0,1,0,0,0,40,1,0,True
279,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\RuleContext.java,org.antlr.v4.runtime.RuleContext,int getAltNumber(),"/**
 * For rule associated with this parse tree internal node, return
 *  the outer alternative number used to match the input. Default
 *  implementation does not compute nor store this alt num. Create
 *  a subclass of ParserRuleContext with backing field and set
 *  option contextSuperClass.
 *  to set it.
 *
 *  @since 4.5.3
 */
public int getAltNumber() {
    return ATN.INVALID_ALT_NUMBER;
}","/**
 * For rule associated with this parse tree internal node, return
 *  the outer alternative number used to match the input. Default
 *  implementation does not compute nor store this alt num. Create
 *  a subclass of ParserRuleContext with backing field and set
 *  option contextSuperClass.
 *  to set it.
 *
 *  @since 4.5.3
 */
", ,"/** * For rule associated with this parse tree internal node, return *  the outer alternative number used to match the input. Default *  implementation does not compute nor store this alt num. Create *  a subclass of ParserRuleContext with backing field and set *  option contextSuperClass. *  to set it. * *  @since 4.5.3 */",152,152,[0],0,[0],0,[0],0,0,0,0,getAltNumber(),org.antlr.v4.runtime.RuleContext,getAltNumber/0,False,152,0,1,1,0,1,0,3,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,37,1,0,True
280,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\RuleContext.java,org.antlr.v4.runtime.RuleContext,void setAltNumber(int),"/**
 * Set the outer alternative number for this context node. Default
 *  implementation does nothing to avoid backing field overhead for
 *  trees that don't need it.  Create
 *  a subclass of ParserRuleContext with backing field and set
 *  option contextSuperClass.
 *
 *  @since 4.5.3
 */
public void setAltNumber(int altNumber) {
}","/**
 * Set the outer alternative number for this context node. Default
 *  implementation does nothing to avoid backing field overhead for
 *  trees that don't need it.  Create
 *  a subclass of ParserRuleContext with backing field and set
 *  option contextSuperClass.
 *
 *  @since 4.5.3
 */
", ,/** * Set the outer alternative number for this context node. Default *  implementation does nothing to avoid backing field overhead for *  trees that don't need it.  Create *  a subclass of ParserRuleContext with backing field and set *  option contextSuperClass. * *  @since 4.5.3 */,162,162,[0],0,[0],0,[0],0,0,0,0,setAltNumber(int),org.antlr.v4.runtime.RuleContext,setAltNumber/1[int],False,162,0,1,1,0,1,0,2,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,32,1,0,True
281,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\RuleContext.java,org.antlr.v4.runtime.RuleContext,void setParent(RuleContext),"/**
 * @since 4.7. {@see ParseTree#setParent} comment
 */
@Override
public void setParent(RuleContext parent) {
    this.parent = parent;
}","/**
 * @since 4.7. {@see ParseTree#setParent} comment
 */
", ,/** * @since 4.7. {@see ParseTree#setParent} comment */,165,168,[0],0,[0],0,[0],0,0,0,0,setParent(RuleContext),org.antlr.v4.runtime.RuleContext,setParent/1[org.antlr.v4.runtime.RuleContext],False,166,1,0,0,0,1,0,3,0,0,1,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,6,1,0,True
282,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\RuleContext.java,org.antlr.v4.runtime.RuleContext,String toStringTree(Parser),"/**
 * Print out a whole tree, not just a node, in LISP format
 *  (root child1 .. childN). Print just a node if this is a leaf.
 *  We have to know the recognizer so we can get rule names.
 */
@Override
public String toStringTree(Parser recog) {
    return Trees.toStringTree(this, recog);
}","/**
 * Print out a whole tree, not just a node, in LISP format
 *  (root child1 .. childN). Print just a node if this is a leaf.
 *  We have to know the recognizer so we can get rule names.
 */
", ,"/** * Print out a whole tree, not just a node, in LISP format *  (root child1 .. childN). Print just a node if this is a leaf. *  We have to know the recognizer so we can get rule names. */",187,190,[0],0,[0],0,[0],0,0,0,0,toStringTree(Parser),org.antlr.v4.runtime.RuleContext,toStringTree/1[org.antlr.v4.runtime.Parser],False,188,2,2,1,1,1,1,3,1,0,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,33,1,0,True
283,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\RuleContext.java,org.antlr.v4.runtime.RuleContext,String toStringTree(List<String>),"/**
 * Print out a whole tree, not just a node, in LISP format
 *  (root child1 .. childN). Print just a node if this is a leaf.
 */
public String toStringTree(List<String> ruleNames) {
    return Trees.toStringTree(this, ruleNames);
}","/**
 * Print out a whole tree, not just a node, in LISP format
 *  (root child1 .. childN). Print just a node if this is a leaf.
 */
", ,"/** * Print out a whole tree, not just a node, in LISP format *  (root child1 .. childN). Print just a node if this is a leaf. */",195,197,[0],0,[0],0,[0],0,0,0,0,toStringTree(List<String>),org.antlr.v4.runtime.RuleContext,toStringTree/1[java.util.List<java.lang.String>],False,195,1,2,1,1,1,1,3,1,0,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,23,1,0,True
284,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\RuleContext.java,org.antlr.v4.runtime.RuleContext,"String toString(Recognizer<?, ?>, RuleContext)","// recog null unless ParserRuleContext, in which case we use subclass toString(...)
public String toString(Recognizer<?, ?> recog, RuleContext stop) {
    String[] ruleNames = recog != null ? recog.getRuleNames() : null;
    List<String> ruleNamesList = ruleNames != null ? Arrays.asList(ruleNames) : null;
    return toString(ruleNamesList, stop);
}","// recog null unless ParserRuleContext, in which case we use subclass toString(...)
", ,"// recog null unless ParserRuleContext, in which case we use subclass toString(...)",218,222,[0],0,[0],0,[0],0,0,0,0,"toString(Recognizer<?, ?>, RuleContext)",org.antlr.v4.runtime.RuleContext,"toString/2[org.antlr.v4.runtime.Recognizer<?,?>,org.antlr.v4.runtime.RuleContext]",False,218,2,3,1,2,3,3,5,1,2,2,3,1,2,0,2,0,0,0,0,2,0,0,0,0,0,8,1,0,False
285,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\RuntimeMetaData.java,org.antlr.v4.runtime.RuntimeMetaData,"void checkVersion(String, String)","/**
 * This method provides the ability to detect mismatches between the version
 * of ANTLR 4 used to generate a parser, the version of the ANTLR runtime a
 * parser was compiled against, and the version of the ANTLR runtime which
 * is currently executing.
 *
 * <p>
 * The version check is designed to detect the following two specific
 * scenarios.</p>
 *
 * <ul>
 * <li>The ANTLR Tool version used for code generation does not match the
 * currently executing runtime version.</li>
 * <li>The ANTLR Runtime version referenced at the time a parser was
 * compiled does not match the currently executing runtime version.</li>
 * </ul>
 *
 * <p>
 * Starting with ANTLR 4.3, the code generator emits a call to this method
 * using two constants in each generated lexer and parser: a hard-coded
 * constant indicating the version of the tool used to generate the parser
 * and a reference to the compile-time constant {@link #VERSION}. At
 * runtime, this method is called during the initialization of the generated
 * parser to detect mismatched versions, and notify the registered listeners
 * prior to creating instances of the parser.</p>
 *
 * <p>
 * This method does not perform any detection or filtering of semantic
 * changes between tool and runtime versions. It simply checks for a
 * version match and emits an error to stderr if a difference
 * is detected.</p>
 *
 * <p>
 * Note that some breaking changes between releases could result in other
 * types of runtime exceptions, such as a {@link LinkageError}, prior to
 * calling this method. In these cases, the underlying version mismatch will
 * not be reported here. This method is primarily intended to
 * notify users of potential semantic changes between releases that do not
 * result in binary compatibility problems which would be detected by the
 * class loader. As with semantic changes, changes that break binary
 * compatibility between releases are mentioned in the release notes
 * accompanying the affected release.</p>
 *
 * <p>
 * <strong>Additional note for target developers:</strong> The version check
 * implemented by this class is designed to address specific compatibility
 * concerns that may arise during the execution of Java applications. Other
 * targets should consider the implementation of this method in the context
 * of that target's known execution environment, which may or may not
 * resemble the design provided for the Java target.</p>
 *
 * @param generatingToolVersion The version of the tool used to generate a parser.
 * This value may be null when called from user code that was not generated
 * by, and does not reference, the ANTLR 4 Tool itself.
 * @param compileTimeVersion The version of the runtime the parser was
 * compiled against. This should always be passed using a direct reference
 * to {@link #VERSION}.
 */
public static void checkVersion(String generatingToolVersion, String compileTimeVersion) {
    String runtimeVersion = VERSION;
    boolean runtimeConflictsWithGeneratingTool = false;
    boolean runtimeConflictsWithCompileTimeTool = false;
    if (generatingToolVersion != null) {
        runtimeConflictsWithGeneratingTool = !runtimeVersion.equals(generatingToolVersion) && !getMajorMinorVersion(runtimeVersion).equals(getMajorMinorVersion(generatingToolVersion));
    }
    runtimeConflictsWithCompileTimeTool = !runtimeVersion.equals(compileTimeVersion) && !getMajorMinorVersion(runtimeVersion).equals(getMajorMinorVersion(compileTimeVersion));
    if (runtimeConflictsWithGeneratingTool) {
        System.err.printf(""ANTLR Tool version %s used for code generation does not match the current runtime version %s%n"", generatingToolVersion, runtimeVersion);
    }
    if (runtimeConflictsWithCompileTimeTool) {
        System.err.printf(""ANTLR Runtime version %s used for parser compilation does not match the current runtime version %s%n"", compileTimeVersion, runtimeVersion);
    }
}","/**
 * This method provides the ability to detect mismatches between the version
 * of ANTLR 4 used to generate a parser, the version of the ANTLR runtime a
 * parser was compiled against, and the version of the ANTLR runtime which
 * is currently executing.
 *
 * <p>
 * The version check is designed to detect the following two specific
 * scenarios.</p>
 *
 * <ul>
 * <li>The ANTLR Tool version used for code generation does not match the
 * currently executing runtime version.</li>
 * <li>The ANTLR Runtime version referenced at the time a parser was
 * compiled does not match the currently executing runtime version.</li>
 * </ul>
 *
 * <p>
 * Starting with ANTLR 4.3, the code generator emits a call to this method
 * using two constants in each generated lexer and parser: a hard-coded
 * constant indicating the version of the tool used to generate the parser
 * and a reference to the compile-time constant {@link #VERSION}. At
 * runtime, this method is called during the initialization of the generated
 * parser to detect mismatched versions, and notify the registered listeners
 * prior to creating instances of the parser.</p>
 *
 * <p>
 * This method does not perform any detection or filtering of semantic
 * changes between tool and runtime versions. It simply checks for a
 * version match and emits an error to stderr if a difference
 * is detected.</p>
 *
 * <p>
 * Note that some breaking changes between releases could result in other
 * types of runtime exceptions, such as a {@link LinkageError}, prior to
 * calling this method. In these cases, the underlying version mismatch will
 * not be reported here. This method is primarily intended to
 * notify users of potential semantic changes between releases that do not
 * result in binary compatibility problems which would be detected by the
 * class loader. As with semantic changes, changes that break binary
 * compatibility between releases are mentioned in the release notes
 * accompanying the affected release.</p>
 *
 * <p>
 * <strong>Additional note for target developers:</strong> The version check
 * implemented by this class is designed to address specific compatibility
 * concerns that may arise during the execution of Java applications. Other
 * targets should consider the implementation of this method in the context
 * of that target's known execution environment, which may or may not
 * resemble the design provided for the Java target.</p>
 *
 * @param generatingToolVersion The version of the tool used to generate a parser.
 * This value may be null when called from user code that was not generated
 * by, and does not reference, the ANTLR 4 Tool itself.
 * @param compileTimeVersion The version of the runtime the parser was
 * compiled against. This should always be passed using a direct reference
 * to {@link #VERSION}.
 */
", ,"/** * This method provides the ability to detect mismatches between the version * of ANTLR 4 used to generate a parser, the version of the ANTLR runtime a * parser was compiled against, and the version of the ANTLR runtime which * is currently executing. * * <p> * The version check is designed to detect the following two specific * scenarios.</p> * * <ul> * <li>The ANTLR Tool version used for code generation does not match the * currently executing runtime version.</li> * <li>The ANTLR Runtime version referenced at the time a parser was * compiled does not match the currently executing runtime version.</li> * </ul> * * <p> * Starting with ANTLR 4.3, the code generator emits a call to this method * using two constants in each generated lexer and parser: a hard-coded * constant indicating the version of the tool used to generate the parser * and a reference to the compile-time constant {@link #VERSION}. At * runtime, this method is called during the initialization of the generated * parser to detect mismatched versions, and notify the registered listeners * prior to creating instances of the parser.</p> * * <p> * This method does not perform any detection or filtering of semantic * changes between tool and runtime versions. It simply checks for a * version match and emits an error to stderr if a difference * is detected.</p> * * <p> * Note that some breaking changes between releases could result in other * types of runtime exceptions, such as a {@link LinkageError}, prior to * calling this method. In these cases, the underlying version mismatch will * not be reported here. This method is primarily intended to * notify users of potential semantic changes between releases that do not * result in binary compatibility problems which would be detected by the * class loader. As with semantic changes, changes that break binary * compatibility between releases are mentioned in the release notes * accompanying the affected release.</p> * * <p> * <strong>Additional note for target developers:</strong> The version check * implemented by this class is designed to address specific compatibility * concerns that may arise during the execution of Java applications. Other * targets should consider the implementation of this method in the context * of that target's known execution environment, which may or may not * resemble the design provided for the Java target.</p> * * @param generatingToolVersion The version of the tool used to generate a parser. * This value may be null when called from user code that was not generated * by, and does not reference, the ANTLR 4 Tool itself. * @param compileTimeVersion The version of the runtime the parser was * compiled against. This should always be passed using a direct reference * to {@link #VERSION}. */",144,167,[0],0,[0],0,[0],0,0,0,1,"checkVersion(String, String)",org.antlr.v4.runtime.RuntimeMetaData,"checkVersion/2[java.lang.String,java.lang.String]",False,144,1,1,0,1,4,3,15,0,3,2,3,1,1,0,1,0,0,2,0,5,0,1,0,0,0,176,9,0,True
286,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\RuntimeMetaData.java,org.antlr.v4.runtime.RuntimeMetaData,String getMajorMinorVersion(String),"/**
 * Gets the major and minor version numbers from a version string. For
 * details about the syntax of the input {@code version}.
 * E.g., from x.y.z return x.y.
 *
 * @param version The complete version string.
 * @return A string of the form <em>major</em>.<em>minor</em> containing
 * only the major and minor components of the version string.
 */
public static String getMajorMinorVersion(String version) {
    int firstDot = version.indexOf('.');
    int secondDot = firstDot >= 0 ? version.indexOf('.', firstDot + 1) : -1;
    int firstDash = version.indexOf('-');
    int referenceLength = version.length();
    if (secondDot >= 0) {
        referenceLength = Math.min(referenceLength, secondDot);
    }
    if (firstDash >= 0) {
        referenceLength = Math.min(referenceLength, firstDash);
    }
    return version.substring(0, referenceLength);
}","/**
 * Gets the major and minor version numbers from a version string. For
 * details about the syntax of the input {@code version}.
 * E.g., from x.y.z return x.y.
 *
 * @param version The complete version string.
 * @return A string of the form <em>major</em>.<em>minor</em> containing
 * only the major and minor components of the version string.
 */
", ,"/** * Gets the major and minor version numbers from a version string. For * details about the syntax of the input {@code version}. * E.g., from x.y.z return x.y. * * @param version The complete version string. * @return A string of the form <em>major</em>.<em>minor</em> containing * only the major and minor components of the version string. */",178,192,[0],0,[0],0,[0],0,0,0,0,getMajorMinorVersion(String),org.antlr.v4.runtime.RuntimeMetaData,getMajorMinorVersion/1[java.lang.String],False,178,0,2,2,0,4,5,13,1,4,1,5,0,0,0,0,0,0,0,6,6,1,1,0,0,0,33,9,0,True
287,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\Token.java,org.antlr.v4.runtime.Token,String getText(),"/**
 * Get the text of the token.
 */
String getText();","/**
 * Get the text of the token.
 */
", ,/** * Get the text of the token. */,52,52,[0],0,[0],0,[0],0,0,0,0,getText(),org.antlr.v4.runtime.Token,getText/0,False,49,0,16,16,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,6,0,0,True
288,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\Token.java,org.antlr.v4.runtime.Token,int getType(),"/**
 * Get the token type of the token
 */
int getType();","/**
 * Get the token type of the token
 */
", ,/** * Get the token type of the token */,55,55,[0],0,[0],0,[0],0,0,0,0,getType(),org.antlr.v4.runtime.Token,getType/0,False,54,0,33,33,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,7,0,0,True
289,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\Token.java,org.antlr.v4.runtime.Token,int getLine(),"/**
 * The line number on which the 1st character of this token was matched,
 *  line=1..n
 */
int getLine();","/**
 * The line number on which the 1st character of this token was matched,
 *  line=1..n
 */
", ,"/** * The line number on which the 1st character of this token was matched, *  line=1..n */",60,60,[0],0,[0],0,[0],0,0,0,0,getLine(),org.antlr.v4.runtime.Token,getLine/0,False,57,0,8,8,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,13,0,0,True
290,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\Token.java,org.antlr.v4.runtime.Token,int getCharPositionInLine(),"/**
 * The index of the first character of this token relative to the
 *  beginning of the line at which it occurs, 0..n-1
 */
int getCharPositionInLine();","/**
 * The index of the first character of this token relative to the
 *  beginning of the line at which it occurs, 0..n-1
 */
", ,"/** * The index of the first character of this token relative to the *  beginning of the line at which it occurs, 0..n-1 */",65,65,[0],0,[0],0,[0],0,0,0,0,getCharPositionInLine(),org.antlr.v4.runtime.Token,getCharPositionInLine/0,False,62,0,8,8,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,19,0,0,True
291,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\Token.java,org.antlr.v4.runtime.Token,int getChannel(),"/**
 * Return the channel this token. Each token can arrive at the parser
 *  on a different channel, but the parser only ""tunes"" to a single channel.
 *  The parser ignores everything not on DEFAULT_CHANNEL.
 */
int getChannel();","/**
 * Return the channel this token. Each token can arrive at the parser
 *  on a different channel, but the parser only ""tunes"" to a single channel.
 *  The parser ignores everything not on DEFAULT_CHANNEL.
 */
", ,"/** * Return the channel this token. Each token can arrive at the parser *  on a different channel, but the parser only ""tunes"" to a single channel. *  The parser ignores everything not on DEFAULT_CHANNEL. */",71,71,[0],0,[0],0,[0],0,0,0,0,getChannel(),org.antlr.v4.runtime.Token,getChannel/0,False,67,0,5,5,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,22,0,0,True
292,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\Token.java,org.antlr.v4.runtime.Token,int getTokenIndex(),"/**
 * An index from 0..n-1 of the token object in the input stream.
 *  This must be valid in order to print token streams and
 *  use TokenRewriteStream.
 *
 *  Return -1 to indicate that this token was conjured up since
 *  it doesn't have a valid index.
 */
int getTokenIndex();","/**
 * An index from 0..n-1 of the token object in the input stream.
 *  This must be valid in order to print token streams and
 *  use TokenRewriteStream.
 *
 *  Return -1 to indicate that this token was conjured up since
 *  it doesn't have a valid index.
 */
", ,/** * An index from 0..n-1 of the token object in the input stream. *  This must be valid in order to print token streams and *  use TokenRewriteStream. * *  Return -1 to indicate that this token was conjured up since *  it doesn't have a valid index. */,80,80,[0],0,[0],0,[0],0,0,0,0,getTokenIndex(),org.antlr.v4.runtime.Token,getTokenIndex/0,False,73,0,12,12,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,32,0,0,True
293,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\Token.java,org.antlr.v4.runtime.Token,int getStartIndex(),"/**
 * The starting character index of the token
 *  This method is optional; return -1 if not implemented.
 */
int getStartIndex();","/**
 * The starting character index of the token
 *  This method is optional; return -1 if not implemented.
 */
", ,/** * The starting character index of the token *  This method is optional; return -1 if not implemented. */,85,85,[0],0,[0],0,[0],0,0,0,0,getStartIndex(),org.antlr.v4.runtime.Token,getStartIndex/0,False,82,0,3,3,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,15,0,0,True
294,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\Token.java,org.antlr.v4.runtime.Token,int getStopIndex(),"/**
 * The last character index of the token.
 *  This method is optional; return -1 if not implemented.
 */
int getStopIndex();","/**
 * The last character index of the token.
 *  This method is optional; return -1 if not implemented.
 */
", ,/** * The last character index of the token. *  This method is optional; return -1 if not implemented. */,90,90,[0],0,[0],0,[0],0,0,0,0,getStopIndex(),org.antlr.v4.runtime.Token,getStopIndex/0,False,87,0,3,3,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,14,0,0,True
295,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\Token.java,org.antlr.v4.runtime.Token,TokenSource getTokenSource(),"/**
 * Gets the {@link TokenSource} which created this token.
 */
TokenSource getTokenSource();","/**
 * Gets the {@link TokenSource} which created this token.
 */
", ,/** * Gets the {@link TokenSource} which created this token. */,94,94,[0],0,[0],0,[0],0,0,0,0,getTokenSource(),org.antlr.v4.runtime.Token,getTokenSource/0,False,92,1,3,3,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,7,0,0,True
296,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\Token.java,org.antlr.v4.runtime.Token,CharStream getInputStream(),"/**
 * Gets the {@link CharStream} from which this token was derived.
 */
CharStream getInputStream();","/**
 * Gets the {@link CharStream} from which this token was derived.
 */
", ,/** * Gets the {@link CharStream} from which this token was derived. */,99,99,[0],0,[0],0,[0],0,0,0,0,getInputStream(),org.antlr.v4.runtime.Token,getInputStream/0,False,96,1,2,2,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,10,0,0,True
297,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\TokenFactory.java,org.antlr.v4.runtime.TokenFactory,"Symbol create(Pair<TokenSource, CharStream>, int, String, int, int, int, int, int)","/**
 * This is the method used to create tokens in the lexer and in the
 *  error handling strategy. If text!=null, than the start and stop positions
 *  are wiped to -1 in the text override is set in the CommonToken.
 */
Symbol create(Pair<TokenSource, CharStream> source, int type, String text, int channel, int start, int stop, int line, int charPositionInLine);","/**
 * This is the method used to create tokens in the lexer and in the
 *  error handling strategy. If text!=null, than the start and stop positions
 *  are wiped to -1 in the text override is set in the CommonToken.
 */
", ,"/** * This is the method used to create tokens in the lexer and in the *  error handling strategy. If text!=null, than the start and stop positions *  are wiped to -1 in the text override is set in the CommonToken. */",20,22,[0],0,[0],0,[0],0,0,0,0,"create(Pair<TokenSource, CharStream>, int, String, int, int, int, int, int)",org.antlr.v4.runtime.TokenFactory,"create/8[org.antlr.v4.runtime.misc.Pair<org.antlr.v4.runtime.TokenSource,org.antlr.v4.runtime.CharStream>,int,java.lang.String,int,int,int,int,int]",False,16,4,0,0,0,1,0,1,0,0,8,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,28,0,0,True
298,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\TokenFactory.java,org.antlr.v4.runtime.TokenFactory,"Symbol create(int, String)","/**
 * Generically useful
 */
Symbol create(int type, String text);","/**
 * Generically useful
 */
", ,/** * Generically useful */,25,25,[0],0,[0],0,[0],0,0,0,0,"create(int, String)",org.antlr.v4.runtime.TokenFactory,"create/2[int,java.lang.String]",False,24,1,0,0,0,1,0,1,0,0,2,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,5,0,0,True
299,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\TokenSource.java,org.antlr.v4.runtime.TokenSource,Token nextToken(),"/**
 * Return a {@link Token} object from your input stream (usually a
 * {@link CharStream}). Do not fail/return upon lexing error; keep chewing
 * on the characters until you get a good one; errors are not passed through
 * to the parser.
 */
public Token nextToken();","/**
 * Return a {@link Token} object from your input stream (usually a
 * {@link CharStream}). Do not fail/return upon lexing error; keep chewing
 * on the characters until you get a good one; errors are not passed through
 * to the parser.
 */
", ,/** * Return a {@link Token} object from your input stream (usually a * {@link CharStream}). Do not fail/return upon lexing error; keep chewing * on the characters until you get a good one; errors are not passed through * to the parser. */,30,30,[0],0,[0],0,[0],0,0,0,0,nextToken(),org.antlr.v4.runtime.TokenSource,nextToken/0,False,24,1,2,2,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,33,1,0,True
300,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\TokenSource.java,org.antlr.v4.runtime.TokenSource,int getLine(),"/**
 * Get the line number for the current position in the input stream. The
 * first line in the input is line 1.
 *
 * @return The line number for the current position in the input stream, or
 * 0 if the current token source does not track line numbers.
 */
public int getLine();","/**
 * Get the line number for the current position in the input stream. The
 * first line in the input is line 1.
 *
 * @return The line number for the current position in the input stream, or
 * 0 if the current token source does not track line numbers.
 */
", ,"/** * Get the line number for the current position in the input stream. The * first line in the input is line 1. * * @return The line number for the current position in the input stream, or * 0 if the current token source does not track line numbers. */",39,39,[0],0,[0],0,[0],0,0,0,0,getLine(),org.antlr.v4.runtime.TokenSource,getLine/0,False,32,0,1,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,19,1,0,True
301,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\TokenSource.java,org.antlr.v4.runtime.TokenSource,int getCharPositionInLine(),"/**
 * Get the index into the current line for the current position in the input
 * stream. The first character on a line has position 0.
 *
 * @return The line number for the current position in the input stream, or
 * -1 if the current token source does not track character positions.
 */
public int getCharPositionInLine();","/**
 * Get the index into the current line for the current position in the input
 * stream. The first character on a line has position 0.
 *
 * @return The line number for the current position in the input stream, or
 * -1 if the current token source does not track character positions.
 */
", ,"/** * Get the index into the current line for the current position in the input * stream. The first character on a line has position 0. * * @return The line number for the current position in the input stream, or * -1 if the current token source does not track character positions. */",48,48,[0],0,[0],0,[0],0,0,0,0,getCharPositionInLine(),org.antlr.v4.runtime.TokenSource,getCharPositionInLine/0,False,41,0,1,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,27,1,0,True
302,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\TokenSource.java,org.antlr.v4.runtime.TokenSource,CharStream getInputStream(),"/**
 * Get the {@link CharStream} from which this token source is currently
 * providing tokens.
 *
 * @return The {@link CharStream} associated with the current position in
 * the input, or {@code null} if no input stream is available for the token
 * source.
 */
public CharStream getInputStream();","/**
 * Get the {@link CharStream} from which this token source is currently
 * providing tokens.
 *
 * @return The {@link CharStream} associated with the current position in
 * the input, or {@code null} if no input stream is available for the token
 * source.
 */
", ,"/** * Get the {@link CharStream} from which this token source is currently * providing tokens. * * @return The {@link CharStream} associated with the current position in * the input, or {@code null} if no input stream is available for the token * source. */",58,58,[0],0,[0],0,[0],0,0,0,0,getInputStream(),org.antlr.v4.runtime.TokenSource,getInputStream/0,False,50,1,2,2,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,24,1,0,True
303,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\TokenSource.java,org.antlr.v4.runtime.TokenSource,String getSourceName(),"/**
 * Gets the name of the underlying input source. This method returns a
 * non-null, non-empty string. If such a name is not known, this method
 * returns {@link IntStream#UNKNOWN_SOURCE_NAME}.
 */
public String getSourceName();","/**
 * Gets the name of the underlying input source. This method returns a
 * non-null, non-empty string. If such a name is not known, this method
 * returns {@link IntStream#UNKNOWN_SOURCE_NAME}.
 */
", ,"/** * Gets the name of the underlying input source. This method returns a * non-null, non-empty string. If such a name is not known, this method * returns {@link IntStream#UNKNOWN_SOURCE_NAME}. */",65,65,[0],0,[0],0,[0],0,0,0,0,getSourceName(),org.antlr.v4.runtime.TokenSource,getSourceName/0,False,60,0,2,2,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,19,1,0,True
304,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\TokenSource.java,org.antlr.v4.runtime.TokenSource,void setTokenFactory(TokenFactory<?>),"/**
 * Set the {@link TokenFactory} this token source should use for creating
 * {@link Token} objects from the input.
 *
 * @param factory The {@link TokenFactory} to use for creating tokens.
 */
public void setTokenFactory(TokenFactory<?> factory);","/**
 * Set the {@link TokenFactory} this token source should use for creating
 * {@link Token} objects from the input.
 *
 * @param factory The {@link TokenFactory} to use for creating tokens.
 */
", ,/** * Set the {@link TokenFactory} this token source should use for creating * {@link Token} objects from the input. * * @param factory The {@link TokenFactory} to use for creating tokens. */,73,73,[0],0,[0],0,[0],0,0,0,0,setTokenFactory(TokenFactory<?>),org.antlr.v4.runtime.TokenSource,setTokenFactory/1[org.antlr.v4.runtime.TokenFactory<?>],False,67,1,1,1,0,1,0,1,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,15,1,0,True
305,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\TokenSource.java,org.antlr.v4.runtime.TokenSource,TokenFactory<?> getTokenFactory(),"/**
 * Gets the {@link TokenFactory} this token source is currently using for
 * creating {@link Token} objects from the input.
 *
 * @return The {@link TokenFactory} currently used by this token source.
 */
public TokenFactory<?> getTokenFactory();","/**
 * Gets the {@link TokenFactory} this token source is currently using for
 * creating {@link Token} objects from the input.
 *
 * @return The {@link TokenFactory} currently used by this token source.
 */
", ,/** * Gets the {@link TokenFactory} this token source is currently using for * creating {@link Token} objects from the input. * * @return The {@link TokenFactory} currently used by this token source. */,81,81,[0],0,[0],0,[0],0,0,0,0,getTokenFactory(),org.antlr.v4.runtime.TokenSource,getTokenFactory/0,False,75,1,1,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,16,1,0,True
306,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\TokenStream.java,org.antlr.v4.runtime.TokenStream,Token LT(int),"/**
 * Get the {@link Token} instance associated with the value returned by
 * {@link #LA LA(k)}. This method has the same pre- and post-conditions as
 * {@link IntStream#LA}. In addition, when the preconditions of this method
 * are met, the return value is non-null and the value of
 * {@code LT(k).getType()==LA(k)}.
 *
 * @see IntStream#LA
 */
public Token LT(int k);","/**
 * Get the {@link Token} instance associated with the value returned by
 * {@link #LA LA(k)}. This method has the same pre- and post-conditions as
 * {@link IntStream#LA}. In addition, when the preconditions of this method
 * are met, the return value is non-null and the value of
 * {@code LT(k).getType()==LA(k)}.
 *
 * @see IntStream#LA
 */
", ,"/** * Get the {@link Token} instance associated with the value returned by * {@link #LA LA(k)}. This method has the same pre- and post-conditions as * {@link IntStream#LA}. In addition, when the preconditions of this method * are met, the return value is non-null and the value of * {@code LT(k).getType()==LA(k)}. * * @see IntStream#LA */",24,24,[0],0,[0],0,[0],0,0,0,0,LT(int),org.antlr.v4.runtime.TokenStream,LT/1[int],False,15,1,12,12,0,1,0,1,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,30,1,0,True
307,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\TokenStream.java,org.antlr.v4.runtime.TokenStream,Token get(int),"/**
 * Gets the {@link Token} at the specified {@code index} in the stream. When
 * the preconditions of this method are met, the return value is non-null.
 *
 * <p>The preconditions for this method are the same as the preconditions of
 * {@link IntStream#seek}. If the behavior of {@code seek(index)} is
 * unspecified for the current state and given {@code index}, then the
 * behavior of this method is also unspecified.</p>
 *
 * <p>The symbol referred to by {@code index} differs from {@code seek()} only
 * in the case of filtering streams where {@code index} lies before the end
 * of the stream. Unlike {@code seek()}, this method does not adjust
 * {@code index} to point to a non-ignored symbol.</p>
 *
 * @throws IllegalArgumentException if {code index} is less than 0
 * @throws UnsupportedOperationException if the stream does not support
 * retrieving the token at the specified index
 */
public Token get(int index);","/**
 * Gets the {@link Token} at the specified {@code index} in the stream. When
 * the preconditions of this method are met, the return value is non-null.
 *
 * <p>The preconditions for this method are the same as the preconditions of
 * {@link IntStream#seek}. If the behavior of {@code seek(index)} is
 * unspecified for the current state and given {@code index}, then the
 * behavior of this method is also unspecified.</p>
 *
 * <p>The symbol referred to by {@code index} differs from {@code seek()} only
 * in the case of filtering streams where {@code index} lies before the end
 * of the stream. Unlike {@code seek()}, this method does not adjust
 * {@code index} to point to a non-ignored symbol.</p>
 *
 * @throws IllegalArgumentException if {code index} is less than 0
 * @throws UnsupportedOperationException if the stream does not support
 * retrieving the token at the specified index
 */
", ,"/** * Gets the {@link Token} at the specified {@code index} in the stream. When * the preconditions of this method are met, the return value is non-null. * * <p>The preconditions for this method are the same as the preconditions of * {@link IntStream#seek}. If the behavior of {@code seek(index)} is * unspecified for the current state and given {@code index}, then the * behavior of this method is also unspecified.</p> * * <p>The symbol referred to by {@code index} differs from {@code seek()} only * in the case of filtering streams where {@code index} lies before the end * of the stream. Unlike {@code seek()}, this method does not adjust * {@code index} to point to a non-ignored symbol.</p> * * @throws IllegalArgumentException if {code index} is less than 0 * @throws UnsupportedOperationException if the stream does not support * retrieving the token at the specified index */",44,44,[0],0,[0],0,[0],0,0,0,0,get(int),org.antlr.v4.runtime.TokenStream,get/1[int],False,26,1,5,5,0,1,0,1,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,61,1,0,True
308,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\TokenStream.java,org.antlr.v4.runtime.TokenStream,TokenSource getTokenSource(),"/**
 * Gets the underlying {@link TokenSource} which provides tokens for this
 * stream.
 */
public TokenSource getTokenSource();","/**
 * Gets the underlying {@link TokenSource} which provides tokens for this
 * stream.
 */
", ,/** * Gets the underlying {@link TokenSource} which provides tokens for this * stream. */,50,50,[0],0,[0],0,[0],0,0,0,0,getTokenSource(),org.antlr.v4.runtime.TokenStream,getTokenSource/0,False,46,1,3,3,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,9,1,0,True
309,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\TokenStream.java,org.antlr.v4.runtime.TokenStream,String getText(Interval),"/**
 * Return the text of all tokens within the specified {@code interval}. This
 * method behaves like the following code (including potential exceptions
 * for violating preconditions of {@link #get}, but may be optimized by the
 * specific implementation.
 *
 * <pre>
 * TokenStream stream = ...;
 * String text = """";
 * for (int i = interval.a; i &lt;= interval.b; i++) {
 *   text += stream.get(i).getText();
 * }
 * </pre>
 *
 * @param interval The interval of tokens within this stream to get text
 * for.
 * @return The text of all tokens within the specified interval in this
 * stream.
 *
 * @throws NullPointerException if {@code interval} is {@code null}
 */
public String getText(Interval interval);","/**
 * Return the text of all tokens within the specified {@code interval}. This
 * method behaves like the following code (including potential exceptions
 * for violating preconditions of {@link #get}, but may be optimized by the
 * specific implementation.
 *
 * <pre>
 * TokenStream stream = ...;
 * String text = """";
 * for (int i = interval.a; i &lt;= interval.b; i++) {
 *   text += stream.get(i).getText();
 * }
 * </pre>
 *
 * @param interval The interval of tokens within this stream to get text
 * for.
 * @return The text of all tokens within the specified interval in this
 * stream.
 *
 * @throws NullPointerException if {@code interval} is {@code null}
 */
", ,"/** * Return the text of all tokens within the specified {@code interval}. This * method behaves like the following code (including potential exceptions * for violating preconditions of {@link #get}, but may be optimized by the * specific implementation. * * <pre> * TokenStream stream = ...; * String text = """"; * for (int i = interval.a; i &lt;= interval.b; i++) { *   text += stream.get(i).getText(); * } * </pre> * * @param interval The interval of tokens within this stream to get text * for. * @return The text of all tokens within the specified interval in this * stream. * * @throws NullPointerException if {@code interval} is {@code null} */",73,73,[0],0,[0],0,[0],0,0,0,0,getText(Interval),org.antlr.v4.runtime.TokenStream,getText/1[org.antlr.v4.runtime.misc.Interval],False,52,1,7,7,0,1,0,1,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,43,1,0,True
310,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\TokenStream.java,org.antlr.v4.runtime.TokenStream,String getText(),"/**
 * Return the text of all tokens in the stream. This method behaves like the
 * following code, including potential exceptions from the calls to
 * {@link IntStream#size} and {@link #getText(Interval)}, but may be
 * optimized by the specific implementation.
 *
 * <pre>
 * TokenStream stream = ...;
 * String text = stream.getText(new Interval(0, stream.size()));
 * </pre>
 *
 * @return The text of all tokens in the stream.
 */
public String getText();","/**
 * Return the text of all tokens in the stream. This method behaves like the
 * following code, including potential exceptions from the calls to
 * {@link IntStream#size} and {@link #getText(Interval)}, but may be
 * optimized by the specific implementation.
 *
 * <pre>
 * TokenStream stream = ...;
 * String text = stream.getText(new Interval(0, stream.size()));
 * </pre>
 *
 * @return The text of all tokens in the stream.
 */
", ,"/** * Return the text of all tokens in the stream. This method behaves like the * following code, including potential exceptions from the calls to * {@link IntStream#size} and {@link #getText(Interval)}, but may be * optimized by the specific implementation. * * <pre> * TokenStream stream = ...; * String text = stream.getText(new Interval(0, stream.size())); * </pre> * * @return The text of all tokens in the stream. */",88,88,[0],0,[0],0,[0],0,0,0,0,getText(),org.antlr.v4.runtime.TokenStream,getText/0,False,75,0,2,2,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,33,1,0,True
311,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\TokenStream.java,org.antlr.v4.runtime.TokenStream,String getText(RuleContext),"/**
 * Return the text of all tokens in the source interval of the specified
 * context. This method behaves like the following code, including potential
 * exceptions from the call to {@link #getText(Interval)}, but may be
 * optimized by the specific implementation.
 *
 * <p>If {@code ctx.getSourceInterval()} does not return a valid interval of
 * tokens provided by this stream, the behavior is unspecified.</p>
 *
 * <pre>
 * TokenStream stream = ...;
 * String text = stream.getText(ctx.getSourceInterval());
 * </pre>
 *
 * @param ctx The context providing the source interval of tokens to get
 * text for.
 * @return The text of all tokens within the source interval of {@code ctx}.
 */
public String getText(RuleContext ctx);","/**
 * Return the text of all tokens in the source interval of the specified
 * context. This method behaves like the following code, including potential
 * exceptions from the call to {@link #getText(Interval)}, but may be
 * optimized by the specific implementation.
 *
 * <p>If {@code ctx.getSourceInterval()} does not return a valid interval of
 * tokens provided by this stream, the behavior is unspecified.</p>
 *
 * <pre>
 * TokenStream stream = ...;
 * String text = stream.getText(ctx.getSourceInterval());
 * </pre>
 *
 * @param ctx The context providing the source interval of tokens to get
 * text for.
 * @return The text of all tokens within the source interval of {@code ctx}.
 */
", ,"/** * Return the text of all tokens in the source interval of the specified * context. This method behaves like the following code, including potential * exceptions from the call to {@link #getText(Interval)}, but may be * optimized by the specific implementation. * * <p>If {@code ctx.getSourceInterval()} does not return a valid interval of * tokens provided by this stream, the behavior is unspecified.</p> * * <pre> * TokenStream stream = ...; * String text = stream.getText(ctx.getSourceInterval()); * </pre> * * @param ctx The context providing the source interval of tokens to get * text for. * @return The text of all tokens within the source interval of {@code ctx}. */",108,108,[0],0,[0],0,[0],0,0,0,0,getText(RuleContext),org.antlr.v4.runtime.TokenStream,getText/1[org.antlr.v4.runtime.RuleContext],False,90,1,0,0,0,1,0,1,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,52,1,0,True
312,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\TokenStream.java,org.antlr.v4.runtime.TokenStream,"String getText(Token, Token)","/**
 * Return the text of all tokens in this stream between {@code start} and
 * {@code stop} (inclusive).
 *
 * <p>If the specified {@code start} or {@code stop} token was not provided by
 * this stream, or if the {@code stop} occurred before the {@code start}
 * token, the behavior is unspecified.</p>
 *
 * <p>For streams which ensure that the {@link Token#getTokenIndex} method is
 * accurate for all of its provided tokens, this method behaves like the
 * following code. Other streams may implement this method in other ways
 * provided the behavior is consistent with this at a high level.</p>
 *
 * <pre>
 * TokenStream stream = ...;
 * String text = """";
 * for (int i = start.getTokenIndex(); i &lt;= stop.getTokenIndex(); i++) {
 *   text += stream.get(i).getText();
 * }
 * </pre>
 *
 * @param start The first token in the interval to get text for.
 * @param stop The last token in the interval to get text for (inclusive).
 * @return The text of all tokens lying between the specified {@code start}
 * and {@code stop} tokens.
 *
 * @throws UnsupportedOperationException if this stream does not support
 * this method for the specified tokens
 */
public String getText(Token start, Token stop);","/**
 * Return the text of all tokens in this stream between {@code start} and
 * {@code stop} (inclusive).
 *
 * <p>If the specified {@code start} or {@code stop} token was not provided by
 * this stream, or if the {@code stop} occurred before the {@code start}
 * token, the behavior is unspecified.</p>
 *
 * <p>For streams which ensure that the {@link Token#getTokenIndex} method is
 * accurate for all of its provided tokens, this method behaves like the
 * following code. Other streams may implement this method in other ways
 * provided the behavior is consistent with this at a high level.</p>
 *
 * <pre>
 * TokenStream stream = ...;
 * String text = """";
 * for (int i = start.getTokenIndex(); i &lt;= stop.getTokenIndex(); i++) {
 *   text += stream.get(i).getText();
 * }
 * </pre>
 *
 * @param start The first token in the interval to get text for.
 * @param stop The last token in the interval to get text for (inclusive).
 * @return The text of all tokens lying between the specified {@code start}
 * and {@code stop} tokens.
 *
 * @throws UnsupportedOperationException if this stream does not support
 * this method for the specified tokens
 */
", ,"/** * Return the text of all tokens in this stream between {@code start} and * {@code stop} (inclusive). * * <p>If the specified {@code start} or {@code stop} token was not provided by * this stream, or if the {@code stop} occurred before the {@code start} * token, the behavior is unspecified.</p> * * <p>For streams which ensure that the {@link Token#getTokenIndex} method is * accurate for all of its provided tokens, this method behaves like the * following code. Other streams may implement this method in other ways * provided the behavior is consistent with this at a high level.</p> * * <pre> * TokenStream stream = ...; * String text = """"; * for (int i = start.getTokenIndex(); i &lt;= stop.getTokenIndex(); i++) { *   text += stream.get(i).getText(); * } * </pre> * * @param start The first token in the interval to get text for. * @param stop The last token in the interval to get text for (inclusive). * @return The text of all tokens lying between the specified {@code start} * and {@code stop} tokens. * * @throws UnsupportedOperationException if this stream does not support * this method for the specified tokens */",139,139,[0],0,[0],0,[0],0,0,0,0,"getText(Token, Token)",org.antlr.v4.runtime.TokenStream,"getText/2[org.antlr.v4.runtime.Token,org.antlr.v4.runtime.Token]",False,110,1,1,1,0,1,0,1,0,0,2,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,65,1,0,True
313,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\TokenStreamRewriter.java,org.antlr.v4.runtime.TokenStreamRewriter,"void rollback(String, int)","/**
 * Rollback the instruction stream for a program so that
 *  the indicated instruction (via instructionIndex) is no
 *  longer in the stream. UNTESTED!
 */
public void rollback(String programName, int instructionIndex) {
    List<RewriteOperation> is = programs.get(programName);
    if (is != null) {
        programs.put(programName, is.subList(MIN_TOKEN_INDEX, instructionIndex));
    }
}","/**
 * Rollback the instruction stream for a program so that
 *  the indicated instruction (via instructionIndex) is no
 *  longer in the stream. UNTESTED!
 */
", ,/** * Rollback the instruction stream for a program so that *  the indicated instruction (via instructionIndex) is no *  longer in the stream. UNTESTED! */,214,219,[0],0,[0],0,[0],0,0,0,0,"rollback(String, int)",org.antlr.v4.runtime.TokenStreamRewriter,"rollback/2[java.lang.String,int]",False,214,1,2,2,0,2,3,6,0,1,2,3,0,0,0,1,0,0,0,0,1,0,1,0,0,0,24,1,0,True
314,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\TokenStreamRewriter.java,org.antlr.v4.runtime.TokenStreamRewriter,void deleteProgram(String),"/**
 * Reset the program so that no instructions exist
 */
public void deleteProgram(String programName) {
    rollback(programName, MIN_TOKEN_INDEX);
}","/**
 * Reset the program so that no instructions exist
 */
", ,/** * Reset the program so that no instructions exist */,226,228,[0],0,[0],0,[0],0,0,0,0,deleteProgram(String),org.antlr.v4.runtime.TokenStreamRewriter,deleteProgram/1[java.lang.String],False,226,1,2,1,1,1,1,3,0,0,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,12,1,0,True
315,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\TokenStreamRewriter.java,org.antlr.v4.runtime.TokenStreamRewriter,"void insertAfter(String, int, Object)","public void insertAfter(String programName, int index, Object text) {
    // to insert after, just insert before next index (even if past end)
    RewriteOperation op = new InsertAfterOp(index, text);
    List<RewriteOperation> rewrites = getProgram(programName);
    op.instructionIndex = rewrites.size();
    rewrites.add(op);
}", ,"// to insert after, just insert before next index (even if past end)
","// to insert after, just insert before next index (even if past end)",242,248,[0],0,[0],0,[0],0,0,0,0,"insertAfter(String, int, Object)",org.antlr.v4.runtime.TokenStreamRewriter,"insertAfter/3[java.lang.String,int,java.lang.Object]",False,242,3,4,2,2,1,3,6,0,2,3,3,1,2,0,0,0,0,0,0,3,0,0,0,0,0,13,1,0,False
316,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\TokenStreamRewriter.java,org.antlr.v4.runtime.TokenStreamRewriter,String getText(),"/**
 * Return the text from the original tokens altered per the
 *  instructions given to this rewriter.
 */
public String getText() {
    return getText(DEFAULT_PROGRAM_NAME, Interval.of(0, tokens.size() - 1));
}","/**
 * Return the text from the original tokens altered per the
 *  instructions given to this rewriter.
 */
", ,/** * Return the text from the original tokens altered per the *  instructions given to this rewriter. */,359,361,[0],0,[0],0,[0],0,0,0,0,getText(),org.antlr.v4.runtime.TokenStreamRewriter,getText/0,False,359,3,45,42,3,1,3,3,1,0,0,3,1,3,0,0,0,0,0,2,0,1,0,0,0,0,13,1,0,True
317,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\TokenStreamRewriter.java,org.antlr.v4.runtime.TokenStreamRewriter,String getText(String),"/**
 * Return the text from the original tokens altered per the
 *  instructions given to this rewriter in programName.
 */
public String getText(String programName) {
    return getText(programName, Interval.of(0, tokens.size() - 1));
}","/**
 * Return the text from the original tokens altered per the
 *  instructions given to this rewriter in programName.
 */
", ,/** * Return the text from the original tokens altered per the *  instructions given to this rewriter in programName. */,366,368,[0],0,[0],0,[0],0,0,0,0,getText(String),org.antlr.v4.runtime.TokenStreamRewriter,getText/1[java.lang.String],False,366,3,3,0,3,1,3,3,1,0,1,3,1,3,0,0,0,0,0,2,0,1,0,0,0,0,17,1,0,True
318,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\TokenStreamRewriter.java,org.antlr.v4.runtime.TokenStreamRewriter,String getText(Interval),"/**
 * Return the text associated with the tokens in the interval from the
 *  original token stream but with the alterations given to this rewriter.
 *  The interval refers to the indexes in the original token stream.
 *  We do not alter the token stream in any way, so the indexes
 *  and intervals are still consistent. Includes any operations done
 *  to the first and last token in the interval. So, if you did an
 *  insertBefore on the first token, you would get that insertion.
 *  The same is true if you do an insertAfter the stop token.
 */
public String getText(Interval interval) {
    return getText(DEFAULT_PROGRAM_NAME, interval);
}","/**
 * Return the text associated with the tokens in the interval from the
 *  original token stream but with the alterations given to this rewriter.
 *  The interval refers to the indexes in the original token stream.
 *  We do not alter the token stream in any way, so the indexes
 *  and intervals are still consistent. Includes any operations done
 *  to the first and last token in the interval. So, if you did an
 *  insertBefore on the first token, you would get that insertion.
 *  The same is true if you do an insertAfter the stop token.
 */
", ,"/** * Return the text associated with the tokens in the interval from the *  original token stream but with the alterations given to this rewriter. *  The interval refers to the indexes in the original token stream. *  We do not alter the token stream in any way, so the indexes *  and intervals are still consistent. Includes any operations done *  to the first and last token in the interval. So, if you did an *  insertBefore on the first token, you would get that insertion. *  The same is true if you do an insertAfter the stop token. */",379,381,[0],0,[0],0,[0],0,0,0,0,getText(Interval),org.antlr.v4.runtime.TokenStreamRewriter,getText/1[org.antlr.v4.runtime.misc.Interval],False,379,2,4,3,1,1,1,3,1,0,1,1,1,3,0,0,0,0,0,0,0,0,0,0,0,0,49,1,0,True
319,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\TokenStreamRewriter.java,org.antlr.v4.runtime.TokenStreamRewriter,"String getText(String, Interval)","public String getText(String programName, Interval interval) {
    List<RewriteOperation> rewrites = programs.get(programName);
    int start = interval.a;
    int stop = interval.b;
    // ensure start/end are in range
    if (stop > tokens.size() - 1)
        stop = tokens.size() - 1;
    if (start < 0)
        start = 0;
    if (rewrites == null || rewrites.isEmpty()) {
        // no instructions to execute
        return tokens.getText(interval);
    }
    StringBuilder buf = new StringBuilder();
    // First, optimize instruction stream
    Map<Integer, RewriteOperation> indexToOp = reduceToSingleOperationPerIndex(rewrites);
    // Walk buffer, executing instructions and emitting tokens
    int i = start;
    while (i <= stop && i < tokens.size()) {
        RewriteOperation op = indexToOp.get(i);
        // remove so any left have index size-1
        indexToOp.remove(i);
        Token t = tokens.get(i);
        if (op == null) {
            // no operation at that index, just dump token
            if (t.getType() != Token.EOF)
                buf.append(t.getText());
            // move to next token
            i++;
        } else {
            // execute operation and skip
            i = op.execute(buf);
        }
    }
    // include stuff after end if it's last index in buffer
    // So, if they did an insertAfter(lastValidIndex, ""foo""), include
    // foo if end==lastValidIndex.
    if (stop == tokens.size() - 1) {
        // Scan any remaining operations after last token
        // should be included (they will be inserts).
        for (RewriteOperation op : indexToOp.values()) {
            if (op.index >= tokens.size() - 1)
                buf.append(op.text);
        }
    }
    return buf.toString();
}", ,"// include stuff after end if it's last index in buffer
[[SEP]]// So, if they did an insertAfter(lastValidIndex, ""foo""), include
[[SEP]]// ensure start/end are in range
[[SEP]]// no instructions to execute
[[SEP]]// First, optimize instruction stream
[[SEP]]// Walk buffer, executing instructions and emitting tokens
[[SEP]]// remove so any left have index size-1
[[SEP]]// no operation at that index, just dump token
[[SEP]]// move to next token
[[SEP]]// execute operation and skip
[[SEP]]// foo if end==lastValidIndex.
[[SEP]]// Scan any remaining operations after last token
[[SEP]]// should be included (they will be inserts).
","// ensure start/end are in range[[SEP]]// no instructions to execute[[SEP]]// First, optimize instruction stream[[SEP]]// Walk buffer, executing instructions and emitting tokens[[SEP]]// remove so any left have index size-1[[SEP]]// no operation at that index, just dump token[[SEP]]// move to next token[[SEP]]// execute operation and skip[[SEP]]// include stuff after end if it's last index in buffer// So, if they did an insertAfter(lastValidIndex, ""foo""), include// foo if end==lastValidIndex.[[SEP]]// Scan any remaining operations after last token// should be included (they will be inserts).",383,427,[0],0,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]",0,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]",0,0,0,0,"getText(String, Interval)",org.antlr.v4.runtime.TokenStreamRewriter,"getText/2[java.lang.String,org.antlr.v4.runtime.misc.Interval]",False,383,6,10,3,7,12,15,31,2,8,2,15,1,2,2,4,0,0,0,6,11,4,3,0,0,0,25,1,0,False
320,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\TokenStreamRewriter.java,org.antlr.v4.runtime.TokenStreamRewriter,"Map<Integer, RewriteOperation> reduceToSingleOperationPerIndex(List<RewriteOperation>)","/**
 *  We need to combine operations and report invalid operations (like
 *   overlapping replaces that are not completed nested). Inserts to
 *   same index need to be combined etc...  Here are the cases:
 *
 *   I.i.u I.j.v								leave alone, nonoverlapping
 *   I.i.u I.i.v								combine: Iivu
 *
 *   R.i-j.u R.x-y.v	| i-j in x-y			delete first R
 *   R.i-j.u R.i-j.v							delete first R
 *   R.i-j.u R.x-y.v	| x-y in i-j			ERROR
 *   R.i-j.u R.x-y.v	| boundaries overlap	ERROR
 *
 *   Delete special case of replace (text==null):
 *   D.i-j.u D.x-y.v	| boundaries overlap	combine to max(min)..max(right)
 *
 *   I.i.u R.x-y.v | i in (x+1)-y			delete I (since insert before
 * 											we're not deleting i)
 *   I.i.u R.x-y.v | i not in (x+1)-y		leave alone, nonoverlapping
 *   R.x-y.v I.i.u | i in x-y				ERROR
 *   R.x-y.v I.x.u 							R.x-y.uv (combine, delete I)
 *   R.x-y.v I.i.u | i not in x-y			leave alone, nonoverlapping
 *
 *   I.i.u = insert u before op @ index i
 *   R.x-y.u = replace x-y indexed tokens with u
 *
 *   First we need to examine replaces. For any replace op:
 *
 *  		1. wipe out any insertions before op within that range.
 * 		2. Drop any replace op before that is contained completely within
 * 	 that range.
 * 		3. Throw exception upon boundary overlap with any previous replace.
 *
 *   Then we can deal with inserts:
 *
 *  		1. for any inserts to same index, combine even if not adjacent.
 *  		2. for any prior replace with same left boundary, combine this
 * 	 insert with replace and delete this replace.
 *  		3. throw exception if index in same range as previous replace
 *
 *   Don't actually delete; make op null in list. Easier to walk list.
 *   Later we can throw as we add to index &rarr; op map.
 *
 *   Note that I.2 R.2-2 will wipe out I.2 even though, technically, the
 *   inserted stuff would be before the replace range. But, if you
 *   add tokens in front of a method body '{' and then delete the method
 *   body, I think the stuff before the '{' you added should disappear too.
 *
 *   Return a map from token index to operation.
 */
protected Map<Integer, RewriteOperation> reduceToSingleOperationPerIndex(List<RewriteOperation> rewrites) {
    // System.out.println(""rewrites=""+rewrites);
    // WALK REPLACES
    for (int i = 0; i < rewrites.size(); i++) {
        RewriteOperation op = rewrites.get(i);
        if (op == null)
            continue;
        if (!(op instanceof ReplaceOp))
            continue;
        ReplaceOp rop = (ReplaceOp) rewrites.get(i);
        // Wipe prior inserts within range
        List<? extends InsertBeforeOp> inserts = getKindOfOps(rewrites, InsertBeforeOp.class, i);
        for (InsertBeforeOp iop : inserts) {
            if (iop.index == rop.index) {
                // E.g., insert before 2, delete 2..2; update replace
                // text to include insert before, kill insert
                rewrites.set(iop.instructionIndex, null);
                rop.text = iop.text.toString() + (rop.text != null ? rop.text.toString() : """");
            } else if (iop.index > rop.index && iop.index <= rop.lastIndex) {
                // delete insert as it's a no-op.
                rewrites.set(iop.instructionIndex, null);
            }
        }
        // Drop any prior replaces contained within
        List<? extends ReplaceOp> prevReplaces = getKindOfOps(rewrites, ReplaceOp.class, i);
        for (ReplaceOp prevRop : prevReplaces) {
            if (prevRop.index >= rop.index && prevRop.lastIndex <= rop.lastIndex) {
                // delete replace as it's a no-op.
                rewrites.set(prevRop.instructionIndex, null);
                continue;
            }
            // throw exception unless disjoint or identical
            boolean disjoint = prevRop.lastIndex < rop.index || prevRop.index > rop.lastIndex;
            // Delete special case of replace (text==null):
            // D.i-j.u D.x-y.v	| boundaries overlap	combine to max(min)..max(right)
            if (prevRop.text == null && rop.text == null && !disjoint) {
                // System.out.println(""overlapping deletes: ""+prevRop+"", ""+rop);
                // kill first delete
                rewrites.set(prevRop.instructionIndex, null);
                rop.index = Math.min(prevRop.index, rop.index);
                rop.lastIndex = Math.max(prevRop.lastIndex, rop.lastIndex);
                System.out.println(""new rop "" + rop);
            } else if (!disjoint) {
                throw new IllegalArgumentException(""replace op boundaries of "" + rop + "" overlap with previous "" + prevRop);
            }
        }
    }
    // WALK INSERTS
    for (int i = 0; i < rewrites.size(); i++) {
        RewriteOperation op = rewrites.get(i);
        if (op == null)
            continue;
        if (!(op instanceof InsertBeforeOp))
            continue;
        InsertBeforeOp iop = (InsertBeforeOp) rewrites.get(i);
        // combine current insert with prior if any at same index
        List<? extends InsertBeforeOp> prevInserts = getKindOfOps(rewrites, InsertBeforeOp.class, i);
        for (InsertBeforeOp prevIop : prevInserts) {
            if (prevIop.index == iop.index) {
                if (InsertAfterOp.class.isInstance(prevIop)) {
                    iop.text = catOpText(prevIop.text, iop.text);
                    rewrites.set(prevIop.instructionIndex, null);
                } else if (InsertBeforeOp.class.isInstance(prevIop)) {
                    // combine objects
                    // convert to strings...we're in process of toString'ing
                    // whole token buffer so no lazy eval issue with any templates
                    iop.text = catOpText(iop.text, prevIop.text);
                    // delete redundant prior insert
                    rewrites.set(prevIop.instructionIndex, null);
                }
            }
        }
        // look for replaces where iop.index is in range; error
        List<? extends ReplaceOp> prevReplaces = getKindOfOps(rewrites, ReplaceOp.class, i);
        for (ReplaceOp rop : prevReplaces) {
            if (iop.index == rop.index) {
                rop.text = catOpText(iop.text, rop.text);
                // delete current insert
                rewrites.set(i, null);
                continue;
            }
            if (iop.index >= rop.index && iop.index <= rop.lastIndex) {
                throw new IllegalArgumentException(""insert op "" + iop + "" within boundaries of previous "" + rop);
            }
        }
    }
    // System.out.println(""rewrites after=""+rewrites);
    Map<Integer, RewriteOperation> m = new HashMap<Integer, RewriteOperation>();
    for (int i = 0; i < rewrites.size(); i++) {
        RewriteOperation op = rewrites.get(i);
        // ignore deleted ops
        if (op == null)
            continue;
        if (m.get(op.index) != null) {
            throw new Error(""should only be one op per index"");
        }
        m.put(op.index, op);
    }
    // System.out.println(""index to op: ""+m);
    return m;
}","/**
 *  We need to combine operations and report invalid operations (like
 *   overlapping replaces that are not completed nested). Inserts to
 *   same index need to be combined etc...  Here are the cases:
 *
 *   I.i.u I.j.v								leave alone, nonoverlapping
 *   I.i.u I.i.v								combine: Iivu
 *
 *   R.i-j.u R.x-y.v	| i-j in x-y			delete first R
 *   R.i-j.u R.i-j.v							delete first R
 *   R.i-j.u R.x-y.v	| x-y in i-j			ERROR
 *   R.i-j.u R.x-y.v	| boundaries overlap	ERROR
 *
 *   Delete special case of replace (text==null):
 *   D.i-j.u D.x-y.v	| boundaries overlap	combine to max(min)..max(right)
 *
 *   I.i.u R.x-y.v | i in (x+1)-y			delete I (since insert before
 * 											we're not deleting i)
 *   I.i.u R.x-y.v | i not in (x+1)-y		leave alone, nonoverlapping
 *   R.x-y.v I.i.u | i in x-y				ERROR
 *   R.x-y.v I.x.u 							R.x-y.uv (combine, delete I)
 *   R.x-y.v I.i.u | i not in x-y			leave alone, nonoverlapping
 *
 *   I.i.u = insert u before op @ index i
 *   R.x-y.u = replace x-y indexed tokens with u
 *
 *   First we need to examine replaces. For any replace op:
 *
 *  		1. wipe out any insertions before op within that range.
 * 		2. Drop any replace op before that is contained completely within
 * 	 that range.
 * 		3. Throw exception upon boundary overlap with any previous replace.
 *
 *   Then we can deal with inserts:
 *
 *  		1. for any inserts to same index, combine even if not adjacent.
 *  		2. for any prior replace with same left boundary, combine this
 * 	 insert with replace and delete this replace.
 *  		3. throw exception if index in same range as previous replace
 *
 *   Don't actually delete; make op null in list. Easier to walk list.
 *   Later we can throw as we add to index &rarr; op map.
 *
 *   Note that I.2 R.2-2 will wipe out I.2 even though, technically, the
 *   inserted stuff would be before the replace range. But, if you
 *   add tokens in front of a method body '{' and then delete the method
 *   body, I think the stuff before the '{' you added should disappear too.
 *
 *   Return a map from token index to operation.
 */
","// System.out.println(""rewrites=""+rewrites);
[[SEP]]// WALK REPLACES
[[SEP]]// Wipe prior inserts within range
[[SEP]]// E.g., insert before 2, delete 2..2; update replace
[[SEP]]// text to include insert before, kill insert
[[SEP]]// delete insert as it's a no-op.
[[SEP]]// Drop any prior replaces contained within
[[SEP]]// Delete special case of replace (text==null):
[[SEP]]// delete replace as it's a no-op.
[[SEP]]// throw exception unless disjoint or identical
[[SEP]]// D.i-j.u D.x-y.v	| boundaries overlap	combine to max(min)..max(right)
[[SEP]]// System.out.println(""overlapping deletes: ""+prevRop+"", ""+rop);
[[SEP]]// kill first delete
[[SEP]]// WALK INSERTS
[[SEP]]// combine current insert with prior if any at same index
[[SEP]]// combine objects
[[SEP]]// convert to strings...we're in process of toString'ing
[[SEP]]// whole token buffer so no lazy eval issue with any templates
[[SEP]]// delete redundant prior insert
[[SEP]]// look for replaces where iop.index is in range; error
[[SEP]]// delete current insert
[[SEP]]// System.out.println(""rewrites after=""+rewrites);
[[SEP]]// ignore deleted ops
[[SEP]]// System.out.println(""index to op: ""+m);
","/** *  We need to combine operations and report invalid operations (like *   overlapping replaces that are not completed nested). Inserts to *   same index need to be combined etc...  Here are the cases: * *   I.i.u I.j.v								leave alone, nonoverlapping *   I.i.u I.i.v								combine: Iivu * *   R.i-j.u R.x-y.v	| i-j in x-y			delete first R *   R.i-j.u R.i-j.v							delete first R *   R.i-j.u R.x-y.v	| x-y in i-j			ERROR *   R.i-j.u R.x-y.v	| boundaries overlap	ERROR * *   Delete special case of replace (text==null): *   D.i-j.u D.x-y.v	| boundaries overlap	combine to max(min)..max(right) * *   I.i.u R.x-y.v | i in (x+1)-y			delete I (since insert before * 											we're not deleting i) *   I.i.u R.x-y.v | i not in (x+1)-y		leave alone, nonoverlapping *   R.x-y.v I.i.u | i in x-y				ERROR *   R.x-y.v I.x.u 							R.x-y.uv (combine, delete I) *   R.x-y.v I.i.u | i not in x-y			leave alone, nonoverlapping * *   I.i.u = insert u before op @ index i *   R.x-y.u = replace x-y indexed tokens with u * *   First we need to examine replaces. For any replace op: * *  		1. wipe out any insertions before op within that range. * 		2. Drop any replace op before that is contained completely within * 	 that range. * 		3. Throw exception upon boundary overlap with any previous replace. * *   Then we can deal with inserts: * *  		1. for any inserts to same index, combine even if not adjacent. *  		2. for any prior replace with same left boundary, combine this * 	 insert with replace and delete this replace. *  		3. throw exception if index in same range as previous replace * *   Don't actually delete; make op null in list. Easier to walk list. *   Later we can throw as we add to index &rarr; op map. * *   Note that I.2 R.2-2 will wipe out I.2 even though, technically, the *   inserted stuff would be before the replace range. But, if you *   add tokens in front of a method body '{' and then delete the method *   body, I think the stuff before the '{' you added should disappear too. * *   Return a map from token index to operation. */[[SEP]]// System.out.println(""rewrites=""+rewrites);// WALK REPLACES[[SEP]]// Wipe prior inserts within range[[SEP]]// E.g., insert before 2, delete 2..2; update replace// text to include insert before, kill insert[[SEP]]// delete insert as it's a no-op.[[SEP]]// Drop any prior replaces contained within[[SEP]]// delete replace as it's a no-op.[[SEP]]// throw exception unless disjoint or identical[[SEP]]// Delete special case of replace (text==null):// D.i-j.u D.x-y.v	| boundaries overlap	combine to max(min)..max(right)[[SEP]]// System.out.println(""overlapping deletes: ""+prevRop+"", ""+rop);// kill first delete[[SEP]]// WALK INSERTS[[SEP]]// combine current insert with prior if any at same index[[SEP]]// combine objects// convert to strings...we're in process of toString'ing// whole token buffer so no lazy eval issue with any templates[[SEP]]// delete redundant prior insert[[SEP]]// look for replaces where iop.index is in range; error[[SEP]]// delete current insert[[SEP]]// System.out.println(""rewrites after=""+rewrites);[[SEP]]// ignore deleted ops[[SEP]]// System.out.println(""index to op: ""+m);",478,575,[0],0,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]",0,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]",0,0,0,1,reduceToSingleOperationPerIndex(List<RewriteOperation>),org.antlr.v4.runtime.TokenStreamRewriter,reduceToSingleOperationPerIndex/1[java.util.List<org.antlr.v4.runtime.TokenStreamRewriter.RewriteOperation>],False,478,5,4,1,3,30,14,75,1,14,1,14,1,1,7,10,0,3,7,3,20,4,4,0,0,0,143,4,0,True
321,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\TokenStreamRewriter.java,org.antlr.v4.runtime.TokenStreamRewriter,"List<? extends T> getKindOfOps(List<? extends RewriteOperation>, Class<T>, int)","/**
 * Get all operations before an index of a particular kind
 */
protected <T extends RewriteOperation> List<? extends T> getKindOfOps(List<? extends RewriteOperation> rewrites, Class<T> kind, int before) {
    List<T> ops = new ArrayList<T>();
    for (int i = 0; i < before && i < rewrites.size(); i++) {
        RewriteOperation op = rewrites.get(i);
        // ignore deleted
        if (op == null)
            continue;
        if (kind.isInstance(op)) {
            ops.add(kind.cast(op));
        }
    }
    return ops;
}","/**
 * Get all operations before an index of a particular kind
 */
","// ignore deleted
",/** * Get all operations before an index of a particular kind */[[SEP]]// ignore deleted,586,596,[0],0,[0],0,"[0, 0]",0,0,0,0,"getKindOfOps(List<?RewriteOperation>, Class<T>, int)",org.antlr.v4.runtime.TokenStreamRewriter,"getKindOfOps/3[java.util.List<? extends org.antlr.v4.runtime.TokenStreamRewriter.RewriteOperation>,java.lang.Class<T>,int]",False,586,2,0,0,0,5,5,11,1,3,3,5,0,0,1,1,0,0,0,1,3,0,2,0,0,0,21,4,0,True
322,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\TokenStreamRewriter.java,org.antlr.v4.runtime.TokenStreamRewriter.RewriteOperation,int execute(StringBuilder),"/**
 * Execute the rewrite operation by possibly adding to the buffer.
 *  Return the index of the next token to operate on.
 */
public int execute(StringBuilder buf) {
    return index;
}","/**
 * Execute the rewrite operation by possibly adding to the buffer.
 *  Return the index of the next token to operate on.
 */
", ,/** * Execute the rewrite operation by possibly adding to the buffer. *  Return the index of the next token to operate on. */,116,118,[0],0,[0],0,[0],0,0,0,0,execute(StringBuilder),org.antlr.v4.runtime.TokenStreamRewriter$RewriteOperation,execute/1[java.lang.StringBuilder],False,116,0,1,1,0,1,0,3,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,18,1,0,True
323,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\UnbufferedCharStream.java,org.antlr.v4.runtime.UnbufferedCharStream,void consume(),"@Override
public void consume() {
    if (LA(1) == IntStream.EOF) {
        throw new IllegalStateException(""cannot consume EOF"");
    }
    // buf always has at least data[p==0] in this method due to ctor
    // track last char for LA(-1)
    lastChar = data[p];
    if (p == n - 1 && numMarkers == 0) {
        n = 0;
        // p++ will leave this at 0
        p = -1;
        lastCharBufferStart = lastChar;
    }
    p++;
    currentCharIndex++;
    sync(1);
}", ,"// buf always has at least data[p==0] in this method due to ctor
[[SEP]]// track last char for LA(-1)
[[SEP]]// p++ will leave this at 0
",// buf always has at least data[p==0] in this method due to ctor// track last char for LA(-1)[[SEP]]// p++ will leave this at 0,120,138,[0],0,"[0, 0, 0]",0,"[0, 0]",0,0,0,0,consume(),org.antlr.v4.runtime.UnbufferedCharStream,consume/0,False,121,1,2,0,2,4,2,14,0,0,0,2,2,4,0,3,0,0,1,6,4,1,1,0,0,0,17,1,0,False
324,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\UnbufferedCharStream.java,org.antlr.v4.runtime.UnbufferedCharStream,void sync(int),"/**
 * Make sure we have 'need' elements from current position {@link #p p}.
 * Last valid {@code p} index is {@code data.length-1}. {@code p+need-1} is
 * the char index 'need' elements ahead. If we need 1 element,
 * {@code (p+1-1)==p} must be less than {@code data.length}.
 */
protected void sync(int want) {
    // how many more elements we need?
    int need = (p + want - 1) - n + 1;
    if (need > 0) {
        fill(need);
    }
}","/**
 * Make sure we have 'need' elements from current position {@link #p p}.
 * Last valid {@code p} index is {@code data.length-1}. {@code p+need-1} is
 * the char index 'need' elements ahead. If we need 1 element,
 * {@code (p+1-1)==p} must be less than {@code data.length}.
 */
","// how many more elements we need?
","/** * Make sure we have 'need' elements from current position {@link #p p}. * Last valid {@code p} index is {@code data.length-1}. {@code p+need-1} is * the char index 'need' elements ahead. If we need 1 element, * {@code (p+1-1)==p} must be less than {@code data.length}. */[[SEP]]// how many more elements we need?",146,151,[0],0,[0],0,"[0, 0]",0,0,1,0,sync(int),org.antlr.v4.runtime.UnbufferedCharStream,sync/1[int],False,146,1,4,3,1,2,1,6,0,1,1,1,1,2,0,0,0,1,0,3,1,4,1,0,0,0,24,4,0,True
325,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\UnbufferedCharStream.java,org.antlr.v4.runtime.UnbufferedCharStream,int fill(int),"/**
 * Add {@code n} characters to the buffer. Returns the number of characters
 * actually added to the buffer. If the return value is less than {@code n},
 * then EOF was reached before {@code n} characters could be added.
 */
protected int fill(int n) {
    for (int i = 0; i < n; i++) {
        if (this.n > 0 && data[this.n - 1] == IntStream.EOF) {
            return i;
        }
        try {
            int c = nextChar();
            if (c > Character.MAX_VALUE || c == IntStream.EOF) {
                add(c);
            } else {
                char ch = (char) c;
                if (Character.isLowSurrogate(ch)) {
                    throw new RuntimeException(""Invalid UTF-16 (low surrogate with no preceding high surrogate)"");
                } else if (Character.isHighSurrogate(ch)) {
                    int lowSurrogate = nextChar();
                    if (lowSurrogate > Character.MAX_VALUE) {
                        throw new RuntimeException(""Invalid UTF-16 (high surrogate followed by code point > U+FFFF"");
                    } else if (lowSurrogate == IntStream.EOF) {
                        throw new RuntimeException(""Invalid UTF-16 (dangling high surrogate at end of file)"");
                    } else {
                        char lowSurrogateChar = (char) lowSurrogate;
                        if (Character.isLowSurrogate(lowSurrogateChar)) {
                            add(Character.toCodePoint(ch, lowSurrogateChar));
                        } else {
                            throw new RuntimeException(""Invalid UTF-16 (dangling high surrogate"");
                        }
                    }
                } else {
                    add(c);
                }
            }
        } catch (IOException ioe) {
            throw new RuntimeException(ioe);
        }
    }
    return n;
}","/**
 * Add {@code n} characters to the buffer. Returns the number of characters
 * actually added to the buffer. If the return value is less than {@code n},
 * then EOF was reached before {@code n} characters could be added.
 */
", ,"/** * Add {@code n} characters to the buffer. Returns the number of characters * actually added to the buffer. If the return value is less than {@code n}, * then EOF was reached before {@code n} characters could be added. */",158,203,[0],0,[0],0,[0],0,0,0,0,fill(int),org.antlr.v4.runtime.UnbufferedCharStream,fill/1[int],False,158,1,5,3,2,12,5,44,2,5,1,5,2,1,1,3,1,0,4,3,5,1,6,0,0,0,52,4,0,True
326,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\UnbufferedCharStream.java,org.antlr.v4.runtime.UnbufferedCharStream,int nextChar(),"/**
 * Override to provide different source of characters than
 * {@link #input input}.
 */
protected int nextChar() throws IOException {
    return input.read();
}","/**
 * Override to provide different source of characters than
 * {@link #input input}.
 */
", ,/** * Override to provide different source of characters than * {@link #input input}. */,209,211,[0],0,[0],0,[0],0,0,0,0,nextChar(),org.antlr.v4.runtime.UnbufferedCharStream,nextChar/0,False,209,0,1,1,0,1,1,3,1,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,14,4,0,True
327,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\UnbufferedCharStream.java,org.antlr.v4.runtime.UnbufferedCharStream,int LA(int),"@Override
public int LA(int i) {
    // special case
    if (i == -1)
        return lastChar;
    sync(i);
    int index = p + i - 1;
    if (index < 0)
        throw new IndexOutOfBoundsException();
    if (index >= n)
        return IntStream.EOF;
    return data[index];
}", ,"// special case
",// special case,220,228,[0],0,[0],0,[0],0,0,0,0,LA(int),org.antlr.v4.runtime.UnbufferedCharStream,LA/1[int],False,221,1,2,1,1,4,1,8,3,1,1,1,1,3,0,1,0,0,0,3,1,2,1,0,0,0,14,1,0,False
328,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\UnbufferedCharStream.java,org.antlr.v4.runtime.UnbufferedCharStream,int mark(),"/**
 * Return a marker that we can release later.
 *
 * <p>The specific marker value used for this class allows for some level of
 * protection against misuse where {@code seek()} is called on a mark or
 * {@code release()} is called in the wrong order.</p>
 */
@Override
public int mark() {
    if (numMarkers == 0) {
        lastCharBufferStart = lastChar;
    }
    int mark = -numMarkers - 1;
    numMarkers++;
    return mark;
}","/**
 * Return a marker that we can release later.
 *
 * <p>The specific marker value used for this class allows for some level of
 * protection against misuse where {@code seek()} is called on a mark or
 * {@code release()} is called in the wrong order.</p>
 */
", ,/** * Return a marker that we can release later. * * <p>The specific marker value used for this class allows for some level of * protection against misuse where {@code seek()} is called on a mark or * {@code release()} is called in the wrong order.</p> */,237,246,[0],0,[0],0,[0],0,0,0,0,mark(),org.antlr.v4.runtime.UnbufferedCharStream,mark/0,False,238,0,0,0,0,2,0,8,1,1,0,0,0,0,0,1,0,0,0,2,2,1,1,0,0,0,35,1,0,True
329,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\UnbufferedCharStream.java,org.antlr.v4.runtime.UnbufferedCharStream,void release(int),"/**
 * Decrement number of markers, resetting buffer if we hit 0.
 * @param marker
 */
@Override
public void release(int marker) {
    int expectedMark = -numMarkers;
    if (marker != expectedMark) {
        throw new IllegalStateException(""release() called with an invalid marker."");
    }
    numMarkers--;
    if (numMarkers == 0 && p > 0) {
        // release buffer when we can, but don't do unnecessary work
        // Copy data[p]..data[n-1] to data[0]..data[(n-1)-p], reset ptrs
        // p is last valid char; move nothing if p==n as we have no valid char
        // shift n-p char from p to 0
        System.arraycopy(data, p, data, 0, n - p);
        n = n - p;
        p = 0;
        lastCharBufferStart = lastChar;
    }
}","/**
 * Decrement number of markers, resetting buffer if we hit 0.
 * @param marker
 */
","// release buffer when we can, but don't do unnecessary work
[[SEP]]// Copy data[p]..data[n-1] to data[0]..data[(n-1)-p], reset ptrs
[[SEP]]// p is last valid char; move nothing if p==n as we have no valid char
[[SEP]]// shift n-p char from p to 0
","/** * Decrement number of markers, resetting buffer if we hit 0. * @param marker */[[SEP]]// release buffer when we can, but don't do unnecessary work// Copy data[p]..data[n-1] to data[0]..data[(n-1)-p], reset ptrs// p is last valid char; move nothing if p==n as we have no valid char// shift n-p char from p to 0",251,267,[0],0,"[0, 0, 0, 0]",0,"[0, 0]",0,0,0,0,release(int),org.antlr.v4.runtime.UnbufferedCharStream,release/1[int],False,252,0,0,0,0,4,1,13,0,1,1,1,0,0,0,2,0,0,1,4,4,2,1,0,0,0,26,1,0,True
330,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\UnbufferedCharStream.java,org.antlr.v4.runtime.UnbufferedCharStream,void seek(int),"/**
 * Seek to absolute character index, which might not be in the current
 *  sliding window.  Move {@code p} to {@code index-bufferStartIndex}.
 */
@Override
public void seek(int index) {
    if (index == currentCharIndex) {
        return;
    }
    if (index > currentCharIndex) {
        sync(index - currentCharIndex);
        index = Math.min(index, getBufferStartIndex() + n - 1);
    }
    // index == to bufferStartIndex should set p to 0
    int i = index - getBufferStartIndex();
    if (i < 0) {
        throw new IllegalArgumentException(""cannot seek to negative index "" + index);
    } else if (i >= n) {
        throw new UnsupportedOperationException(""seek to index outside buffer: "" + index + "" not in "" + getBufferStartIndex() + "".."" + (getBufferStartIndex() + n));
    }
    p = i;
    currentCharIndex = index;
    if (p == 0) {
        lastChar = lastCharBufferStart;
    } else {
        lastChar = data[p - 1];
    }
}","/**
 * Seek to absolute character index, which might not be in the current
 *  sliding window.  Move {@code p} to {@code index-bufferStartIndex}.
 */
","// index == to bufferStartIndex should set p to 0
","/** * Seek to absolute character index, which might not be in the current *  sliding window.  Move {@code p} to {@code index-bufferStartIndex}. */[[SEP]]// index == to bufferStartIndex should set p to 0",277,306,[0],0,[0],0,"[0, 0]",0,0,0,0,seek(int),org.antlr.v4.runtime.UnbufferedCharStream,seek/1[int],False,278,1,2,0,2,6,3,24,1,1,1,3,2,3,0,2,0,1,4,4,6,8,1,0,0,0,33,1,0,True
331,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\UnbufferedCharStream.java,org.antlr.v4.runtime.UnbufferedCharStream,String getText(Interval),"@Override
public String getText(Interval interval) {
    if (interval.a < 0 || interval.b < interval.a - 1) {
        throw new IllegalArgumentException(""invalid interval"");
    }
    int bufferStartIndex = getBufferStartIndex();
    if (n > 0 && data[n - 1] == Character.MAX_VALUE) {
        if (interval.a + interval.length() > bufferStartIndex + n) {
            throw new IllegalArgumentException(""the interval extends past the end of the stream"");
        }
    }
    if (interval.a < bufferStartIndex || interval.b >= bufferStartIndex + n) {
        throw new UnsupportedOperationException(""interval "" + interval + "" outside buffer: "" + bufferStartIndex + "".."" + (bufferStartIndex + n - 1));
    }
    // convert from absolute to local index
    int i = interval.a - bufferStartIndex;
    return new String(data, i, interval.length());
}", ,"// convert from absolute to local index
",// convert from absolute to local index,322,342,[0],0,[0],0,[0],0,0,0,0,getText(Interval),org.antlr.v4.runtime.UnbufferedCharStream,getText/1[org.antlr.v4.runtime.misc.Interval],False,323,2,2,0,2,8,2,16,1,2,1,2,1,1,0,1,0,1,5,5,2,9,2,0,0,0,20,1,0,False
332,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\UnbufferedTokenStream.java,org.antlr.v4.runtime.UnbufferedTokenStream,Token get(int),"@Override
public Token get(int i) {
    // get absolute index
    int bufferStartIndex = getBufferStartIndex();
    if (i < bufferStartIndex || i >= bufferStartIndex + n) {
        throw new IndexOutOfBoundsException(""get("" + i + "") outside buffer: "" + bufferStartIndex + "".."" + (bufferStartIndex + n));
    }
    return tokens[i - bufferStartIndex];
}", ,"// get absolute index
",// get absolute index,78,86,[0],0,[0],0,[0],0,0,0,0,get(int),org.antlr.v4.runtime.UnbufferedTokenStream,get/1[int],False,79,2,1,0,1,3,1,7,1,1,1,1,0,0,0,0,0,1,3,0,1,4,1,0,0,0,13,1,0,False
333,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\UnbufferedTokenStream.java,org.antlr.v4.runtime.UnbufferedTokenStream,void consume(),"@Override
public void consume() {
    if (LA(1) == Token.EOF) {
        throw new IllegalStateException(""cannot consume EOF"");
    }
    // buf always has at least tokens[p==0] in this method due to ctor
    // track last token for LT(-1)
    lastToken = tokens[p];
    // if we're at last token and no markers, opportunity to flush buffer
    if (p == n - 1 && numMarkers == 0) {
        n = 0;
        // p++ will leave this at 0
        p = -1;
        lastTokenBufferStart = lastToken;
    }
    p++;
    currentTokenIndex++;
    sync(1);
}", ,"// buf always has at least tokens[p==0] in this method due to ctor
[[SEP]]// track last token for LT(-1)
[[SEP]]// if we're at last token and no markers, opportunity to flush buffer
[[SEP]]// p++ will leave this at 0
","// buf always has at least tokens[p==0] in this method due to ctor// track last token for LT(-1)[[SEP]]// if we're at last token and no markers, opportunity to flush buffer[[SEP]]// p++ will leave this at 0",136,155,[0],0,"[0, 0, 0, 0]",0,"[0, 0, 0]",0,0,0,0,consume(),org.antlr.v4.runtime.UnbufferedTokenStream,consume/0,False,137,1,2,0,2,4,2,14,0,0,0,2,0,0,0,3,0,0,1,6,4,1,1,0,0,0,17,1,0,False
334,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\UnbufferedTokenStream.java,org.antlr.v4.runtime.UnbufferedTokenStream,void sync(int),"/**
 * Make sure we have 'need' elements from current position {@link #p p}. Last valid
 *  {@code p} index is {@code tokens.length-1}.  {@code p+need-1} is the tokens index 'need' elements
 *  ahead.  If we need 1 element, {@code (p+1-1)==p} must be less than {@code tokens.length}.
 */
protected void sync(int want) {
    // how many more elements we need?
    int need = (p + want - 1) - n + 1;
    if (need > 0) {
        fill(need);
    }
}","/**
 * Make sure we have 'need' elements from current position {@link #p p}. Last valid
 *  {@code p} index is {@code tokens.length-1}.  {@code p+need-1} is the tokens index 'need' elements
 *  ahead.  If we need 1 element, {@code (p+1-1)==p} must be less than {@code tokens.length}.
 */
","// how many more elements we need?
","/** * Make sure we have 'need' elements from current position {@link #p p}. Last valid *  {@code p} index is {@code tokens.length-1}.  {@code p+need-1} is the tokens index 'need' elements *  ahead.  If we need 1 element, {@code (p+1-1)==p} must be less than {@code tokens.length}. */[[SEP]]// how many more elements we need?",161,166,[0],0,[0],0,"[0, 0]",0,0,1,0,sync(int),org.antlr.v4.runtime.UnbufferedTokenStream,sync/1[int],False,161,1,1,0,1,2,1,6,0,1,1,1,0,0,0,0,0,1,0,3,1,4,1,0,0,0,25,4,0,True
335,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\UnbufferedTokenStream.java,org.antlr.v4.runtime.UnbufferedTokenStream,int fill(int),"/**
 * Add {@code n} elements to the buffer. Returns the number of tokens
 * actually added to the buffer. If the return value is less than {@code n},
 * then EOF was reached before {@code n} tokens could be added.
 */
protected int fill(int n) {
    for (int i = 0; i < n; i++) {
        if (this.n > 0 && tokens[this.n - 1].getType() == Token.EOF) {
            return i;
        }
        Token t = tokenSource.nextToken();
        add(t);
    }
    return n;
}","/**
 * Add {@code n} elements to the buffer. Returns the number of tokens
 * actually added to the buffer. If the return value is less than {@code n},
 * then EOF was reached before {@code n} tokens could be added.
 */
", ,"/** * Add {@code n} elements to the buffer. Returns the number of tokens * actually added to the buffer. If the return value is less than {@code n}, * then EOF was reached before {@code n} tokens could be added. */",173,184,[0],0,[0],0,[0],0,0,0,0,fill(int),org.antlr.v4.runtime.UnbufferedTokenStream,fill/1[int],False,173,3,3,0,3,4,3,10,2,2,1,3,0,0,1,1,0,0,0,3,2,1,2,0,0,0,30,4,0,True
336,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\UnbufferedTokenStream.java,org.antlr.v4.runtime.UnbufferedTokenStream,int mark(),"/**
 * Return a marker that we can release later.
 *
 * <p>The specific marker value used for this class allows for some level of
 * protection against misuse where {@code seek()} is called on a mark or
 * {@code release()} is called in the wrong order.</p>
 */
@Override
public int mark() {
    if (numMarkers == 0) {
        lastTokenBufferStart = lastToken;
    }
    int mark = -numMarkers - 1;
    numMarkers++;
    return mark;
}","/**
 * Return a marker that we can release later.
 *
 * <p>The specific marker value used for this class allows for some level of
 * protection against misuse where {@code seek()} is called on a mark or
 * {@code release()} is called in the wrong order.</p>
 */
", ,/** * Return a marker that we can release later. * * <p>The specific marker value used for this class allows for some level of * protection against misuse where {@code seek()} is called on a mark or * {@code release()} is called in the wrong order.</p> */,205,214,[0],0,[0],0,[0],0,0,0,0,mark(),org.antlr.v4.runtime.UnbufferedTokenStream,mark/0,False,206,0,0,0,0,2,0,8,1,1,0,0,0,0,0,1,0,0,0,2,2,1,1,0,0,0,35,1,0,True
337,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\UnbufferedTokenStream.java,org.antlr.v4.runtime.UnbufferedTokenStream,void release(int),"@Override
public void release(int marker) {
    int expectedMark = -numMarkers;
    if (marker != expectedMark) {
        throw new IllegalStateException(""release() called with an invalid marker."");
    }
    numMarkers--;
    if (numMarkers == 0) {
        // can we release buffer?
        if (p > 0) {
            // Copy tokens[p]..tokens[n-1] to tokens[0]..tokens[(n-1)-p], reset ptrs
            // p is last valid token; move nothing if p==n as we have no valid char
            // shift n-p tokens from p to 0
            System.arraycopy(tokens, p, tokens, 0, n - p);
            n = n - p;
            p = 0;
        }
        lastTokenBufferStart = lastToken;
    }
}", ,"// can we release buffer?
[[SEP]]// Copy tokens[p]..tokens[n-1] to tokens[0]..tokens[(n-1)-p], reset ptrs
[[SEP]]// p is last valid token; move nothing if p==n as we have no valid char
[[SEP]]// shift n-p tokens from p to 0
","// can we release buffer?[[SEP]]// Copy tokens[p]..tokens[n-1] to tokens[0]..tokens[(n-1)-p], reset ptrs// p is last valid token; move nothing if p==n as we have no valid char// shift n-p tokens from p to 0",216,235,[0],0,"[0, 0, 0, 0]",0,"[0, 0]",0,0,0,0,release(int),org.antlr.v4.runtime.UnbufferedTokenStream,release/1[int],False,217,0,0,0,0,4,1,15,0,1,1,1,0,0,0,2,0,0,1,4,4,2,2,0,0,0,19,1,0,False
338,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\UnbufferedTokenStream.java,org.antlr.v4.runtime.UnbufferedTokenStream,void seek(int),"@Override
public void seek(int index) {
    // seek to absolute index
    if (index == currentTokenIndex) {
        return;
    }
    if (index > currentTokenIndex) {
        sync(index - currentTokenIndex);
        index = Math.min(index, getBufferStartIndex() + n - 1);
    }
    int bufferStartIndex = getBufferStartIndex();
    int i = index - bufferStartIndex;
    if (i < 0) {
        throw new IllegalArgumentException(""cannot seek to negative index "" + index);
    } else if (i >= n) {
        throw new UnsupportedOperationException(""seek to index outside buffer: "" + index + "" not in "" + bufferStartIndex + "".."" + (bufferStartIndex + n));
    }
    p = i;
    currentTokenIndex = index;
    if (p == 0) {
        lastToken = lastTokenBufferStart;
    } else {
        lastToken = tokens[p - 1];
    }
}", ,"// seek to absolute index
",// seek to absolute index,242,271,[0],0,[0],0,[0],0,0,0,0,seek(int),org.antlr.v4.runtime.UnbufferedTokenStream,seek/1[int],False,243,1,2,0,2,6,3,25,1,2,1,3,0,0,0,2,0,1,4,4,7,8,1,0,0,0,24,1,0,False
339,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\Vocabulary.java,org.antlr.v4.runtime.Vocabulary,int getMaxTokenType(),"/**
 * Returns the highest token type value. It can be used to iterate from
 * zero to that number, inclusively, thus querying all stored entries.
 * @return the highest token type value
 */
int getMaxTokenType();","/**
 * Returns the highest token type value. It can be used to iterate from
 * zero to that number, inclusively, thus querying all stored entries.
 * @return the highest token type value
 */
", ,"/** * Returns the highest token type value. It can be used to iterate from * zero to that number, inclusively, thus querying all stored entries. * @return the highest token type value */",21,21,[0],0,[0],0,[0],0,0,0,0,getMaxTokenType(),org.antlr.v4.runtime.Vocabulary,getMaxTokenType/0,False,16,0,1,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,23,0,0,True
340,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\Vocabulary.java,org.antlr.v4.runtime.Vocabulary,String getLiteralName(int),"/**
 * Gets the string literal associated with a token type. The string returned
 * by this method, when not {@code null}, can be used unaltered in a parser
 * grammar to represent this token type.
 *
 * <p>The following table shows examples of lexer rules and the literal
 * names assigned to the corresponding token types.</p>
 *
 * <table>
 *  <tr>
 *   <th>Rule</th>
 *   <th>Literal Name</th>
 *   <th>Java String Literal</th>
 *  </tr>
 *  <tr>
 *   <td>{@code THIS : 'this';}</td>
 *   <td>{@code 'this'}</td>
 *   <td>{@code ""'this'""}</td>
 *  </tr>
 *  <tr>
 *   <td>{@code SQUOTE : '\'';}</td>
 *   <td>{@code '\''}</td>
 *   <td>{@code ""'\\''""}</td>
 *  </tr>
 *  <tr>
 *   <td>{@code ID : [A-Z]+;}</td>
 *   <td>n/a</td>
 *   <td>{@code null}</td>
 *  </tr>
 * </table>
 *
 * @param tokenType The token type.
 *
 * @return The string literal associated with the specified token type, or
 * {@code null} if no string literal is associated with the type.
 */
String getLiteralName(int tokenType);","/**
 * Gets the string literal associated with a token type. The string returned
 * by this method, when not {@code null}, can be used unaltered in a parser
 * grammar to represent this token type.
 *
 * <p>The following table shows examples of lexer rules and the literal
 * names assigned to the corresponding token types.</p>
 *
 * <table>
 *  <tr>
 *   <th>Rule</th>
 *   <th>Literal Name</th>
 *   <th>Java String Literal</th>
 *  </tr>
 *  <tr>
 *   <td>{@code THIS : 'this';}</td>
 *   <td>{@code 'this'}</td>
 *   <td>{@code ""'this'""}</td>
 *  </tr>
 *  <tr>
 *   <td>{@code SQUOTE : '\'';}</td>
 *   <td>{@code '\''}</td>
 *   <td>{@code ""'\\''""}</td>
 *  </tr>
 *  <tr>
 *   <td>{@code ID : [A-Z]+;}</td>
 *   <td>n/a</td>
 *   <td>{@code null}</td>
 *  </tr>
 * </table>
 *
 * @param tokenType The token type.
 *
 * @return The string literal associated with the specified token type, or
 * {@code null} if no string literal is associated with the type.
 */
", ,"/** * Gets the string literal associated with a token type. The string returned * by this method, when not {@code null}, can be used unaltered in a parser * grammar to represent this token type. * * <p>The following table shows examples of lexer rules and the literal * names assigned to the corresponding token types.</p> * * <table> *  <tr> *   <th>Rule</th> *   <th>Literal Name</th> *   <th>Java String Literal</th> *  </tr> *  <tr> *   <td>{@code THIS : 'this';}</td> *   <td>{@code 'this'}</td> *   <td>{@code ""'this'""}</td> *  </tr> *  <tr> *   <td>{@code SQUOTE : '\'';}</td> *   <td>{@code '\''}</td> *   <td>{@code ""'\\''""}</td> *  </tr> *  <tr> *   <td>{@code ID : [A-Z]+;}</td> *   <td>n/a</td> *   <td>{@code null}</td> *  </tr> * </table> * * @param tokenType The token type. * * @return The string literal associated with the specified token type, or * {@code null} if no string literal is associated with the type. */",59,59,[0],0,[0],0,[0],0,0,0,0,getLiteralName(int),org.antlr.v4.runtime.Vocabulary,getLiteralName/1[int],False,23,0,2,2,0,1,0,1,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,57,0,0,True
341,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\Vocabulary.java,org.antlr.v4.runtime.Vocabulary,String getSymbolicName(int),"/**
 * Gets the symbolic name associated with a token type. The string returned
 * by this method, when not {@code null}, can be used unaltered in a parser
 * grammar to represent this token type.
 *
 * <p>This method supports token types defined by any of the following
 * methods:</p>
 *
 * <ul>
 *  <li>Tokens created by lexer rules.</li>
 *  <li>Tokens defined in a <code>tokens{}</code> block in a lexer or parser
 *  grammar.</li>
 *  <li>The implicitly defined {@code EOF} token, which has the token type
 *  {@link Token#EOF}.</li>
 * </ul>
 *
 * <p>The following table shows examples of lexer rules and the literal
 * names assigned to the corresponding token types.</p>
 *
 * <table>
 *  <tr>
 *   <th>Rule</th>
 *   <th>Symbolic Name</th>
 *  </tr>
 *  <tr>
 *   <td>{@code THIS : 'this';}</td>
 *   <td>{@code THIS}</td>
 *  </tr>
 *  <tr>
 *   <td>{@code SQUOTE : '\'';}</td>
 *   <td>{@code SQUOTE}</td>
 *  </tr>
 *  <tr>
 *   <td>{@code ID : [A-Z]+;}</td>
 *   <td>{@code ID}</td>
 *  </tr>
 * </table>
 *
 * @param tokenType The token type.
 *
 * @return The symbolic name associated with the specified token type, or
 * {@code null} if no symbolic name is associated with the type.
 */
String getSymbolicName(int tokenType);","/**
 * Gets the symbolic name associated with a token type. The string returned
 * by this method, when not {@code null}, can be used unaltered in a parser
 * grammar to represent this token type.
 *
 * <p>This method supports token types defined by any of the following
 * methods:</p>
 *
 * <ul>
 *  <li>Tokens created by lexer rules.</li>
 *  <li>Tokens defined in a <code>tokens{}</code> block in a lexer or parser
 *  grammar.</li>
 *  <li>The implicitly defined {@code EOF} token, which has the token type
 *  {@link Token#EOF}.</li>
 * </ul>
 *
 * <p>The following table shows examples of lexer rules and the literal
 * names assigned to the corresponding token types.</p>
 *
 * <table>
 *  <tr>
 *   <th>Rule</th>
 *   <th>Symbolic Name</th>
 *  </tr>
 *  <tr>
 *   <td>{@code THIS : 'this';}</td>
 *   <td>{@code THIS}</td>
 *  </tr>
 *  <tr>
 *   <td>{@code SQUOTE : '\'';}</td>
 *   <td>{@code SQUOTE}</td>
 *  </tr>
 *  <tr>
 *   <td>{@code ID : [A-Z]+;}</td>
 *   <td>{@code ID}</td>
 *  </tr>
 * </table>
 *
 * @param tokenType The token type.
 *
 * @return The symbolic name associated with the specified token type, or
 * {@code null} if no symbolic name is associated with the type.
 */
", ,"/** * Gets the symbolic name associated with a token type. The string returned * by this method, when not {@code null}, can be used unaltered in a parser * grammar to represent this token type. * * <p>This method supports token types defined by any of the following * methods:</p> * * <ul> *  <li>Tokens created by lexer rules.</li> *  <li>Tokens defined in a <code>tokens{}</code> block in a lexer or parser *  grammar.</li> *  <li>The implicitly defined {@code EOF} token, which has the token type *  {@link Token#EOF}.</li> * </ul> * * <p>The following table shows examples of lexer rules and the literal * names assigned to the corresponding token types.</p> * * <table> *  <tr> *   <th>Rule</th> *   <th>Symbolic Name</th> *  </tr> *  <tr> *   <td>{@code THIS : 'this';}</td> *   <td>{@code THIS}</td> *  </tr> *  <tr> *   <td>{@code SQUOTE : '\'';}</td> *   <td>{@code SQUOTE}</td> *  </tr> *  <tr> *   <td>{@code ID : [A-Z]+;}</td> *   <td>{@code ID}</td> *  </tr> * </table> * * @param tokenType The token type. * * @return The symbolic name associated with the specified token type, or * {@code null} if no symbolic name is associated with the type. */",104,104,[0],0,[0],0,[0],0,0,0,0,getSymbolicName(int),org.antlr.v4.runtime.Vocabulary,getSymbolicName/1[int],False,61,0,2,2,0,1,0,1,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,75,0,0,True
342,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\Vocabulary.java,org.antlr.v4.runtime.Vocabulary,String getDisplayName(int),"/**
 * Gets the display name of a token type.
 *
 * <p>ANTLR provides a default implementation of this method, but
 * applications are free to override the behavior in any manner which makes
 * sense for the application. The default implementation returns the first
 * result from the following list which produces a non-{@code null}
 * result.</p>
 *
 * <ol>
 *  <li>The result of {@link #getLiteralName}</li>
 *  <li>The result of {@link #getSymbolicName}</li>
 *  <li>The result of {@link Integer#toString}</li>
 * </ol>
 *
 * @param tokenType The token type.
 *
 * @return The display name of the token type, for use in error reporting or
 * other user-visible messages which reference specific token types.
 */
String getDisplayName(int tokenType);","/**
 * Gets the display name of a token type.
 *
 * <p>ANTLR provides a default implementation of this method, but
 * applications are free to override the behavior in any manner which makes
 * sense for the application. The default implementation returns the first
 * result from the following list which produces a non-{@code null}
 * result.</p>
 *
 * <ol>
 *  <li>The result of {@link #getLiteralName}</li>
 *  <li>The result of {@link #getSymbolicName}</li>
 *  <li>The result of {@link Integer#toString}</li>
 * </ol>
 *
 * @param tokenType The token type.
 *
 * @return The display name of the token type, for use in error reporting or
 * other user-visible messages which reference specific token types.
 */
", ,"/** * Gets the display name of a token type. * * <p>ANTLR provides a default implementation of this method, but * applications are free to override the behavior in any manner which makes * sense for the application. The default implementation returns the first * result from the following list which produces a non-{@code null} * result.</p> * * <ol> *  <li>The result of {@link #getLiteralName}</li> *  <li>The result of {@link #getSymbolicName}</li> *  <li>The result of {@link Integer#toString}</li> * </ol> * * @param tokenType The token type. * * @return The display name of the token type, for use in error reporting or * other user-visible messages which reference specific token types. */",126,126,[0],0,[0],0,[0],0,0,0,0,getDisplayName(int),org.antlr.v4.runtime.Vocabulary,getDisplayName/1[int],False,106,0,7,7,0,1,0,1,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,53,0,0,True
343,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\VocabularyImpl.java,org.antlr.v4.runtime.VocabularyImpl,Vocabulary fromTokenNames(String[]),"/**
 * Returns a {@link VocabularyImpl} instance from the specified set of token
 * names. This method acts as a compatibility layer for the single
 * {@code tokenNames} array generated by previous releases of ANTLR.
 *
 * <p>The resulting vocabulary instance returns {@code null} for
 * {@link #getLiteralName(int)} and {@link #getSymbolicName(int)}, and the
 * value from {@code tokenNames} for the display names.</p>
 *
 * @param tokenNames The token names, or {@code null} if no token names are
 * available.
 * @return A {@link Vocabulary} instance which uses {@code tokenNames} for
 * the display names of tokens.
 */
public static Vocabulary fromTokenNames(String[] tokenNames) {
    if (tokenNames == null || tokenNames.length == 0) {
        return EMPTY_VOCABULARY;
    }
    String[] literalNames = Arrays.copyOf(tokenNames, tokenNames.length);
    String[] symbolicNames = Arrays.copyOf(tokenNames, tokenNames.length);
    for (int i = 0; i < tokenNames.length; i++) {
        String tokenName = tokenNames[i];
        if (tokenName == null) {
            continue;
        }
        if (!tokenName.isEmpty()) {
            char firstChar = tokenName.charAt(0);
            if (firstChar == '\'') {
                symbolicNames[i] = null;
                continue;
            } else if (Character.isUpperCase(firstChar)) {
                literalNames[i] = null;
                continue;
            }
        }
        // wasn't a literal or symbolic name
        literalNames[i] = null;
        symbolicNames[i] = null;
    }
    return new VocabularyImpl(literalNames, symbolicNames, tokenNames);
}","/**
 * Returns a {@link VocabularyImpl} instance from the specified set of token
 * names. This method acts as a compatibility layer for the single
 * {@code tokenNames} array generated by previous releases of ANTLR.
 *
 * <p>The resulting vocabulary instance returns {@code null} for
 * {@link #getLiteralName(int)} and {@link #getSymbolicName(int)}, and the
 * value from {@code tokenNames} for the display names.</p>
 *
 * @param tokenNames The token names, or {@code null} if no token names are
 * available.
 * @return A {@link Vocabulary} instance which uses {@code tokenNames} for
 * the display names of tokens.
 */
","// wasn't a literal or symbolic name
","/** * Returns a {@link VocabularyImpl} instance from the specified set of token * names. This method acts as a compatibility layer for the single * {@code tokenNames} array generated by previous releases of ANTLR. * * <p>The resulting vocabulary instance returns {@code null} for * {@link #getLiteralName(int)} and {@link #getSymbolicName(int)}, and the * value from {@code tokenNames} for the display names.</p> * * @param tokenNames The token names, or {@code null} if no token names are * available. * @return A {@link Vocabulary} instance which uses {@code tokenNames} for * the display names of tokens. */[[SEP]]// wasn't a literal or symbolic name",95,126,[0],0,[0],0,"[0, 0]",0,0,0,0,fromTokenNames(String[]),org.antlr.v4.runtime.VocabularyImpl,fromTokenNames/1[java.lang.String[]],False,95,2,7,6,1,8,4,27,2,5,1,4,0,0,1,4,0,0,0,3,9,0,3,0,0,0,60,9,0,True
344,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\atn\ATN.java,org.antlr.v4.runtime.atn.ATN,"IntervalSet nextTokens(ATNState, RuleContext)","/**
 * Compute the set of valid tokens that can occur starting in state {@code s}.
 *  If {@code ctx} is null, the set of tokens will not include what can follow
 *  the rule surrounding {@code s}. In other words, the set will be
 *  restricted to tokens reachable staying within {@code s}'s rule.
 */
public IntervalSet nextTokens(ATNState s, RuleContext ctx) {
    LL1Analyzer anal = new LL1Analyzer(this);
    IntervalSet next = anal.LOOK(s, ctx);
    return next;
}","/**
 * Compute the set of valid tokens that can occur starting in state {@code s}.
 *  If {@code ctx} is null, the set of tokens will not include what can follow
 *  the rule surrounding {@code s}. In other words, the set will be
 *  restricted to tokens reachable staying within {@code s}'s rule.
 */
", ,"/** * Compute the set of valid tokens that can occur starting in state {@code s}. *  If {@code ctx} is null, the set of tokens will not include what can follow *  the rule surrounding {@code s}. In other words, the set will be *  restricted to tokens reachable staying within {@code s}'s rule. */",84,88,[0],0,[0],0,[0],0,0,0,0,"nextTokens(ATNState, RuleContext)",org.antlr.v4.runtime.atn.ATN,"nextTokens/2[org.antlr.v4.runtime.atn.ATNState,org.antlr.v4.runtime.RuleContext]",False,84,4,4,2,2,1,1,5,1,2,2,1,0,0,0,0,0,0,0,0,2,0,0,0,0,0,43,1,0,True
345,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\atn\ATN.java,org.antlr.v4.runtime.atn.ATN,IntervalSet nextTokens(ATNState),"/**
 * Compute the set of valid tokens that can occur starting in {@code s} and
 * staying in same rule. {@link Token#EPSILON} is in set if we reach end of
 * rule.
 */
public IntervalSet nextTokens(ATNState s) {
    if (s.nextTokenWithinRule != null)
        return s.nextTokenWithinRule;
    s.nextTokenWithinRule = nextTokens(s, null);
    s.nextTokenWithinRule.setReadonly(true);
    return s.nextTokenWithinRule;
}","/**
 * Compute the set of valid tokens that can occur starting in {@code s} and
 * staying in same rule. {@link Token#EPSILON} is in set if we reach end of
 * rule.
 */
", ,/** * Compute the set of valid tokens that can occur starting in {@code s} and * staying in same rule. {@link Token#EPSILON} is in set if we reach end of * rule. */,95,100,[0],0,[0],0,[0],0,0,0,0,nextTokens(ATNState),org.antlr.v4.runtime.atn.ATN,nextTokens/1[org.antlr.v4.runtime.atn.ATNState],False,95,3,8,6,2,2,2,6,2,0,1,2,1,1,0,1,0,0,0,0,1,0,1,0,0,0,28,1,0,True
346,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\atn\ATN.java,org.antlr.v4.runtime.atn.ATN,void removeState(ATNState),"public void removeState(ATNState state) {
    // just free mem, don't shift states in list
    states.set(state.stateNumber, null);
}", ,"// just free mem, don't shift states in list
","// just free mem, don't shift states in list",111,113,[0],0,[0],0,[0],0,0,0,0,removeState(ATNState),org.antlr.v4.runtime.atn.ATN,removeState/1[org.antlr.v4.runtime.atn.ATNState],False,111,1,3,3,0,1,1,3,0,0,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,6,1,0,False
347,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\atn\ATN.java,org.antlr.v4.runtime.atn.ATN,"IntervalSet getExpectedTokens(int, RuleContext)","/**
 * Computes the set of input symbols which could follow ATN state number
 * {@code stateNumber} in the specified full {@code context}. This method
 * considers the complete parser context, but does not evaluate semantic
 * predicates (i.e. all predicates encountered during the calculation are
 * assumed true). If a path in the ATN exists from the starting state to the
 * {@link RuleStopState} of the outermost context without matching any
 * symbols, {@link Token#EOF} is added to the returned set.
 *
 * <p>If {@code context} is {@code null}, it is treated as {@link ParserRuleContext#EMPTY}.</p>
 *
 * Note that this does NOT give you the set of all tokens that could
 * appear at a given token position in the input phrase.  In other words,
 * it does not answer:
 *
 *   ""Given a specific partial input phrase, return the set of all tokens
 *    that can follow the last token in the input phrase.""
 *
 * The big difference is that with just the input, the parser could
 * land right in the middle of a lookahead decision. Getting
 * all *possible* tokens given a partial input stream is a separate
 * computation. See https://github.com/antlr/antlr4/issues/1428
 *
 * For this function, we are specifying an ATN state and call stack to compute
 * what token(s) can come next and specifically: outside of a lookahead decision.
 * That is what you want for error reporting and recovery upon parse error.
 *
 * @param stateNumber the ATN state number
 * @param context the full parse context
 * @return The set of potentially valid input symbols which could follow the
 * specified state in the specified context.
 * @throws IllegalArgumentException if the ATN does not contain a state with
 * number {@code stateNumber}
 */
public IntervalSet getExpectedTokens(int stateNumber, RuleContext context) {
    if (stateNumber < 0 || stateNumber >= states.size()) {
        throw new IllegalArgumentException(""Invalid state number."");
    }
    RuleContext ctx = context;
    ATNState s = states.get(stateNumber);
    IntervalSet following = nextTokens(s);
    if (!following.contains(Token.EPSILON)) {
        return following;
    }
    IntervalSet expected = new IntervalSet();
    expected.addAll(following);
    expected.remove(Token.EPSILON);
    while (ctx != null && ctx.invokingState >= 0 && following.contains(Token.EPSILON)) {
        ATNState invokingState = states.get(ctx.invokingState);
        RuleTransition rt = (RuleTransition) invokingState.transition(0);
        following = nextTokens(rt.followState);
        expected.addAll(following);
        expected.remove(Token.EPSILON);
        ctx = ctx.parent;
    }
    if (following.contains(Token.EPSILON)) {
        expected.add(Token.EOF);
    }
    return expected;
}","/**
 * Computes the set of input symbols which could follow ATN state number
 * {@code stateNumber} in the specified full {@code context}. This method
 * considers the complete parser context, but does not evaluate semantic
 * predicates (i.e. all predicates encountered during the calculation are
 * assumed true). If a path in the ATN exists from the starting state to the
 * {@link RuleStopState} of the outermost context without matching any
 * symbols, {@link Token#EOF} is added to the returned set.
 *
 * <p>If {@code context} is {@code null}, it is treated as {@link ParserRuleContext#EMPTY}.</p>
 *
 * Note that this does NOT give you the set of all tokens that could
 * appear at a given token position in the input phrase.  In other words,
 * it does not answer:
 *
 *   ""Given a specific partial input phrase, return the set of all tokens
 *    that can follow the last token in the input phrase.""
 *
 * The big difference is that with just the input, the parser could
 * land right in the middle of a lookahead decision. Getting
 * all *possible* tokens given a partial input stream is a separate
 * computation. See https://github.com/antlr/antlr4/issues/1428
 *
 * For this function, we are specifying an ATN state and call stack to compute
 * what token(s) can come next and specifically: outside of a lookahead decision.
 * That is what you want for error reporting and recovery upon parse error.
 *
 * @param stateNumber the ATN state number
 * @param context the full parse context
 * @return The set of potentially valid input symbols which could follow the
 * specified state in the specified context.
 * @throws IllegalArgumentException if the ATN does not contain a state with
 * number {@code stateNumber}
 */
", ,"/** * Computes the set of input symbols which could follow ATN state number * {@code stateNumber} in the specified full {@code context}. This method * considers the complete parser context, but does not evaluate semantic * predicates (i.e. all predicates encountered during the calculation are * assumed true). If a path in the ATN exists from the starting state to the * {@link RuleStopState} of the outermost context without matching any * symbols, {@link Token#EOF} is added to the returned set. * * <p>If {@code context} is {@code null}, it is treated as {@link ParserRuleContext#EMPTY}.</p> * * Note that this does NOT give you the set of all tokens that could * appear at a given token position in the input phrase.  In other words, * it does not answer: * *   ""Given a specific partial input phrase, return the set of all tokens *    that can follow the last token in the input phrase."" * * The big difference is that with just the input, the parser could * land right in the middle of a lookahead decision. Getting * all *possible* tokens given a partial input stream is a separate * computation. See https://github.com/antlr/antlr4/issues/1428 * * For this function, we are specifying an ATN state and call stack to compute * what token(s) can come next and specifically: outside of a lookahead decision. * That is what you want for error reporting and recovery upon parse error. * * @param stateNumber the ATN state number * @param context the full parse context * @return The set of potentially valid input symbols which could follow the * specified state in the specified context. * @throws IllegalArgumentException if the ATN does not contain a state with * number {@code stateNumber} */",166,195,[0],0,[0],0,[0],0,0,0,0,"getExpectedTokens(int, RuleContext)",org.antlr.v4.runtime.atn.ATN,"getExpectedTokens/2[int,org.antlr.v4.runtime.RuleContext]",False,166,5,13,6,7,8,8,26,2,6,2,8,1,2,1,1,0,0,1,3,8,0,1,0,0,0,132,1,0,True
348,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\atn\ATNConfig.java,org.antlr.v4.runtime.atn.ATNConfig,int getOuterContextDepth(),"/**
 * This method gets the value of the {@link #reachesIntoOuterContext} field
 * as it existed prior to the introduction of the
 * {@link #isPrecedenceFilterSuppressed} method.
 */
public final int getOuterContextDepth() {
    return reachesIntoOuterContext & ~SUPPRESS_PRECEDENCE_FILTER;
}","/**
 * This method gets the value of the {@link #reachesIntoOuterContext} field
 * as it existed prior to the introduction of the
 * {@link #isPrecedenceFilterSuppressed} method.
 */
", ,/** * This method gets the value of the {@link #reachesIntoOuterContext} field * as it existed prior to the introduction of the * {@link #isPrecedenceFilterSuppressed} method. */,134,136,[0],0,[0],0,[0],0,0,0,0,getOuterContextDepth(),org.antlr.v4.runtime.atn.ATNConfig,getOuterContextDepth/0,False,134,0,3,3,0,1,0,3,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,18,17,0,True
349,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\atn\ATNConfig.java,org.antlr.v4.runtime.atn.ATNConfig,boolean equals(Object),"/**
 * An ATN configuration is equal to another if both have
 *  the same state, they predict the same alternative, and
 *  syntactic/semantic contexts are the same.
 */
@Override
public boolean equals(Object o) {
    if (!(o instanceof ATNConfig)) {
        return false;
    }
    return this.equals((ATNConfig) o);
}","/**
 * An ATN configuration is equal to another if both have
 *  the same state, they predict the same alternative, and
 *  syntactic/semantic contexts are the same.
 */
", ,"/** * An ATN configuration is equal to another if both have *  the same state, they predict the same alternative, and *  syntactic/semantic contexts are the same. */",155,162,[0],0,[0],0,[0],0,0,0,0,equals(Object),org.antlr.v4.runtime.atn.ATNConfig,equals/1[java.lang.Object],False,156,1,1,0,1,2,1,6,2,0,1,1,1,2,0,0,0,1,0,0,0,0,1,0,0,0,25,1,0,True
350,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\atn\ATNConfig.java,org.antlr.v4.runtime.atn.ATNConfig,"String toString(Recognizer<?, ?>, boolean)","public String toString(Recognizer<?, ?> recog, boolean showAlt) {
    StringBuilder buf = new StringBuilder();
    // if ( state.ruleIndex>=0 ) {
    // if ( recog!=null ) buf.append(recog.getRuleNames()[state.ruleIndex]+"":"");
    // else buf.append(state.ruleIndex+"":"");
    // }
    buf.append('(');
    buf.append(state);
    if (showAlt) {
        buf.append("","");
        buf.append(alt);
    }
    if (context != null) {
        buf.append("",["");
        buf.append(context.toString());
        buf.append(""]"");
    }
    if (semanticContext != null && semanticContext != SemanticContext.Empty.Instance) {
        buf.append("","");
        buf.append(semanticContext);
    }
    if (getOuterContextDepth() > 0) {
        buf.append("",up="").append(getOuterContextDepth());
    }
    buf.append(')');
    return buf.toString();
}", ,"// if ( state.ruleIndex>=0 ) {
[[SEP]]// if ( recog!=null ) buf.append(recog.getRuleNames()[state.ruleIndex]+"":"");
[[SEP]]// else buf.append(state.ruleIndex+"":"");
[[SEP]]// }
","// if ( state.ruleIndex>=0 ) {// if ( recog!=null ) buf.append(recog.getRuleNames()[state.ruleIndex]+"":"");// else buf.append(state.ruleIndex+"":"");// }",195,221,[0],0,"[0, 0, 0, 0]",0,[0],0,0,0,0,"toString(Recognizer<?, ?>, boolean)",org.antlr.v4.runtime.atn.ATNConfig,"toString/2[org.antlr.v4.runtime.Recognizer<?,?>,boolean]",False,195,2,6,5,1,6,7,23,1,1,2,7,1,1,0,3,0,0,5,1,1,0,1,0,0,0,15,1,0,False
351,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\atn\ATNConfigSet.java,org.antlr.v4.runtime.atn.ATNConfigSet,"boolean add(ATNConfig, DoubleKeyMap<PredictionContext, PredictionContext, PredictionContext>)","/**
 * Adding a new config means merging contexts with existing configs for
 * {@code (s, i, pi, _)}, where {@code s} is the
 * {@link ATNConfig#state}, {@code i} is the {@link ATNConfig#alt}, and
 * {@code pi} is the {@link ATNConfig#semanticContext}. We use
 * {@code (s,i,pi)} as key.
 *
 * <p>This method updates {@link #dipsIntoOuterContext} and
 * {@link #hasSemanticContext} when necessary.</p>
 */
public boolean add(ATNConfig config, DoubleKeyMap<PredictionContext, PredictionContext, PredictionContext> mergeCache) {
    if (readonly)
        throw new IllegalStateException(""This set is readonly"");
    if (config.semanticContext != SemanticContext.Empty.Instance) {
        hasSemanticContext = true;
    }
    if (config.getOuterContextDepth() > 0) {
        dipsIntoOuterContext = true;
    }
    ATNConfig existing = configLookup.getOrAdd(config);
    if (existing == config) {
        // we added this new one
        cachedHashCode = -1;
        // track order here
        configs.add(config);
        return true;
    }
    // a previous (s,i,pi,_), merge with it and save result
    boolean rootIsWildcard = !fullCtx;
    PredictionContext merged = PredictionContext.merge(existing.context, config.context, rootIsWildcard, mergeCache);
    // no need to check for existing.context, config.context in cache
    // since only way to create new graphs is ""call rule"" and here. We
    // cache at both places.
    existing.reachesIntoOuterContext = Math.max(existing.reachesIntoOuterContext, config.reachesIntoOuterContext);
    // make sure to preserve the precedence filter suppression during the merge
    if (config.isPrecedenceFilterSuppressed()) {
        existing.setPrecedenceFilterSuppressed(true);
    }
    // replace context; no need to alt mapping
    existing.context = merged;
    return true;
}","/**
 * Adding a new config means merging contexts with existing configs for
 * {@code (s, i, pi, _)}, where {@code s} is the
 * {@link ATNConfig#state}, {@code i} is the {@link ATNConfig#alt}, and
 * {@code pi} is the {@link ATNConfig#semanticContext}. We use
 * {@code (s,i,pi)} as key.
 *
 * <p>This method updates {@link #dipsIntoOuterContext} and
 * {@link #hasSemanticContext} when necessary.</p>
 */
","// no need to check for existing.context, config.context in cache
[[SEP]]// since only way to create new graphs is ""call rule"" and here. We
[[SEP]]// we added this new one
[[SEP]]// track order here
[[SEP]]// a previous (s,i,pi,_), merge with it and save result
[[SEP]]// cache at both places.
[[SEP]]// make sure to preserve the precedence filter suppression during the merge
[[SEP]]// replace context; no need to alt mapping
","/** * Adding a new config means merging contexts with existing configs for * {@code (s, i, pi, _)}, where {@code s} is the * {@link ATNConfig#state}, {@code i} is the {@link ATNConfig#alt}, and * {@code pi} is the {@link ATNConfig#semanticContext}. We use * {@code (s,i,pi)} as key. * * <p>This method updates {@link #dipsIntoOuterContext} and * {@link #hasSemanticContext} when necessary.</p> */[[SEP]]// we added this new one[[SEP]]// track order here[[SEP]]// a previous (s,i,pi,_), merge with it and save result[[SEP]]// no need to check for existing.context, config.context in cache// since only way to create new graphs is ""call rule"" and here. We// cache at both places.[[SEP]]// make sure to preserve the precedence filter suppression during the merge[[SEP]]// replace context; no need to alt mapping",135,169,[0],0,"[0, 0, 0, 0, 0, 0, 0, 0]",0,"[0, 0, 0, 0, 0, 0, 0]",0,0,0,0,"add(ATNConfig, DoubleKeyMap<PredictionContext, PredictionContext, PredictionContext>)",org.antlr.v4.runtime.atn.ATNConfigSet,"add/2[org.antlr.v4.runtime.atn.ATNConfig,org.antlr.v4.runtime.misc.DoubleKeyMap<org.antlr.v4.runtime.atn.PredictionContext,org.antlr.v4.runtime.atn.PredictionContext,org.antlr.v4.runtime.atn.PredictionContext>]",False,138,4,11,6,5,6,7,23,2,3,2,7,0,0,0,2,0,0,1,2,8,0,1,0,0,0,54,1,0,True
352,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\atn\ATNConfigSet.java,org.antlr.v4.runtime.atn.ATNConfigSet,List<ATNConfig> elements(),"/**
 * Return a List holding list of configs
 */
public List<ATNConfig> elements() {
    return configs;
}","/**
 * Return a List holding list of configs
 */
", ,/** * Return a List holding list of configs */,172,172,[0],0,[0],0,[0],0,0,0,0,elements(),org.antlr.v4.runtime.atn.ATNConfigSet,elements/0,False,172,1,1,1,0,1,0,3,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,8,1,0,True
353,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\atn\ATNConfigSet.java,org.antlr.v4.runtime.atn.ATNConfigSet,void optimizeConfigs(ATNSimulator),"public void optimizeConfigs(ATNSimulator interpreter) {
    if (readonly)
        throw new IllegalStateException(""This set is readonly"");
    if (configLookup.isEmpty())
        return;
    for (ATNConfig config : configs) {
        // int before = PredictionContext.getAllContextNodes(config.context).size();
        config.context = interpreter.getCachedContext(config.context);
        // int after = PredictionContext.getAllContextNodes(config.context).size();
        // System.out.println(""configs ""+before+""->""+after);
    }
}", ,"// int after = PredictionContext.getAllContextNodes(config.context).size();
[[SEP]]// System.out.println(""configs ""+before+""->""+after);
[[SEP]]// int before = PredictionContext.getAllContextNodes(config.context).size();
","// int before = PredictionContext.getAllContextNodes(config.context).size();[[SEP]]// int after = PredictionContext.getAllContextNodes(config.context).size();// System.out.println(""configs ""+before+""->""+after);",211,221,[0],0,"[0, 0, 0]",0,"[0, 0]",0,0,0,0,optimizeConfigs(ATNSimulator),org.antlr.v4.runtime.atn.ATNConfigSet,optimizeConfigs/1[org.antlr.v4.runtime.atn.ATNSimulator],False,211,2,3,1,2,4,2,7,1,0,1,2,0,0,1,0,0,0,1,0,1,0,1,0,0,0,16,1,0,False
354,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\atn\ATNConfigSet.java,org.antlr.v4.runtime.atn.ATNConfigSet,boolean equals(Object),"@Override
public boolean equals(Object o) {
    if (o == this) {
        return true;
    } else if (!(o instanceof ATNConfigSet)) {
        return false;
    }
    // System.out.print(""equals "" + this + "", "" + o+"" = "");
    ATNConfigSet other = (ATNConfigSet) o;
    boolean same = configs != null && // includes stack context
    configs.equals(other.configs) && this.fullCtx == other.fullCtx && this.uniqueAlt == other.uniqueAlt && this.conflictingAlts == other.conflictingAlts && this.hasSemanticContext == other.hasSemanticContext && this.dipsIntoOuterContext == other.dipsIntoOuterContext;
    // System.out.println(same);
    return same;
}", ,"// System.out.print(""equals "" + this + "", "" + o+"" = "");
[[SEP]]// includes stack context
[[SEP]]// System.out.println(same);
","// System.out.print(""equals "" + this + "", "" + o+"" = "");[[SEP]]// includes stack context[[SEP]]// System.out.println(same);",229,250,[0],0,"[0, 0, 0]",0,"[0, 0, 0]",0,0,0,0,equals(Object),org.antlr.v4.runtime.atn.ATNConfigSet,equals/1[java.lang.Object],False,230,1,1,1,0,9,1,11,3,2,1,1,0,0,0,7,0,1,0,0,2,0,1,0,0,0,14,1,0,False
355,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\atn\ATNConfigSet.java,org.antlr.v4.runtime.atn.ATNConfigSet,void setReadonly(boolean),"public void setReadonly(boolean readonly) {
    this.readonly = readonly;
    // can't mod, no need for lookup cache
    configLookup = null;
}", ,"// can't mod, no need for lookup cache
","// can't mod, no need for lookup cache",309,312,[0],0,[0],0,[0],0,0,0,0,setReadonly(boolean),org.antlr.v4.runtime.atn.ATNConfigSet,setReadonly/1[boolean],False,309,0,2,2,0,1,0,4,0,0,1,0,0,0,0,0,0,0,0,0,2,0,0,0,0,0,6,1,0,False
356,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\atn\ATNDeserializer.java,org.antlr.v4.runtime.atn.ATNDeserializer,ATN deserialize(int[]),"public ATN deserialize(int[] data) {
    int p = 0;
    int version = data[p++];
    if (version != SERIALIZED_VERSION) {
        String reason = String.format(Locale.getDefault(), ""Could not deserialize ATN with version %d (expected %d)."", version, SERIALIZED_VERSION);
        throw new UnsupportedOperationException(new InvalidClassException(ATN.class.getName(), reason));
    }
    ATNType grammarType = ATNType.values()[data[p++]];
    int maxTokenType = data[p++];
    ATN atn = new ATN(grammarType, maxTokenType);
    // 
    // STATES
    // 
    List<Pair<LoopEndState, Integer>> loopBackStateNumbers = new ArrayList<Pair<LoopEndState, Integer>>();
    List<Pair<BlockStartState, Integer>> endStateNumbers = new ArrayList<Pair<BlockStartState, Integer>>();
    int nstates = data[p++];
    for (int i = 0; i < nstates; i++) {
        int stype = data[p++];
        // ignore bad type of states
        if (stype == ATNState.INVALID_TYPE) {
            atn.addState(null);
            continue;
        }
        int ruleIndex = data[p++];
        ATNState s = stateFactory(stype, ruleIndex);
        if (stype == ATNState.LOOP_END) {
            // special case
            int loopBackStateNumber = data[p++];
            loopBackStateNumbers.add(new Pair<LoopEndState, Integer>((LoopEndState) s, loopBackStateNumber));
        } else if (s instanceof BlockStartState) {
            int endStateNumber = data[p++];
            endStateNumbers.add(new Pair<BlockStartState, Integer>((BlockStartState) s, endStateNumber));
        }
        atn.addState(s);
    }
    // delay the assignment of loop back and end states until we know all the state instances have been initialized
    for (Pair<LoopEndState, Integer> pair : loopBackStateNumbers) {
        pair.a.loopBackState = atn.states.get(pair.b);
    }
    for (Pair<BlockStartState, Integer> pair : endStateNumbers) {
        pair.a.endState = (BlockEndState) atn.states.get(pair.b);
    }
    int numNonGreedyStates = data[p++];
    for (int i = 0; i < numNonGreedyStates; i++) {
        int stateNumber = data[p++];
        ((DecisionState) atn.states.get(stateNumber)).nonGreedy = true;
    }
    int numPrecedenceStates = data[p++];
    for (int i = 0; i < numPrecedenceStates; i++) {
        int stateNumber = data[p++];
        ((RuleStartState) atn.states.get(stateNumber)).isLeftRecursiveRule = true;
    }
    // 
    // RULES
    // 
    int nrules = data[p++];
    if (atn.grammarType == ATNType.LEXER) {
        atn.ruleToTokenType = new int[nrules];
    }
    atn.ruleToStartState = new RuleStartState[nrules];
    for (int i = 0; i < nrules; i++) {
        int s = data[p++];
        RuleStartState startState = (RuleStartState) atn.states.get(s);
        atn.ruleToStartState[i] = startState;
        if (atn.grammarType == ATNType.LEXER) {
            int tokenType = data[p++];
            atn.ruleToTokenType[i] = tokenType;
        }
    }
    atn.ruleToStopState = new RuleStopState[nrules];
    for (ATNState state : atn.states) {
        if (!(state instanceof RuleStopState)) {
            continue;
        }
        RuleStopState stopState = (RuleStopState) state;
        atn.ruleToStopState[state.ruleIndex] = stopState;
        atn.ruleToStartState[state.ruleIndex].stopState = stopState;
    }
    // 
    // MODES
    // 
    int nmodes = data[p++];
    for (int i = 0; i < nmodes; i++) {
        int s = data[p++];
        atn.modeToStartState.add((TokensStartState) atn.states.get(s));
    }
    // 
    // SETS
    // 
    List<IntervalSet> sets = new ArrayList<IntervalSet>();
    p = deserializeSets(data, p, sets);
    // 
    // EDGES
    // 
    int nedges = data[p++];
    for (int i = 0; i < nedges; i++) {
        int src = data[p];
        int trg = data[p + 1];
        int ttype = data[p + 2];
        int arg1 = data[p + 3];
        int arg2 = data[p + 4];
        int arg3 = data[p + 5];
        Transition trans = edgeFactory(atn, ttype, src, trg, arg1, arg2, arg3, sets);
        // System.out.println(""EDGE ""+trans.getClass().getSimpleName()+"" ""+
        // src+""->""+trg+
        // "" ""+Transition.serializationNames[ttype]+
        // "" ""+arg1+"",""+arg2+"",""+arg3);
        ATNState srcState = atn.states.get(src);
        srcState.addTransition(trans);
        p += 6;
    }
    // edges for rule stop states can be derived, so they aren't serialized
    for (ATNState state : atn.states) {
        for (int i = 0; i < state.getNumberOfTransitions(); i++) {
            Transition t = state.transition(i);
            if (!(t instanceof RuleTransition)) {
                continue;
            }
            RuleTransition ruleTransition = (RuleTransition) t;
            int outermostPrecedenceReturn = -1;
            if (atn.ruleToStartState[ruleTransition.target.ruleIndex].isLeftRecursiveRule) {
                if (ruleTransition.precedence == 0) {
                    outermostPrecedenceReturn = ruleTransition.target.ruleIndex;
                }
            }
            EpsilonTransition returnTransition = new EpsilonTransition(ruleTransition.followState, outermostPrecedenceReturn);
            atn.ruleToStopState[ruleTransition.target.ruleIndex].addTransition(returnTransition);
        }
    }
    for (ATNState state : atn.states) {
        if (state instanceof BlockStartState) {
            // we need to know the end state to set its start state
            if (((BlockStartState) state).endState == null) {
                throw new IllegalStateException();
            }
            // block end states can only be associated to a single block start state
            if (((BlockStartState) state).endState.startState != null) {
                throw new IllegalStateException();
            }
            ((BlockStartState) state).endState.startState = (BlockStartState) state;
        }
        if (state instanceof PlusLoopbackState) {
            PlusLoopbackState loopbackState = (PlusLoopbackState) state;
            for (int i = 0; i < loopbackState.getNumberOfTransitions(); i++) {
                ATNState target = loopbackState.transition(i).target;
                if (target instanceof PlusBlockStartState) {
                    ((PlusBlockStartState) target).loopBackState = loopbackState;
                }
            }
        } else if (state instanceof StarLoopbackState) {
            StarLoopbackState loopbackState = (StarLoopbackState) state;
            for (int i = 0; i < loopbackState.getNumberOfTransitions(); i++) {
                ATNState target = loopbackState.transition(i).target;
                if (target instanceof StarLoopEntryState) {
                    ((StarLoopEntryState) target).loopBackState = loopbackState;
                }
            }
        }
    }
    // 
    // DECISIONS
    // 
    int ndecisions = data[p++];
    for (int i = 1; i <= ndecisions; i++) {
        int s = data[p++];
        DecisionState decState = (DecisionState) atn.states.get(s);
        atn.decisionToState.add(decState);
        decState.decision = i - 1;
    }
    // 
    // LEXER ACTIONS
    // 
    if (atn.grammarType == ATNType.LEXER) {
        atn.lexerActions = new LexerAction[data[p++]];
        for (int i = 0; i < atn.lexerActions.length; i++) {
            LexerActionType actionType = LexerActionType.values()[data[p++]];
            int data1 = data[p++];
            int data2 = data[p++];
            LexerAction lexerAction = lexerActionFactory(actionType, data1, data2);
            atn.lexerActions[i] = lexerAction;
        }
    }
    markPrecedenceDecisions(atn);
    if (deserializationOptions.isVerifyATN()) {
        verifyATN(atn);
    }
    if (deserializationOptions.isGenerateRuleBypassTransitions() && atn.grammarType == ATNType.PARSER) {
        atn.ruleToTokenType = new int[atn.ruleToStartState.length];
        for (int i = 0; i < atn.ruleToStartState.length; i++) {
            atn.ruleToTokenType[i] = atn.maxTokenType + i + 1;
        }
        for (int i = 0; i < atn.ruleToStartState.length; i++) {
            BasicBlockStartState bypassStart = new BasicBlockStartState();
            bypassStart.ruleIndex = i;
            atn.addState(bypassStart);
            BlockEndState bypassStop = new BlockEndState();
            bypassStop.ruleIndex = i;
            atn.addState(bypassStop);
            bypassStart.endState = bypassStop;
            atn.defineDecisionState(bypassStart);
            bypassStop.startState = bypassStart;
            ATNState endState;
            Transition excludeTransition = null;
            if (atn.ruleToStartState[i].isLeftRecursiveRule) {
                // wrap from the beginning of the rule to the StarLoopEntryState
                endState = null;
                for (ATNState state : atn.states) {
                    if (state.ruleIndex != i) {
                        continue;
                    }
                    if (!(state instanceof StarLoopEntryState)) {
                        continue;
                    }
                    ATNState maybeLoopEndState = state.transition(state.getNumberOfTransitions() - 1).target;
                    if (!(maybeLoopEndState instanceof LoopEndState)) {
                        continue;
                    }
                    if (maybeLoopEndState.epsilonOnlyTransitions && maybeLoopEndState.transition(0).target instanceof RuleStopState) {
                        endState = state;
                        break;
                    }
                }
                if (endState == null) {
                    throw new UnsupportedOperationException(""Couldn't identify final state of the precedence rule prefix section."");
                }
                excludeTransition = ((StarLoopEntryState) endState).loopBackState.transition(0);
            } else {
                endState = atn.ruleToStopState[i];
            }
            // all non-excluded transitions that currently target end state need to target blockEnd instead
            for (ATNState state : atn.states) {
                for (Transition transition : state.transitions) {
                    if (transition == excludeTransition) {
                        continue;
                    }
                    if (transition.target == endState) {
                        transition.target = bypassStop;
                    }
                }
            }
            // all transitions leaving the rule start state need to leave blockStart instead
            while (atn.ruleToStartState[i].getNumberOfTransitions() > 0) {
                Transition transition = atn.ruleToStartState[i].removeTransition(atn.ruleToStartState[i].getNumberOfTransitions() - 1);
                bypassStart.addTransition(transition);
            }
            // link the new states
            atn.ruleToStartState[i].addTransition(new EpsilonTransition(bypassStart));
            bypassStop.addTransition(new EpsilonTransition(endState));
            ATNState matchState = new BasicState();
            atn.addState(matchState);
            matchState.addTransition(new AtomTransition(bypassStop, atn.ruleToTokenType[i]));
            bypassStart.addTransition(new EpsilonTransition(matchState));
        }
        if (deserializationOptions.isVerifyATN()) {
            // reverify after modification
            verifyATN(atn);
        }
    }
    return atn;
}", ,"// 
[[SEP]]// STATES
[[SEP]]// 
[[SEP]]// RULES
[[SEP]]// 
[[SEP]]// MODES
[[SEP]]// 
[[SEP]]// SETS
[[SEP]]// 
[[SEP]]// EDGES
[[SEP]]// 
[[SEP]]// DECISIONS
[[SEP]]// 
[[SEP]]// LEXER ACTIONS
[[SEP]]// 
[[SEP]]// ignore bad type of states
[[SEP]]// special case
[[SEP]]// delay the assignment of loop back and end states until we know all the state instances have been initialized
[[SEP]]// 
[[SEP]]// 
[[SEP]]// 
[[SEP]]// 
[[SEP]]// System.out.println(""EDGE ""+trans.getClass().getSimpleName()+"" ""+
[[SEP]]// src+""->""+trg+
[[SEP]]// "" ""+Transition.serializationNames[ttype]+
[[SEP]]// "" ""+arg1+"",""+arg2+"",""+arg3);
[[SEP]]// edges for rule stop states can be derived, so they aren't serialized
[[SEP]]// we need to know the end state to set its start state
[[SEP]]// block end states can only be associated to a single block start state
[[SEP]]// 
[[SEP]]// 
[[SEP]]// wrap from the beginning of the rule to the StarLoopEntryState
[[SEP]]// all non-excluded transitions that currently target end state need to target blockEnd instead
[[SEP]]// all transitions leaving the rule start state need to leave blockStart instead
[[SEP]]// link the new states
[[SEP]]// reverify after modification
","//// STATES//[[SEP]]// ignore bad type of states[[SEP]]// special case[[SEP]]// delay the assignment of loop back and end states until we know all the state instances have been initialized[[SEP]]//// RULES//[[SEP]]//// MODES//[[SEP]]//// SETS//[[SEP]]//// EDGES//[[SEP]]// System.out.println(""EDGE ""+trans.getClass().getSimpleName()+"" ""+// src+""->""+trg+// "" ""+Transition.serializationNames[ttype]+// "" ""+arg1+"",""+arg2+"",""+arg3);[[SEP]]// edges for rule stop states can be derived, so they aren't serialized[[SEP]]// we need to know the end state to set its start state[[SEP]]// block end states can only be associated to a single block start state[[SEP]]//// DECISIONS//[[SEP]]//// LEXER ACTIONS//[[SEP]]// wrap from the beginning of the rule to the StarLoopEntryState[[SEP]]// all non-excluded transitions that currently target end state need to target blockEnd instead[[SEP]]// all transitions leaving the rule start state need to leave blockStart instead[[SEP]]// link the new states[[SEP]]// reverify after modification",51,357,[0],0,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]",0,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]",0,0,0,0,deserialize(int[]),org.antlr.v4.runtime.atn.ATNDeserializer,deserialize/1[int[]],False,51,27,27,2,25,54,24,227,1,70,1,24,6,3,22,14,0,12,2,29,100,9,5,0,0,0,113,1,0,False
357,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\atn\ATNDeserializer.java,org.antlr.v4.runtime.atn.ATNDeserializer,void markPrecedenceDecisions(ATN),"/**
 * Analyze the {@link StarLoopEntryState} states in the specified ATN to set
 * the {@link StarLoopEntryState#isPrecedenceDecision} field to the
 * correct value.
 *
 * @param atn The ATN.
 */
protected void markPrecedenceDecisions(ATN atn) {
    for (ATNState state : atn.states) {
        if (!(state instanceof StarLoopEntryState)) {
            continue;
        }
        /* We analyze the ATN to determine if this ATN decision state is the
			 * decision for the closure block that determines whether a
			 * precedence rule should continue or complete.
			 */
        if (atn.ruleToStartState[state.ruleIndex].isLeftRecursiveRule) {
            ATNState maybeLoopEndState = state.transition(state.getNumberOfTransitions() - 1).target;
            if (maybeLoopEndState instanceof LoopEndState) {
                if (maybeLoopEndState.epsilonOnlyTransitions && maybeLoopEndState.transition(0).target instanceof RuleStopState) {
                    ((StarLoopEntryState) state).isPrecedenceDecision = true;
                }
            }
        }
    }
}","/**
 * Analyze the {@link StarLoopEntryState} states in the specified ATN to set
 * the {@link StarLoopEntryState#isPrecedenceDecision} field to the
 * correct value.
 *
 * @param atn The ATN.
 */
","/* We analyze the ATN to determine if this ATN decision state is the
			 * decision for the closure block that determines whether a
			 * precedence rule should continue or complete.
			 */
",/** * Analyze the {@link StarLoopEntryState} states in the specified ATN to set * the {@link StarLoopEntryState#isPrecedenceDecision} field to the * correct value. * * @param atn The ATN. */[[SEP]]/* We analyze the ATN to determine if this ATN decision state is the			 * decision for the closure block that determines whether a			 * precedence rule should continue or complete.			 */,388,407,[0],0,[0],0,"[0, 0]",0,0,0,0,markPrecedenceDecisions(ATN),org.antlr.v4.runtime.atn.ATNDeserializer,markPrecedenceDecisions/1[org.antlr.v4.runtime.atn.ATN],False,388,5,3,1,2,7,2,15,0,1,1,2,0,0,1,0,0,2,0,2,2,1,4,0,0,0,27,4,0,True
358,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\atn\ATNDeserializer.java,org.antlr.v4.runtime.atn.ATNDeserializer,void verifyATN(ATN),"protected void verifyATN(ATN atn) {
    // verify assumptions
    for (ATNState state : atn.states) {
        if (state == null) {
            continue;
        }
        checkCondition(state.onlyHasEpsilonTransitions() || state.getNumberOfTransitions() <= 1);
        if (state instanceof PlusBlockStartState) {
            checkCondition(((PlusBlockStartState) state).loopBackState != null);
        }
        if (state instanceof StarLoopEntryState) {
            StarLoopEntryState starLoopEntryState = (StarLoopEntryState) state;
            checkCondition(starLoopEntryState.loopBackState != null);
            checkCondition(starLoopEntryState.getNumberOfTransitions() == 2);
            if (starLoopEntryState.transition(0).target instanceof StarBlockStartState) {
                checkCondition(starLoopEntryState.transition(1).target instanceof LoopEndState);
                checkCondition(!starLoopEntryState.nonGreedy);
            } else if (starLoopEntryState.transition(0).target instanceof LoopEndState) {
                checkCondition(starLoopEntryState.transition(1).target instanceof StarBlockStartState);
                checkCondition(starLoopEntryState.nonGreedy);
            } else {
                throw new IllegalStateException();
            }
        }
        if (state instanceof StarLoopbackState) {
            checkCondition(state.getNumberOfTransitions() == 1);
            checkCondition(state.transition(0).target instanceof StarLoopEntryState);
        }
        if (state instanceof LoopEndState) {
            checkCondition(((LoopEndState) state).loopBackState != null);
        }
        if (state instanceof RuleStartState) {
            checkCondition(((RuleStartState) state).stopState != null);
        }
        if (state instanceof BlockStartState) {
            checkCondition(((BlockStartState) state).endState != null);
        }
        if (state instanceof BlockEndState) {
            checkCondition(((BlockEndState) state).startState != null);
        }
        if (state instanceof DecisionState) {
            DecisionState decisionState = (DecisionState) state;
            checkCondition(decisionState.getNumberOfTransitions() <= 1 || decisionState.decision >= 0);
        } else {
            checkCondition(state.getNumberOfTransitions() <= 1 || state instanceof RuleStopState);
        }
    }
}", ,"// verify assumptions
",// verify assumptions,409,469,[0],0,[0],0,[0],0,0,0,0,verifyATN(ATN),org.antlr.v4.runtime.atn.ATNDeserializer,verifyATN/1[org.antlr.v4.runtime.atn.ATN],False,409,13,5,1,4,13,4,50,0,2,1,4,1,2,1,9,0,5,0,11,2,0,3,0,0,0,25,4,0,False
359,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\atn\ATNDeserializer.java,org.antlr.v4.runtime.atn.ATNDeserializer,IntegerList encodeIntsWith16BitWords(IntegerList),"/**
 * Given a list of integers representing a serialized ATN, encode values too large to fit into 15 bits
 *  as two 16bit values. We use the high bit (0x8000_0000) to indicate values requiring two 16 bit words.
 *  If the high bit is set, we grab the next value and combine them to get a 31-bit value. The possible
 *  input int values are [-1,0x7FFF_FFFF].
 *
 * 		| compression/encoding                         | uint16 count | type            |
 * 		| -------------------------------------------- | ------------ | --------------- |
 * 		| 0xxxxxxx xxxxxxxx                            | 1            | uint (15 bit)   |
 * 		| 1xxxxxxx xxxxxxxx yyyyyyyy yyyyyyyy          | 2            | uint (16+ bits) |
 * 		| 11111111 11111111 11111111 11111111          | 2            | int value -1    |
 *
 * 	This is only used (other than for testing) by {@link org.antlr.v4.codegen.model.SerializedJavaATN}
 * 	to encode ints as char values for the java target, but it is convenient to combine it with the
 * 	#decodeIntsEncodedAs16BitWords that follows as they are a pair (I did not want to introduce a new class
 * 	into the runtime). Used only for Java Target.
 */
public static IntegerList encodeIntsWith16BitWords(IntegerList data) {
    IntegerList data16 = new IntegerList((int) (data.size() * 1.5));
    for (int i = 0; i < data.size(); i++) {
        int v = data.get(i);
        if (v == -1) {
            // use two max uint16 for -1
            data16.add(0xFFFF);
            data16.add(0xFFFF);
        } else if (v <= 0x7FFF) {
            data16.add(v);
        } else {
            // v > 0x7FFF
            if (v >= 0x7FFF_FFFF) {
                // too big to fit in 15 bits + 16 bits? (+1 would be 8000_0000 which is bad encoding)
                throw new UnsupportedOperationException(""Serialized ATN data element["" + i + ""] = "" + v + "" doesn't fit in 31 bits"");
            }
            // strip high bit (sentinel) if set
            v = v & 0x7FFF_FFFF;
            // store high 15-bit word first and set high bit to say word follows
            data16.add((v >> 16) | 0x8000);
            // then store lower 16-bit word
            data16.add((v & 0xFFFF));
        }
    }
    return data16;
}","/**
 * Given a list of integers representing a serialized ATN, encode values too large to fit into 15 bits
 *  as two 16bit values. We use the high bit (0x8000_0000) to indicate values requiring two 16 bit words.
 *  If the high bit is set, we grab the next value and combine them to get a 31-bit value. The possible
 *  input int values are [-1,0x7FFF_FFFF].
 *
 * 		| compression/encoding                         | uint16 count | type            |
 * 		| -------------------------------------------- | ------------ | --------------- |
 * 		| 0xxxxxxx xxxxxxxx                            | 1            | uint (15 bit)   |
 * 		| 1xxxxxxx xxxxxxxx yyyyyyyy yyyyyyyy          | 2            | uint (16+ bits) |
 * 		| 11111111 11111111 11111111 11111111          | 2            | int value -1    |
 *
 * 	This is only used (other than for testing) by {@link org.antlr.v4.codegen.model.SerializedJavaATN}
 * 	to encode ints as char values for the java target, but it is convenient to combine it with the
 * 	#decodeIntsEncodedAs16BitWords that follows as they are a pair (I did not want to introduce a new class
 * 	into the runtime). Used only for Java Target.
 */
","// use two max uint16 for -1
[[SEP]]// v > 0x7FFF
[[SEP]]// too big to fit in 15 bits + 16 bits? (+1 would be 8000_0000 which is bad encoding)
[[SEP]]// strip high bit (sentinel) if set
[[SEP]]// store high 15-bit word first and set high bit to say word follows
[[SEP]]// then store lower 16-bit word
","/** * Given a list of integers representing a serialized ATN, encode values too large to fit into 15 bits *  as two 16bit values. We use the high bit (0x8000_0000) to indicate values requiring two 16 bit words. *  If the high bit is set, we grab the next value and combine them to get a 31-bit value. The possible *  input int values are [-1,0x7FFF_FFFF]. * * 		| compression/encoding                         | uint16 count | type            | * 		| -------------------------------------------- | ------------ | --------------- | * 		| 0xxxxxxx xxxxxxxx                            | 1            | uint (15 bit)   | * 		| 1xxxxxxx xxxxxxxx yyyyyyyy yyyyyyyy          | 2            | uint (16+ bits) | * 		| 11111111 11111111 11111111 11111111          | 2            | int value -1    | * * 	This is only used (other than for testing) by {@link org.antlr.v4.codegen.model.SerializedJavaATN} * 	to encode ints as char values for the java target, but it is convenient to combine it with the * 	#decodeIntsEncodedAs16BitWords that follows as they are a pair (I did not want to introduce a new class * 	into the runtime). Used only for Java Target. */[[SEP]]// use two max uint16 for -1[[SEP]]// v > 0x7FFF[[SEP]]// too big to fit in 15 bits + 16 bits? (+1 would be 8000_0000 which is bad encoding)[[SEP]]// strip high bit (sentinel) if set[[SEP]]// store high 15-bit word first and set high bit to say word follows[[SEP]]// then store lower 16-bit word",606,627,[0],0,"[0, 0, 1, 0, 0, 0]",1,"[0, 0, 0, 1, 0, 0, 0]",1,0,1,0,encodeIntsWith16BitWords(IntegerList),org.antlr.v4.runtime.atn.ATNDeserializer,encodeIntsWith16BitWords/1[org.antlr.v4.runtime.misc.IntegerList],False,606,1,5,1,4,5,3,22,1,3,1,3,0,0,1,1,0,3,3,11,4,3,3,0,0,0,97,9,0,True
360,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\atn\ATNDeserializer.java,org.antlr.v4.runtime.atn.ATNDeserializer,"int[] decodeIntsEncodedAs16BitWords(char[], boolean)","/**
 * Convert a list of chars (16 uint) that represent a serialized and compressed list of ints for an ATN.
 *  This method pairs with {@link #encodeIntsWith16BitWords(IntegerList)} above. Used only for Java Target.
 */
public static int[] decodeIntsEncodedAs16BitWords(char[] data16, boolean trimToSize) {
    // will be strictly smaller but we waste bit of space to avoid copying during initialization of parsers
    int[] data = new int[data16.length];
    int i = 0;
    int i2 = 0;
    while (i < data16.length) {
        char v = data16[i++];
        if ((v & 0x8000) == 0) {
            // hi bit not set? Implies 1-word value
            // 7 bit int
            data[i2++] = v;
        } else {
            // hi bit set. Implies 2-word value
            char vnext = data16[i++];
            if (v == 0xFFFF && vnext == 0xFFFF) {
                // is it -1?
                data[i2++] = -1;
            } else {
                // 31-bit int
                data[i2++] = (v & 0x7FFF) << 16 | (vnext & 0xFFFF);
            }
        }
    }
    if (trimToSize) {
        return Arrays.copyOf(data, i2);
    }
    return data;
}","/**
 * Convert a list of chars (16 uint) that represent a serialized and compressed list of ints for an ATN.
 *  This method pairs with {@link #encodeIntsWith16BitWords(IntegerList)} above. Used only for Java Target.
 */
","// will be strictly smaller but we waste bit of space to avoid copying during initialization of parsers
[[SEP]]// hi bit not set? Implies 1-word value
[[SEP]]// 7 bit int
[[SEP]]// hi bit set. Implies 2-word value
[[SEP]]// is it -1?
[[SEP]]// 31-bit int
",/** * Convert a list of chars (16 uint) that represent a serialized and compressed list of ints for an ATN. *  This method pairs with {@link #encodeIntsWith16BitWords(IntegerList)} above. Used only for Java Target. */[[SEP]]// will be strictly smaller but we waste bit of space to avoid copying during initialization of parsers[[SEP]]// hi bit not set? Implies 1-word value// 7 bit int[[SEP]]// hi bit set. Implies 2-word value[[SEP]]// is it -1?[[SEP]]// 31-bit int,636,660,[0],0,"[0, 0, 0, 0, 0, 0]",0,"[0, 0, 0, 0, 0, 0]",0,0,0,0,"decodeIntsEncodedAs16BitWords(char[], boolean)",org.antlr.v4.runtime.atn.ATNDeserializer,"decodeIntsEncodedAs16BitWords/2[char[],boolean]",False,636,2,1,1,0,7,1,24,2,5,2,1,0,0,1,3,0,3,0,10,8,1,3,0,0,0,40,9,0,True
361,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\atn\ATNSerializer.java,org.antlr.v4.runtime.atn.ATNSerializer,IntegerList serialize(),"/**
 *  Serialize state descriptors, edge descriptors, and decision&rarr;state map
 *   into list of ints.  Likely out of date, but keeping as it could be helpful:
 *
 *       SERIALIZED_VERSION
 *       UUID (2 longs)
 *  		grammar-type, (ANTLRParser.LEXER, ...)
 *   	max token type,
 *   	num states,
 *   	state-0-type ruleIndex, state-1-type ruleIndex, ... state-i-type ruleIndex optional-arg ...
 *   	num rules,
 *   	rule-1-start-state rule-1-args, rule-2-start-state  rule-2-args, ...
 *   	(args are token type,actionIndex in lexer else 0,0)
 *       num modes,
 *       mode-0-start-state, mode-1-start-state, ... (parser has 0 modes)
 *       num unicode-bmp-sets
 *       bmp-set-0-interval-count intervals, bmp-set-1-interval-count intervals, ...
 *       num unicode-smp-sets
 *       smp-set-0-interval-count intervals, smp-set-1-interval-count intervals, ...
 * 	num total edges,
 *       src, trg, edge-type, edge arg1, optional edge arg2 (present always), ...
 *       num decisions,
 *       decision-0-start-state, decision-1-start-state, ...
 *
 *   Convenient to pack into unsigned shorts to make as Java string.
 */
public IntegerList serialize() {
    addPreamble();
    int nedges = addEdges();
    addNonGreedyStates();
    addPrecedenceStates();
    addRuleStatesAndLexerTokenTypes();
    addModeStartStates();
    Map<IntervalSet, Integer> setIndices = null;
    setIndices = addSets();
    addEdges(nedges, setIndices);
    addDecisionStartStates();
    addLexerActions();
    return data;
}","/**
 *  Serialize state descriptors, edge descriptors, and decision&rarr;state map
 *   into list of ints.  Likely out of date, but keeping as it could be helpful:
 *
 *       SERIALIZED_VERSION
 *       UUID (2 longs)
 *  		grammar-type, (ANTLRParser.LEXER, ...)
 *   	max token type,
 *   	num states,
 *   	state-0-type ruleIndex, state-1-type ruleIndex, ... state-i-type ruleIndex optional-arg ...
 *   	num rules,
 *   	rule-1-start-state rule-1-args, rule-2-start-state  rule-2-args, ...
 *   	(args are token type,actionIndex in lexer else 0,0)
 *       num modes,
 *       mode-0-start-state, mode-1-start-state, ... (parser has 0 modes)
 *       num unicode-bmp-sets
 *       bmp-set-0-interval-count intervals, bmp-set-1-interval-count intervals, ...
 *       num unicode-smp-sets
 *       smp-set-0-interval-count intervals, smp-set-1-interval-count intervals, ...
 * 	num total edges,
 *       src, trg, edge-type, edge arg1, optional edge arg2 (present always), ...
 *       num decisions,
 *       decision-0-start-state, decision-1-start-state, ...
 *
 *   Convenient to pack into unsigned shorts to make as Java string.
 */
", ,"/** *  Serialize state descriptors, edge descriptors, and decision&rarr;state map *   into list of ints.  Likely out of date, but keeping as it could be helpful: * *       SERIALIZED_VERSION *       UUID (2 longs) *  		grammar-type, (ANTLRParser.LEXER, ...) *   	max token type, *   	num states, *   	state-0-type ruleIndex, state-1-type ruleIndex, ... state-i-type ruleIndex optional-arg ... *   	num rules, *   	rule-1-start-state rule-1-args, rule-2-start-state  rule-2-args, ... *   	(args are token type,actionIndex in lexer else 0,0) *       num modes, *       mode-0-start-state, mode-1-start-state, ... (parser has 0 modes) *       num unicode-bmp-sets *       bmp-set-0-interval-count intervals, bmp-set-1-interval-count intervals, ... *       num unicode-smp-sets *       smp-set-0-interval-count intervals, smp-set-1-interval-count intervals, ... * 	num total edges, *       src, trg, edge-type, edge arg1, optional edge arg2 (present always), ... *       num decisions, *       decision-0-start-state, decision-1-start-state, ... * *   Convenient to pack into unsigned shorts to make as Java string. */",67,81,[0],0,[0],0,[0],0,0,0,0,serialize(),org.antlr.v4.runtime.atn.ATNSerializer,serialize/0,False,67,3,11,1,10,1,10,14,1,2,0,10,10,2,0,0,0,0,0,0,3,0,0,0,0,0,93,1,0,True
362,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\atn\ATNSerializer.java,org.antlr.v4.runtime.atn.ATNSerializer,void addPreamble(),"private void addPreamble() {
    data.add(ATNDeserializer.SERIALIZED_VERSION);
    // convert grammar type to ATN const to avoid dependence on ANTLRParser
    data.add(atn.grammarType.ordinal());
    data.add(atn.maxTokenType);
}", ,"// convert grammar type to ATN const to avoid dependence on ANTLRParser
",// convert grammar type to ATN const to avoid dependence on ANTLRParser,83,89,[0],0,[0],0,[0],0,0,0,0,addPreamble(),org.antlr.v4.runtime.atn.ATNSerializer,addPreamble/0,False,83,1,2,1,1,1,2,5,0,0,0,2,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,2,0,False
363,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\atn\ATNSerializer.java,org.antlr.v4.runtime.atn.ATNSerializer,"void addEdges(int, Map<IntervalSet, Integer>)","private void addEdges(int nedges, Map<IntervalSet, Integer> setIndices) {
    data.add(nedges);
    for (ATNState s : atn.states) {
        if (s == null) {
            // might be optimized away
            continue;
        }
        if (s.getStateType() == ATNState.RULE_STOP) {
            continue;
        }
        for (int i = 0; i < s.getNumberOfTransitions(); i++) {
            Transition t = s.transition(i);
            if (atn.states.get(t.target.stateNumber) == null) {
                throw new IllegalStateException(""Cannot serialize a transition to a removed state."");
            }
            int src = s.stateNumber;
            int trg = t.target.stateNumber;
            int edgeType = Transition.serializationTypes.get(t.getClass());
            int arg1 = 0;
            int arg2 = 0;
            int arg3 = 0;
            switch(edgeType) {
                case Transition.RULE:
                    trg = ((RuleTransition) t).followState.stateNumber;
                    arg1 = ((RuleTransition) t).target.stateNumber;
                    arg2 = ((RuleTransition) t).ruleIndex;
                    arg3 = ((RuleTransition) t).precedence;
                    break;
                case Transition.PRECEDENCE:
                    PrecedencePredicateTransition ppt = (PrecedencePredicateTransition) t;
                    arg1 = ppt.precedence;
                    break;
                case Transition.PREDICATE:
                    PredicateTransition pt = (PredicateTransition) t;
                    arg1 = pt.ruleIndex;
                    arg2 = pt.predIndex;
                    arg3 = pt.isCtxDependent ? 1 : 0;
                    break;
                case Transition.RANGE:
                    arg1 = ((RangeTransition) t).from;
                    arg2 = ((RangeTransition) t).to;
                    if (arg1 == Token.EOF) {
                        arg1 = 0;
                        arg3 = 1;
                    }
                    break;
                case Transition.ATOM:
                    arg1 = ((AtomTransition) t).label;
                    if (arg1 == Token.EOF) {
                        arg1 = 0;
                        arg3 = 1;
                    }
                    break;
                case Transition.ACTION:
                    ActionTransition at = (ActionTransition) t;
                    arg1 = at.ruleIndex;
                    arg2 = at.actionIndex;
                    arg3 = at.isCtxDependent ? 1 : 0;
                    break;
                case Transition.SET:
                    arg1 = setIndices.get(((SetTransition) t).set);
                    break;
                case Transition.NOT_SET:
                    arg1 = setIndices.get(((SetTransition) t).set);
                    break;
                case Transition.WILDCARD:
                    break;
            }
            data.add(src);
            data.add(trg);
            data.add(edgeType);
            data.add(arg1);
            data.add(arg2);
            data.add(arg3);
        }
    }
}", ,"// might be optimized away
",// might be optimized away,159,240,[0],0,[0],0,[0],0,0,0,0,"addEdges(int, Map<IntervalSet, Integer>)",org.antlr.v4.runtime.atn.ATNSerializer,"addEdges/2[int,java.util.Map<org.antlr.v4.runtime.misc.IntervalSet,java.lang.Integer>]",False,159,11,5,1,4,19,8,76,0,11,2,8,0,0,2,5,0,9,1,12,31,0,4,0,0,0,38,2,0,False
364,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\atn\ATNSerializer.java,org.antlr.v4.runtime.atn.ATNSerializer,void addRuleStatesAndLexerTokenTypes(),"private void addRuleStatesAndLexerTokenTypes() {
    int nrules = atn.ruleToStartState.length;
    data.add(nrules);
    for (int r = 0; r < nrules; r++) {
        ATNState ruleStartState = atn.ruleToStartState[r];
        data.add(ruleStartState.stateNumber);
        if (atn.grammarType == ATNType.LEXER) {
            // 0 implies fragment rule, other token types > 0
            assert atn.ruleToTokenType[r] >= 0;
            data.add(atn.ruleToTokenType[r]);
        }
    }
}", ,"// 0 implies fragment rule, other token types > 0
","// 0 implies fragment rule, other token types > 0",262,273,[0],0,[0],0,[0],0,0,0,0,addRuleStatesAndLexerTokenTypes(),org.antlr.v4.runtime.atn.ATNSerializer,addRuleStatesAndLexerTokenTypes/0,False,262,2,2,1,1,3,1,12,0,3,0,1,0,0,1,1,0,0,0,2,3,0,2,0,0,0,16,2,0,False
365,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\atn\ATNSerializer.java,org.antlr.v4.runtime.atn.ATNSerializer,int addEdges(),"private int addEdges() {
    int nedges = 0;
    data.add(atn.states.size());
    for (ATNState s : atn.states) {
        if (s == null) {
            // might be optimized away
            data.add(ATNState.INVALID_TYPE);
            continue;
        }
        int stateType = s.getStateType();
        if (s instanceof DecisionState && ((DecisionState) s).nonGreedy) {
            nonGreedyStates.add(s.stateNumber);
        }
        if (s instanceof RuleStartState && ((RuleStartState) s).isLeftRecursiveRule) {
            precedenceStates.add(s.stateNumber);
        }
        data.add(stateType);
        data.add(s.ruleIndex);
        if (s.getStateType() == ATNState.LOOP_END) {
            data.add(((LoopEndState) s).loopBackState.stateNumber);
        } else if (s instanceof BlockStartState) {
            data.add(((BlockStartState) s).endState.stateNumber);
        }
        if (s.getStateType() != ATNState.RULE_STOP) {
            // the deserializer can trivially derive these edges, so there's no need to serialize them
            nedges += s.getNumberOfTransitions();
        }
        for (int i = 0; i < s.getNumberOfTransitions(); i++) {
            Transition t = s.transition(i);
            int edgeType = Transition.serializationTypes.get(t.getClass());
            if (edgeType == Transition.SET || edgeType == Transition.NOT_SET) {
                SetTransition st = (SetTransition) t;
                sets.put(st.set, true);
            }
        }
    }
    return nedges;
}", ,"// might be optimized away
[[SEP]]// the deserializer can trivially derive these edges, so there's no need to serialize them
","// might be optimized away[[SEP]]// the deserializer can trivially derive these edges, so there's no need to serialize them",289,333,[0],0,"[0, 0]",0,"[0, 0]",0,0,0,0,addEdges(),org.antlr.v4.runtime.atn.ATNSerializer,addEdges/0,False,289,8,5,1,4,13,8,37,1,6,0,8,0,0,2,5,0,4,0,2,7,0,3,0,0,0,23,2,0,False
366,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\atn\ATNSimulator.java,org.antlr.v4.runtime.atn.ATNSimulator,void clearDFA(),"/**
 * Clear the DFA cache used by the current instance. Since the DFA cache may
 * be shared by multiple ATN simulators, this method may affect the
 * performance (but not accuracy) of other parsers which are being used
 * concurrently.
 *
 * @throws UnsupportedOperationException if the current instance does not
 * support clearing the DFA.
 *
 * @since 4.3
 */
public void clearDFA() {
    throw new UnsupportedOperationException(""This ATN simulator does not support clearing the DFA."");
}","/**
 * Clear the DFA cache used by the current instance. Since the DFA cache may
 * be shared by multiple ATN simulators, this method may affect the
 * performance (but not accuracy) of other parsers which are being used
 * concurrently.
 *
 * @throws UnsupportedOperationException if the current instance does not
 * support clearing the DFA.
 *
 * @since 4.3
 */
", ,"/** * Clear the DFA cache used by the current instance. Since the DFA cache may * be shared by multiple ATN simulators, this method may affect the * performance (but not accuracy) of other parsers which are being used * concurrently. * * @throws UnsupportedOperationException if the current instance does not * support clearing the DFA. * * @since 4.3 */",69,71,[0],0,[0],0,[0],0,0,0,0,clearDFA(),org.antlr.v4.runtime.atn.ATNSimulator,clearDFA/0,False,69,0,0,0,0,1,0,3,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,38,1,0,True
367,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\atn\ATNState.java,org.antlr.v4.runtime.atn.ATNState,boolean equals(Object),"@Override
public boolean equals(Object o) {
    // are these states same object?
    if (o instanceof ATNState)
        return stateNumber == ((ATNState) o).stateNumber;
    return false;
}", ,"// are these states same object?
",// are these states same object?,133,138,[0],0,[0],0,[0],0,0,0,0,equals(Object),org.antlr.v4.runtime.atn.ATNState,equals/1[java.lang.Object],False,134,1,0,0,0,2,0,4,2,0,1,0,0,0,0,1,0,1,0,0,0,0,1,0,0,0,10,1,0,False
368,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\atn\ATNState.java,org.antlr.v4.runtime.atn.ATNState,"void addTransition(int, Transition)","public void addTransition(int index, Transition e) {
    if (transitions.isEmpty()) {
        epsilonOnlyTransitions = e.isEpsilon();
    } else if (epsilonOnlyTransitions != e.isEpsilon()) {
        System.err.format(Locale.getDefault(), ""ATN state %d has both epsilon and non-epsilon transitions.\n"", stateNumber);
        epsilonOnlyTransitions = false;
    }
    boolean alreadyPresent = false;
    for (Transition t : transitions) {
        if (t.target.stateNumber == e.target.stateNumber) {
            if (t.label() != null && e.label() != null && t.label().equals(e.label())) {
                // System.err.println(""Repeated transition upon ""+e.label()+"" from ""+stateNumber+""->""+t.target.stateNumber);
                alreadyPresent = true;
                break;
            } else if (t.isEpsilon() && e.isEpsilon()) {
                // System.err.println(""Repeated epsilon transition from ""+stateNumber+""->""+t.target.stateNumber);
                alreadyPresent = true;
                break;
            }
        }
    }
    if (!alreadyPresent) {
        transitions.add(index, e);
    }
}", ,"// System.err.println(""Repeated transition upon ""+e.label()+"" from ""+stateNumber+""->""+t.target.stateNumber);
[[SEP]]// System.err.println(""Repeated epsilon transition from ""+stateNumber+""->""+t.target.stateNumber);
","// System.err.println(""Repeated transition upon ""+e.label()+"" from ""+stateNumber+""->""+t.target.stateNumber);[[SEP]]// System.err.println(""Repeated epsilon transition from ""+stateNumber+""->""+t.target.stateNumber);",161,188,[0],0,"[0, 0]",0,"[0, 0]",0,0,0,0,"addTransition(int, Transition)",org.antlr.v4.runtime.atn.ATNState,"addTransition/2[int,org.antlr.v4.runtime.atn.Transition]",False,161,2,5,2,3,11,7,25,0,1,2,7,0,0,1,4,0,0,1,0,5,0,3,0,0,0,18,1,0,False
369,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\atn\ActionTransition.java,org.antlr.v4.runtime.atn.ActionTransition,boolean isEpsilon(),"@Override
public boolean isEpsilon() {
    // we are to be ignored by analysis 'cept for predicates
    return true;
}", ,"// we are to be ignored by analysis 'cept for predicates
",// we are to be ignored by analysis 'cept for predicates,30,33,[0],0,[0],0,[0],0,0,0,0,isEpsilon(),org.antlr.v4.runtime.atn.ActionTransition,isEpsilon/0,False,31,0,0,0,0,1,0,3,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,3,1,0,False
370,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\atn\ArrayPredictionContext.java,org.antlr.v4.runtime.atn.ArrayPredictionContext,boolean isEmpty(),"@Override
public boolean isEmpty() {
    // since EMPTY_RETURN_STATE can only appear in the last position, we
    // don't need to verify that size==1
    return returnStates[0] == EMPTY_RETURN_STATE;
}", ,"// since EMPTY_RETURN_STATE can only appear in the last position, we
[[SEP]]// don't need to verify that size==1
","// since EMPTY_RETURN_STATE can only appear in the last position, we// don't need to verify that size==1",36,41,[0],0,"[0, 0]",0,[0],0,0,0,0,isEmpty(),org.antlr.v4.runtime.atn.ArrayPredictionContext,isEmpty/0,False,37,0,1,1,0,2,0,3,1,0,0,0,0,0,0,1,0,0,0,1,0,0,0,0,0,0,13,1,0,False
371,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\atn\ArrayPredictionContext.java,org.antlr.v4.runtime.atn.ArrayPredictionContext,boolean equals(Object),"// @Override
// public int findReturnState(int returnState) {
// return Arrays.binarySearch(returnStates, returnState);
// }
@Override
public boolean equals(Object o) {
    if (this == o) {
        return true;
    } else if (!(o instanceof ArrayPredictionContext)) {
        return false;
    }
    if (this.hashCode() != o.hashCode()) {
        // can't be same if hash is different
        return false;
    }
    ArrayPredictionContext a = (ArrayPredictionContext) o;
    return Arrays.equals(returnStates, a.returnStates) && Arrays.equals(parents, a.parents);
}", ,"// can't be same if hash is different
","// @Override// public int findReturnState(int returnState) {// return Arrays.binarySearch(returnStates, returnState);// }[[SEP]]// can't be same if hash is different",63,79,[0],0,[0],0,"[0, 0]",0,0,0,0,equals(Object),org.antlr.v4.runtime.atn.ArrayPredictionContext,equals/1[java.lang.Object],False,64,2,1,0,1,4,4,13,4,1,1,4,0,0,0,2,0,1,0,0,1,0,1,0,0,0,9,1,0,False
372,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\atn\CodePointTransitions.java,org.antlr.v4.runtime.atn.CodePointTransitions,"Transition createWithCodePoint(ATNState, int)","/**
 * Return new {@link AtomTransition}
 */
public static Transition createWithCodePoint(ATNState target, int codePoint) {
    return createWithCodePointRange(target, codePoint, codePoint);
}","/**
 * Return new {@link AtomTransition}
 */
", ,/** * Return new {@link AtomTransition} */,20,22,[0],0,[0],0,[0],0,0,0,0,"createWithCodePoint(ATNState, int)",org.antlr.v4.runtime.atn.CodePointTransitions,"createWithCodePoint/2[org.antlr.v4.runtime.atn.ATNState,int]",False,20,3,2,1,1,1,1,3,1,0,2,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,13,9,0,True
373,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\atn\CodePointTransitions.java,org.antlr.v4.runtime.atn.CodePointTransitions,"Transition createWithCodePointRange(ATNState, int, int)","/**
 * Return new {@link AtomTransition} if range represents one atom else {@link SetTransition}.
 */
public static Transition createWithCodePointRange(ATNState target, int codePointFrom, int codePointTo) {
    return codePointFrom == codePointTo ? new AtomTransition(target, codePointFrom) : new RangeTransition(target, codePointFrom, codePointTo);
}","/**
 * Return new {@link AtomTransition} if range represents one atom else {@link SetTransition}.
 */
", ,/** * Return new {@link AtomTransition} if range represents one atom else {@link SetTransition}. */,25,29,[0],0,[0],0,[0],0,0,0,0,"createWithCodePointRange(ATNState, int, int)",org.antlr.v4.runtime.atn.CodePointTransitions,"createWithCodePointRange/3[org.antlr.v4.runtime.atn.ATNState,int,int]",False,25,4,6,4,2,2,0,3,1,0,3,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,20,9,0,True
374,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\atn\EpsilonTransition.java,org.antlr.v4.runtime.atn.EpsilonTransition,int outermostPrecedenceReturn(),"/**
 * @return the rule index of a precedence rule for which this transition is
 * returning from, where the precedence value is 0; otherwise, -1.
 *
 * @see ATNConfig#isPrecedenceFilterSuppressed()
 * @see ParserATNSimulator#applyPrecedenceFilter(ATNConfigSet)
 * @since 4.4.1
 */
public int outermostPrecedenceReturn() {
    return outermostPrecedenceReturn;
}","/**
 * @return the rule index of a precedence rule for which this transition is
 * returning from, where the precedence value is 0; otherwise, -1.
 *
 * @see ATNConfig#isPrecedenceFilterSuppressed()
 * @see ParserATNSimulator#applyPrecedenceFilter(ATNConfigSet)
 * @since 4.4.1
 */
", ,"/** * @return the rule index of a precedence rule for which this transition is * returning from, where the precedence value is 0; otherwise, -1. * * @see ATNConfig#isPrecedenceFilterSuppressed() * @see ParserATNSimulator#applyPrecedenceFilter(ATNConfigSet) * @since 4.4.1 */",30,32,[0],0,[0],0,[0],0,0,0,0,outermostPrecedenceReturn(),org.antlr.v4.runtime.atn.EpsilonTransition,outermostPrecedenceReturn/0,False,30,0,1,1,0,1,0,3,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,20,1,0,True
375,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\atn\LL1Analyzer.java,org.antlr.v4.runtime.atn.LL1Analyzer,IntervalSet[] getDecisionLookahead(ATNState),"/**
 * Calculates the SLL(1) expected lookahead set for each outgoing transition
 * of an {@link ATNState}. The returned array has one element for each
 * outgoing transition in {@code s}. If the closure from transition
 * <em>i</em> leads to a semantic predicate before matching a symbol, the
 * element at index <em>i</em> of the result will be {@code null}.
 *
 * @param s the ATN state
 * @return the expected symbols for each outgoing transition of {@code s}.
 */
public IntervalSet[] getDecisionLookahead(ATNState s) {
    // System.out.println(""LOOK(""+s.stateNumber+"")"");
    if (s == null) {
        return null;
    }
    IntervalSet[] look = new IntervalSet[s.getNumberOfTransitions()];
    for (int alt = 0; alt < s.getNumberOfTransitions(); alt++) {
        look[alt] = new IntervalSet();
        Set<ATNConfig> lookBusy = new HashSet<ATNConfig>();
        // fail to get lookahead upon pred
        boolean seeThruPreds = false;
        _LOOK(s.transition(alt).target, null, EmptyPredictionContext.Instance, look[alt], lookBusy, new BitSet(), seeThruPreds, false);
        // Wipe out lookahead for this alternative if we found nothing
        // or we had a predicate when we !seeThruPreds
        if (look[alt].size() == 0 || look[alt].contains(HIT_PRED)) {
            look[alt] = null;
        }
    }
    return look;
}","/**
 * Calculates the SLL(1) expected lookahead set for each outgoing transition
 * of an {@link ATNState}. The returned array has one element for each
 * outgoing transition in {@code s}. If the closure from transition
 * <em>i</em> leads to a semantic predicate before matching a symbol, the
 * element at index <em>i</em> of the result will be {@code null}.
 *
 * @param s the ATN state
 * @return the expected symbols for each outgoing transition of {@code s}.
 */
","// System.out.println(""LOOK(""+s.stateNumber+"")"");
[[SEP]]// Wipe out lookahead for this alternative if we found nothing
[[SEP]]// fail to get lookahead upon pred
[[SEP]]// or we had a predicate when we !seeThruPreds
","/** * Calculates the SLL(1) expected lookahead set for each outgoing transition * of an {@link ATNState}. The returned array has one element for each * outgoing transition in {@code s}. If the closure from transition * <em>i</em> leads to a semantic predicate before matching a symbol, the * element at index <em>i</em> of the result will be {@code null}. * * @param s the ATN state * @return the expected symbols for each outgoing transition of {@code s}. */[[SEP]]// System.out.println(""LOOK(""+s.stateNumber+"")"");[[SEP]]// fail to get lookahead upon pred[[SEP]]// Wipe out lookahead for this alternative if we found nothing// or we had a predicate when we !seeThruPreds",37,57,[0],0,"[0, 0, 0, 0]",0,"[0, 0, 0, 0]",0,0,0,0,getDecisionLookahead(ATNState),org.antlr.v4.runtime.atn.LL1Analyzer,getDecisionLookahead/1[org.antlr.v4.runtime.atn.ATNState],False,37,4,7,1,6,5,5,16,2,4,1,5,1,1,1,2,0,0,0,2,6,0,2,0,0,0,66,1,0,True
376,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\atn\LL1Analyzer.java,org.antlr.v4.runtime.atn.LL1Analyzer,"IntervalSet LOOK(ATNState, RuleContext)","/**
 * Compute set of tokens that can follow {@code s} in the ATN in the
 * specified {@code ctx}.
 *
 * <p>If {@code ctx} is {@code null} and the end of the rule containing
 * {@code s} is reached, {@link Token#EPSILON} is added to the result set.
 * If {@code ctx} is not {@code null} and the end of the outermost rule is
 * reached, {@link Token#EOF} is added to the result set.</p>
 *
 * @param s the ATN state
 * @param ctx the complete parser context, or {@code null} if the context
 * should be ignored
 *
 * @return The set of tokens that can follow {@code s} in the ATN in the
 * specified {@code ctx}.
 */
public IntervalSet LOOK(ATNState s, RuleContext ctx) {
    return LOOK(s, null, ctx);
}","/**
 * Compute set of tokens that can follow {@code s} in the ATN in the
 * specified {@code ctx}.
 *
 * <p>If {@code ctx} is {@code null} and the end of the rule containing
 * {@code s} is reached, {@link Token#EPSILON} is added to the result set.
 * If {@code ctx} is not {@code null} and the end of the outermost rule is
 * reached, {@link Token#EOF} is added to the result set.</p>
 *
 * @param s the ATN state
 * @param ctx the complete parser context, or {@code null} if the context
 * should be ignored
 *
 * @return The set of tokens that can follow {@code s} in the ATN in the
 * specified {@code ctx}.
 */
", ,"/** * Compute set of tokens that can follow {@code s} in the ATN in the * specified {@code ctx}. * * <p>If {@code ctx} is {@code null} and the end of the rule containing * {@code s} is reached, {@link Token#EPSILON} is added to the result set. * If {@code ctx} is not {@code null} and the end of the outermost rule is * reached, {@link Token#EOF} is added to the result set.</p> * * @param s the ATN state * @param ctx the complete parser context, or {@code null} if the context * should be ignored * * @return The set of tokens that can follow {@code s} in the ATN in the * specified {@code ctx}. */",75,77,[0],0,[0],0,[0],0,0,0,0,"LOOK(ATNState, RuleContext)",org.antlr.v4.runtime.atn.LL1Analyzer,"LOOK/2[org.antlr.v4.runtime.atn.ATNState,org.antlr.v4.runtime.RuleContext]",False,75,4,3,2,1,1,1,3,1,0,2,1,1,2,0,0,0,0,0,0,0,0,0,0,0,0,42,1,0,True
377,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\atn\LL1Analyzer.java,org.antlr.v4.runtime.atn.LL1Analyzer,"IntervalSet LOOK(ATNState, ATNState, RuleContext)","/**
 * Compute set of tokens that can follow {@code s} in the ATN in the
 * specified {@code ctx}.
 *
 * <p>If {@code ctx} is {@code null} and the end of the rule containing
 * {@code s} is reached, {@link Token#EPSILON} is added to the result set.
 * If {@code ctx} is not {@code null} and the end of the outermost rule is
 * reached, {@link Token#EOF} is added to the result set.</p>
 *
 * @param s the ATN state
 * @param stopState the ATN state to stop at. This can be a
 * {@link BlockEndState} to detect epsilon paths through a closure.
 * @param ctx the complete parser context, or {@code null} if the context
 * should be ignored
 *
 * @return The set of tokens that can follow {@code s} in the ATN in the
 * specified {@code ctx}.
 */
public IntervalSet LOOK(ATNState s, ATNState stopState, RuleContext ctx) {
    IntervalSet r = new IntervalSet();
    // ignore preds; get all lookahead
    boolean seeThruPreds = true;
    PredictionContext lookContext = ctx != null ? PredictionContext.fromRuleContext(s.atn, ctx) : null;
    _LOOK(s, stopState, lookContext, r, new HashSet<ATNConfig>(), new BitSet(), seeThruPreds, true);
    return r;
}", ,"// ignore preds; get all lookahead
","/** * Compute set of tokens that can follow {@code s} in the ATN in the * specified {@code ctx}. * * <p>If {@code ctx} is {@code null} and the end of the rule containing * {@code s} is reached, {@link Token#EPSILON} is added to the result set. * If {@code ctx} is not {@code null} and the end of the outermost rule is * reached, {@link Token#EOF} is added to the result set.</p> * * @param s the ATN state * @param stopState the ATN state to stop at. This can be a * {@link BlockEndState} to detect epsilon paths through a closure. * @param ctx the complete parser context, or {@code null} if the context * should be ignored * * @return The set of tokens that can follow {@code s} in the ATN in the * specified {@code ctx}. */[[SEP]]// ignore preds; get all lookahead",98,105,[0],0,[0],0,"[0, 0]",0,0,0,0,"LOOK(ATNState, ATNState, RuleContext)",org.antlr.v4.runtime.atn.LL1Analyzer,"LOOK/3[org.antlr.v4.runtime.atn.ATNState,org.antlr.v4.runtime.atn.ATNState,org.antlr.v4.runtime.RuleContext]",False,98,6,6,3,3,2,2,7,1,3,3,2,1,1,0,1,0,0,0,0,3,0,0,0,0,0,61,1,0,True
378,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\atn\LL1Analyzer.java,org.antlr.v4.runtime.atn.LL1Analyzer,"void _LOOK(ATNState, ATNState, PredictionContext, IntervalSet, Set<ATNConfig>, BitSet, boolean, boolean)","/**
 * Compute set of tokens that can follow {@code s} in the ATN in the
 * specified {@code ctx}.
 *
 * <p>If {@code ctx} is {@code null} and {@code stopState} or the end of the
 * rule containing {@code s} is reached, {@link Token#EPSILON} is added to
 * the result set. If {@code ctx} is not {@code null} and {@code addEOF} is
 * {@code true} and {@code stopState} or the end of the outermost rule is
 * reached, {@link Token#EOF} is added to the result set.</p>
 *
 * @param s the ATN state.
 * @param stopState the ATN state to stop at. This can be a
 * {@link BlockEndState} to detect epsilon paths through a closure.
 * @param ctx The outer context, or {@code null} if the outer context should
 * not be used.
 * @param look The result lookahead set.
 * @param lookBusy A set used for preventing epsilon closures in the ATN
 * from causing a stack overflow. Outside code should pass
 * {@code new HashSet<ATNConfig>} for this argument.
 * @param calledRuleStack A set used for preventing left recursion in the
 * ATN from causing a stack overflow. Outside code should pass
 * {@code new BitSet()} for this argument.
 * @param seeThruPreds {@code true} to true semantic predicates as
 * implicitly {@code true} and ""see through them"", otherwise {@code false}
 * to treat semantic predicates as opaque and add {@link #HIT_PRED} to the
 * result if one is encountered.
 * @param addEOF Add {@link Token#EOF} to the result if the end of the
 * outermost context is reached. This parameter has no effect if {@code ctx}
 * is {@code null}.
 */
protected void _LOOK(ATNState s, ATNState stopState, PredictionContext ctx, IntervalSet look, Set<ATNConfig> lookBusy, BitSet calledRuleStack, boolean seeThruPreds, boolean addEOF) {
    // System.out.println(""_LOOK(""+s.stateNumber+"", ctx=""+ctx);
    ATNConfig c = new ATNConfig(s, 0, ctx);
    if (!lookBusy.add(c))
        return;
    if (s == stopState) {
        if (ctx == null) {
            look.add(Token.EPSILON);
            return;
        } else if (ctx.isEmpty() && addEOF) {
            look.add(Token.EOF);
            return;
        }
    }
    if (s instanceof RuleStopState) {
        if (ctx == null) {
            look.add(Token.EPSILON);
            return;
        } else if (ctx.isEmpty() && addEOF) {
            look.add(Token.EOF);
            return;
        }
        if (ctx != EmptyPredictionContext.Instance) {
            // run thru all possible stack tops in ctx
            boolean removed = calledRuleStack.get(s.ruleIndex);
            try {
                calledRuleStack.clear(s.ruleIndex);
                for (int i = 0; i < ctx.size(); i++) {
                    ATNState returnState = atn.states.get(ctx.getReturnState(i));
                    // System.out.println(""popping back to ""+retState);
                    _LOOK(returnState, stopState, ctx.getParent(i), look, lookBusy, calledRuleStack, seeThruPreds, addEOF);
                }
            } finally {
                if (removed) {
                    calledRuleStack.set(s.ruleIndex);
                }
            }
            return;
        }
    }
    int n = s.getNumberOfTransitions();
    for (int i = 0; i < n; i++) {
        Transition t = s.transition(i);
        if (t.getClass() == RuleTransition.class) {
            if (calledRuleStack.get(((RuleTransition) t).target.ruleIndex)) {
                continue;
            }
            PredictionContext newContext = SingletonPredictionContext.create(ctx, ((RuleTransition) t).followState.stateNumber);
            try {
                calledRuleStack.set(((RuleTransition) t).target.ruleIndex);
                _LOOK(t.target, stopState, newContext, look, lookBusy, calledRuleStack, seeThruPreds, addEOF);
            } finally {
                calledRuleStack.clear(((RuleTransition) t).target.ruleIndex);
            }
        } else if (t instanceof AbstractPredicateTransition) {
            if (seeThruPreds) {
                _LOOK(t.target, stopState, ctx, look, lookBusy, calledRuleStack, seeThruPreds, addEOF);
            } else {
                look.add(HIT_PRED);
            }
        } else if (t.isEpsilon()) {
            _LOOK(t.target, stopState, ctx, look, lookBusy, calledRuleStack, seeThruPreds, addEOF);
        } else if (t.getClass() == WildcardTransition.class) {
            look.addAll(IntervalSet.of(Token.MIN_USER_TOKEN_TYPE, atn.maxTokenType));
        } else {
            // System.out.println(""adding ""+ t);
            IntervalSet set = t.label();
            if (set != null) {
                if (t instanceof NotSetTransition) {
                    set = set.complement(IntervalSet.of(Token.MIN_USER_TOKEN_TYPE, atn.maxTokenType));
                }
                look.addAll(set);
            }
        }
    }
}","/**
 * Compute set of tokens that can follow {@code s} in the ATN in the
 * specified {@code ctx}.
 *
 * <p>If {@code ctx} is {@code null} and {@code stopState} or the end of the
 * rule containing {@code s} is reached, {@link Token#EPSILON} is added to
 * the result set. If {@code ctx} is not {@code null} and {@code addEOF} is
 * {@code true} and {@code stopState} or the end of the outermost rule is
 * reached, {@link Token#EOF} is added to the result set.</p>
 *
 * @param s the ATN state.
 * @param stopState the ATN state to stop at. This can be a
 * {@link BlockEndState} to detect epsilon paths through a closure.
 * @param ctx The outer context, or {@code null} if the outer context should
 * not be used.
 * @param look The result lookahead set.
 * @param lookBusy A set used for preventing epsilon closures in the ATN
 * from causing a stack overflow. Outside code should pass
 * {@code new HashSet<ATNConfig>} for this argument.
 * @param calledRuleStack A set used for preventing left recursion in the
 * ATN from causing a stack overflow. Outside code should pass
 * {@code new BitSet()} for this argument.
 * @param seeThruPreds {@code true} to true semantic predicates as
 * implicitly {@code true} and ""see through them"", otherwise {@code false}
 * to treat semantic predicates as opaque and add {@link #HIT_PRED} to the
 * result if one is encountered.
 * @param addEOF Add {@link Token#EOF} to the result if the end of the
 * outermost context is reached. This parameter has no effect if {@code ctx}
 * is {@code null}.
 */
","// System.out.println(""_LOOK(""+s.stateNumber+"", ctx=""+ctx);
[[SEP]]// run thru all possible stack tops in ctx
[[SEP]]// System.out.println(""popping back to ""+retState);
[[SEP]]// System.out.println(""adding ""+ t);
","/** * Compute set of tokens that can follow {@code s} in the ATN in the * specified {@code ctx}. * * <p>If {@code ctx} is {@code null} and {@code stopState} or the end of the * rule containing {@code s} is reached, {@link Token#EPSILON} is added to * the result set. If {@code ctx} is not {@code null} and {@code addEOF} is * {@code true} and {@code stopState} or the end of the outermost rule is * reached, {@link Token#EOF} is added to the result set.</p> * * @param s the ATN state. * @param stopState the ATN state to stop at. This can be a * {@link BlockEndState} to detect epsilon paths through a closure. * @param ctx The outer context, or {@code null} if the outer context should * not be used. * @param look The result lookahead set. * @param lookBusy A set used for preventing epsilon closures in the ATN * from causing a stack overflow. Outside code should pass * {@code new HashSet<ATNConfig>} for this argument. * @param calledRuleStack A set used for preventing left recursion in the * ATN from causing a stack overflow. Outside code should pass * {@code new BitSet()} for this argument. * @param seeThruPreds {@code true} to true semantic predicates as * implicitly {@code true} and ""see through them"", otherwise {@code false} * to treat semantic predicates as opaque and add {@link #HIT_PRED} to the * result if one is encountered. * @param addEOF Add {@link Token#EOF} to the result if the end of the * outermost context is reached. This parameter has no effect if {@code ctx} * is {@code null}. */[[SEP]]// System.out.println(""_LOOK(""+s.stateNumber+"", ctx=""+ctx);[[SEP]]// run thru all possible stack tops in ctx[[SEP]]// System.out.println(""popping back to ""+retState);[[SEP]]// System.out.println(""adding ""+ t);",137,234,[0],0,"[0, 0, 0, 0]",0,"[0, 0, 0, 0, 0]",0,0,0,0,"_LOOK(ATNState, ATNState, PredictionContext, IntervalSet, Set<ATNConfig>, BitSet, boolean, boolean)",org.antlr.v4.runtime.atn.LL1Analyzer,"_LOOK/8[org.antlr.v4.runtime.atn.ATNState,org.antlr.v4.runtime.atn.ATNState,org.antlr.v4.runtime.atn.PredictionContext,org.antlr.v4.runtime.misc.IntervalSet,java.util.Set<org.antlr.v4.runtime.atn.ATNConfig>,java.util.BitSet,boolean,boolean]",False,144,12,18,3,15,22,20,80,6,9,8,20,1,0,2,7,2,4,0,3,10,0,4,0,0,0,117,4,0,True
379,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\atn\LexerATNConfig.java,org.antlr.v4.runtime.atn.LexerATNConfig,LexerActionExecutor getLexerActionExecutor(),"/**
 * Gets the {@link LexerActionExecutor} capable of executing the embedded
 * action(s) for the current configuration.
 */
public final LexerActionExecutor getLexerActionExecutor() {
    return lexerActionExecutor;
}","/**
 * Gets the {@link LexerActionExecutor} capable of executing the embedded
 * action(s) for the current configuration.
 */
", ,/** * Gets the {@link LexerActionExecutor} capable of executing the embedded * action(s) for the current configuration. */,64,66,[0],0,[0],0,[0],0,0,0,0,getLexerActionExecutor(),org.antlr.v4.runtime.atn.LexerATNConfig,getLexerActionExecutor/0,False,64,1,3,3,0,1,0,3,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,13,17,0,True
380,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\atn\LexerATNSimulator.java,org.antlr.v4.runtime.atn.LexerATNSimulator,"int execATN(CharStream, DFAState)","protected int execATN(CharStream input, DFAState ds0) {
    // System.out.println(""enter exec index ""+input.index()+"" from ""+ds0.configs);
    if (debug) {
        System.out.format(Locale.getDefault(), ""start state closure=%s\n"", ds0.configs);
    }
    if (ds0.isAcceptState) {
        // allow zero-length tokens
        captureSimState(prevAccept, input, ds0);
    }
    int t = input.LA(1);
    // s is current/from DFA state
    DFAState s = ds0;
    while (true) {
        // while more work
        if (debug) {
            System.out.format(Locale.getDefault(), ""execATN loop starting closure: %s\n"", s.configs);
        }
        // As we move src->trg, src->trg, we keep track of the previous trg to
        // avoid looking up the DFA state again, which is expensive.
        // If the previous target was already part of the DFA, we might
        // be able to avoid doing a reach operation upon t. If s!=null,
        // it means that semantic predicates didn't prevent us from
        // creating a DFA state. Once we know s!=null, we check to see if
        // the DFA state has an edge already for t. If so, we can just reuse
        // it's configuration set; there's no point in re-computing it.
        // This is kind of like doing DFA simulation within the ATN
        // simulation because DFA simulation is really just a way to avoid
        // computing reach/closure sets. Technically, once we know that
        // we have a previously added DFA state, we could jump over to
        // the DFA simulator. But, that would mean popping back and forth
        // a lot and making things more complicated algorithmically.
        // This optimization makes a lot of sense for loops within DFA.
        // A character will take us back to an existing DFA state
        // that already has lots of edges out of it. e.g., .* in comments.
        DFAState target = getExistingTargetState(s, t);
        if (target == null) {
            target = computeTargetState(input, s, t);
        }
        if (target == ERROR) {
            break;
        }
        // If this is a consumable input element, make sure to consume before
        // capturing the accept state so the input index, line, and char
        // position accurately reflect the state of the interpreter at the
        // end of the token.
        if (t != IntStream.EOF) {
            consume(input);
        }
        if (target.isAcceptState) {
            captureSimState(prevAccept, input, target);
            if (t == IntStream.EOF) {
                break;
            }
        }
        t = input.LA(1);
        // flip; current DFA target becomes new src/from state
        s = target;
    }
    return failOrAccept(prevAccept, input, s.configs, t);
}", ,"// System.out.println(""enter exec index ""+input.index()+"" from ""+ds0.configs);
[[SEP]]// allow zero-length tokens
[[SEP]]// s is current/from DFA state
[[SEP]]// As we move src->trg, src->trg, we keep track of the previous trg to
[[SEP]]// avoid looking up the DFA state again, which is expensive.
[[SEP]]// If the previous target was already part of the DFA, we might
[[SEP]]// be able to avoid doing a reach operation upon t. If s!=null,
[[SEP]]// it means that semantic predicates didn't prevent us from
[[SEP]]// creating a DFA state. Once we know s!=null, we check to see if
[[SEP]]// the DFA state has an edge already for t. If so, we can just reuse
[[SEP]]// it's configuration set; there's no point in re-computing it.
[[SEP]]// This is kind of like doing DFA simulation within the ATN
[[SEP]]// simulation because DFA simulation is really just a way to avoid
[[SEP]]// computing reach/closure sets. Technically, once we know that
[[SEP]]// we have a previously added DFA state, we could jump over to
[[SEP]]// the DFA simulator. But, that would mean popping back and forth
[[SEP]]// a lot and making things more complicated algorithmically.
[[SEP]]// This optimization makes a lot of sense for loops within DFA.
[[SEP]]// A character will take us back to an existing DFA state
[[SEP]]// If this is a consumable input element, make sure to consume before
[[SEP]]// capturing the accept state so the input index, line, and char
[[SEP]]// position accurately reflect the state of the interpreter at the
[[SEP]]// while more work
[[SEP]]// that already has lots of edges out of it. e.g., .* in comments.
[[SEP]]// end of the token.
[[SEP]]// flip; current DFA target becomes new src/from state
","// System.out.println(""enter exec index ""+input.index()+"" from ""+ds0.configs);[[SEP]]// allow zero-length tokens[[SEP]]// s is current/from DFA state[[SEP]]// while more work[[SEP]]// As we move src->trg, src->trg, we keep track of the previous trg to// avoid looking up the DFA state again, which is expensive.// If the previous target was already part of the DFA, we might// be able to avoid doing a reach operation upon t. If s!=null,// it means that semantic predicates didn't prevent us from// creating a DFA state. Once we know s!=null, we check to see if// the DFA state has an edge already for t. If so, we can just reuse// it's configuration set; there's no point in re-computing it.// This is kind of like doing DFA simulation within the ATN// simulation because DFA simulation is really just a way to avoid// computing reach/closure sets. Technically, once we know that// we have a previously added DFA state, we could jump over to// the DFA simulator. But, that would mean popping back and forth// a lot and making things more complicated algorithmically.// This optimization makes a lot of sense for loops within DFA.// A character will take us back to an existing DFA state// that already has lots of edges out of it. e.g., .* in comments.[[SEP]]// If this is a consumable input element, make sure to consume before// capturing the accept state so the input index, line, and char// position accurately reflect the state of the interpreter at the// end of the token.[[SEP]]// flip; current DFA target becomes new src/from state",165,231,[0],0,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]",0,"[0, 0, 0, 0, 0, 0, 0]",0,0,0,1,"execATN(CharStream, DFAState)",org.antlr.v4.runtime.atn.LexerATNSimulator,"execATN/2[org.antlr.v4.runtime.CharStream,org.antlr.v4.runtime.dfa.DFAState]",False,165,4,8,2,6,10,8,34,1,3,2,8,5,8,1,4,0,0,2,2,6,0,3,0,0,0,34,4,0,False
381,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\atn\LexerATNSimulator.java,org.antlr.v4.runtime.atn.LexerATNSimulator,"DFAState computeTargetState(CharStream, DFAState, int)","/**
 * Compute a target state for an edge in the DFA, and attempt to add the
 * computed state and corresponding edge to the DFA.
 *
 * @param input The input stream
 * @param s The current DFA state
 * @param t The next input symbol
 *
 * @return The computed target DFA state for the given input symbol
 * {@code t}. If {@code t} does not lead to a valid DFA state, this method
 * returns {@link #ERROR}.
 */
protected DFAState computeTargetState(CharStream input, DFAState s, int t) {
    ATNConfigSet reach = new OrderedATNConfigSet();
    // if we don't find an existing DFA state
    // Fill reach starting from closure, following t transitions
    getReachableConfigSet(input, s.configs, reach, t);
    if (reach.isEmpty()) {
        // we got nowhere on t from s
        if (!reach.hasSemanticContext) {
            // we got nowhere on t, don't throw out this knowledge; it'd
            // cause a failover from DFA later.
            addDFAEdge(s, t, ERROR);
        }
        // stop when we can't match any more char
        return ERROR;
    }
    // Add an edge from s to target DFA found/created for reach
    return addDFAEdge(s, t, reach);
}", ,"// if we don't find an existing DFA state
[[SEP]]// Fill reach starting from closure, following t transitions
[[SEP]]// we got nowhere on t from s
[[SEP]]// we got nowhere on t, don't throw out this knowledge; it'd
[[SEP]]// cause a failover from DFA later.
[[SEP]]// stop when we can't match any more char
[[SEP]]// Add an edge from s to target DFA found/created for reach
","/** * Compute a target state for an edge in the DFA, and attempt to add the * computed state and corresponding edge to the DFA. * * @param input The input stream * @param s The current DFA state * @param t The next input symbol * * @return The computed target DFA state for the given input symbol * {@code t}. If {@code t} does not lead to a valid DFA state, this method * returns {@link #ERROR}. */[[SEP]]// if we don't find an existing DFA state// Fill reach starting from closure, following t transitions[[SEP]]// we got nowhere on t from s[[SEP]]// we got nowhere on t, don't throw out this knowledge; it'd// cause a failover from DFA later.[[SEP]]// stop when we can't match any more char[[SEP]]// Add an edge from s to target DFA found/created for reach",272,292,[0],0,"[0, 0, 0, 0, 0, 0, 0]",0,"[0, 0, 0, 0, 0, 0]",0,0,0,0,"computeTargetState(CharStream, DFAState, int)",org.antlr.v4.runtime.atn.LexerATNSimulator,"computeTargetState/3[org.antlr.v4.runtime.CharStream,org.antlr.v4.runtime.dfa.DFAState,int]",False,272,5,6,1,5,3,4,11,2,1,3,4,3,6,0,0,0,0,0,0,1,0,2,0,0,0,49,4,0,True
382,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\atn\LexerATNSimulator.java,org.antlr.v4.runtime.atn.LexerATNSimulator,"int failOrAccept(SimState, CharStream, ATNConfigSet, int)","protected int failOrAccept(SimState prevAccept, CharStream input, ATNConfigSet reach, int t) {
    if (prevAccept.dfaState != null) {
        LexerActionExecutor lexerActionExecutor = prevAccept.dfaState.lexerActionExecutor;
        accept(input, lexerActionExecutor, startIndex, prevAccept.index, prevAccept.line, prevAccept.charPos);
        return prevAccept.dfaState.prediction;
    } else {
        // if no accept and EOF is first char, return EOF
        if (t == IntStream.EOF && input.index() == startIndex) {
            return Token.EOF;
        }
        throw new LexerNoViableAltException(recog, input, startIndex, reach);
    }
}", ,"// if no accept and EOF is first char, return EOF
","// if no accept and EOF is first char, return EOF",294,311,[0],0,[0],0,[0],0,0,0,0,"failOrAccept(SimState, CharStream, ATNConfigSet, int)",org.antlr.v4.runtime.atn.LexerATNSimulator,"failOrAccept/4[org.antlr.v4.runtime.atn.LexerATNSimulator.SimState,org.antlr.v4.runtime.CharStream,org.antlr.v4.runtime.atn.ATNConfigSet,int]",False,296,7,4,1,3,4,2,13,2,1,4,2,1,1,0,3,0,0,0,0,1,0,2,0,0,0,18,4,0,False
383,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\atn\LexerATNSimulator.java,org.antlr.v4.runtime.atn.LexerATNSimulator,"void getReachableConfigSet(CharStream, ATNConfigSet, ATNConfigSet, int)","/**
 * Given a starting configuration set, figure out all ATN configurations
 *  we can reach upon input {@code t}. Parameter {@code reach} is a return
 *  parameter.
 */
protected void getReachableConfigSet(CharStream input, ATNConfigSet closure, ATNConfigSet reach, int t) {
    // this is used to skip processing for configs which have a lower priority
    // than a config that already reached an accept state for the same rule
    int skipAlt = ATN.INVALID_ALT_NUMBER;
    for (ATNConfig c : closure) {
        boolean currentAltReachedAcceptState = c.alt == skipAlt;
        if (currentAltReachedAcceptState && ((LexerATNConfig) c).hasPassedThroughNonGreedyDecision()) {
            continue;
        }
        if (debug) {
            System.out.format(Locale.getDefault(), ""testing %s at %s\n"", getTokenName(t), c.toString(recog, true));
        }
        int n = c.state.getNumberOfTransitions();
        for (int ti = 0; ti < n; ti++) {
            // for each transition
            Transition trans = c.state.transition(ti);
            ATNState target = getReachableTarget(trans, t);
            if (target != null) {
                LexerActionExecutor lexerActionExecutor = ((LexerATNConfig) c).getLexerActionExecutor();
                if (lexerActionExecutor != null) {
                    lexerActionExecutor = lexerActionExecutor.fixOffsetBeforeMatch(input.index() - startIndex);
                }
                boolean treatEofAsEpsilon = t == CharStream.EOF;
                if (closure(input, new LexerATNConfig((LexerATNConfig) c, target, lexerActionExecutor), reach, currentAltReachedAcceptState, true, treatEofAsEpsilon)) {
                    // any remaining configs for this alt have a lower priority than
                    // the one that just reached an accept state.
                    skipAlt = c.alt;
                    break;
                }
            }
        }
    }
}","/**
 * Given a starting configuration set, figure out all ATN configurations
 *  we can reach upon input {@code t}. Parameter {@code reach} is a return
 *  parameter.
 */
","// this is used to skip processing for configs which have a lower priority
[[SEP]]// than a config that already reached an accept state for the same rule
[[SEP]]// for each transition
[[SEP]]// any remaining configs for this alt have a lower priority than
[[SEP]]// the one that just reached an accept state.
","/** * Given a starting configuration set, figure out all ATN configurations *  we can reach upon input {@code t}. Parameter {@code reach} is a return *  parameter. */[[SEP]]// this is used to skip processing for configs which have a lower priority// than a config that already reached an accept state for the same rule[[SEP]]// for each transition[[SEP]]// any remaining configs for this alt have a lower priority than// the one that just reached an accept state.",317,351,[0],0,"[0, 0, 0, 0, 0]",0,"[0, 0, 0, 0]",0,0,0,0,"getReachableConfigSet(CharStream, ATNConfigSet, ATNConfigSet, int)",org.antlr.v4.runtime.atn.LexerATNSimulator,"getReachableConfigSet/4[org.antlr.v4.runtime.CharStream,org.antlr.v4.runtime.atn.ATNConfigSet,org.antlr.v4.runtime.atn.ATNConfigSet,int]",False,317,9,12,1,11,9,12,28,0,8,4,12,3,4,2,4,0,2,1,1,10,1,4,0,0,0,52,4,0,True
384,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\atn\LexerATNSimulator.java,org.antlr.v4.runtime.atn.LexerATNSimulator,"void accept(CharStream, LexerActionExecutor, int, int, int, int)","protected void accept(CharStream input, LexerActionExecutor lexerActionExecutor, int startIndex, int index, int line, int charPos) {
    if (debug) {
        System.out.format(Locale.getDefault(), ""ACTION %s\n"", lexerActionExecutor);
    }
    // seek to after last char in token
    input.seek(index);
    this.line = line;
    this.charPositionInLine = charPos;
    if (lexerActionExecutor != null && recog != null) {
        lexerActionExecutor.execute(recog, input, startIndex);
    }
}", ,"// seek to after last char in token
",// seek to after last char in token,353,368,[0],0,[0],0,[0],0,0,0,0,"accept(CharStream, LexerActionExecutor, int, int, int, int)",org.antlr.v4.runtime.atn.LexerATNSimulator,"accept/6[org.antlr.v4.runtime.CharStream,org.antlr.v4.runtime.atn.LexerActionExecutor,int,int,int,int]",False,355,3,3,1,2,4,4,11,0,0,6,4,0,0,0,2,0,0,1,0,2,0,1,0,0,0,13,4,0,False
385,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\atn\LexerATNSimulator.java,org.antlr.v4.runtime.atn.LexerATNSimulator,"boolean closure(CharStream, LexerATNConfig, ATNConfigSet, boolean, boolean, boolean)","/**
 * Since the alternatives within any lexer decision are ordered by
 * preference, this method stops pursuing the closure as soon as an accept
 * state is reached. After the first accept state is reached by depth-first
 * search from {@code config}, all other (potentially reachable) states for
 * this rule would have a lower priority.
 *
 * @return {@code true} if an accept state is reached, otherwise
 * {@code false}.
 */
protected boolean closure(CharStream input, LexerATNConfig config, ATNConfigSet configs, boolean currentAltReachedAcceptState, boolean speculative, boolean treatEofAsEpsilon) {
    if (debug) {
        System.out.println(""closure("" + config.toString(recog, true) + "")"");
    }
    if (config.state instanceof RuleStopState) {
        if (debug) {
            if (recog != null) {
                System.out.format(Locale.getDefault(), ""closure at %s rule stop %s\n"", recog.getRuleNames()[config.state.ruleIndex], config);
            } else {
                System.out.format(Locale.getDefault(), ""closure at rule stop %s\n"", config);
            }
        }
        if (config.context == null || config.context.hasEmptyPath()) {
            if (config.context == null || config.context.isEmpty()) {
                configs.add(config);
                return true;
            } else {
                configs.add(new LexerATNConfig(config, config.state, EmptyPredictionContext.Instance));
                currentAltReachedAcceptState = true;
            }
        }
        if (config.context != null && !config.context.isEmpty()) {
            for (int i = 0; i < config.context.size(); i++) {
                if (config.context.getReturnState(i) != PredictionContext.EMPTY_RETURN_STATE) {
                    // ""pop"" return state
                    PredictionContext newContext = config.context.getParent(i);
                    ATNState returnState = atn.states.get(config.context.getReturnState(i));
                    LexerATNConfig c = new LexerATNConfig(config, returnState, newContext);
                    currentAltReachedAcceptState = closure(input, c, configs, currentAltReachedAcceptState, speculative, treatEofAsEpsilon);
                }
            }
        }
        return currentAltReachedAcceptState;
    }
    // optimization
    if (!config.state.onlyHasEpsilonTransitions()) {
        if (!currentAltReachedAcceptState || !config.hasPassedThroughNonGreedyDecision()) {
            configs.add(config);
        }
    }
    ATNState p = config.state;
    for (int i = 0; i < p.getNumberOfTransitions(); i++) {
        Transition t = p.transition(i);
        LexerATNConfig c = getEpsilonTarget(input, config, t, configs, speculative, treatEofAsEpsilon);
        if (c != null) {
            currentAltReachedAcceptState = closure(input, c, configs, currentAltReachedAcceptState, speculative, treatEofAsEpsilon);
        }
    }
    return currentAltReachedAcceptState;
}","/**
 * Since the alternatives within any lexer decision are ordered by
 * preference, this method stops pursuing the closure as soon as an accept
 * state is reached. After the first accept state is reached by depth-first
 * search from {@code config}, all other (potentially reachable) states for
 * this rule would have a lower priority.
 *
 * @return {@code true} if an accept state is reached, otherwise
 * {@code false}.
 */
","// ""pop"" return state
[[SEP]]// optimization
","/** * Since the alternatives within any lexer decision are ordered by * preference, this method stops pursuing the closure as soon as an accept * state is reached. After the first accept state is reached by depth-first * search from {@code config}, all other (potentially reachable) states for * this rule would have a lower priority. * * @return {@code true} if an accept state is reached, otherwise * {@code false}. */[[SEP]]// ""pop"" return state[[SEP]]// optimization",403,460,[0],0,"[0, 0]",0,"[0, 0, 0]",0,0,0,0,"closure(CharStream, LexerATNConfig, ATNConfigSet, boolean, boolean, boolean)",org.antlr.v4.runtime.atn.LexerATNSimulator,"closure/6[org.antlr.v4.runtime.CharStream,org.antlr.v4.runtime.atn.LexerATNConfig,org.antlr.v4.runtime.atn.ATNConfigSet,boolean,boolean,boolean]",False,403,10,18,3,15,18,18,50,3,8,6,18,2,3,2,6,0,0,4,2,11,1,4,0,0,0,74,4,0,True
386,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\atn\LexerATNSimulator.java,org.antlr.v4.runtime.atn.LexerATNSimulator,"LexerATNConfig getEpsilonTarget(CharStream, LexerATNConfig, Transition, ATNConfigSet, boolean, boolean)","// side-effect: can alter configs.hasSemanticContext
protected LexerATNConfig getEpsilonTarget(CharStream input, LexerATNConfig config, Transition t, ATNConfigSet configs, boolean speculative, boolean treatEofAsEpsilon) {
    LexerATNConfig c = null;
    switch(t.getSerializationType()) {
        case Transition.RULE:
            RuleTransition ruleTransition = (RuleTransition) t;
            PredictionContext newContext = SingletonPredictionContext.create(config.context, ruleTransition.followState.stateNumber);
            c = new LexerATNConfig(config, t.target, newContext);
            break;
        case Transition.PRECEDENCE:
            throw new UnsupportedOperationException(""Precedence predicates are not supported in lexers."");
        case Transition.PREDICATE:
            /*  Track traversing semantic predicates. If we traverse,
				 we cannot add a DFA state for this ""reach"" computation
				 because the DFA would not test the predicate again in the
				 future. Rather than creating collections of semantic predicates
				 like v3 and testing them on prediction, v4 will test them on the
				 fly all the time using the ATN not the DFA. This is slower but
				 semantically it's not used that often. One of the key elements to
				 this predicate mechanism is not adding DFA states that see
				 predicates immediately afterwards in the ATN. For example,

				 a : ID {p1}? | ID {p2}? ;

				 should create the start state for rule 'a' (to save start state
				 competition), but should not create target of ID state. The
				 collection of ATN states the following ID references includes
				 states reached by traversing predicates. Since this is when we
				 test them, we cannot cash the DFA state target of ID.
			 */
            PredicateTransition pt = (PredicateTransition) t;
            if (debug) {
                System.out.println(""EVAL rule "" + pt.ruleIndex + "":"" + pt.predIndex);
            }
            configs.hasSemanticContext = true;
            if (evaluatePredicate(input, pt.ruleIndex, pt.predIndex, speculative)) {
                c = new LexerATNConfig(config, t.target);
            }
            break;
        case Transition.ACTION:
            if (config.context == null || config.context.hasEmptyPath()) {
                // execute actions anywhere in the start rule for a token.
                // 
                // TODO: if the entry rule is invoked recursively, some
                // actions may be executed during the recursive call. The
                // problem can appear when hasEmptyPath() is true but
                // isEmpty() is false. In this case, the config needs to be
                // split into two contexts - one with just the empty path
                // and another with everything but the empty path.
                // Unfortunately, the current algorithm does not allow
                // getEpsilonTarget to return two configurations, so
                // additional modifications are needed before we can support
                // the split operation.
                LexerActionExecutor lexerActionExecutor = LexerActionExecutor.append(config.getLexerActionExecutor(), atn.lexerActions[((ActionTransition) t).actionIndex]);
                c = new LexerATNConfig(config, t.target, lexerActionExecutor);
                break;
            } else {
                // ignore actions in referenced rules
                c = new LexerATNConfig(config, t.target);
                break;
            }
        case Transition.EPSILON:
            c = new LexerATNConfig(config, t.target);
            break;
        case Transition.ATOM:
        case Transition.RANGE:
        case Transition.SET:
            if (treatEofAsEpsilon) {
                if (t.matches(CharStream.EOF, Lexer.MIN_CHAR_VALUE, Lexer.MAX_CHAR_VALUE)) {
                    c = new LexerATNConfig(config, t.target);
                    break;
                }
            }
            break;
    }
    return c;
}", ,"/*  Track traversing semantic predicates. If we traverse,
				 we cannot add a DFA state for this ""reach"" computation
				 because the DFA would not test the predicate again in the
				 future. Rather than creating collections of semantic predicates
				 like v3 and testing them on prediction, v4 will test them on the
				 fly all the time using the ATN not the DFA. This is slower but
				 semantically it's not used that often. One of the key elements to
				 this predicate mechanism is not adding DFA states that see
				 predicates immediately afterwards in the ATN. For example,

				 a : ID {p1}? | ID {p2}? ;

				 should create the start state for rule 'a' (to save start state
				 competition), but should not create target of ID state. The
				 collection of ATN states the following ID references includes
				 states reached by traversing predicates. Since this is when we
				 test them, we cannot cash the DFA state target of ID.
			 */
[[SEP]]// execute actions anywhere in the start rule for a token.
[[SEP]]// 
[[SEP]]// TODO: if the entry rule is invoked recursively, some
[[SEP]]// actions may be executed during the recursive call. The
[[SEP]]// problem can appear when hasEmptyPath() is true but
[[SEP]]// isEmpty() is false. In this case, the config needs to be
[[SEP]]// split into two contexts - one with just the empty path
[[SEP]]// and another with everything but the empty path.
[[SEP]]// Unfortunately, the current algorithm does not allow
[[SEP]]// getEpsilonTarget to return two configurations, so
[[SEP]]// additional modifications are needed before we can support
[[SEP]]// the split operation.
[[SEP]]// ignore actions in referenced rules
","// side-effect: can alter configs.hasSemanticContext[[SEP]]/*  Track traversing semantic predicates. If we traverse,				 we cannot add a DFA state for this ""reach"" computation				 because the DFA would not test the predicate again in the				 future. Rather than creating collections of semantic predicates				 like v3 and testing them on prediction, v4 will test them on the				 fly all the time using the ATN not the DFA. This is slower but				 semantically it's not used that often. One of the key elements to				 this predicate mechanism is not adding DFA states that see				 predicates immediately afterwards in the ATN. For example,				 a : ID {p1}? | ID {p2}? ;				 should create the start state for rule 'a' (to save start state				 competition), but should not create target of ID state. The				 collection of ATN states the following ID references includes				 states reached by traversing predicates. Since this is when we				 test them, we cannot cash the DFA state target of ID.			 */[[SEP]]// execute actions anywhere in the start rule for a token.//// TODO: if the entry rule is invoked recursively, some// actions may be executed during the recursive call. The// problem can appear when hasEmptyPath() is true but// isEmpty() is false. In this case, the config needs to be// split into two contexts - one with just the empty path// and another with everything but the empty path.// Unfortunately, the current algorithm does not allow// getEpsilonTarget to return two configurations, so// additional modifications are needed before we can support// the split operation.[[SEP]]// ignore actions in referenced rules",464,554,[0],0,"[0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,"[0, 0, 1, 0]",1,1,1,1,"getEpsilonTarget(CharStream, LexerATNConfig, Transition, ATNConfigSet, boolean, boolean)",org.antlr.v4.runtime.atn.LexerATNSimulator,"getEpsilonTarget/6[org.antlr.v4.runtime.CharStream,org.antlr.v4.runtime.atn.LexerATNConfig,org.antlr.v4.runtime.atn.Transition,org.antlr.v4.runtime.atn.ATNConfigSet,boolean,boolean]",False,470,11,11,1,10,15,8,46,1,5,6,8,1,2,0,1,0,1,3,0,12,1,3,0,0,0,38,4,0,False
387,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\atn\LexerATNSimulator.java,org.antlr.v4.runtime.atn.LexerATNSimulator,"boolean evaluatePredicate(CharStream, int, int, boolean)","/**
 * Evaluate a predicate specified in the lexer.
 *
 * <p>If {@code speculative} is {@code true}, this method was called before
 * {@link #consume} for the matched character. This method should call
 * {@link #consume} before evaluating the predicate to ensure position
 * sensitive values, including {@link Lexer#getText}, {@link Lexer#getLine},
 * and {@link Lexer#getCharPositionInLine}, properly reflect the current
 * lexer state. This method should restore {@code input} and the simulator
 * to the original state before returning (i.e. undo the actions made by the
 * call to {@link #consume}.</p>
 *
 * @param input The input stream.
 * @param ruleIndex The rule containing the predicate.
 * @param predIndex The index of the predicate within the rule.
 * @param speculative {@code true} if the current index in {@code input} is
 * one character before the predicate's location.
 *
 * @return {@code true} if the specified predicate evaluates to
 * {@code true}.
 */
protected boolean evaluatePredicate(CharStream input, int ruleIndex, int predIndex, boolean speculative) {
    // assume true if no recognizer was provided
    if (recog == null) {
        return true;
    }
    if (!speculative) {
        return recog.sempred(null, ruleIndex, predIndex);
    }
    int savedCharPositionInLine = charPositionInLine;
    int savedLine = line;
    int index = input.index();
    int marker = input.mark();
    try {
        consume(input);
        return recog.sempred(null, ruleIndex, predIndex);
    } finally {
        charPositionInLine = savedCharPositionInLine;
        line = savedLine;
        input.seek(index);
        input.release(marker);
    }
}","/**
 * Evaluate a predicate specified in the lexer.
 *
 * <p>If {@code speculative} is {@code true}, this method was called before
 * {@link #consume} for the matched character. This method should call
 * {@link #consume} before evaluating the predicate to ensure position
 * sensitive values, including {@link Lexer#getText}, {@link Lexer#getLine},
 * and {@link Lexer#getCharPositionInLine}, properly reflect the current
 * lexer state. This method should restore {@code input} and the simulator
 * to the original state before returning (i.e. undo the actions made by the
 * call to {@link #consume}.</p>
 *
 * @param input The input stream.
 * @param ruleIndex The rule containing the predicate.
 * @param predIndex The index of the predicate within the rule.
 * @param speculative {@code true} if the current index in {@code input} is
 * one character before the predicate's location.
 *
 * @return {@code true} if the specified predicate evaluates to
 * {@code true}.
 */
","// assume true if no recognizer was provided
","/** * Evaluate a predicate specified in the lexer. * * <p>If {@code speculative} is {@code true}, this method was called before * {@link #consume} for the matched character. This method should call * {@link #consume} before evaluating the predicate to ensure position * sensitive values, including {@link Lexer#getText}, {@link Lexer#getLine}, * and {@link Lexer#getCharPositionInLine}, properly reflect the current * lexer state. This method should restore {@code input} and the simulator * to the original state before returning (i.e. undo the actions made by the * call to {@link #consume}.</p> * * @param input The input stream. * @param ruleIndex The rule containing the predicate. * @param predIndex The index of the predicate within the rule. * @param speculative {@code true} if the current index in {@code input} is * one character before the predicate's location. * * @return {@code true} if the specified predicate evaluates to * {@code true}. */[[SEP]]// assume true if no recognizer was provided",577,601,[0],0,[0],0,"[0, 0]",0,0,0,0,"evaluatePredicate(CharStream, int, int, boolean)",org.antlr.v4.runtime.atn.LexerATNSimulator,"evaluatePredicate/4[org.antlr.v4.runtime.CharStream,int,int,boolean]",False,577,4,7,1,6,3,6,22,3,4,4,6,1,1,0,1,1,0,0,0,6,0,1,0,0,0,64,4,0,True
388,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\atn\LexerATNSimulator.java,org.antlr.v4.runtime.atn.LexerATNSimulator,"DFAState addDFAEdge(DFAState, int, ATNConfigSet)","protected DFAState addDFAEdge(DFAState from, int t, ATNConfigSet q) {
    /* leading to this call, ATNConfigSet.hasSemanticContext is used as a
		 * marker indicating dynamic predicate evaluation makes this edge
		 * dependent on the specific input sequence, so the static edge in the
		 * DFA should be omitted. The target DFAState is still created since
		 * execATN has the ability to resynchronize with the DFA state cache
		 * following the predicate evaluation step.
		 *
		 * TJP notes: next time through the DFA, we see a pred again and eval.
		 * If that gets us to a previously created (but dangling) DFA
		 * state, we can continue in pure DFA mode from there.
		 */
    boolean suppressEdge = q.hasSemanticContext;
    q.hasSemanticContext = false;
    DFAState to = addDFAState(q);
    if (suppressEdge) {
        return to;
    }
    addDFAEdge(from, t, to);
    return to;
}", ,"/* leading to this call, ATNConfigSet.hasSemanticContext is used as a
		 * marker indicating dynamic predicate evaluation makes this edge
		 * dependent on the specific input sequence, so the static edge in the
		 * DFA should be omitted. The target DFAState is still created since
		 * execATN has the ability to resynchronize with the DFA state cache
		 * following the predicate evaluation step.
		 *
		 * TJP notes: next time through the DFA, we see a pred again and eval.
		 * If that gets us to a previously created (but dangling) DFA
		 * state, we can continue in pure DFA mode from there.
		 */
","/* leading to this call, ATNConfigSet.hasSemanticContext is used as a		 * marker indicating dynamic predicate evaluation makes this edge		 * dependent on the specific input sequence, so the static edge in the		 * DFA should be omitted. The target DFAState is still created since		 * execATN has the ability to resynchronize with the DFA state cache		 * following the predicate evaluation step.		 *		 * TJP notes: next time through the DFA, we see a pred again and eval.		 * If that gets us to a previously created (but dangling) DFA		 * state, we can continue in pure DFA mode from there.		 */",614,641,[0],0,[0],0,[0],0,0,0,0,"addDFAEdge(DFAState, int, ATNConfigSet)",org.antlr.v4.runtime.atn.LexerATNSimulator,"addDFAEdge/3[org.antlr.v4.runtime.dfa.DFAState,int,org.antlr.v4.runtime.atn.ATNConfigSet]",False,617,3,3,1,2,2,2,10,2,2,3,2,2,1,0,0,0,0,0,0,3,0,1,0,0,0,10,4,0,False
389,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\atn\LexerATNSimulator.java,org.antlr.v4.runtime.atn.LexerATNSimulator,"void addDFAEdge(DFAState, int, DFAState)","protected void addDFAEdge(DFAState p, int t, DFAState q) {
    if (t < MIN_DFA_EDGE || t > MAX_DFA_EDGE) {
        // Only track edges within the DFA bounds
        return;
    }
    if (debug) {
        System.out.println(""EDGE "" + p + "" -> "" + q + "" upon "" + ((char) t));
    }
    synchronized (p) {
        if (p.edges == null) {
            // make room for tokens 1..n and -1 masquerading as index 0
            p.edges = new DFAState[MAX_DFA_EDGE - MIN_DFA_EDGE + 1];
        }
        // connect
        p.edges[t - MIN_DFA_EDGE] = q;
    }
}", ,"// Only track edges within the DFA bounds
[[SEP]]// make room for tokens 1..n and -1 masquerading as index 0
[[SEP]]// connect
",// Only track edges within the DFA bounds[[SEP]]// make room for tokens 1..n and -1 masquerading as index 0[[SEP]]// connect,643,660,[0],0,"[0, 0, 0]",0,"[0, 0, 0]",0,0,0,0,"addDFAEdge(DFAState, int, DFAState)",org.antlr.v4.runtime.atn.LexerATNSimulator,"addDFAEdge/3[org.antlr.v4.runtime.dfa.DFAState,int,org.antlr.v4.runtime.dfa.DFAState]",False,643,1,2,2,0,5,1,14,1,0,3,1,0,0,0,1,0,1,3,1,2,4,2,0,0,0,19,4,0,False
390,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\atn\LexerATNSimulator.java,org.antlr.v4.runtime.atn.LexerATNSimulator,DFAState addDFAState(ATNConfigSet),"/**
 *  Add a new DFA state if there isn't one with this set of
 * 		configurations already. This method also detects the first
 * 		configuration containing an ATN rule stop state. Later, when
 * 		traversing the DFA, we will know which rule to accept.
 */
protected DFAState addDFAState(ATNConfigSet configs) {
    /* the lexer evaluates predicates on-the-fly; by this point configs
		 * should not contain any configurations with unevaluated predicates.
		 */
    assert !configs.hasSemanticContext;
    DFAState proposed = new DFAState(configs);
    ATNConfig firstConfigWithRuleStopState = null;
    for (ATNConfig c : configs) {
        if (c.state instanceof RuleStopState) {
            firstConfigWithRuleStopState = c;
            break;
        }
    }
    if (firstConfigWithRuleStopState != null) {
        proposed.isAcceptState = true;
        proposed.lexerActionExecutor = ((LexerATNConfig) firstConfigWithRuleStopState).getLexerActionExecutor();
        proposed.prediction = atn.ruleToTokenType[firstConfigWithRuleStopState.state.ruleIndex];
    }
    DFA dfa = decisionToDFA[mode];
    synchronized (dfa.states) {
        DFAState existing = dfa.states.get(proposed);
        if (existing != null)
            return existing;
        DFAState newState = proposed;
        newState.stateNumber = dfa.states.size();
        configs.setReadonly(true);
        newState.configs = configs;
        dfa.states.put(newState, newState);
        return newState;
    }
}", ,"/* the lexer evaluates predicates on-the-fly; by this point configs
		 * should not contain any configurations with unevaluated predicates.
		 */
","/** *  Add a new DFA state if there isn't one with this set of * 		configurations already. This method also detects the first * 		configuration containing an ATN rule stop state. Later, when * 		traversing the DFA, we will know which rule to accept. */[[SEP]]/* the lexer evaluates predicates on-the-fly; by this point configs		 * should not contain any configurations with unevaluated predicates.		 */",668,702,[0],0,[0],0,"[0, 0]",0,0,1,0,addDFAState(ATNConfigSet),org.antlr.v4.runtime.atn.LexerATNSimulator,addDFAState/1[org.antlr.v4.runtime.atn.ATNConfigSet],False,668,7,5,2,3,5,5,27,2,5,1,5,0,0,1,2,0,1,0,0,11,0,2,0,0,0,49,4,0,True
391,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\atn\LexerATNSimulator.java,org.antlr.v4.runtime.atn.LexerATNSimulator,String getText(CharStream),"/**
 * Get the text matched so far for the current token.
 */
public String getText(CharStream input) {
    // index is first lookahead char, don't include.
    return input.getText(Interval.of(startIndex, input.index() - 1));
}", ,"// index is first lookahead char, don't include.
","/** * Get the text matched so far for the current token. */[[SEP]]// index is first lookahead char, don't include.",712,715,[0],0,[0],0,"[0, 0]",0,0,0,0,getText(CharStream),org.antlr.v4.runtime.atn.LexerATNSimulator,getText/1[org.antlr.v4.runtime.CharStream],False,712,3,4,1,3,1,3,3,1,0,1,3,0,0,0,0,0,0,0,1,0,1,0,0,0,0,12,1,0,True
392,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\atn\LexerATNSimulator.java,org.antlr.v4.runtime.atn.LexerATNSimulator,String getTokenName(int),"public String getTokenName(int t) {
    if (t == -1)
        return ""EOF"";
    // if ( atn.g!=null ) return atn.g.getTokenDisplayName(t);
    return ""'"" + (char) t + ""'"";
}", ,"// if ( atn.g!=null ) return atn.g.getTokenDisplayName(t);
",// if ( atn.g!=null ) return atn.g.getTokenDisplayName(t);,746,750,[0],0,[0],0,[0],0,0,0,0,getTokenName(int),org.antlr.v4.runtime.atn.LexerATNSimulator,getTokenName/1[int],False,746,0,1,1,0,2,0,4,2,0,1,0,0,0,0,1,0,0,3,1,0,1,1,0,0,0,4,1,0,False
393,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\atn\LexerAction.java,org.antlr.v4.runtime.atn.LexerAction,LexerActionType getActionType(),"/**
 * Gets the serialization type of the lexer action.
 *
 * @return The serialization type of the lexer action.
 */
LexerActionType getActionType();","/**
 * Gets the serialization type of the lexer action.
 *
 * @return The serialization type of the lexer action.
 */
", ,/** * Gets the serialization type of the lexer action. * * @return The serialization type of the lexer action. */,26,26,[0],0,[0],0,[0],0,0,0,0,getActionType(),org.antlr.v4.runtime.atn.LexerAction,getActionType/0,False,21,1,2,2,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,11,0,0,True
394,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\atn\LexerAction.java,org.antlr.v4.runtime.atn.LexerAction,boolean isPositionDependent(),"/**
 * Gets whether the lexer action is position-dependent. Position-dependent
 * actions may have different semantics depending on the {@link CharStream}
 * index at the time the action is executed.
 *
 * <p>Many lexer commands, including {@code type}, {@code skip}, and
 * {@code more}, do not check the input index during their execution.
 * Actions like this are position-independent, and may be stored more
 * efficiently as part of the {@link LexerATNConfig#lexerActionExecutor}.</p>
 *
 * @return {@code true} if the lexer action semantics can be affected by the
 * position of the input {@link CharStream} at the time it is executed;
 * otherwise, {@code false}.
 */
boolean isPositionDependent();","/**
 * Gets whether the lexer action is position-dependent. Position-dependent
 * actions may have different semantics depending on the {@link CharStream}
 * index at the time the action is executed.
 *
 * <p>Many lexer commands, including {@code type}, {@code skip}, and
 * {@code more}, do not check the input index during their execution.
 * Actions like this are position-independent, and may be stored more
 * efficiently as part of the {@link LexerATNConfig#lexerActionExecutor}.</p>
 *
 * @return {@code true} if the lexer action semantics can be affected by the
 * position of the input {@link CharStream} at the time it is executed;
 * otherwise, {@code false}.
 */
", ,"/** * Gets whether the lexer action is position-dependent. Position-dependent * actions may have different semantics depending on the {@link CharStream} * index at the time the action is executed. * * <p>Many lexer commands, including {@code type}, {@code skip}, and * {@code more}, do not check the input index during their execution. * Actions like this are position-independent, and may be stored more * efficiently as part of the {@link LexerATNConfig#lexerActionExecutor}.</p> * * @return {@code true} if the lexer action semantics can be affected by the * position of the input {@link CharStream} at the time it is executed; * otherwise, {@code false}. */",42,42,[0],0,[0],0,[0],0,0,0,0,isPositionDependent(),org.antlr.v4.runtime.atn.LexerAction,isPositionDependent/0,False,28,0,2,2,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,51,0,0,True
395,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\atn\LexerAction.java,org.antlr.v4.runtime.atn.LexerAction,void execute(Lexer),"/**
 * Execute the lexer action in the context of the specified {@link Lexer}.
 *
 * <p>For position-dependent actions, the input stream must already be
 * positioned correctly prior to calling this method.</p>
 *
 * @param lexer The lexer instance.
 */
void execute(Lexer lexer);","/**
 * Execute the lexer action in the context of the specified {@link Lexer}.
 *
 * <p>For position-dependent actions, the input stream must already be
 * positioned correctly prior to calling this method.</p>
 *
 * @param lexer The lexer instance.
 */
", ,"/** * Execute the lexer action in the context of the specified {@link Lexer}. * * <p>For position-dependent actions, the input stream must already be * positioned correctly prior to calling this method.</p> * * @param lexer The lexer instance. */",52,52,[0],0,[0],0,[0],0,0,0,0,execute(Lexer),org.antlr.v4.runtime.atn.LexerAction,execute/1[org.antlr.v4.runtime.Lexer],False,44,1,2,2,0,1,0,1,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,25,0,0,True
396,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\atn\LexerActionExecutor.java,org.antlr.v4.runtime.atn.LexerActionExecutor,"LexerActionExecutor append(LexerActionExecutor, LexerAction)","/**
 * Creates a {@link LexerActionExecutor} which executes the actions for
 * the input {@code lexerActionExecutor} followed by a specified
 * {@code lexerAction}.
 *
 * @param lexerActionExecutor The executor for actions already traversed by
 * the lexer while matching a token within a particular
 * {@link LexerATNConfig}. If this is {@code null}, the method behaves as
 * though it were an empty executor.
 * @param lexerAction The lexer action to execute after the actions
 * specified in {@code lexerActionExecutor}.
 *
 * @return A {@link LexerActionExecutor} for executing the combine actions
 * of {@code lexerActionExecutor} and {@code lexerAction}.
 */
public static LexerActionExecutor append(LexerActionExecutor lexerActionExecutor, LexerAction lexerAction) {
    if (lexerActionExecutor == null) {
        return new LexerActionExecutor(new LexerAction[] { lexerAction });
    }
    LexerAction[] lexerActions = Arrays.copyOf(lexerActionExecutor.lexerActions, lexerActionExecutor.lexerActions.length + 1);
    lexerActions[lexerActions.length - 1] = lexerAction;
    return new LexerActionExecutor(lexerActions);
}","/**
 * Creates a {@link LexerActionExecutor} which executes the actions for
 * the input {@code lexerActionExecutor} followed by a specified
 * {@code lexerAction}.
 *
 * @param lexerActionExecutor The executor for actions already traversed by
 * the lexer while matching a token within a particular
 * {@link LexerATNConfig}. If this is {@code null}, the method behaves as
 * though it were an empty executor.
 * @param lexerAction The lexer action to execute after the actions
 * specified in {@code lexerActionExecutor}.
 *
 * @return A {@link LexerActionExecutor} for executing the combine actions
 * of {@code lexerActionExecutor} and {@code lexerAction}.
 */
", ,"/** * Creates a {@link LexerActionExecutor} which executes the actions for * the input {@code lexerActionExecutor} followed by a specified * {@code lexerAction}. * * @param lexerActionExecutor The executor for actions already traversed by * the lexer while matching a token within a particular * {@link LexerATNConfig}. If this is {@code null}, the method behaves as * though it were an empty executor. * @param lexerAction The lexer action to execute after the actions * specified in {@code lexerActionExecutor}. * * @return A {@link LexerActionExecutor} for executing the combine actions * of {@code lexerActionExecutor} and {@code lexerAction}. */",67,75,[0],0,[0],0,[0],0,0,0,0,"append(LexerActionExecutor, LexerAction)",org.antlr.v4.runtime.atn.LexerActionExecutor,"append/2[org.antlr.v4.runtime.atn.LexerActionExecutor,org.antlr.v4.runtime.atn.LexerAction]",False,67,2,2,1,1,2,1,8,2,1,2,1,0,0,0,1,0,0,0,2,2,2,1,0,0,0,51,9,0,True
397,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\atn\LexerActionExecutor.java,org.antlr.v4.runtime.atn.LexerActionExecutor,LexerActionExecutor fixOffsetBeforeMatch(int),"/**
 * Creates a {@link LexerActionExecutor} which encodes the current offset
 * for position-dependent lexer actions.
 *
 * <p>Normally, when the executor encounters lexer actions where
 * {@link LexerAction#isPositionDependent} returns {@code true}, it calls
 * {@link IntStream#seek} on the input {@link CharStream} to set the input
 * position to the <em>end</em> of the current token. This behavior provides
 * for efficient DFA representation of lexer actions which appear at the end
 * of a lexer rule, even when the lexer rule matches a variable number of
 * characters.</p>
 *
 * <p>Prior to traversing a match transition in the ATN, the current offset
 * from the token start index is assigned to all position-dependent lexer
 * actions which have not already been assigned a fixed offset. By storing
 * the offsets relative to the token start index, the DFA representation of
 * lexer actions which appear in the middle of tokens remains efficient due
 * to sharing among tokens of the same length, regardless of their absolute
 * position in the input stream.</p>
 *
 * <p>If the current executor already has offsets assigned to all
 * position-dependent lexer actions, the method returns {@code this}.</p>
 *
 * @param offset The current offset to assign to all position-dependent
 * lexer actions which do not already have offsets assigned.
 *
 * @return A {@link LexerActionExecutor} which stores input stream offsets
 * for all position-dependent lexer actions.
 */
public LexerActionExecutor fixOffsetBeforeMatch(int offset) {
    LexerAction[] updatedLexerActions = null;
    for (int i = 0; i < lexerActions.length; i++) {
        if (lexerActions[i].isPositionDependent() && !(lexerActions[i] instanceof LexerIndexedCustomAction)) {
            if (updatedLexerActions == null) {
                updatedLexerActions = lexerActions.clone();
            }
            updatedLexerActions[i] = new LexerIndexedCustomAction(offset, lexerActions[i]);
        }
    }
    if (updatedLexerActions == null) {
        return this;
    }
    return new LexerActionExecutor(updatedLexerActions);
}","/**
 * Creates a {@link LexerActionExecutor} which encodes the current offset
 * for position-dependent lexer actions.
 *
 * <p>Normally, when the executor encounters lexer actions where
 * {@link LexerAction#isPositionDependent} returns {@code true}, it calls
 * {@link IntStream#seek} on the input {@link CharStream} to set the input
 * position to the <em>end</em> of the current token. This behavior provides
 * for efficient DFA representation of lexer actions which appear at the end
 * of a lexer rule, even when the lexer rule matches a variable number of
 * characters.</p>
 *
 * <p>Prior to traversing a match transition in the ATN, the current offset
 * from the token start index is assigned to all position-dependent lexer
 * actions which have not already been assigned a fixed offset. By storing
 * the offsets relative to the token start index, the DFA representation of
 * lexer actions which appear in the middle of tokens remains efficient due
 * to sharing among tokens of the same length, regardless of their absolute
 * position in the input stream.</p>
 *
 * <p>If the current executor already has offsets assigned to all
 * position-dependent lexer actions, the method returns {@code this}.</p>
 *
 * @param offset The current offset to assign to all position-dependent
 * lexer actions which do not already have offsets assigned.
 *
 * @return A {@link LexerActionExecutor} which stores input stream offsets
 * for all position-dependent lexer actions.
 */
", ,"/** * Creates a {@link LexerActionExecutor} which encodes the current offset * for position-dependent lexer actions. * * <p>Normally, when the executor encounters lexer actions where * {@link LexerAction#isPositionDependent} returns {@code true}, it calls * {@link IntStream#seek} on the input {@link CharStream} to set the input * position to the <em>end</em> of the current token. This behavior provides * for efficient DFA representation of lexer actions which appear at the end * of a lexer rule, even when the lexer rule matches a variable number of * characters.</p> * * <p>Prior to traversing a match transition in the ATN, the current offset * from the token start index is assigned to all position-dependent lexer * actions which have not already been assigned a fixed offset. By storing * the offsets relative to the token start index, the DFA representation of * lexer actions which appear in the middle of tokens remains efficient due * to sharing among tokens of the same length, regardless of their absolute * position in the input stream.</p> * * <p>If the current executor already has offsets assigned to all * position-dependent lexer actions, the method returns {@code this}.</p> * * @param offset The current offset to assign to all position-dependent * lexer actions which do not already have offsets assigned. * * @return A {@link LexerActionExecutor} which stores input stream offsets * for all position-dependent lexer actions. */",106,123,[0],0,[0],0,[0],0,0,0,0,fixOffsetBeforeMatch(int),org.antlr.v4.runtime.atn.LexerActionExecutor,fixOffsetBeforeMatch/1[int],False,106,3,4,1,3,6,2,15,2,2,1,2,0,0,1,2,0,1,0,1,4,0,3,0,0,0,99,1,0,True
398,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\atn\LexerActionExecutor.java,org.antlr.v4.runtime.atn.LexerActionExecutor,LexerAction[] getLexerActions(),"/**
 * Gets the lexer actions to be executed by this executor.
 * @return The lexer actions to be executed by this executor.
 */
public LexerAction[] getLexerActions() {
    return lexerActions;
}","/**
 * Gets the lexer actions to be executed by this executor.
 * @return The lexer actions to be executed by this executor.
 */
", ,/** * Gets the lexer actions to be executed by this executor. * @return The lexer actions to be executed by this executor. */,129,131,[0],0,[0],0,[0],0,0,0,0,getLexerActions(),org.antlr.v4.runtime.atn.LexerActionExecutor,getLexerActions/0,False,129,1,0,0,0,1,0,3,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,12,1,0,True
399,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\atn\LexerActionExecutor.java,org.antlr.v4.runtime.atn.LexerActionExecutor,"void execute(Lexer, CharStream, int)","/**
 * Execute the actions encapsulated by this executor within the context of a
 * particular {@link Lexer}.
 *
 * <p>This method calls {@link IntStream#seek} to set the position of the
 * {@code input} {@link CharStream} prior to calling
 * {@link LexerAction#execute} on a position-dependent action. Before the
 * method returns, the input position will be restored to the same position
 * it was in when the method was invoked.</p>
 *
 * @param lexer The lexer instance.
 * @param input The input stream which is the source for the current token.
 * When this method is called, the current {@link IntStream#index} for
 * {@code input} should be the start of the following token, i.e. 1
 * character past the end of the current token.
 * @param startIndex The token start index. This value may be passed to
 * {@link IntStream#seek} to set the {@code input} position to the beginning
 * of the token.
 */
public void execute(Lexer lexer, CharStream input, int startIndex) {
    boolean requiresSeek = false;
    int stopIndex = input.index();
    try {
        for (LexerAction lexerAction : lexerActions) {
            if (lexerAction instanceof LexerIndexedCustomAction) {
                int offset = ((LexerIndexedCustomAction) lexerAction).getOffset();
                input.seek(startIndex + offset);
                lexerAction = ((LexerIndexedCustomAction) lexerAction).getAction();
                requiresSeek = (startIndex + offset) != stopIndex;
            } else if (lexerAction.isPositionDependent()) {
                input.seek(stopIndex);
                requiresSeek = false;
            }
            lexerAction.execute(lexer);
        }
    } finally {
        if (requiresSeek) {
            input.seek(stopIndex);
        }
    }
}","/**
 * Execute the actions encapsulated by this executor within the context of a
 * particular {@link Lexer}.
 *
 * <p>This method calls {@link IntStream#seek} to set the position of the
 * {@code input} {@link CharStream} prior to calling
 * {@link LexerAction#execute} on a position-dependent action. Before the
 * method returns, the input position will be restored to the same position
 * it was in when the method was invoked.</p>
 *
 * @param lexer The lexer instance.
 * @param input The input stream which is the source for the current token.
 * When this method is called, the current {@link IntStream#index} for
 * {@code input} should be the start of the following token, i.e. 1
 * character past the end of the current token.
 * @param startIndex The token start index. This value may be passed to
 * {@link IntStream#seek} to set the {@code input} position to the beginning
 * of the token.
 */
", ,"/** * Execute the actions encapsulated by this executor within the context of a * particular {@link Lexer}. * * <p>This method calls {@link IntStream#seek} to set the position of the * {@code input} {@link CharStream} prior to calling * {@link LexerAction#execute} on a position-dependent action. Before the * method returns, the input position will be restored to the same position * it was in when the method was invoked.</p> * * @param lexer The lexer instance. * @param input The input stream which is the source for the current token. * When this method is called, the current {@link IntStream#index} for * {@code input} should be the start of the following token, i.e. 1 * character past the end of the current token. * @param startIndex The token start index. This value may be passed to * {@link IntStream#seek} to set the {@code input} position to the beginning * of the token. */",152,176,[0],0,[0],0,[0],0,0,0,0,"execute(Lexer, CharStream, int)",org.antlr.v4.runtime.atn.LexerActionExecutor,"execute/3[org.antlr.v4.runtime.Lexer,org.antlr.v4.runtime.CharStream,int]",False,152,5,7,1,6,5,6,24,0,3,3,6,0,0,1,1,1,3,0,0,6,2,3,0,0,0,65,1,0,True
400,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\atn\LexerChannelAction.java,org.antlr.v4.runtime.atn.LexerChannelAction,int getChannel(),"/**
 * Gets the channel to use for the {@link Token} created by the lexer.
 *
 * @return The channel to use for the {@link Token} created by the lexer.
 */
public int getChannel() {
    return channel;
}","/**
 * Gets the channel to use for the {@link Token} created by the lexer.
 *
 * @return The channel to use for the {@link Token} created by the lexer.
 */
", ,/** * Gets the channel to use for the {@link Token} created by the lexer. * * @return The channel to use for the {@link Token} created by the lexer. */,36,38,[0],0,[0],0,[0],0,0,0,0,getChannel(),org.antlr.v4.runtime.atn.LexerChannelAction,getChannel/0,False,36,0,1,1,0,1,0,3,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,11,1,0,True
401,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\atn\LexerChannelAction.java,org.antlr.v4.runtime.atn.LexerChannelAction,LexerActionType getActionType(),"/**
 * {@inheritDoc}
 * @return This method returns {@link LexerActionType#CHANNEL}.
 */
@Override
public LexerActionType getActionType() {
    return LexerActionType.CHANNEL;
}","/**
 * {@inheritDoc}
 * @return This method returns {@link LexerActionType#CHANNEL}.
 */
", ,/** * {@inheritDoc} * @return This method returns {@link LexerActionType#CHANNEL}. */,44,47,[0],0,[0],0,[0],0,0,0,0,getActionType(),org.antlr.v4.runtime.atn.LexerChannelAction,getActionType/0,False,45,1,1,1,0,1,0,3,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,7,1,0,True
402,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\atn\LexerChannelAction.java,org.antlr.v4.runtime.atn.LexerChannelAction,boolean isPositionDependent(),"/**
 * {@inheritDoc}
 * @return This method returns {@code false}.
 */
@Override
public boolean isPositionDependent() {
    return false;
}","/**
 * {@inheritDoc}
 * @return This method returns {@code false}.
 */
", ,/** * {@inheritDoc} * @return This method returns {@code false}. */,53,56,[0],0,[0],0,[0],0,0,0,0,isPositionDependent(),org.antlr.v4.runtime.atn.LexerChannelAction,isPositionDependent/0,False,54,0,0,0,0,1,0,3,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,7,1,0,True
403,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\atn\LexerChannelAction.java,org.antlr.v4.runtime.atn.LexerChannelAction,void execute(Lexer),"/**
 * {@inheritDoc}
 *
 * <p>This action is implemented by calling {@link Lexer#setChannel} with the
 * value provided by {@link #getChannel}.</p>
 */
@Override
public void execute(Lexer lexer) {
    lexer.setChannel(channel);
}","/**
 * {@inheritDoc}
 *
 * <p>This action is implemented by calling {@link Lexer#setChannel} with the
 * value provided by {@link #getChannel}.</p>
 */
", ,/** * {@inheritDoc} * * <p>This action is implemented by calling {@link Lexer#setChannel} with the * value provided by {@link #getChannel}.</p> */,64,67,[0],0,[0],0,[0],0,0,0,0,execute(Lexer),org.antlr.v4.runtime.atn.LexerChannelAction,execute/1[org.antlr.v4.runtime.Lexer],False,65,1,1,0,1,1,1,3,0,0,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,14,1,0,True
404,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\atn\LexerCustomAction.java,org.antlr.v4.runtime.atn.LexerCustomAction,int getRuleIndex(),"/**
 * Gets the rule index to use for calls to {@link Recognizer#action}.
 *
 * @return The rule index for the custom action.
 */
public int getRuleIndex() {
    return ruleIndex;
}","/**
 * Gets the rule index to use for calls to {@link Recognizer#action}.
 *
 * @return The rule index for the custom action.
 */
", ,/** * Gets the rule index to use for calls to {@link Recognizer#action}. * * @return The rule index for the custom action. */,50,52,[0],0,[0],0,[0],0,0,0,0,getRuleIndex(),org.antlr.v4.runtime.atn.LexerCustomAction,getRuleIndex/0,False,50,0,1,1,0,1,0,3,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,12,1,0,True
405,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\atn\LexerCustomAction.java,org.antlr.v4.runtime.atn.LexerCustomAction,int getActionIndex(),"/**
 * Gets the action index to use for calls to {@link Recognizer#action}.
 *
 * @return The action index for the custom action.
 */
public int getActionIndex() {
    return actionIndex;
}","/**
 * Gets the action index to use for calls to {@link Recognizer#action}.
 *
 * @return The action index for the custom action.
 */
", ,/** * Gets the action index to use for calls to {@link Recognizer#action}. * * @return The action index for the custom action. */,59,61,[0],0,[0],0,[0],0,0,0,0,getActionIndex(),org.antlr.v4.runtime.atn.LexerCustomAction,getActionIndex/0,False,59,0,1,1,0,1,0,3,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,12,1,0,True
406,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\atn\LexerCustomAction.java,org.antlr.v4.runtime.atn.LexerCustomAction,LexerActionType getActionType(),"/**
 * {@inheritDoc}
 *
 * @return This method returns {@link LexerActionType#CUSTOM}.
 */
@Override
public LexerActionType getActionType() {
    return LexerActionType.CUSTOM;
}","/**
 * {@inheritDoc}
 *
 * @return This method returns {@link LexerActionType#CUSTOM}.
 */
", ,/** * {@inheritDoc} * * @return This method returns {@link LexerActionType#CUSTOM}. */,68,71,[0],0,[0],0,[0],0,0,0,0,getActionType(),org.antlr.v4.runtime.atn.LexerCustomAction,getActionType/0,False,69,1,1,1,0,1,0,3,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,7,1,0,True
407,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\atn\LexerCustomAction.java,org.antlr.v4.runtime.atn.LexerCustomAction,boolean isPositionDependent(),"/**
 * Gets whether the lexer action is position-dependent. Position-dependent
 * actions may have different semantics depending on the {@link CharStream}
 * index at the time the action is executed.
 *
 * <p>Custom actions are position-dependent since they may represent a
 * user-defined embedded action which makes calls to methods like
 * {@link Lexer#getText}.</p>
 *
 * @return This method returns {@code true}.
 */
@Override
public boolean isPositionDependent() {
    return true;
}","/**
 * Gets whether the lexer action is position-dependent. Position-dependent
 * actions may have different semantics depending on the {@link CharStream}
 * index at the time the action is executed.
 *
 * <p>Custom actions are position-dependent since they may represent a
 * user-defined embedded action which makes calls to methods like
 * {@link Lexer#getText}.</p>
 *
 * @return This method returns {@code true}.
 */
", ,/** * Gets whether the lexer action is position-dependent. Position-dependent * actions may have different semantics depending on the {@link CharStream} * index at the time the action is executed. * * <p>Custom actions are position-dependent since they may represent a * user-defined embedded action which makes calls to methods like * {@link Lexer#getText}.</p> * * @return This method returns {@code true}. */,84,87,[0],0,[0],0,[0],0,0,0,0,isPositionDependent(),org.antlr.v4.runtime.atn.LexerCustomAction,isPositionDependent/0,False,85,0,0,0,0,1,0,3,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,42,1,0,True
408,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\atn\LexerCustomAction.java,org.antlr.v4.runtime.atn.LexerCustomAction,void execute(Lexer),"/**
 * {@inheritDoc}
 *
 * <p>Custom actions are implemented by calling {@link Lexer#action} with the
 * appropriate rule and action indexes.</p>
 */
@Override
public void execute(Lexer lexer) {
    lexer.action(null, ruleIndex, actionIndex);
}","/**
 * {@inheritDoc}
 *
 * <p>Custom actions are implemented by calling {@link Lexer#action} with the
 * appropriate rule and action indexes.</p>
 */
", ,/** * {@inheritDoc} * * <p>Custom actions are implemented by calling {@link Lexer#action} with the * appropriate rule and action indexes.</p> */,95,98,[0],0,[0],0,[0],0,0,0,0,execute(Lexer),org.antlr.v4.runtime.atn.LexerCustomAction,execute/1[org.antlr.v4.runtime.Lexer],False,96,2,1,0,1,1,1,3,0,0,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,15,1,0,True
409,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\atn\LexerIndexedCustomAction.java,org.antlr.v4.runtime.atn.LexerIndexedCustomAction,int getOffset(),"/**
 * Gets the location in the input {@link CharStream} at which the lexer
 * action should be executed. The value is interpreted as an offset relative
 * to the token start index.
 *
 * @return The location in the input {@link CharStream} at which the lexer
 * action should be executed.
 */
public int getOffset() {
    return offset;
}","/**
 * Gets the location in the input {@link CharStream} at which the lexer
 * action should be executed. The value is interpreted as an offset relative
 * to the token start index.
 *
 * @return The location in the input {@link CharStream} at which the lexer
 * action should be executed.
 */
", ,/** * Gets the location in the input {@link CharStream} at which the lexer * action should be executed. The value is interpreted as an offset relative * to the token start index. * * @return The location in the input {@link CharStream} at which the lexer * action should be executed. */,56,58,[0],0,[0],0,[0],0,0,0,0,getOffset(),org.antlr.v4.runtime.atn.LexerIndexedCustomAction,getOffset/0,False,56,0,1,1,0,1,0,3,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,25,1,0,True
410,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\atn\LexerIndexedCustomAction.java,org.antlr.v4.runtime.atn.LexerIndexedCustomAction,LexerAction getAction(),"/**
 * Gets the lexer action to execute.
 *
 * @return A {@link LexerAction} object which executes the lexer action.
 */
public LexerAction getAction() {
    return action;
}","/**
 * Gets the lexer action to execute.
 *
 * @return A {@link LexerAction} object which executes the lexer action.
 */
", ,/** * Gets the lexer action to execute. * * @return A {@link LexerAction} object which executes the lexer action. */,65,67,[0],0,[0],0,[0],0,0,0,0,getAction(),org.antlr.v4.runtime.atn.LexerIndexedCustomAction,getAction/0,False,65,1,1,1,0,1,0,3,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,12,1,0,True
411,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\atn\LexerIndexedCustomAction.java,org.antlr.v4.runtime.atn.LexerIndexedCustomAction,LexerActionType getActionType(),"/**
 * {@inheritDoc}
 *
 * @return This method returns the result of calling {@link #getActionType}
 * on the {@link LexerAction} returned by {@link #getAction}.
 */
@Override
public LexerActionType getActionType() {
    return action.getActionType();
}","/**
 * {@inheritDoc}
 *
 * @return This method returns the result of calling {@link #getActionType}
 * on the {@link LexerAction} returned by {@link #getAction}.
 */
", ,/** * {@inheritDoc} * * @return This method returns the result of calling {@link #getActionType} * on the {@link LexerAction} returned by {@link #getAction}. */,75,78,[0],0,[0],0,[0],0,0,0,0,getActionType(),org.antlr.v4.runtime.atn.LexerIndexedCustomAction,getActionType/0,False,76,2,1,0,1,1,1,3,1,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,14,1,0,True
412,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\atn\LexerIndexedCustomAction.java,org.antlr.v4.runtime.atn.LexerIndexedCustomAction,boolean isPositionDependent(),"/**
 * {@inheritDoc}
 * @return This method returns {@code true}.
 */
@Override
public boolean isPositionDependent() {
    return true;
}","/**
 * {@inheritDoc}
 * @return This method returns {@code true}.
 */
", ,/** * {@inheritDoc} * @return This method returns {@code true}. */,84,87,[0],0,[0],0,[0],0,0,0,0,isPositionDependent(),org.antlr.v4.runtime.atn.LexerIndexedCustomAction,isPositionDependent/0,False,85,0,0,0,0,1,0,3,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,7,1,0,True
413,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\atn\LexerIndexedCustomAction.java,org.antlr.v4.runtime.atn.LexerIndexedCustomAction,void execute(Lexer),"/**
 * {@inheritDoc}
 *
 * <p>This method calls {@link #execute} on the result of {@link #getAction}
 * using the provided {@code lexer}.</p>
 */
@Override
public void execute(Lexer lexer) {
    // assume the input stream position was properly set by the calling code
    action.execute(lexer);
}","/**
 * {@inheritDoc}
 *
 * <p>This method calls {@link #execute} on the result of {@link #getAction}
 * using the provided {@code lexer}.</p>
 */
","// assume the input stream position was properly set by the calling code
",/** * {@inheritDoc} * * <p>This method calls {@link #execute} on the result of {@link #getAction} * using the provided {@code lexer}.</p> */[[SEP]]// assume the input stream position was properly set by the calling code,95,99,[0],0,[0],0,"[0, 0]",0,0,0,0,execute(Lexer),org.antlr.v4.runtime.atn.LexerIndexedCustomAction,execute/1[org.antlr.v4.runtime.Lexer],False,96,2,1,0,1,1,1,3,0,0,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,13,1,0,True
414,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\atn\LexerModeAction.java,org.antlr.v4.runtime.atn.LexerModeAction,int getMode(),"/**
 * Get the lexer mode this action should transition the lexer to.
 *
 * @return The lexer mode for this {@code mode} command.
 */
public int getMode() {
    return mode;
}","/**
 * Get the lexer mode this action should transition the lexer to.
 *
 * @return The lexer mode for this {@code mode} command.
 */
", ,/** * Get the lexer mode this action should transition the lexer to. * * @return The lexer mode for this {@code mode} command. */,35,37,[0],0,[0],0,[0],0,0,0,0,getMode(),org.antlr.v4.runtime.atn.LexerModeAction,getMode/0,False,35,0,1,1,0,1,0,3,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,10,1,0,True
415,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\atn\LexerModeAction.java,org.antlr.v4.runtime.atn.LexerModeAction,LexerActionType getActionType(),"/**
 * {@inheritDoc}
 * @return This method returns {@link LexerActionType#MODE}.
 */
@Override
public LexerActionType getActionType() {
    return LexerActionType.MODE;
}","/**
 * {@inheritDoc}
 * @return This method returns {@link LexerActionType#MODE}.
 */
", ,/** * {@inheritDoc} * @return This method returns {@link LexerActionType#MODE}. */,43,46,[0],0,[0],0,[0],0,0,0,0,getActionType(),org.antlr.v4.runtime.atn.LexerModeAction,getActionType/0,False,44,1,1,1,0,1,0,3,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,7,1,0,True
416,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\atn\LexerModeAction.java,org.antlr.v4.runtime.atn.LexerModeAction,boolean isPositionDependent(),"/**
 * {@inheritDoc}
 * @return This method returns {@code false}.
 */
@Override
public boolean isPositionDependent() {
    return false;
}","/**
 * {@inheritDoc}
 * @return This method returns {@code false}.
 */
", ,/** * {@inheritDoc} * @return This method returns {@code false}. */,52,55,[0],0,[0],0,[0],0,0,0,0,isPositionDependent(),org.antlr.v4.runtime.atn.LexerModeAction,isPositionDependent/0,False,53,0,0,0,0,1,0,3,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,7,1,0,True
417,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\atn\LexerModeAction.java,org.antlr.v4.runtime.atn.LexerModeAction,void execute(Lexer),"/**
 * {@inheritDoc}
 *
 * <p>This action is implemented by calling {@link Lexer#mode} with the
 * value provided by {@link #getMode}.</p>
 */
@Override
public void execute(Lexer lexer) {
    lexer.mode(mode);
}","/**
 * {@inheritDoc}
 *
 * <p>This action is implemented by calling {@link Lexer#mode} with the
 * value provided by {@link #getMode}.</p>
 */
", ,/** * {@inheritDoc} * * <p>This action is implemented by calling {@link Lexer#mode} with the * value provided by {@link #getMode}.</p> */,63,66,[0],0,[0],0,[0],0,0,0,0,execute(Lexer),org.antlr.v4.runtime.atn.LexerModeAction,execute/1[org.antlr.v4.runtime.Lexer],False,64,1,1,0,1,1,1,3,0,0,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,14,1,0,True
418,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\atn\LexerMoreAction.java,org.antlr.v4.runtime.atn.LexerMoreAction,LexerActionType getActionType(),"/**
 * {@inheritDoc}
 * @return This method returns {@link LexerActionType#MORE}.
 */
@Override
public LexerActionType getActionType() {
    return LexerActionType.MORE;
}","/**
 * {@inheritDoc}
 * @return This method returns {@link LexerActionType#MORE}.
 */
", ,/** * {@inheritDoc} * @return This method returns {@link LexerActionType#MORE}. */,37,40,[0],0,[0],0,[0],0,0,0,0,getActionType(),org.antlr.v4.runtime.atn.LexerMoreAction,getActionType/0,False,38,1,1,1,0,1,0,3,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,7,1,0,True
419,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\atn\LexerMoreAction.java,org.antlr.v4.runtime.atn.LexerMoreAction,boolean isPositionDependent(),"/**
 * {@inheritDoc}
 * @return This method returns {@code false}.
 */
@Override
public boolean isPositionDependent() {
    return false;
}","/**
 * {@inheritDoc}
 * @return This method returns {@code false}.
 */
", ,/** * {@inheritDoc} * @return This method returns {@code false}. */,46,49,[0],0,[0],0,[0],0,0,0,0,isPositionDependent(),org.antlr.v4.runtime.atn.LexerMoreAction,isPositionDependent/0,False,47,0,0,0,0,1,0,3,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,7,1,0,True
420,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\atn\LexerMoreAction.java,org.antlr.v4.runtime.atn.LexerMoreAction,void execute(Lexer),"/**
 * {@inheritDoc}
 *
 * <p>This action is implemented by calling {@link Lexer#more}.</p>
 */
@Override
public void execute(Lexer lexer) {
    lexer.more();
}","/**
 * {@inheritDoc}
 *
 * <p>This action is implemented by calling {@link Lexer#more}.</p>
 */
", ,/** * {@inheritDoc} * * <p>This action is implemented by calling {@link Lexer#more}.</p> */,56,59,[0],0,[0],0,[0],0,0,0,0,execute(Lexer),org.antlr.v4.runtime.atn.LexerMoreAction,execute/1[org.antlr.v4.runtime.Lexer],False,57,1,1,0,1,1,1,3,0,0,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,10,1,0,True
421,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\atn\LexerPopModeAction.java,org.antlr.v4.runtime.atn.LexerPopModeAction,LexerActionType getActionType(),"/**
 * {@inheritDoc}
 * @return This method returns {@link LexerActionType#POP_MODE}.
 */
@Override
public LexerActionType getActionType() {
    return LexerActionType.POP_MODE;
}","/**
 * {@inheritDoc}
 * @return This method returns {@link LexerActionType#POP_MODE}.
 */
", ,/** * {@inheritDoc} * @return This method returns {@link LexerActionType#POP_MODE}. */,37,40,[0],0,[0],0,[0],0,0,0,0,getActionType(),org.antlr.v4.runtime.atn.LexerPopModeAction,getActionType/0,False,38,1,1,1,0,1,0,3,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,7,1,0,True
422,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\atn\LexerPopModeAction.java,org.antlr.v4.runtime.atn.LexerPopModeAction,boolean isPositionDependent(),"/**
 * {@inheritDoc}
 * @return This method returns {@code false}.
 */
@Override
public boolean isPositionDependent() {
    return false;
}","/**
 * {@inheritDoc}
 * @return This method returns {@code false}.
 */
", ,/** * {@inheritDoc} * @return This method returns {@code false}. */,46,49,[0],0,[0],0,[0],0,0,0,0,isPositionDependent(),org.antlr.v4.runtime.atn.LexerPopModeAction,isPositionDependent/0,False,47,0,0,0,0,1,0,3,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,7,1,0,True
423,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\atn\LexerPopModeAction.java,org.antlr.v4.runtime.atn.LexerPopModeAction,void execute(Lexer),"/**
 * {@inheritDoc}
 *
 * <p>This action is implemented by calling {@link Lexer#popMode}.</p>
 */
@Override
public void execute(Lexer lexer) {
    lexer.popMode();
}","/**
 * {@inheritDoc}
 *
 * <p>This action is implemented by calling {@link Lexer#popMode}.</p>
 */
", ,/** * {@inheritDoc} * * <p>This action is implemented by calling {@link Lexer#popMode}.</p> */,56,59,[0],0,[0],0,[0],0,0,0,0,execute(Lexer),org.antlr.v4.runtime.atn.LexerPopModeAction,execute/1[org.antlr.v4.runtime.Lexer],False,57,1,1,0,1,1,1,3,0,0,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,10,1,0,True
424,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\atn\LexerPushModeAction.java,org.antlr.v4.runtime.atn.LexerPushModeAction,int getMode(),"/**
 * Get the lexer mode this action should transition the lexer to.
 *
 * @return The lexer mode for this {@code pushMode} command.
 */
public int getMode() {
    return mode;
}","/**
 * Get the lexer mode this action should transition the lexer to.
 *
 * @return The lexer mode for this {@code pushMode} command.
 */
", ,/** * Get the lexer mode this action should transition the lexer to. * * @return The lexer mode for this {@code pushMode} command. */,35,37,[0],0,[0],0,[0],0,0,0,0,getMode(),org.antlr.v4.runtime.atn.LexerPushModeAction,getMode/0,False,35,0,1,1,0,1,0,3,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,11,1,0,True
425,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\atn\LexerPushModeAction.java,org.antlr.v4.runtime.atn.LexerPushModeAction,LexerActionType getActionType(),"/**
 * {@inheritDoc}
 * @return This method returns {@link LexerActionType#PUSH_MODE}.
 */
@Override
public LexerActionType getActionType() {
    return LexerActionType.PUSH_MODE;
}","/**
 * {@inheritDoc}
 * @return This method returns {@link LexerActionType#PUSH_MODE}.
 */
", ,/** * {@inheritDoc} * @return This method returns {@link LexerActionType#PUSH_MODE}. */,43,46,[0],0,[0],0,[0],0,0,0,0,getActionType(),org.antlr.v4.runtime.atn.LexerPushModeAction,getActionType/0,False,44,1,1,1,0,1,0,3,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,7,1,0,True
426,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\atn\LexerPushModeAction.java,org.antlr.v4.runtime.atn.LexerPushModeAction,boolean isPositionDependent(),"/**
 * {@inheritDoc}
 * @return This method returns {@code false}.
 */
@Override
public boolean isPositionDependent() {
    return false;
}","/**
 * {@inheritDoc}
 * @return This method returns {@code false}.
 */
", ,/** * {@inheritDoc} * @return This method returns {@code false}. */,52,55,[0],0,[0],0,[0],0,0,0,0,isPositionDependent(),org.antlr.v4.runtime.atn.LexerPushModeAction,isPositionDependent/0,False,53,0,0,0,0,1,0,3,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,7,1,0,True
427,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\atn\LexerPushModeAction.java,org.antlr.v4.runtime.atn.LexerPushModeAction,void execute(Lexer),"/**
 * {@inheritDoc}
 *
 * <p>This action is implemented by calling {@link Lexer#pushMode} with the
 * value provided by {@link #getMode}.</p>
 */
@Override
public void execute(Lexer lexer) {
    lexer.pushMode(mode);
}","/**
 * {@inheritDoc}
 *
 * <p>This action is implemented by calling {@link Lexer#pushMode} with the
 * value provided by {@link #getMode}.</p>
 */
", ,/** * {@inheritDoc} * * <p>This action is implemented by calling {@link Lexer#pushMode} with the * value provided by {@link #getMode}.</p> */,63,66,[0],0,[0],0,[0],0,0,0,0,execute(Lexer),org.antlr.v4.runtime.atn.LexerPushModeAction,execute/1[org.antlr.v4.runtime.Lexer],False,64,1,1,0,1,1,1,3,0,0,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,14,1,0,True
428,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\atn\LexerSkipAction.java,org.antlr.v4.runtime.atn.LexerSkipAction,LexerActionType getActionType(),"/**
 * {@inheritDoc}
 * @return This method returns {@link LexerActionType#SKIP}.
 */
@Override
public LexerActionType getActionType() {
    return LexerActionType.SKIP;
}","/**
 * {@inheritDoc}
 * @return This method returns {@link LexerActionType#SKIP}.
 */
", ,/** * {@inheritDoc} * @return This method returns {@link LexerActionType#SKIP}. */,37,40,[0],0,[0],0,[0],0,0,0,0,getActionType(),org.antlr.v4.runtime.atn.LexerSkipAction,getActionType/0,False,38,1,1,1,0,1,0,3,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,7,1,0,True
429,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\atn\LexerSkipAction.java,org.antlr.v4.runtime.atn.LexerSkipAction,boolean isPositionDependent(),"/**
 * {@inheritDoc}
 * @return This method returns {@code false}.
 */
@Override
public boolean isPositionDependent() {
    return false;
}","/**
 * {@inheritDoc}
 * @return This method returns {@code false}.
 */
", ,/** * {@inheritDoc} * @return This method returns {@code false}. */,46,49,[0],0,[0],0,[0],0,0,0,0,isPositionDependent(),org.antlr.v4.runtime.atn.LexerSkipAction,isPositionDependent/0,False,47,0,0,0,0,1,0,3,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,7,1,0,True
430,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\atn\LexerSkipAction.java,org.antlr.v4.runtime.atn.LexerSkipAction,void execute(Lexer),"/**
 * {@inheritDoc}
 *
 * <p>This action is implemented by calling {@link Lexer#skip}.</p>
 */
@Override
public void execute(Lexer lexer) {
    lexer.skip();
}","/**
 * {@inheritDoc}
 *
 * <p>This action is implemented by calling {@link Lexer#skip}.</p>
 */
", ,/** * {@inheritDoc} * * <p>This action is implemented by calling {@link Lexer#skip}.</p> */,56,59,[0],0,[0],0,[0],0,0,0,0,execute(Lexer),org.antlr.v4.runtime.atn.LexerSkipAction,execute/1[org.antlr.v4.runtime.Lexer],False,57,1,1,0,1,1,1,3,0,0,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,10,1,0,True
431,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\atn\LexerTypeAction.java,org.antlr.v4.runtime.atn.LexerTypeAction,int getType(),"/**
 * Gets the type to assign to a token created by the lexer.
 * @return The type to assign to a token created by the lexer.
 */
public int getType() {
    return type;
}","/**
 * Gets the type to assign to a token created by the lexer.
 * @return The type to assign to a token created by the lexer.
 */
", ,/** * Gets the type to assign to a token created by the lexer. * @return The type to assign to a token created by the lexer. */,34,36,[0],0,[0],0,[0],0,0,0,0,getType(),org.antlr.v4.runtime.atn.LexerTypeAction,getType/0,False,34,0,1,1,0,1,0,3,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,12,1,0,True
432,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\atn\LexerTypeAction.java,org.antlr.v4.runtime.atn.LexerTypeAction,LexerActionType getActionType(),"/**
 * {@inheritDoc}
 * @return This method returns {@link LexerActionType#TYPE}.
 */
@Override
public LexerActionType getActionType() {
    return LexerActionType.TYPE;
}","/**
 * {@inheritDoc}
 * @return This method returns {@link LexerActionType#TYPE}.
 */
", ,/** * {@inheritDoc} * @return This method returns {@link LexerActionType#TYPE}. */,42,45,[0],0,[0],0,[0],0,0,0,0,getActionType(),org.antlr.v4.runtime.atn.LexerTypeAction,getActionType/0,False,43,1,1,1,0,1,0,3,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,7,1,0,True
433,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\atn\LexerTypeAction.java,org.antlr.v4.runtime.atn.LexerTypeAction,boolean isPositionDependent(),"/**
 * {@inheritDoc}
 * @return This method returns {@code false}.
 */
@Override
public boolean isPositionDependent() {
    return false;
}","/**
 * {@inheritDoc}
 * @return This method returns {@code false}.
 */
", ,/** * {@inheritDoc} * @return This method returns {@code false}. */,51,54,[0],0,[0],0,[0],0,0,0,0,isPositionDependent(),org.antlr.v4.runtime.atn.LexerTypeAction,isPositionDependent/0,False,52,0,0,0,0,1,0,3,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,7,1,0,True
434,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\atn\LexerTypeAction.java,org.antlr.v4.runtime.atn.LexerTypeAction,void execute(Lexer),"/**
 * {@inheritDoc}
 *
 * <p>This action is implemented by calling {@link Lexer#setType} with the
 * value provided by {@link #getType}.</p>
 */
@Override
public void execute(Lexer lexer) {
    lexer.setType(type);
}","/**
 * {@inheritDoc}
 *
 * <p>This action is implemented by calling {@link Lexer#setType} with the
 * value provided by {@link #getType}.</p>
 */
", ,/** * {@inheritDoc} * * <p>This action is implemented by calling {@link Lexer#setType} with the * value provided by {@link #getType}.</p> */,62,65,[0],0,[0],0,[0],0,0,0,0,execute(Lexer),org.antlr.v4.runtime.atn.LexerTypeAction,execute/1[org.antlr.v4.runtime.Lexer],False,63,1,1,0,1,1,1,3,0,0,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,14,1,0,True
435,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\atn\ParseInfo.java,org.antlr.v4.runtime.atn.ParseInfo,DecisionInfo[] getDecisionInfo(),"/**
 * Gets an array of {@link DecisionInfo} instances containing the profiling
 * information gathered for each decision in the ATN.
 *
 * @return An array of {@link DecisionInfo} instances, indexed by decision
 * number.
 */
public DecisionInfo[] getDecisionInfo() {
    return atnSimulator.getDecisionInfo();
}","/**
 * Gets an array of {@link DecisionInfo} instances containing the profiling
 * information gathered for each decision in the ATN.
 *
 * @return An array of {@link DecisionInfo} instances, indexed by decision
 * number.
 */
", ,"/** * Gets an array of {@link DecisionInfo} instances containing the profiling * information gathered for each decision in the ATN. * * @return An array of {@link DecisionInfo} instances, indexed by decision * number. */",34,36,[0],0,[0],0,[0],0,0,0,0,getDecisionInfo(),org.antlr.v4.runtime.atn.ParseInfo,getDecisionInfo/0,False,34,2,2,1,1,1,1,3,1,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,18,1,0,True
436,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\atn\ParseInfo.java,org.antlr.v4.runtime.atn.ParseInfo,List<Integer> getLLDecisions(),"/**
 * Gets the decision numbers for decisions that required one or more
 * full-context predictions during parsing. These are decisions for which
 * {@link DecisionInfo#LL_Fallback} is non-zero.
 *
 * @return A list of decision numbers which required one or more
 * full-context predictions during parsing.
 */
public List<Integer> getLLDecisions() {
    DecisionInfo[] decisions = atnSimulator.getDecisionInfo();
    List<Integer> LL = new ArrayList<Integer>();
    for (int i = 0; i < decisions.length; i++) {
        long fallBack = decisions[i].LL_Fallback;
        if (fallBack > 0)
            LL.add(i);
    }
    return LL;
}","/**
 * Gets the decision numbers for decisions that required one or more
 * full-context predictions during parsing. These are decisions for which
 * {@link DecisionInfo#LL_Fallback} is non-zero.
 *
 * @return A list of decision numbers which required one or more
 * full-context predictions during parsing.
 */
", ,/** * Gets the decision numbers for decisions that required one or more * full-context predictions during parsing. These are decisions for which * {@link DecisionInfo#LL_Fallback} is non-zero. * * @return A list of decision numbers which required one or more * full-context predictions during parsing. */,46,54,[0],0,[0],0,[0],0,0,0,0,getLLDecisions(),org.antlr.v4.runtime.atn.ParseInfo,getLLDecisions/0,False,46,2,1,0,1,3,2,9,1,4,0,2,0,0,1,0,0,0,0,2,4,0,2,0,0,0,29,1,0,True
437,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\atn\ParseInfo.java,org.antlr.v4.runtime.atn.ParseInfo,long getTotalTimeInPrediction(),"/**
 * Gets the total time spent during prediction across all decisions made
 * during parsing. This value is the sum of
 * {@link DecisionInfo#timeInPrediction} for all decisions.
 */
public long getTotalTimeInPrediction() {
    DecisionInfo[] decisions = atnSimulator.getDecisionInfo();
    long t = 0;
    for (int i = 0; i < decisions.length; i++) {
        t += decisions[i].timeInPrediction;
    }
    return t;
}","/**
 * Gets the total time spent during prediction across all decisions made
 * during parsing. This value is the sum of
 * {@link DecisionInfo#timeInPrediction} for all decisions.
 */
", ,/** * Gets the total time spent during prediction across all decisions made * during parsing. This value is the sum of * {@link DecisionInfo#timeInPrediction} for all decisions. */,61,68,[0],0,[0],0,[0],0,0,0,0,getTotalTimeInPrediction(),org.antlr.v4.runtime.atn.ParseInfo,getTotalTimeInPrediction/0,False,61,2,1,0,1,2,1,8,1,3,0,1,0,0,1,0,0,0,0,2,4,0,1,0,0,0,23,1,0,True
438,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\atn\ParseInfo.java,org.antlr.v4.runtime.atn.ParseInfo,long getTotalSLLLookaheadOps(),"/**
 * Gets the total number of SLL lookahead operations across all decisions
 * made during parsing. This value is the sum of
 * {@link DecisionInfo#SLL_TotalLook} for all decisions.
 */
public long getTotalSLLLookaheadOps() {
    DecisionInfo[] decisions = atnSimulator.getDecisionInfo();
    long k = 0;
    for (int i = 0; i < decisions.length; i++) {
        k += decisions[i].SLL_TotalLook;
    }
    return k;
}","/**
 * Gets the total number of SLL lookahead operations across all decisions
 * made during parsing. This value is the sum of
 * {@link DecisionInfo#SLL_TotalLook} for all decisions.
 */
", ,/** * Gets the total number of SLL lookahead operations across all decisions * made during parsing. This value is the sum of * {@link DecisionInfo#SLL_TotalLook} for all decisions. */,75,82,[0],0,[0],0,[0],0,0,0,0,getTotalSLLLookaheadOps(),org.antlr.v4.runtime.atn.ParseInfo,getTotalSLLLookaheadOps/0,False,75,2,1,0,1,2,1,8,1,3,0,1,0,0,1,0,0,0,0,2,4,0,1,0,0,0,24,1,0,True
439,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\atn\ParseInfo.java,org.antlr.v4.runtime.atn.ParseInfo,long getTotalLLLookaheadOps(),"/**
 * Gets the total number of LL lookahead operations across all decisions
 * made during parsing. This value is the sum of
 * {@link DecisionInfo#LL_TotalLook} for all decisions.
 */
public long getTotalLLLookaheadOps() {
    DecisionInfo[] decisions = atnSimulator.getDecisionInfo();
    long k = 0;
    for (int i = 0; i < decisions.length; i++) {
        k += decisions[i].LL_TotalLook;
    }
    return k;
}","/**
 * Gets the total number of LL lookahead operations across all decisions
 * made during parsing. This value is the sum of
 * {@link DecisionInfo#LL_TotalLook} for all decisions.
 */
", ,/** * Gets the total number of LL lookahead operations across all decisions * made during parsing. This value is the sum of * {@link DecisionInfo#LL_TotalLook} for all decisions. */,89,96,[0],0,[0],0,[0],0,0,0,0,getTotalLLLookaheadOps(),org.antlr.v4.runtime.atn.ParseInfo,getTotalLLLookaheadOps/0,False,89,2,1,0,1,2,1,8,1,3,0,1,0,0,1,0,0,0,0,2,4,0,1,0,0,0,23,1,0,True
440,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\atn\ParseInfo.java,org.antlr.v4.runtime.atn.ParseInfo,long getTotalSLLATNLookaheadOps(),"/**
 * Gets the total number of ATN lookahead operations for SLL prediction
 * across all decisions made during parsing.
 */
public long getTotalSLLATNLookaheadOps() {
    DecisionInfo[] decisions = atnSimulator.getDecisionInfo();
    long k = 0;
    for (int i = 0; i < decisions.length; i++) {
        k += decisions[i].SLL_ATNTransitions;
    }
    return k;
}","/**
 * Gets the total number of ATN lookahead operations for SLL prediction
 * across all decisions made during parsing.
 */
", ,/** * Gets the total number of ATN lookahead operations for SLL prediction * across all decisions made during parsing. */,102,109,[0],0,[0],0,[0],0,0,0,0,getTotalSLLATNLookaheadOps(),org.antlr.v4.runtime.atn.ParseInfo,getTotalSLLATNLookaheadOps/0,False,102,2,1,0,1,2,1,8,1,3,0,1,0,0,1,0,0,0,0,2,4,0,1,0,0,0,24,1,0,True
441,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\atn\ParseInfo.java,org.antlr.v4.runtime.atn.ParseInfo,long getTotalLLATNLookaheadOps(),"/**
 * Gets the total number of ATN lookahead operations for LL prediction
 * across all decisions made during parsing.
 */
public long getTotalLLATNLookaheadOps() {
    DecisionInfo[] decisions = atnSimulator.getDecisionInfo();
    long k = 0;
    for (int i = 0; i < decisions.length; i++) {
        k += decisions[i].LL_ATNTransitions;
    }
    return k;
}","/**
 * Gets the total number of ATN lookahead operations for LL prediction
 * across all decisions made during parsing.
 */
", ,/** * Gets the total number of ATN lookahead operations for LL prediction * across all decisions made during parsing. */,115,122,[0],0,[0],0,[0],0,0,0,0,getTotalLLATNLookaheadOps(),org.antlr.v4.runtime.atn.ParseInfo,getTotalLLATNLookaheadOps/0,False,115,2,1,0,1,2,1,8,1,3,0,1,0,0,1,0,0,0,0,2,4,0,1,0,0,0,23,1,0,True
442,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\atn\ParseInfo.java,org.antlr.v4.runtime.atn.ParseInfo,long getTotalATNLookaheadOps(),"/**
 * Gets the total number of ATN lookahead operations for SLL and LL
 * prediction across all decisions made during parsing.
 *
 * <p>
 * This value is the sum of {@link #getTotalSLLATNLookaheadOps} and
 * {@link #getTotalLLATNLookaheadOps}.</p>
 */
public long getTotalATNLookaheadOps() {
    DecisionInfo[] decisions = atnSimulator.getDecisionInfo();
    long k = 0;
    for (int i = 0; i < decisions.length; i++) {
        k += decisions[i].SLL_ATNTransitions;
        k += decisions[i].LL_ATNTransitions;
    }
    return k;
}","/**
 * Gets the total number of ATN lookahead operations for SLL and LL
 * prediction across all decisions made during parsing.
 *
 * <p>
 * This value is the sum of {@link #getTotalSLLATNLookaheadOps} and
 * {@link #getTotalLLATNLookaheadOps}.</p>
 */
", ,/** * Gets the total number of ATN lookahead operations for SLL and LL * prediction across all decisions made during parsing. * * <p> * This value is the sum of {@link #getTotalSLLATNLookaheadOps} and * {@link #getTotalLLATNLookaheadOps}.</p> */,132,140,[0],0,[0],0,[0],0,0,0,0,getTotalATNLookaheadOps(),org.antlr.v4.runtime.atn.ParseInfo,getTotalATNLookaheadOps/0,False,132,2,1,0,1,2,1,9,1,3,0,1,0,0,1,0,0,0,0,2,5,0,1,0,0,0,30,1,0,True
443,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\atn\ParseInfo.java,org.antlr.v4.runtime.atn.ParseInfo,int getDFASize(),"/**
 * Gets the total number of DFA states stored in the DFA cache for all
 * decisions in the ATN.
 */
public int getDFASize() {
    int n = 0;
    DFA[] decisionToDFA = atnSimulator.decisionToDFA;
    for (int i = 0; i < decisionToDFA.length; i++) {
        n += getDFASize(i);
    }
    return n;
}","/**
 * Gets the total number of DFA states stored in the DFA cache for all
 * decisions in the ATN.
 */
", ,/** * Gets the total number of DFA states stored in the DFA cache for all * decisions in the ATN. */,146,153,[0],0,[0],0,[0],0,0,0,0,getDFASize(),org.antlr.v4.runtime.atn.ParseInfo,getDFASize/0,False,146,2,1,0,1,2,1,8,1,3,0,1,1,1,1,0,0,0,0,2,4,0,1,0,0,0,20,1,0,True
444,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\atn\ParseInfo.java,org.antlr.v4.runtime.atn.ParseInfo,int getDFASize(int),"/**
 * Gets the total number of DFA states stored in the DFA cache for a
 * particular decision.
 */
public int getDFASize(int decision) {
    DFA decisionToDFA = atnSimulator.decisionToDFA[decision];
    return decisionToDFA.states.size();
}","/**
 * Gets the total number of DFA states stored in the DFA cache for a
 * particular decision.
 */
", ,/** * Gets the total number of DFA states stored in the DFA cache for a * particular decision. */,159,162,[0],0,[0],0,[0],0,0,0,0,getDFASize(int),org.antlr.v4.runtime.atn.ParseInfo,getDFASize/1[int],False,159,1,1,1,0,1,1,4,1,1,1,1,0,0,0,0,0,0,0,0,1,0,0,0,0,0,18,1,0,True
445,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\atn\ParserATNSimulator.java,org.antlr.v4.runtime.atn.ParserATNSimulator,"int adaptivePredict(TokenStream, int, ParserRuleContext)","public int adaptivePredict(TokenStream input, int decision, ParserRuleContext outerContext) {
    if (debug || debug_list_atn_decisions) {
        System.out.println(""adaptivePredict decision "" + decision + "" exec LA(1)=="" + getLookaheadName(input) + "" line "" + input.LT(1).getLine() + "":"" + input.LT(1).getCharPositionInLine());
    }
    _input = input;
    _startIndex = input.index();
    _outerContext = outerContext;
    DFA dfa = decisionToDFA[decision];
    _dfa = dfa;
    int m = input.mark();
    int index = _startIndex;
    // Now we are certain to have a specific decision's DFA
    // But, do we still need an initial state?
    try {
        DFAState s0;
        if (dfa.isPrecedenceDfa()) {
            // the start state for a precedence DFA depends on the current
            // parser precedence, and is provided by a DFA method.
            s0 = dfa.getPrecedenceStartState(parser.getPrecedence());
        } else {
            // the start state for a ""regular"" DFA is just s0
            s0 = dfa.s0;
        }
        if (s0 == null) {
            if (outerContext == null)
                outerContext = ParserRuleContext.EMPTY;
            if (debug || debug_list_atn_decisions) {
                System.out.println(""predictATN decision "" + dfa.decision + "" exec LA(1)=="" + getLookaheadName(input) + "", outerContext="" + outerContext.toString(parser));
            }
            boolean fullCtx = false;
            ATNConfigSet s0_closure = computeStartState(dfa.atnStartState, ParserRuleContext.EMPTY, fullCtx);
            if (dfa.isPrecedenceDfa()) {
                /* If this is a precedence DFA, we use applyPrecedenceFilter
					 * to convert the computed start state to a precedence start
					 * state. We then use DFA.setPrecedenceStartState to set the
					 * appropriate start state for the precedence level rather
					 * than simply setting DFA.s0.
					 */
                // not used for prediction but useful to know start configs anyway
                dfa.s0.configs = s0_closure;
                s0_closure = applyPrecedenceFilter(s0_closure);
                s0 = addDFAState(dfa, new DFAState(s0_closure));
                dfa.setPrecedenceStartState(parser.getPrecedence(), s0);
            } else {
                s0 = addDFAState(dfa, new DFAState(s0_closure));
                dfa.s0 = s0;
            }
        }
        int alt = execATN(dfa, s0, input, index, outerContext);
        if (debug)
            System.out.println(""DFA after predictATN: "" + dfa.toString(parser.getVocabulary()));
        return alt;
    } finally {
        // wack cache after each prediction
        mergeCache = null;
        _dfa = null;
        input.seek(index);
        input.release(m);
    }
}", ,"// Now we are certain to have a specific decision's DFA
[[SEP]]// But, do we still need an initial state?
[[SEP]]// the start state for a precedence DFA depends on the current
[[SEP]]// parser precedence, and is provided by a DFA method.
[[SEP]]// the start state for a ""regular"" DFA is just s0
[[SEP]]/* If this is a precedence DFA, we use applyPrecedenceFilter
					 * to convert the computed start state to a precedence start
					 * state. We then use DFA.setPrecedenceStartState to set the
					 * appropriate start state for the precedence level rather
					 * than simply setting DFA.s0.
					 */
[[SEP]]// not used for prediction but useful to know start configs anyway
[[SEP]]// wack cache after each prediction
","// Now we are certain to have a specific decision's DFA// But, do we still need an initial state?[[SEP]]// the start state for a precedence DFA depends on the current// parser precedence, and is provided by a DFA method.[[SEP]]// the start state for a ""regular"" DFA is just s0[[SEP]]/* If this is a precedence DFA, we use applyPrecedenceFilter					 * to convert the computed start state to a precedence start					 * state. We then use DFA.setPrecedenceStartState to set the					 * appropriate start state for the precedence level rather					 * than simply setting DFA.s0.					 */[[SEP]]// not used for prediction but useful to know start configs anyway[[SEP]]// wack cache after each prediction",332,406,[0],0,"[0, 0, 0, 0, 0, 0, 0, 0]",0,"[0, 0, 0, 0, 0, 0]",0,0,1,0,"adaptivePredict(TokenStream, int, ParserRuleContext)",org.antlr.v4.runtime.atn.ParserATNSimulator,"adaptivePredict/3[org.antlr.v4.runtime.TokenStream,int,org.antlr.v4.runtime.ParserRuleContext]",False,334,11,21,1,20,10,20,48,1,7,3,20,5,19,0,2,1,0,8,2,20,3,3,0,0,0,51,1,0,False
446,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\atn\ParserATNSimulator.java,org.antlr.v4.runtime.atn.ParserATNSimulator,"int execATN(DFA, DFAState, TokenStream, int, ParserRuleContext)","/**
 *  Performs ATN simulation to compute a predicted alternative based
 *   upon the remaining input, but also updates the DFA cache to avoid
 *   having to traverse the ATN again for the same input sequence.
 *
 * 	 There are some key conditions we're looking for after computing a new
 * 	 set of ATN configs (proposed DFA state):
 *  if the set is empty, there is no viable alternative for current symbol
 *  does the state uniquely predict an alternative?
 *  does the state have a conflict that would prevent us from
 * 	         putting it on the work list?
 *
 * 	 We also have some key operations to do:
 *  add an edge from previous DFA state to potentially new DFA state, D,
 * 	         upon current symbol but only if adding to work list, which means in all
 * 	         cases except no viable alternative (and possibly non-greedy decisions?)
 *  collecting predicates and adding semantic context to DFA accept states
 *  adding rule context to context-sensitive DFA accept states
 *  consuming an input symbol
 *  reporting a conflict
 *  reporting an ambiguity
 *  reporting a context sensitivity
 *  reporting insufficient predicates
 *
 * 	 cover these cases:
 * 	    dead end
 * 	    single alt
 * 	    single alt + preds
 * 	    conflict
 * 	    conflict + preds
 */
protected int execATN(DFA dfa, DFAState s0, TokenStream input, int startIndex, ParserRuleContext outerContext) {
    if (debug || debug_list_atn_decisions) {
        System.out.println(""execATN decision "" + dfa.decision + "" exec LA(1)=="" + getLookaheadName(input) + "" line "" + input.LT(1).getLine() + "":"" + input.LT(1).getCharPositionInLine());
    }
    DFAState previousD = s0;
    if (debug)
        System.out.println(""s0 = "" + s0);
    int t = input.LA(1);
    while (true) {
        // while more work
        DFAState D = getExistingTargetState(previousD, t);
        if (D == null) {
            D = computeTargetState(dfa, previousD, t);
        }
        if (D == ERROR) {
            // if any configs in previous dipped into outer context, that
            // means that input up to t actually finished entry rule
            // at least for SLL decision. Full LL doesn't dip into outer
            // so don't need special case.
            // We will get an error no matter what so delay until after
            // decision; better error message. Also, no reachable target
            // ATN states in SLL implies LL will also get nowhere.
            // If conflict in states that dip out, choose min since we
            // will get error no matter what.
            NoViableAltException e = noViableAlt(input, outerContext, previousD.configs, startIndex);
            input.seek(startIndex);
            int alt = getSynValidOrSemInvalidAltThatFinishedDecisionEntryRule(previousD.configs, outerContext);
            if (alt != ATN.INVALID_ALT_NUMBER) {
                return alt;
            }
            throw e;
        }
        if (D.requiresFullContext && mode != PredictionMode.SLL) {
            // IF PREDS, MIGHT RESOLVE TO SINGLE ALT => SLL (or syntax error)
            BitSet conflictingAlts = D.configs.conflictingAlts;
            if (D.predicates != null) {
                if (debug)
                    System.out.println(""DFA state has preds in DFA sim LL failover"");
                int conflictIndex = input.index();
                if (conflictIndex != startIndex) {
                    input.seek(startIndex);
                }
                conflictingAlts = evalSemanticContext(D.predicates, outerContext, true);
                if (conflictingAlts.cardinality() == 1) {
                    if (debug)
                        System.out.println(""Full LL avoided"");
                    return conflictingAlts.nextSetBit(0);
                }
                if (conflictIndex != startIndex) {
                    // restore the index so reporting the fallback to full
                    // context occurs with the index at the correct spot
                    input.seek(conflictIndex);
                }
            }
            if (dfa_debug)
                System.out.println(""ctx sensitive state "" + outerContext + "" in "" + D);
            boolean fullCtx = true;
            ATNConfigSet s0_closure = computeStartState(dfa.atnStartState, outerContext, fullCtx);
            reportAttemptingFullContext(dfa, conflictingAlts, D.configs, startIndex, input.index());
            int alt = execATNWithFullContext(dfa, D, s0_closure, input, startIndex, outerContext);
            return alt;
        }
        if (D.isAcceptState) {
            if (D.predicates == null) {
                return D.prediction;
            }
            int stopIndex = input.index();
            input.seek(startIndex);
            BitSet alts = evalSemanticContext(D.predicates, outerContext, true);
            switch(alts.cardinality()) {
                case 0:
                    throw noViableAlt(input, outerContext, D.configs, startIndex);
                case 1:
                    return alts.nextSetBit(0);
                default:
                    // report ambiguity after predicate evaluation to make sure the correct
                    // set of ambig alts is reported.
                    reportAmbiguity(dfa, D, startIndex, stopIndex, false, alts, D.configs);
                    return alts.nextSetBit(0);
            }
        }
        previousD = D;
        if (t != IntStream.EOF) {
            input.consume();
            t = input.LA(1);
        }
    }
}","/**
 *  Performs ATN simulation to compute a predicted alternative based
 *   upon the remaining input, but also updates the DFA cache to avoid
 *   having to traverse the ATN again for the same input sequence.
 *
 * 	 There are some key conditions we're looking for after computing a new
 * 	 set of ATN configs (proposed DFA state):
 *  if the set is empty, there is no viable alternative for current symbol
 *  does the state uniquely predict an alternative?
 *  does the state have a conflict that would prevent us from
 * 	         putting it on the work list?
 *
 * 	 We also have some key operations to do:
 *  add an edge from previous DFA state to potentially new DFA state, D,
 * 	         upon current symbol but only if adding to work list, which means in all
 * 	         cases except no viable alternative (and possibly non-greedy decisions?)
 *  collecting predicates and adding semantic context to DFA accept states
 *  adding rule context to context-sensitive DFA accept states
 *  consuming an input symbol
 *  reporting a conflict
 *  reporting an ambiguity
 *  reporting a context sensitivity
 *  reporting insufficient predicates
 *
 * 	 cover these cases:
 * 	    dead end
 * 	    single alt
 * 	    single alt + preds
 * 	    conflict
 * 	    conflict + preds
 */
","// while more work
[[SEP]]// if any configs in previous dipped into outer context, that
[[SEP]]// means that input up to t actually finished entry rule
[[SEP]]// at least for SLL decision. Full LL doesn't dip into outer
[[SEP]]// so don't need special case.
[[SEP]]// We will get an error no matter what so delay until after
[[SEP]]// decision; better error message. Also, no reachable target
[[SEP]]// ATN states in SLL implies LL will also get nowhere.
[[SEP]]// If conflict in states that dip out, choose min since we
[[SEP]]// will get error no matter what.
[[SEP]]// IF PREDS, MIGHT RESOLVE TO SINGLE ALT => SLL (or syntax error)
[[SEP]]// restore the index so reporting the fallback to full
[[SEP]]// context occurs with the index at the correct spot
[[SEP]]// report ambiguity after predicate evaluation to make sure the correct
[[SEP]]// set of ambig alts is reported.
","/** *  Performs ATN simulation to compute a predicted alternative based *   upon the remaining input, but also updates the DFA cache to avoid *   having to traverse the ATN again for the same input sequence. * * 	 There are some key conditions we're looking for after computing a new * 	 set of ATN configs (proposed DFA state): *  if the set is empty, there is no viable alternative for current symbol *  does the state uniquely predict an alternative? *  does the state have a conflict that would prevent us from * 	         putting it on the work list? * * 	 We also have some key operations to do: *  add an edge from previous DFA state to potentially new DFA state, D, * 	         upon current symbol but only if adding to work list, which means in all * 	         cases except no viable alternative (and possibly non-greedy decisions?) *  collecting predicates and adding semantic context to DFA accept states *  adding rule context to context-sensitive DFA accept states *  consuming an input symbol *  reporting a conflict *  reporting an ambiguity *  reporting a context sensitivity *  reporting insufficient predicates * * 	 cover these cases: * 	    dead end * 	    single alt * 	    single alt + preds * 	    conflict * 	    conflict + preds */[[SEP]]// while more work[[SEP]]// if any configs in previous dipped into outer context, that// means that input up to t actually finished entry rule// at least for SLL decision. Full LL doesn't dip into outer// so don't need special case.// We will get an error no matter what so delay until after// decision; better error message. Also, no reachable target// ATN states in SLL implies LL will also get nowhere.// If conflict in states that dip out, choose min since we// will get error no matter what.[[SEP]]// IF PREDS, MIGHT RESOLVE TO SINGLE ALT => SLL (or syntax error)[[SEP]]// restore the index so reporting the fallback to full// context occurs with the index at the correct spot[[SEP]]// report ambiguity after predicate evaluation to make sure the correct// set of ambig alts is reported.",438,544,[0],0,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]",0,"[0, 0, 0, 0, 0, 0]",0,0,0,0,"execATN(DFA, DFAState, TokenStream, int, ParserRuleContext)",org.antlr.v4.runtime.atn.ParserATNSimulator,"execATN/5[org.antlr.v4.runtime.dfa.DFA,org.antlr.v4.runtime.dfa.DFAState,org.antlr.v4.runtime.TokenStream,int,org.antlr.v4.runtime.ParserRuleContext]",False,441,9,18,1,17,22,20,69,6,12,5,20,10,18,1,10,0,0,9,10,16,3,5,0,0,0,160,4,0,True
447,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\atn\ParserATNSimulator.java,org.antlr.v4.runtime.atn.ParserATNSimulator,"DFAState getExistingTargetState(DFAState, int)","/**
 * Get an existing target state for an edge in the DFA. If the target state
 * for the edge has not yet been computed or is otherwise not available,
 * this method returns {@code null}.
 *
 * @param previousD The current DFA state
 * @param t The next input symbol
 * @return The existing target DFA state for the given input symbol
 * {@code t}, or {@code null} if the target state for this edge is not
 * already cached
 */
protected DFAState getExistingTargetState(DFAState previousD, int t) {
    DFAState[] edges = previousD.edges;
    if (edges == null || t + 1 < 0 || t + 1 >= edges.length) {
        return null;
    }
    return edges[t + 1];
}","/**
 * Get an existing target state for an edge in the DFA. If the target state
 * for the edge has not yet been computed or is otherwise not available,
 * this method returns {@code null}.
 *
 * @param previousD The current DFA state
 * @param t The next input symbol
 * @return The existing target DFA state for the given input symbol
 * {@code t}, or {@code null} if the target state for this edge is not
 * already cached
 */
", ,"/** * Get an existing target state for an edge in the DFA. If the target state * for the edge has not yet been computed or is otherwise not available, * this method returns {@code null}. * * @param previousD The current DFA state * @param t The next input symbol * @return The existing target DFA state for the given input symbol * {@code t}, or {@code null} if the target state for this edge is not * already cached */",557,564,[0],0,[0],0,[0],0,0,0,0,"getExistingTargetState(DFAState, int)",org.antlr.v4.runtime.atn.ParserATNSimulator,"getExistingTargetState/2[org.antlr.v4.runtime.dfa.DFAState,int]",False,557,1,1,1,0,4,0,7,2,1,2,0,0,0,0,1,0,0,0,4,1,3,1,0,0,0,38,4,0,True
448,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\atn\ParserATNSimulator.java,org.antlr.v4.runtime.atn.ParserATNSimulator,"DFAState computeTargetState(DFA, DFAState, int)","/**
 * Compute a target state for an edge in the DFA, and attempt to add the
 * computed state and corresponding edge to the DFA.
 *
 * @param dfa The DFA
 * @param previousD The current DFA state
 * @param t The next input symbol
 *
 * @return The computed target DFA state for the given input symbol
 * {@code t}. If {@code t} does not lead to a valid DFA state, this method
 * returns {@link #ERROR}.
 */
protected DFAState computeTargetState(DFA dfa, DFAState previousD, int t) {
    ATNConfigSet reach = computeReachSet(previousD.configs, t, false);
    if (reach == null) {
        addDFAEdge(dfa, previousD, t, ERROR);
        return ERROR;
    }
    // create new target state; we'll add to DFA after it's complete
    DFAState D = new DFAState(reach);
    int predictedAlt = getUniqueAlt(reach);
    if (debug) {
        Collection<BitSet> altSubSets = PredictionMode.getConflictingAltSubsets(reach);
        System.out.println(""SLL altSubSets="" + altSubSets + "", configs="" + reach + "", predict="" + predictedAlt + "", allSubsetsConflict="" + PredictionMode.allSubsetsConflict(altSubSets) + "", conflictingAlts="" + getConflictingAlts(reach));
    }
    if (predictedAlt != ATN.INVALID_ALT_NUMBER) {
        // NO CONFLICT, UNIQUELY PREDICTED ALT
        D.isAcceptState = true;
        D.configs.uniqueAlt = predictedAlt;
        D.prediction = predictedAlt;
    } else if (PredictionMode.hasSLLConflictTerminatingPrediction(mode, reach)) {
        // MORE THAN ONE VIABLE ALTERNATIVE
        D.configs.conflictingAlts = getConflictingAlts(reach);
        D.requiresFullContext = true;
        // in SLL-only mode, we will stop at this state and return the minimum alt
        D.isAcceptState = true;
        D.prediction = D.configs.conflictingAlts.nextSetBit(0);
    }
    if (D.isAcceptState && D.configs.hasSemanticContext) {
        predicateDFAState(D, atn.getDecisionState(dfa.decision));
        if (D.predicates != null) {
            D.prediction = ATN.INVALID_ALT_NUMBER;
        }
    }
    // all adds to dfa are done after we've created full D state
    D = addDFAEdge(dfa, previousD, t, D);
    return D;
}","/**
 * Compute a target state for an edge in the DFA, and attempt to add the
 * computed state and corresponding edge to the DFA.
 *
 * @param dfa The DFA
 * @param previousD The current DFA state
 * @param t The next input symbol
 *
 * @return The computed target DFA state for the given input symbol
 * {@code t}. If {@code t} does not lead to a valid DFA state, this method
 * returns {@link #ERROR}.
 */
","// create new target state; we'll add to DFA after it's complete
[[SEP]]// NO CONFLICT, UNIQUELY PREDICTED ALT
[[SEP]]// MORE THAN ONE VIABLE ALTERNATIVE
[[SEP]]// in SLL-only mode, we will stop at this state and return the minimum alt
[[SEP]]// all adds to dfa are done after we've created full D state
","/** * Compute a target state for an edge in the DFA, and attempt to add the * computed state and corresponding edge to the DFA. * * @param dfa The DFA * @param previousD The current DFA state * @param t The next input symbol * * @return The computed target DFA state for the given input symbol * {@code t}. If {@code t} does not lead to a valid DFA state, this method * returns {@link #ERROR}. */[[SEP]]// create new target state; we'll add to DFA after it's complete[[SEP]]// NO CONFLICT, UNIQUELY PREDICTED ALT[[SEP]]// MORE THAN ONE VIABLE ALTERNATIVE[[SEP]]// in SLL-only mode, we will stop at this state and return the minimum alt[[SEP]]// all adds to dfa are done after we've created full D state",578,624,[0],0,"[0, 0, 0, 0, 0]",0,"[0, 0, 0, 0, 0, 0]",0,0,0,0,"computeTargetState(DFA, DFAState, int)",org.antlr.v4.runtime.atn.ParserATNSimulator,"computeTargetState/3[org.antlr.v4.runtime.dfa.DFA,org.antlr.v4.runtime.dfa.DFAState,int]",False,578,6,11,1,10,8,11,32,2,4,3,11,5,11,0,3,0,0,5,1,13,1,2,0,0,0,64,4,0,True
449,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\atn\ParserATNSimulator.java,org.antlr.v4.runtime.atn.ParserATNSimulator,"void predicateDFAState(DFAState, DecisionState)","protected void predicateDFAState(DFAState dfaState, DecisionState decisionState) {
    // We need to test all predicates, even in DFA states that
    // uniquely predict alternative.
    int nalts = decisionState.getNumberOfTransitions();
    // Update DFA so reach becomes accept state with (predicate,alt)
    // pairs if preds found for conflicting alts
    BitSet altsToCollectPredsFrom = getConflictingAltsOrUniqueAlt(dfaState.configs);
    SemanticContext[] altToPred = getPredsForAmbigAlts(altsToCollectPredsFrom, dfaState.configs, nalts);
    if (altToPred != null) {
        dfaState.predicates = getPredicatePredictions(altsToCollectPredsFrom, altToPred);
        // make sure we use preds
        dfaState.prediction = ATN.INVALID_ALT_NUMBER;
    } else {
        // There are preds in configs but they might go away
        // when OR'd together like {p}? || NONE == NONE. If neither
        // alt has preds, resolve to min alt
        dfaState.prediction = altsToCollectPredsFrom.nextSetBit(0);
    }
}", ,"// We need to test all predicates, even in DFA states that
[[SEP]]// Update DFA so reach becomes accept state with (predicate,alt)
[[SEP]]// uniquely predict alternative.
[[SEP]]// pairs if preds found for conflicting alts
[[SEP]]// make sure we use preds
[[SEP]]// There are preds in configs but they might go away
[[SEP]]// when OR'd together like {p}? || NONE == NONE. If neither
[[SEP]]// alt has preds, resolve to min alt
","// We need to test all predicates, even in DFA states that// uniquely predict alternative.[[SEP]]// Update DFA so reach becomes accept state with (predicate,alt)// pairs if preds found for conflicting alts[[SEP]]// make sure we use preds[[SEP]]// There are preds in configs but they might go away// when OR'd together like {p}? || NONE == NONE. If neither// alt has preds, resolve to min alt",626,644,[0],0,"[0, 0, 0, 0, 0, 0, 0, 0]",0,"[0, 0, 0, 0]",0,0,0,0,"predicateDFAState(DFAState, DecisionState)",org.antlr.v4.runtime.atn.ParserATNSimulator,"predicateDFAState/2[org.antlr.v4.runtime.dfa.DFAState,org.antlr.v4.runtime.atn.DecisionState]",False,626,5,5,1,4,2,5,12,0,3,2,5,3,1,0,1,0,0,0,1,6,0,1,0,0,0,27,4,0,False
450,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\atn\ParserATNSimulator.java,org.antlr.v4.runtime.atn.ParserATNSimulator,"int execATNWithFullContext(DFA, DFAState, ATNConfigSet, TokenStream, int, ParserRuleContext)","// comes back with reach.uniqueAlt set to a valid alt
protected int execATNWithFullContext(DFA dfa, // how far we got in SLL DFA before failing over
DFAState D, ATNConfigSet s0, TokenStream input, int startIndex, ParserRuleContext outerContext) {
    if (debug || debug_list_atn_decisions) {
        System.out.println(""execATNWithFullContext "" + s0);
    }
    boolean fullCtx = true;
    boolean foundExactAmbig = false;
    ATNConfigSet reach = null;
    ATNConfigSet previous = s0;
    input.seek(startIndex);
    int t = input.LA(1);
    int predictedAlt;
    while (true) {
        // while more work
        // System.out.println(""LL REACH ""+getLookaheadName(input)+
        // "" from configs.size=""+previous.size()+
        // "" line ""+input.LT(1).getLine()+"":""+input.LT(1).getCharPositionInLine());
        reach = computeReachSet(previous, t, fullCtx);
        if (reach == null) {
            // if any configs in previous dipped into outer context, that
            // means that input up to t actually finished entry rule
            // at least for LL decision. Full LL doesn't dip into outer
            // so don't need special case.
            // We will get an error no matter what so delay until after
            // decision; better error message. Also, no reachable target
            // ATN states in SLL implies LL will also get nowhere.
            // If conflict in states that dip out, choose min since we
            // will get error no matter what.
            NoViableAltException e = noViableAlt(input, outerContext, previous, startIndex);
            input.seek(startIndex);
            int alt = getSynValidOrSemInvalidAltThatFinishedDecisionEntryRule(previous, outerContext);
            if (alt != ATN.INVALID_ALT_NUMBER) {
                return alt;
            }
            throw e;
        }
        Collection<BitSet> altSubSets = PredictionMode.getConflictingAltSubsets(reach);
        if (debug) {
            System.out.println(""LL altSubSets="" + altSubSets + "", predict="" + PredictionMode.getUniqueAlt(altSubSets) + "", resolvesToJustOneViableAlt="" + PredictionMode.resolvesToJustOneViableAlt(altSubSets));
        }
        // System.out.println(""altSubSets: ""+altSubSets);
        // System.err.println(""reach=""+reach+"", ""+reach.conflictingAlts);
        reach.uniqueAlt = getUniqueAlt(reach);
        // unique prediction?
        if (reach.uniqueAlt != ATN.INVALID_ALT_NUMBER) {
            predictedAlt = reach.uniqueAlt;
            break;
        }
        if (mode != PredictionMode.LL_EXACT_AMBIG_DETECTION) {
            predictedAlt = PredictionMode.resolvesToJustOneViableAlt(altSubSets);
            if (predictedAlt != ATN.INVALID_ALT_NUMBER) {
                break;
            }
        } else {
            // In exact ambiguity mode, we never try to terminate early.
            // Just keeps scarfing until we know what the conflict is
            if (PredictionMode.allSubsetsConflict(altSubSets) && PredictionMode.allSubsetsEqual(altSubSets)) {
                foundExactAmbig = true;
                predictedAlt = PredictionMode.getSingleViableAlt(altSubSets);
                break;
            }
            // else there are multiple non-conflicting subsets or
            // we're not sure what the ambiguity is yet.
            // So, keep going.
        }
        previous = reach;
        if (t != IntStream.EOF) {
            input.consume();
            t = input.LA(1);
        }
    }
    // If the configuration set uniquely predicts an alternative,
    // without conflict, then we know that it's a full LL decision
    // not SLL.
    if (reach.uniqueAlt != ATN.INVALID_ALT_NUMBER) {
        reportContextSensitivity(dfa, predictedAlt, reach, startIndex, input.index());
        return predictedAlt;
    }
    // We do not check predicates here because we have checked them
    // on-the-fly when doing full context prediction.
    /*
		In non-exact ambiguity detection mode, we might	actually be able to
		detect an exact ambiguity, but I'm not going to spend the cycles
		needed to check. We only emit ambiguity warnings in exact ambiguity
		mode.

		For example, we might know that we have conflicting configurations.
		But, that does not mean that there is no way forward without a
		conflict. It's possible to have nonconflicting alt subsets as in:

		   LL altSubSets=[{1, 2}, {1, 2}, {1}, {1, 2}]

		from

		   [(17,1,[5 $]), (13,1,[5 10 $]), (21,1,[5 10 $]), (11,1,[$]),
			(13,2,[5 10 $]), (21,2,[5 10 $]), (11,2,[$])]

		In this case, (17,1,[5 $]) indicates there is some next sequence that
		would resolve this without conflict to alternative 1. Any other viable
		next sequence, however, is associated with a conflict.  We stop
		looking for input because no amount of further lookahead will alter
		the fact that we should predict alternative 1.  We just can't say for
		sure that there is an ambiguity without looking further.
		*/
    reportAmbiguity(dfa, D, startIndex, input.index(), foundExactAmbig, reach.getAlts(), reach);
    return predictedAlt;
}","// comes back with reach.uniqueAlt set to a valid alt
","// how far we got in SLL DFA before failing over
[[SEP]]// If the configuration set uniquely predicts an alternative,
[[SEP]]// without conflict, then we know that it's a full LL decision
[[SEP]]// We do not check predicates here because we have checked them
[[SEP]]// on-the-fly when doing full context prediction.
[[SEP]]// while more work
[[SEP]]// System.out.println(""LL REACH ""+getLookaheadName(input)+
[[SEP]]// "" from configs.size=""+previous.size()+
[[SEP]]// System.out.println(""altSubSets: ""+altSubSets);
[[SEP]]// "" line ""+input.LT(1).getLine()+"":""+input.LT(1).getCharPositionInLine());
[[SEP]]// if any configs in previous dipped into outer context, that
[[SEP]]// means that input up to t actually finished entry rule
[[SEP]]// at least for LL decision. Full LL doesn't dip into outer
[[SEP]]// so don't need special case.
[[SEP]]// We will get an error no matter what so delay until after
[[SEP]]// decision; better error message. Also, no reachable target
[[SEP]]// ATN states in SLL implies LL will also get nowhere.
[[SEP]]// If conflict in states that dip out, choose min since we
[[SEP]]// will get error no matter what.
[[SEP]]// System.err.println(""reach=""+reach+"", ""+reach.conflictingAlts);
[[SEP]]// unique prediction?
[[SEP]]// In exact ambiguity mode, we never try to terminate early.
[[SEP]]// else there are multiple non-conflicting subsets or
[[SEP]]// we're not sure what the ambiguity is yet.
[[SEP]]// So, keep going.
[[SEP]]// Just keeps scarfing until we know what the conflict is
[[SEP]]// not SLL.
[[SEP]]/*
		In non-exact ambiguity detection mode, we might	actually be able to
		detect an exact ambiguity, but I'm not going to spend the cycles
		needed to check. We only emit ambiguity warnings in exact ambiguity
		mode.

		For example, we might know that we have conflicting configurations.
		But, that does not mean that there is no way forward without a
		conflict. It's possible to have nonconflicting alt subsets as in:

		   LL altSubSets=[{1, 2}, {1, 2}, {1}, {1, 2}]

		from

		   [(17,1,[5 $]), (13,1,[5 10 $]), (21,1,[5 10 $]), (11,1,[$]),
			(13,2,[5 10 $]), (21,2,[5 10 $]), (11,2,[$])]

		In this case, (17,1,[5 $]) indicates there is some next sequence that
		would resolve this without conflict to alternative 1. Any other viable
		next sequence, however, is associated with a conflict.  We stop
		looking for input because no amount of further lookahead will alter
		the fact that we should predict alternative 1.  We just can't say for
		sure that there is an ambiguity without looking further.
		*/
","// comes back with reach.uniqueAlt set to a valid alt[[SEP]]// how far we got in SLL DFA before failing over[[SEP]]// while more work// System.out.println(""LL REACH ""+getLookaheadName(input)+// "" from configs.size=""+previous.size()+// "" line ""+input.LT(1).getLine()+"":""+input.LT(1).getCharPositionInLine());[[SEP]]// if any configs in previous dipped into outer context, that// means that input up to t actually finished entry rule// at least for LL decision. Full LL doesn't dip into outer// so don't need special case.// We will get an error no matter what so delay until after// decision; better error message. Also, no reachable target// ATN states in SLL implies LL will also get nowhere.// If conflict in states that dip out, choose min since we// will get error no matter what.[[SEP]]// System.out.println(""altSubSets: ""+altSubSets);// System.err.println(""reach=""+reach+"", ""+reach.conflictingAlts);[[SEP]]// unique prediction?[[SEP]]// In exact ambiguity mode, we never try to terminate early.// Just keeps scarfing until we know what the conflict is[[SEP]]// else there are multiple non-conflicting subsets or// we're not sure what the ambiguity is yet.// So, keep going.[[SEP]]// If the configuration set uniquely predicts an alternative,// without conflict, then we know that it's a full LL decision// not SLL.[[SEP]]// We do not check predicates here because we have checked them// on-the-fly when doing full context prediction.[[SEP]]/*		In non-exact ambiguity detection mode, we might	actually be able to		detect an exact ambiguity, but I'm not going to spend the cycles		needed to check. We only emit ambiguity warnings in exact ambiguity		mode.		For example, we might know that we have conflicting configurations.		But, that does not mean that there is no way forward without a		conflict. It's possible to have nonconflicting alt subsets as in:		   LL altSubSets=[{1, 2}, {1, 2}, {1}, {1, 2}]		from		   [(17,1,[5 $]), (13,1,[5 10 $]), (21,1,[5 10 $]), (11,1,[$]),			(13,2,[5 10 $]), (21,2,[5 10 $]), (11,2,[$])]		In this case, (17,1,[5 $]) indicates there is some next sequence that		would resolve this without conflict to alternative 1. Any other viable		next sequence, however, is associated with a conflict.  We stop		looking for input because no amount of further lookahead will alter		the fact that we should predict alternative 1.  We just can't say for		sure that there is an ambiguity without looking further.		*/",647,770,[0],0,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]",1,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]",1,0,0,1,"execATNWithFullContext(DFA, DFAState, ATNConfigSet, TokenStream, int, ParserRuleContext)",org.antlr.v4.runtime.atn.ParserATNSimulator,"execATNWithFullContext/6[org.antlr.v4.runtime.dfa.DFA,org.antlr.v4.runtime.dfa.DFAState,org.antlr.v4.runtime.atn.ATNConfigSet,org.antlr.v4.runtime.TokenStream,int,org.antlr.v4.runtime.ParserRuleContext]",False,652,9,18,1,17,14,18,57,3,9,6,18,6,11,1,7,0,0,4,2,16,2,3,0,0,0,63,4,0,False
451,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\atn\ParserATNSimulator.java,org.antlr.v4.runtime.atn.ParserATNSimulator,"ATNConfigSet computeReachSet(ATNConfigSet, int, boolean)","protected ATNConfigSet computeReachSet(ATNConfigSet closure, int t, boolean fullCtx) {
    if (debug)
        System.out.println(""in computeReachSet, starting closure: "" + closure);
    if (mergeCache == null) {
        mergeCache = new DoubleKeyMap<PredictionContext, PredictionContext, PredictionContext>();
    }
    ATNConfigSet intermediate = new ATNConfigSet(fullCtx);
    /* Configurations already in a rule stop state indicate reaching the end
		 * of the decision rule (local context) or end of the start rule (full
		 * context). Once reached, these configurations are never updated by a
		 * closure operation, so they are handled separately for the performance
		 * advantage of having a smaller intermediate set when calling closure.
		 *
		 * For full-context reach operations, separate handling is required to
		 * ensure that the alternative matching the longest overall sequence is
		 * chosen when multiple such configurations can match the input.
		 */
    List<ATNConfig> skippedStopStates = null;
    // First figure out where we can reach on input t
    for (ATNConfig c : closure) {
        if (debug)
            System.out.println(""testing "" + getTokenName(t) + "" at "" + c.toString());
        if (c.state instanceof RuleStopState) {
            assert c.context.isEmpty();
            if (fullCtx || t == IntStream.EOF) {
                if (skippedStopStates == null) {
                    skippedStopStates = new ArrayList<ATNConfig>();
                }
                skippedStopStates.add(c);
            }
            continue;
        }
        int n = c.state.getNumberOfTransitions();
        for (int ti = 0; ti < n; ti++) {
            // for each transition
            Transition trans = c.state.transition(ti);
            ATNState target = getReachableTarget(trans, t);
            if (target != null) {
                intermediate.add(new ATNConfig(c, target), mergeCache);
            }
        }
    }
    // Now figure out where the reach operation can take us...
    ATNConfigSet reach = null;
    /* This block optimizes the reach operation for intermediate sets which
		 * trivially indicate a termination state for the overall
		 * adaptivePredict operation.
		 *
		 * The conditions assume that intermediate
		 * contains all configurations relevant to the reach set, but this
		 * condition is not true when one or more configurations have been
		 * withheld in skippedStopStates, or when the current symbol is EOF.
		 */
    if (skippedStopStates == null && t != Token.EOF) {
        if (intermediate.size() == 1) {
            // Don't pursue the closure if there is just one state.
            // It can only have one alternative; just add to result
            // Also don't pursue the closure if there is unique alternative
            // among the configurations.
            reach = intermediate;
        } else if (getUniqueAlt(intermediate) != ATN.INVALID_ALT_NUMBER) {
            // Also don't pursue the closure if there is unique alternative
            // among the configurations.
            reach = intermediate;
        }
    }
    /* If the reach set could not be trivially determined, perform a closure
		 * operation on the intermediate set to compute its initial value.
		 */
    if (reach == null) {
        reach = new ATNConfigSet(fullCtx);
        Set<ATNConfig> closureBusy = new HashSet<ATNConfig>();
        boolean treatEofAsEpsilon = t == Token.EOF;
        for (ATNConfig c : intermediate) {
            closure(c, reach, closureBusy, false, fullCtx, treatEofAsEpsilon);
        }
    }
    if (t == IntStream.EOF) {
        /* After consuming EOF no additional input is possible, so we are
			 * only interested in configurations which reached the end of the
			 * decision rule (local context) or end of the start rule (full
			 * context). Update reach to contain only these configurations. This
			 * handles both explicit EOF transitions in the grammar and implicit
			 * EOF transitions following the end of the decision or start rule.
			 *
			 * When reach==intermediate, no closure operation was performed. In
			 * this case, removeAllConfigsNotInRuleStopState needs to check for
			 * reachable rule stop states as well as configurations already in
			 * a rule stop state.
			 *
			 * This is handled before the configurations in skippedStopStates,
			 * because any configurations potentially added from that list are
			 * already guaranteed to meet this condition whether or not it's
			 * required.
			 */
        reach = removeAllConfigsNotInRuleStopState(reach, reach == intermediate);
    }
    /* If skippedStopStates is not null, then it contains at least one
		 * configuration. For full-context reach operations, these
		 * configurations reached the end of the start rule, in which case we
		 * only add them back to reach if no configuration during the current
		 * closure operation reached such a state. This ensures adaptivePredict
		 * chooses an alternative matching the longest overall sequence when
		 * multiple alternatives are viable.
		 */
    if (skippedStopStates != null && (!fullCtx || !PredictionMode.hasConfigInRuleStopState(reach))) {
        assert !skippedStopStates.isEmpty();
        for (ATNConfig c : skippedStopStates) {
            reach.add(c, mergeCache);
        }
    }
    if (reach.isEmpty())
        return null;
    return reach;
}", ,"// Now figure out where the reach operation can take us...
[[SEP]]/* Configurations already in a rule stop state indicate reaching the end
		 * of the decision rule (local context) or end of the start rule (full
		 * context). Once reached, these configurations are never updated by a
		 * closure operation, so they are handled separately for the performance
		 * advantage of having a smaller intermediate set when calling closure.
		 *
		 * For full-context reach operations, separate handling is required to
		 * ensure that the alternative matching the longest overall sequence is
		 * chosen when multiple such configurations can match the input.
		 */
[[SEP]]// First figure out where we can reach on input t
[[SEP]]// for each transition
[[SEP]]/* This block optimizes the reach operation for intermediate sets which
		 * trivially indicate a termination state for the overall
		 * adaptivePredict operation.
		 *
		 * The conditions assume that intermediate
		 * contains all configurations relevant to the reach set, but this
		 * condition is not true when one or more configurations have been
		 * withheld in skippedStopStates, or when the current symbol is EOF.
		 */
[[SEP]]// Don't pursue the closure if there is just one state.
[[SEP]]// It can only have one alternative; just add to result
[[SEP]]// Also don't pursue the closure if there is unique alternative
[[SEP]]// among the configurations.
[[SEP]]// Also don't pursue the closure if there is unique alternative
[[SEP]]// among the configurations.
[[SEP]]/* If the reach set could not be trivially determined, perform a closure
		 * operation on the intermediate set to compute its initial value.
		 */
[[SEP]]/* After consuming EOF no additional input is possible, so we are
			 * only interested in configurations which reached the end of the
			 * decision rule (local context) or end of the start rule (full
			 * context). Update reach to contain only these configurations. This
			 * handles both explicit EOF transitions in the grammar and implicit
			 * EOF transitions following the end of the decision or start rule.
			 *
			 * When reach==intermediate, no closure operation was performed. In
			 * this case, removeAllConfigsNotInRuleStopState needs to check for
			 * reachable rule stop states as well as configurations already in
			 * a rule stop state.
			 *
			 * This is handled before the configurations in skippedStopStates,
			 * because any configurations potentially added from that list are
			 * already guaranteed to meet this condition whether or not it's
			 * required.
			 */
[[SEP]]/* If skippedStopStates is not null, then it contains at least one
		 * configuration. For full-context reach operations, these
		 * configurations reached the end of the start rule, in which case we
		 * only add them back to reach if no configuration during the current
		 * closure operation reached such a state. This ensures adaptivePredict
		 * chooses an alternative matching the longest overall sequence when
		 * multiple alternatives are viable.
		 */
","/* Configurations already in a rule stop state indicate reaching the end		 * of the decision rule (local context) or end of the start rule (full		 * context). Once reached, these configurations are never updated by a		 * closure operation, so they are handled separately for the performance		 * advantage of having a smaller intermediate set when calling closure.		 *		 * For full-context reach operations, separate handling is required to		 * ensure that the alternative matching the longest overall sequence is		 * chosen when multiple such configurations can match the input.		 */[[SEP]]// First figure out where we can reach on input t[[SEP]]// for each transition[[SEP]]// Now figure out where the reach operation can take us...[[SEP]]/* This block optimizes the reach operation for intermediate sets which		 * trivially indicate a termination state for the overall		 * adaptivePredict operation.		 *		 * The conditions assume that intermediate		 * contains all configurations relevant to the reach set, but this		 * condition is not true when one or more configurations have been		 * withheld in skippedStopStates, or when the current symbol is EOF.		 */[[SEP]]// Don't pursue the closure if there is just one state.// It can only have one alternative; just add to result// Also don't pursue the closure if there is unique alternative// among the configurations.[[SEP]]// Also don't pursue the closure if there is unique alternative// among the configurations.[[SEP]]/* If the reach set could not be trivially determined, perform a closure		 * operation on the intermediate set to compute its initial value.		 */[[SEP]]/* After consuming EOF no additional input is possible, so we are			 * only interested in configurations which reached the end of the			 * decision rule (local context) or end of the start rule (full			 * context). Update reach to contain only these configurations. This			 * handles both explicit EOF transitions in the grammar and implicit			 * EOF transitions following the end of the decision or start rule.			 *			 * When reach==intermediate, no closure operation was performed. In			 * this case, removeAllConfigsNotInRuleStopState needs to check for			 * reachable rule stop states as well as configurations already in			 * a rule stop state.			 *			 * This is handled before the configurations in skippedStopStates,			 * because any configurations potentially added from that list are			 * already guaranteed to meet this condition whether or not it's			 * required.			 */[[SEP]]/* If skippedStopStates is not null, then it contains at least one		 * configuration. For full-context reach operations, these		 * configurations reached the end of the start rule, in which case we		 * only add them back to reach if no configuration during the current		 * closure operation reached such a state. This ensures adaptivePredict		 * chooses an alternative matching the longest overall sequence when		 * multiple alternatives are viable.		 */",772,901,[0],0,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]",0,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]",0,0,0,0,"computeReachSet(ATNConfigSet, int, boolean)",org.antlr.v4.runtime.atn.ParserATNSimulator,"computeReachSet/3[org.antlr.v4.runtime.atn.ATNConfigSet,int,boolean]",False,774,9,18,2,16,23,16,57,2,9,3,16,5,8,4,13,0,1,3,2,15,2,4,0,0,0,48,4,0,False
452,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\atn\ParserATNSimulator.java,org.antlr.v4.runtime.atn.ParserATNSimulator,"ATNConfigSet removeAllConfigsNotInRuleStopState(ATNConfigSet, boolean)","/**
 * Return a configuration set containing only the configurations from
 * {@code configs} which are in a {@link RuleStopState}. If all
 * configurations in {@code configs} are already in a rule stop state, this
 * method simply returns {@code configs}.
 *
 * <p>When {@code lookToEndOfRule} is true, this method uses
 * {@link ATN#nextTokens} for each configuration in {@code configs} which is
 * not already in a rule stop state to see if a rule stop state is reachable
 * from the configuration via epsilon-only transitions.</p>
 *
 * @param configs the configuration set to update
 * @param lookToEndOfRule when true, this method checks for rule stop states
 * reachable by epsilon-only transitions from each configuration in
 * {@code configs}.
 *
 * @return {@code configs} if all configurations in {@code configs} are in a
 * rule stop state, otherwise return a new configuration set containing only
 * the configurations from {@code configs} which are in a rule stop state
 */
protected ATNConfigSet removeAllConfigsNotInRuleStopState(ATNConfigSet configs, boolean lookToEndOfRule) {
    if (PredictionMode.allConfigsInRuleStopStates(configs)) {
        return configs;
    }
    ATNConfigSet result = new ATNConfigSet(configs.fullCtx);
    for (ATNConfig config : configs) {
        if (config.state instanceof RuleStopState) {
            result.add(config, mergeCache);
            continue;
        }
        if (lookToEndOfRule && config.state.onlyHasEpsilonTransitions()) {
            IntervalSet nextTokens = atn.nextTokens(config.state);
            if (nextTokens.contains(Token.EPSILON)) {
                ATNState endOfRuleState = atn.ruleToStopState[config.state.ruleIndex];
                result.add(new ATNConfig(config, endOfRuleState), mergeCache);
            }
        }
    }
    return result;
}","/**
 * Return a configuration set containing only the configurations from
 * {@code configs} which are in a {@link RuleStopState}. If all
 * configurations in {@code configs} are already in a rule stop state, this
 * method simply returns {@code configs}.
 *
 * <p>When {@code lookToEndOfRule} is true, this method uses
 * {@link ATN#nextTokens} for each configuration in {@code configs} which is
 * not already in a rule stop state to see if a rule stop state is reachable
 * from the configuration via epsilon-only transitions.</p>
 *
 * @param configs the configuration set to update
 * @param lookToEndOfRule when true, this method checks for rule stop states
 * reachable by epsilon-only transitions from each configuration in
 * {@code configs}.
 *
 * @return {@code configs} if all configurations in {@code configs} are in a
 * rule stop state, otherwise return a new configuration set containing only
 * the configurations from {@code configs} which are in a rule stop state
 */
", ,"/** * Return a configuration set containing only the configurations from * {@code configs} which are in a {@link RuleStopState}. If all * configurations in {@code configs} are already in a rule stop state, this * method simply returns {@code configs}. * * <p>When {@code lookToEndOfRule} is true, this method uses * {@link ATN#nextTokens} for each configuration in {@code configs} which is * not already in a rule stop state to see if a rule stop state is reachable * from the configuration via epsilon-only transitions.</p> * * @param configs the configuration set to update * @param lookToEndOfRule when true, this method checks for rule stop states * reachable by epsilon-only transitions from each configuration in * {@code configs}. * * @return {@code configs} if all configurations in {@code configs} are in a * rule stop state, otherwise return a new configuration set containing only * the configurations from {@code configs} which are in a rule stop state */",923,945,[0],0,[0],0,[0],0,0,0,0,"removeAllConfigsNotInRuleStopState(ATNConfigSet, boolean)",org.antlr.v4.runtime.atn.ParserATNSimulator,"removeAllConfigsNotInRuleStopState/2[org.antlr.v4.runtime.atn.ATNConfigSet,boolean]",False,923,7,8,1,7,7,5,20,2,3,2,5,0,0,1,0,0,0,0,0,3,0,3,0,0,0,65,4,0,True
453,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\atn\ParserATNSimulator.java,org.antlr.v4.runtime.atn.ParserATNSimulator,"ATNConfigSet computeStartState(ATNState, RuleContext, boolean)","protected ATNConfigSet computeStartState(ATNState p, RuleContext ctx, boolean fullCtx) {
    // always at least the implicit call to start rule
    PredictionContext initialContext = PredictionContext.fromRuleContext(atn, ctx);
    ATNConfigSet configs = new ATNConfigSet(fullCtx);
    for (int i = 0; i < p.getNumberOfTransitions(); i++) {
        ATNState target = p.transition(i).target;
        ATNConfig c = new ATNConfig(target, i + 1, initialContext);
        Set<ATNConfig> closureBusy = new HashSet<ATNConfig>();
        closure(c, configs, closureBusy, true, fullCtx, false);
    }
    return configs;
}", ,"// always at least the implicit call to start rule
",// always at least the implicit call to start rule,948,964,[0],0,[0],0,[0],0,0,0,0,"computeStartState(ATNState, RuleContext, boolean)",org.antlr.v4.runtime.atn.ParserATNSimulator,"computeStartState/3[org.antlr.v4.runtime.atn.ATNState,org.antlr.v4.runtime.RuleContext,boolean]",False,951,6,8,2,6,2,4,11,1,6,3,4,1,8,1,0,0,0,0,2,6,1,1,0,0,0,19,4,0,False
454,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\atn\ParserATNSimulator.java,org.antlr.v4.runtime.atn.ParserATNSimulator,ATNConfigSet applyPrecedenceFilter(ATNConfigSet),"/* parrt internal source braindump that doesn't mess up
	 * external API spec.
		context-sensitive in that they can only be properly evaluated
		in the context of the proper prec argument. Without pruning,
		these predicates are normal predicates evaluated when we reach
		conflict state (or unique prediction). As we cannot evaluate
		these predicates out of context, the resulting conflict leads
		to full LL evaluation and nonlinear prediction which shows up
		very clearly with fairly large expressions.

		Example grammar:

		e : e '*' e
		  | e '+' e
		  | INT
		  ;

		We convert that to the following:

		e[int prec]
			:   INT
				( {3>=prec}? '*' e[4]
				| {2>=prec}? '+' e[3]
				)*
			;

		The (..)* loop has a decision for the inner block as well as
		an enter or exit decision, which is what concerns us here. At
		the 1st + of input 1+2+3, the loop entry sees both predicates
		and the loop exit also sees both predicates by falling off the
		edge of e.  This is because we have no stack information with
		SLL and find the follow of e, which will hit the return states
		inside the loop after e[4] and e[3], which brings it back to
		the enter or exit decision. In this case, we know that we
		cannot evaluate those predicates because we have fallen off
		the edge of the stack and will in general not know which prec
		parameter is the right one to use in the predicate.

		Because we have special information, that these are precedence
		predicates, we can resolve them without failing over to full
		LL despite their context sensitive nature. We make an
		assumption that prec[-1] <= prec[0], meaning that the current
		precedence level is greater than or equal to the precedence
		level of recursive invocations above us in the stack. For
		example, if predicate {3>=prec}? is true of the current prec,
		then one option is to enter the loop to match it now. The
		other option is to exit the loop and the left recursive rule
		to match the current operator in rule invocation further up
		the stack. But, we know that all of those prec are lower or
		the same value and so we can decide to enter the loop instead
		of matching it later. That means we can strip out the other
		configuration for the exit branch.

		So imagine we have (14,1,$,{2>=prec}?) and then
		(14,2,$-dipsIntoOuterContext,{2>=prec}?). The optimization
		allows us to collapse these two configurations. We know that
		if {2>=prec}? is true for the current prec parameter, it will
		also be true for any prec from an invoking e call, indicated
		by dipsIntoOuterContext. As the predicates are both true, we
		have the option to evaluate them early in the decision start
		state. We do this by stripping both predicates and choosing to
		enter the loop as it is consistent with the notion of operator
		precedence. It's also how the full LL conflict resolution
		would work.

		The solution requires a different DFA start state for each
		precedence level.

		The basic filter mechanism is to remove configurations of the
		form (p, 2, pi) if (p, 1, pi) exists for the same p and pi. In
		other words, for the same ATN state and predicate context,
		remove any configuration associated with an exit branch if
		there is a configuration associated with the enter branch.

		It's also the case that the filter evaluates precedence
		predicates and resolves conflicts according to precedence
		levels. For example, for input 1+2+3 at the first +, we see
		prediction filtering

		[(11,1,[$],{3>=prec}?), (14,1,[$],{2>=prec}?), (5,2,[$],up=1),
		 (11,2,[$],up=1), (14,2,[$],up=1)],hasSemanticContext=true,dipsIntoOuterContext

		to

		[(11,1,[$]), (14,1,[$]), (5,2,[$],up=1)],dipsIntoOuterContext

		This filters because {3>=prec}? evals to true and collapses
		(11,1,[$],{3>=prec}?) and (11,2,[$],up=1) since early conflict
		resolution based upon rules of operator precedence fits with
		our usual match first alt upon conflict.

		We noticed a problem where a recursive call resets precedence
		to 0. Sam's fix: each config has flag indicating if it has
		returned from an expr[0] call. then just don't filter any
		config with that flag set. flag is carried along in
		closure(). so to avoid adding field, set bit just under sign
		bit of dipsIntoOuterContext (SUPPRESS_PRECEDENCE_FILTER).
		With the change you filter ""unless (p, 2, pi) was reached
		after leaving the rule stop state of the LR rule containing
		state p, corresponding to a rule invocation with precedence
		level 0""
	 */
/**
 * This method transforms the start state computed by
 * {@link #computeStartState} to the special start state used by a
 * precedence DFA for a particular precedence value. The transformation
 * process applies the following changes to the start state's configuration
 * set.
 *
 * <ol>
 * <li>Evaluate the precedence predicates for each configuration using
 * {@link SemanticContext#evalPrecedence}.</li>
 * <li>When {@link ATNConfig#isPrecedenceFilterSuppressed} is {@code false},
 * remove all configurations which predict an alternative greater than 1,
 * for which another configuration that predicts alternative 1 is in the
 * same ATN state with the same prediction context. This transformation is
 * valid for the following reasons:
 * <ul>
 * <li>The closure block cannot contain any epsilon transitions which bypass
 * the body of the closure, so all states reachable via alternative 1 are
 * part of the precedence alternatives of the transformed left-recursive
 * rule.</li>
 * <li>The ""primary"" portion of a left recursive rule cannot contain an
 * epsilon transition, so the only way an alternative other than 1 can exist
 * in a state that is also reachable via alternative 1 is by nesting calls
 * to the left-recursive rule, with the outer calls not being at the
 * preferred precedence level. The
 * {@link ATNConfig#isPrecedenceFilterSuppressed} property marks ATN
 * configurations which do not meet this condition, and therefore are not
 * eligible for elimination during the filtering process.</li>
 * </ul>
 * </li>
 * </ol>
 *
 * <p>
 * The prediction context must be considered by this filter to address
 * situations like the following.
 * </p>
 * <code>
 * <pre>
 * grammar TA;
 * prog: statement* EOF;
 * statement: letterA | statement letterA 'b' ;
 * letterA: 'a';
 * </pre>
 * </code>
 * <p>
 * If the above grammar, the ATN state immediately before the token
 * reference {@code 'a'} in {@code letterA} is reachable from the left edge
 * of both the primary and closure blocks of the left-recursive rule
 * {@code statement}. The prediction context associated with each of these
 * configurations distinguishes between them, and prevents the alternative
 * which stepped out to {@code prog} (and then back in to {@code statement}
 * from being eliminated by the filter.
 * </p>
 *
 * @param configs The configuration set computed by
 * {@link #computeStartState} as the start state for the DFA.
 * @return The transformed configuration set representing the start state
 * for a precedence DFA at a particular precedence level (determined by
 * calling {@link Parser#getPrecedence}).
 */
protected ATNConfigSet applyPrecedenceFilter(ATNConfigSet configs) {
    Map<Integer, PredictionContext> statesFromAlt1 = new HashMap<Integer, PredictionContext>();
    ATNConfigSet configSet = new ATNConfigSet(configs.fullCtx);
    for (ATNConfig config : configs) {
        // handle alt 1 first
        if (config.alt != 1) {
            continue;
        }
        SemanticContext updatedContext = config.semanticContext.evalPrecedence(parser, _outerContext);
        if (updatedContext == null) {
            // the configuration was eliminated
            continue;
        }
        statesFromAlt1.put(config.state.stateNumber, config.context);
        if (updatedContext != config.semanticContext) {
            configSet.add(new ATNConfig(config, updatedContext), mergeCache);
        } else {
            configSet.add(config, mergeCache);
        }
    }
    for (ATNConfig config : configs) {
        if (config.alt == 1) {
            // already handled
            continue;
        }
        if (!config.isPrecedenceFilterSuppressed()) {
            /* In the future, this elimination step could be updated to also
				 * filter the prediction context for alternatives predicting alt>1
				 * (basically a graph subtraction algorithm).
				 */
            PredictionContext context = statesFromAlt1.get(config.state.stateNumber);
            if (context != null && context.equals(config.context)) {
                // eliminated
                continue;
            }
        }
        configSet.add(config, mergeCache);
    }
    return configSet;
}","/**
 * This method transforms the start state computed by
 * {@link #computeStartState} to the special start state used by a
 * precedence DFA for a particular precedence value. The transformation
 * process applies the following changes to the start state's configuration
 * set.
 *
 * <ol>
 * <li>Evaluate the precedence predicates for each configuration using
 * {@link SemanticContext#evalPrecedence}.</li>
 * <li>When {@link ATNConfig#isPrecedenceFilterSuppressed} is {@code false},
 * remove all configurations which predict an alternative greater than 1,
 * for which another configuration that predicts alternative 1 is in the
 * same ATN state with the same prediction context. This transformation is
 * valid for the following reasons:
 * <ul>
 * <li>The closure block cannot contain any epsilon transitions which bypass
 * the body of the closure, so all states reachable via alternative 1 are
 * part of the precedence alternatives of the transformed left-recursive
 * rule.</li>
 * <li>The ""primary"" portion of a left recursive rule cannot contain an
 * epsilon transition, so the only way an alternative other than 1 can exist
 * in a state that is also reachable via alternative 1 is by nesting calls
 * to the left-recursive rule, with the outer calls not being at the
 * preferred precedence level. The
 * {@link ATNConfig#isPrecedenceFilterSuppressed} property marks ATN
 * configurations which do not meet this condition, and therefore are not
 * eligible for elimination during the filtering process.</li>
 * </ul>
 * </li>
 * </ol>
 *
 * <p>
 * The prediction context must be considered by this filter to address
 * situations like the following.
 * </p>
 * <code>
 * <pre>
 * grammar TA;
 * prog: statement* EOF;
 * statement: letterA | statement letterA 'b' ;
 * letterA: 'a';
 * </pre>
 * </code>
 * <p>
 * If the above grammar, the ATN state immediately before the token
 * reference {@code 'a'} in {@code letterA} is reachable from the left edge
 * of both the primary and closure blocks of the left-recursive rule
 * {@code statement}. The prediction context associated with each of these
 * configurations distinguishes between them, and prevents the alternative
 * which stepped out to {@code prog} (and then back in to {@code statement}
 * from being eliminated by the filter.
 * </p>
 *
 * @param configs The configuration set computed by
 * {@link #computeStartState} as the start state for the DFA.
 * @return The transformed configuration set representing the start state
 * for a precedence DFA at a particular precedence level (determined by
 * calling {@link Parser#getPrecedence}).
 */
","// handle alt 1 first
[[SEP]]// the configuration was eliminated
[[SEP]]// already handled
[[SEP]]/* In the future, this elimination step could be updated to also
				 * filter the prediction context for alternatives predicting alt>1
				 * (basically a graph subtraction algorithm).
				 */
[[SEP]]// eliminated
","/* parrt internal source braindump that doesn't mess up	 * external API spec.		context-sensitive in that they can only be properly evaluated		in the context of the proper prec argument. Without pruning,		these predicates are normal predicates evaluated when we reach		conflict state (or unique prediction). As we cannot evaluate		these predicates out of context, the resulting conflict leads		to full LL evaluation and nonlinear prediction which shows up		very clearly with fairly large expressions.		Example grammar:		e : e '*' e		  | e '+' e		  | INT		  ;		We convert that to the following:		e[int prec]			:   INT				( {3>=prec}? '*' e[4]				| {2>=prec}? '+' e[3]				)*			;		The (..)* loop has a decision for the inner block as well as		an enter or exit decision, which is what concerns us here. At		the 1st + of input 1+2+3, the loop entry sees both predicates		and the loop exit also sees both predicates by falling off the		edge of e.  This is because we have no stack information with		SLL and find the follow of e, which will hit the return states		inside the loop after e[4] and e[3], which brings it back to		the enter or exit decision. In this case, we know that we		cannot evaluate those predicates because we have fallen off		the edge of the stack and will in general not know which prec		parameter is the right one to use in the predicate.		Because we have special information, that these are precedence		predicates, we can resolve them without failing over to full		LL despite their context sensitive nature. We make an		assumption that prec[-1] <= prec[0], meaning that the current		precedence level is greater than or equal to the precedence		level of recursive invocations above us in the stack. For		example, if predicate {3>=prec}? is true of the current prec,		then one option is to enter the loop to match it now. The		other option is to exit the loop and the left recursive rule		to match the current operator in rule invocation further up		the stack. But, we know that all of those prec are lower or		the same value and so we can decide to enter the loop instead		of matching it later. That means we can strip out the other		configuration for the exit branch.		So imagine we have (14,1,$,{2>=prec}?) and then		(14,2,$-dipsIntoOuterContext,{2>=prec}?). The optimization		allows us to collapse these two configurations. We know that		if {2>=prec}? is true for the current prec parameter, it will		also be true for any prec from an invoking e call, indicated		by dipsIntoOuterContext. As the predicates are both true, we		have the option to evaluate them early in the decision start		state. We do this by stripping both predicates and choosing to		enter the loop as it is consistent with the notion of operator		precedence. It's also how the full LL conflict resolution		would work.		The solution requires a different DFA start state for each		precedence level.		The basic filter mechanism is to remove configurations of the		form (p, 2, pi) if (p, 1, pi) exists for the same p and pi. In		other words, for the same ATN state and predicate context,		remove any configuration associated with an exit branch if		there is a configuration associated with the enter branch.		It's also the case that the filter evaluates precedence		predicates and resolves conflicts according to precedence		levels. For example, for input 1+2+3 at the first +, we see		prediction filtering		[(11,1,[$],{3>=prec}?), (14,1,[$],{2>=prec}?), (5,2,[$],up=1),		 (11,2,[$],up=1), (14,2,[$],up=1)],hasSemanticContext=true,dipsIntoOuterContext		to		[(11,1,[$]), (14,1,[$]), (5,2,[$],up=1)],dipsIntoOuterContext		This filters because {3>=prec}? evals to true and collapses		(11,1,[$],{3>=prec}?) and (11,2,[$],up=1) since early conflict		resolution based upon rules of operator precedence fits with		our usual match first alt upon conflict.		We noticed a problem where a recursive call resets precedence		to 0. Sam's fix: each config has flag indicating if it has		returned from an expr[0] call. then just don't filter any		config with that flag set. flag is carried along in		closure(). so to avoid adding field, set bit just under sign		bit of dipsIntoOuterContext (SUPPRESS_PRECEDENCE_FILTER).		With the change you filter ""unless (p, 2, pi) was reached		after leaving the rule stop state of the LR rule containing		state p, corresponding to a rule invocation with precedence		level 0""	 */[[SEP]]/** * This method transforms the start state computed by * {@link #computeStartState} to the special start state used by a * precedence DFA for a particular precedence value. The transformation * process applies the following changes to the start state's configuration * set. * * <ol> * <li>Evaluate the precedence predicates for each configuration using * {@link SemanticContext#evalPrecedence}.</li> * <li>When {@link ATNConfig#isPrecedenceFilterSuppressed} is {@code false}, * remove all configurations which predict an alternative greater than 1, * for which another configuration that predicts alternative 1 is in the * same ATN state with the same prediction context. This transformation is * valid for the following reasons: * <ul> * <li>The closure block cannot contain any epsilon transitions which bypass * the body of the closure, so all states reachable via alternative 1 are * part of the precedence alternatives of the transformed left-recursive * rule.</li> * <li>The ""primary"" portion of a left recursive rule cannot contain an * epsilon transition, so the only way an alternative other than 1 can exist * in a state that is also reachable via alternative 1 is by nesting calls * to the left-recursive rule, with the outer calls not being at the * preferred precedence level. The * {@link ATNConfig#isPrecedenceFilterSuppressed} property marks ATN * configurations which do not meet this condition, and therefore are not * eligible for elimination during the filtering process.</li> * </ul> * </li> * </ol> * * <p> * The prediction context must be considered by this filter to address * situations like the following. * </p> * <code> * <pre> * grammar TA; * prog: statement* EOF; * statement: letterA | statement letterA 'b' ; * letterA: 'a'; * </pre> * </code> * <p> * If the above grammar, the ATN state immediately before the token * reference {@code 'a'} in {@code letterA} is reachable from the left edge * of both the primary and closure blocks of the left-recursive rule * {@code statement}. The prediction context associated with each of these * configurations distinguishes between them, and prevents the alternative * which stepped out to {@code prog} (and then back in to {@code statement} * from being eliminated by the filter. * </p> * * @param configs The configuration set computed by * {@link #computeStartState} as the start state for the DFA. * @return The transformed configuration set representing the start state * for a precedence DFA at a particular precedence level (determined by * calling {@link Parser#getPrecedence}). */[[SEP]]// handle alt 1 first[[SEP]]// the configuration was eliminated[[SEP]]// already handled[[SEP]]/* In the future, this elimination step could be updated to also				 * filter the prediction context for alternatives predicting alt>1				 * (basically a graph subtraction algorithm).				 */[[SEP]]// eliminated",1129,1175,[0],0,"[0, 0, 0, 0, 0]",0,"[0, 0, 0, 0, 0, 0, 0]",0,0,0,1,applyPrecedenceFilter(ATNConfigSet),org.antlr.v4.runtime.atn.ParserATNSimulator,applyPrecedenceFilter/1[org.antlr.v4.runtime.atn.ATNConfigSet],False,1129,4,7,1,6,10,6,33,1,4,1,6,0,0,2,5,0,0,0,2,4,0,3,0,0,0,158,4,0,True
455,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\atn\ParserATNSimulator.java,org.antlr.v4.runtime.atn.ParserATNSimulator,"SemanticContext[] getPredsForAmbigAlts(BitSet, ATNConfigSet, int)","protected SemanticContext[] getPredsForAmbigAlts(BitSet ambigAlts, ATNConfigSet configs, int nalts) {
    // REACH=[1|1|[]|0:0, 1|2|[]|0:1]
    /* altToPred starts as an array of all null contexts. The entry at index i
		 * corresponds to alternative i. altToPred[i] may have one of three values:
		 *   1. null: no ATNConfig c is found such that c.alt==i
		 *   2. SemanticContext.NONE: At least one ATNConfig c exists such that
		 *      c.alt==i and c.semanticContext==SemanticContext.NONE. In other words,
		 *      alt i has at least one unpredicated config.
		 *   3. Non-NONE Semantic Context: There exists at least one, and for all
		 *      ATNConfig c such that c.alt==i, c.semanticContext!=SemanticContext.NONE.
		 *
		 * From this, it is clear that NONE||anything==NONE.
		 */
    SemanticContext[] altToPred = new SemanticContext[nalts + 1];
    for (ATNConfig c : configs) {
        if (ambigAlts.get(c.alt)) {
            altToPred[c.alt] = SemanticContext.or(altToPred[c.alt], c.semanticContext);
        }
    }
    int nPredAlts = 0;
    for (int i = 1; i <= nalts; i++) {
        if (altToPred[i] == null) {
            altToPred[i] = SemanticContext.Empty.Instance;
        } else if (altToPred[i] != SemanticContext.Empty.Instance) {
            nPredAlts++;
        }
    }
    // // Optimize away p||p and p&&p TODO: optimize() was a no-op
    // for (int i = 0; i < altToPred.length; i++) {
    // altToPred[i] = altToPred[i].optimize();
    // }
    // nonambig alts are null in altToPred
    if (nPredAlts == 0)
        altToPred = null;
    if (debug)
        System.out.println(""getPredsForAmbigAlts result "" + Arrays.toString(altToPred));
    return altToPred;
}", ,"// REACH=[1|1|[]|0:0, 1|2|[]|0:1]
[[SEP]]// // Optimize away p||p and p&&p TODO: optimize() was a no-op
[[SEP]]// for (int i = 0; i < altToPred.length; i++) {
[[SEP]]// altToPred[i] = altToPred[i].optimize();
[[SEP]]// }
[[SEP]]/* altToPred starts as an array of all null contexts. The entry at index i
		 * corresponds to alternative i. altToPred[i] may have one of three values:
		 *   1. null: no ATNConfig c is found such that c.alt==i
		 *   2. SemanticContext.NONE: At least one ATNConfig c exists such that
		 *      c.alt==i and c.semanticContext==SemanticContext.NONE. In other words,
		 *      alt i has at least one unpredicated config.
		 *   3. Non-NONE Semantic Context: There exists at least one, and for all
		 *      ATNConfig c such that c.alt==i, c.semanticContext!=SemanticContext.NONE.
		 *
		 * From this, it is clear that NONE||anything==NONE.
		 */
[[SEP]]// nonambig alts are null in altToPred
","// REACH=[1|1|[]|0:0, 1|2|[]|0:1][[SEP]]/* altToPred starts as an array of all null contexts. The entry at index i		 * corresponds to alternative i. altToPred[i] may have one of three values:		 *   1. null: no ATNConfig c is found such that c.alt==i		 *   2. SemanticContext.NONE: At least one ATNConfig c exists such that		 *      c.alt==i and c.semanticContext==SemanticContext.NONE. In other words,		 *      alt i has at least one unpredicated config.		 *   3. Non-NONE Semantic Context: There exists at least one, and for all		 *      ATNConfig c such that c.alt==i, c.semanticContext!=SemanticContext.NONE.		 *		 * From this, it is clear that NONE||anything==NONE.		 */[[SEP]]// // Optimize away p||p and p&&p TODO: optimize() was a no-op// for (int i = 0; i < altToPred.length; i++) {// altToPred[i] = altToPred[i].optimize();// }// nonambig alts are null in altToPred",1185,1227,[0],0,"[0, 1, 0, 0, 0, 0, 0]",1,"[0, 0, 1]",1,1,1,1,"getPredsForAmbigAlts(BitSet, ATNConfigSet, int)",org.antlr.v4.runtime.atn.ParserATNSimulator,"getPredsForAmbigAlts/3[java.util.BitSet,org.antlr.v4.runtime.atn.ATNConfigSet,int]",False,1188,2,2,1,1,8,4,20,1,3,3,4,0,0,2,3,0,0,1,4,6,2,2,0,0,0,22,4,0,False
456,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\atn\ParserATNSimulator.java,org.antlr.v4.runtime.atn.ParserATNSimulator,"DFAState.PredPrediction[] getPredicatePredictions(BitSet, SemanticContext[])","protected DFAState.PredPrediction[] getPredicatePredictions(BitSet ambigAlts, SemanticContext[] altToPred) {
    List<DFAState.PredPrediction> pairs = new ArrayList<DFAState.PredPrediction>();
    boolean containsPredicate = false;
    for (int i = 1; i < altToPred.length; i++) {
        SemanticContext pred = altToPred[i];
        // unpredicated is indicated by SemanticContext.NONE
        assert pred != null;
        if (ambigAlts != null && ambigAlts.get(i)) {
            pairs.add(new DFAState.PredPrediction(pred, i));
        }
        if (pred != SemanticContext.Empty.Instance)
            containsPredicate = true;
    }
    if (!containsPredicate) {
        return null;
    }
    // System.out.println(Arrays.toString(altToPred)+""->""+pairs);
    return pairs.toArray(new DFAState.PredPrediction[0]);
}", ,"// unpredicated is indicated by SemanticContext.NONE
[[SEP]]// System.out.println(Arrays.toString(altToPred)+""->""+pairs);
","// unpredicated is indicated by SemanticContext.NONE[[SEP]]// System.out.println(Arrays.toString(altToPred)+""->""+pairs);",1229,1252,[0],0,"[0, 0]",0,"[0, 0]",0,0,0,0,"getPredicatePredictions(BitSet, SemanticContext[])",org.antlr.v4.runtime.atn.ParserATNSimulator,"getPredicatePredictions/2[java.util.BitSet,org.antlr.v4.runtime.atn.SemanticContext[]]",False,1231,2,2,1,1,6,3,16,2,4,2,3,0,0,1,3,0,0,0,2,5,0,2,0,0,0,20,4,0,False
457,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\atn\ParserATNSimulator.java,org.antlr.v4.runtime.atn.ParserATNSimulator,"int getSynValidOrSemInvalidAltThatFinishedDecisionEntryRule(ATNConfigSet, ParserRuleContext)","/**
 * This method is used to improve the localization of error messages by
 * choosing an alternative rather than throwing a
 * {@link NoViableAltException} in particular prediction scenarios where the
 * {@link #ERROR} state was reached during ATN simulation.
 *
 * <p>
 * The default implementation of this method uses the following
 * algorithm to identify an ATN configuration which successfully parsed the
 * decision entry rule. Choosing such an alternative ensures that the
 * {@link ParserRuleContext} returned by the calling rule will be complete
 * and valid, and the syntax error will be reported later at a more
 * localized location.</p>
 *
 * <ul>
 * <li>If a syntactically valid path or paths reach the end of the decision rule and
 * they are semantically valid if predicated, return the min associated alt.</li>
 * <li>Else, if a semantically invalid but syntactically valid path exist
 * or paths exist, return the minimum associated alt.
 * </li>
 * <li>Otherwise, return {@link ATN#INVALID_ALT_NUMBER}.</li>
 * </ul>
 *
 * <p>
 * In some scenarios, the algorithm described above could predict an
 * alternative which will result in a {@link FailedPredicateException} in
 * the parser. Specifically, this could occur if the <em>only</em> configuration
 * capable of successfully parsing to the end of the decision rule is
 * blocked by a semantic predicate. By choosing this alternative within
 * {@link #adaptivePredict} instead of throwing a
 * {@link NoViableAltException}, the resulting
 * {@link FailedPredicateException} in the parser will identify the specific
 * predicate which is preventing the parser from successfully parsing the
 * decision rule, which helps developers identify and correct logic errors
 * in semantic predicates.
 * </p>
 *
 * @param configs The ATN configurations which were valid immediately before
 * the {@link #ERROR} state was reached
 * @param outerContext The is the \gamma_0 initial parser context from the paper
 * or the parser stack at the instant before prediction commences.
 *
 * @return The value to return from {@link #adaptivePredict}, or
 * {@link ATN#INVALID_ALT_NUMBER} if a suitable alternative was not
 * identified and {@link #adaptivePredict} should report an error instead.
 */
protected int getSynValidOrSemInvalidAltThatFinishedDecisionEntryRule(ATNConfigSet configs, ParserRuleContext outerContext) {
    Pair<ATNConfigSet, ATNConfigSet> sets = splitAccordingToSemanticValidity(configs, outerContext);
    ATNConfigSet semValidConfigs = sets.a;
    ATNConfigSet semInvalidConfigs = sets.b;
    int alt = getAltThatFinishedDecisionEntryRule(semValidConfigs);
    if (alt != ATN.INVALID_ALT_NUMBER) {
        // semantically/syntactically viable path exists
        return alt;
    }
    // Is there a syntactically valid path with a failed pred?
    if (semInvalidConfigs.size() > 0) {
        alt = getAltThatFinishedDecisionEntryRule(semInvalidConfigs);
        if (alt != ATN.INVALID_ALT_NUMBER) {
            // syntactically viable path exists
            return alt;
        }
    }
    return ATN.INVALID_ALT_NUMBER;
}","/**
 * This method is used to improve the localization of error messages by
 * choosing an alternative rather than throwing a
 * {@link NoViableAltException} in particular prediction scenarios where the
 * {@link #ERROR} state was reached during ATN simulation.
 *
 * <p>
 * The default implementation of this method uses the following
 * algorithm to identify an ATN configuration which successfully parsed the
 * decision entry rule. Choosing such an alternative ensures that the
 * {@link ParserRuleContext} returned by the calling rule will be complete
 * and valid, and the syntax error will be reported later at a more
 * localized location.</p>
 *
 * <ul>
 * <li>If a syntactically valid path or paths reach the end of the decision rule and
 * they are semantically valid if predicated, return the min associated alt.</li>
 * <li>Else, if a semantically invalid but syntactically valid path exist
 * or paths exist, return the minimum associated alt.
 * </li>
 * <li>Otherwise, return {@link ATN#INVALID_ALT_NUMBER}.</li>
 * </ul>
 *
 * <p>
 * In some scenarios, the algorithm described above could predict an
 * alternative which will result in a {@link FailedPredicateException} in
 * the parser. Specifically, this could occur if the <em>only</em> configuration
 * capable of successfully parsing to the end of the decision rule is
 * blocked by a semantic predicate. By choosing this alternative within
 * {@link #adaptivePredict} instead of throwing a
 * {@link NoViableAltException}, the resulting
 * {@link FailedPredicateException} in the parser will identify the specific
 * predicate which is preventing the parser from successfully parsing the
 * decision rule, which helps developers identify and correct logic errors
 * in semantic predicates.
 * </p>
 *
 * @param configs The ATN configurations which were valid immediately before
 * the {@link #ERROR} state was reached
 * @param outerContext The is the \gamma_0 initial parser context from the paper
 * or the parser stack at the instant before prediction commences.
 *
 * @return The value to return from {@link #adaptivePredict}, or
 * {@link ATN#INVALID_ALT_NUMBER} if a suitable alternative was not
 * identified and {@link #adaptivePredict} should report an error instead.
 */
","// semantically/syntactically viable path exists
[[SEP]]// Is there a syntactically valid path with a failed pred?
[[SEP]]// syntactically viable path exists
","/** * This method is used to improve the localization of error messages by * choosing an alternative rather than throwing a * {@link NoViableAltException} in particular prediction scenarios where the * {@link #ERROR} state was reached during ATN simulation. * * <p> * The default implementation of this method uses the following * algorithm to identify an ATN configuration which successfully parsed the * decision entry rule. Choosing such an alternative ensures that the * {@link ParserRuleContext} returned by the calling rule will be complete * and valid, and the syntax error will be reported later at a more * localized location.</p> * * <ul> * <li>If a syntactically valid path or paths reach the end of the decision rule and * they are semantically valid if predicated, return the min associated alt.</li> * <li>Else, if a semantically invalid but syntactically valid path exist * or paths exist, return the minimum associated alt. * </li> * <li>Otherwise, return {@link ATN#INVALID_ALT_NUMBER}.</li> * </ul> * * <p> * In some scenarios, the algorithm described above could predict an * alternative which will result in a {@link FailedPredicateException} in * the parser. Specifically, this could occur if the <em>only</em> configuration * capable of successfully parsing to the end of the decision rule is * blocked by a semantic predicate. By choosing this alternative within * {@link #adaptivePredict} instead of throwing a * {@link NoViableAltException}, the resulting * {@link FailedPredicateException} in the parser will identify the specific * predicate which is preventing the parser from successfully parsing the * decision rule, which helps developers identify and correct logic errors * in semantic predicates. * </p> * * @param configs The ATN configurations which were valid immediately before * the {@link #ERROR} state was reached * @param outerContext The is the \gamma_0 initial parser context from the paper * or the parser stack at the instant before prediction commences. * * @return The value to return from {@link #adaptivePredict}, or * {@link ATN#INVALID_ALT_NUMBER} if a suitable alternative was not * identified and {@link #adaptivePredict} should report an error instead. */[[SEP]]// semantically/syntactically viable path exists[[SEP]]// Is there a syntactically valid path with a failed pred?[[SEP]]// syntactically viable path exists",1300,1319,[0],0,"[0, 0, 0]",0,"[0, 0, 0, 0]",0,0,0,0,"getSynValidOrSemInvalidAltThatFinishedDecisionEntryRule(ATNConfigSet, ParserRuleContext)",org.antlr.v4.runtime.atn.ParserATNSimulator,"getSynValidOrSemInvalidAltThatFinishedDecisionEntryRule/2[org.antlr.v4.runtime.atn.ATNConfigSet,org.antlr.v4.runtime.ParserRuleContext]",False,1302,4,5,2,3,4,3,16,3,4,2,3,2,2,0,2,0,0,0,1,5,0,2,0,0,0,154,4,0,True
458,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\atn\ParserATNSimulator.java,org.antlr.v4.runtime.atn.ParserATNSimulator,"Pair<ATNConfigSet, ATNConfigSet> splitAccordingToSemanticValidity(ATNConfigSet, ParserRuleContext)","/**
 * Walk the list of configurations and split them according to
 *  those that have preds evaluating to true/false.  If no pred, assume
 *  true pred and include in succeeded set.  Returns Pair of sets.
 *
 *  Create a new set so as not to alter the incoming parameter.
 *
 *  Assumption: the input stream has been restored to the starting point
 *  prediction, which is where predicates need to evaluate.
 */
protected Pair<ATNConfigSet, ATNConfigSet> splitAccordingToSemanticValidity(ATNConfigSet configs, ParserRuleContext outerContext) {
    ATNConfigSet succeeded = new ATNConfigSet(configs.fullCtx);
    ATNConfigSet failed = new ATNConfigSet(configs.fullCtx);
    for (ATNConfig c : configs) {
        if (c.semanticContext != SemanticContext.Empty.Instance) {
            boolean predicateEvaluationResult = evalSemanticContext(c.semanticContext, outerContext, c.alt, configs.fullCtx);
            if (predicateEvaluationResult) {
                succeeded.add(c);
            } else {
                failed.add(c);
            }
        } else {
            succeeded.add(c);
        }
    }
    return new Pair<ATNConfigSet, ATNConfigSet>(succeeded, failed);
}","/**
 * Walk the list of configurations and split them according to
 *  those that have preds evaluating to true/false.  If no pred, assume
 *  true pred and include in succeeded set.  Returns Pair of sets.
 *
 *  Create a new set so as not to alter the incoming parameter.
 *
 *  Assumption: the input stream has been restored to the starting point
 *  prediction, which is where predicates need to evaluate.
 */
", ,"/** * Walk the list of configurations and split them according to *  those that have preds evaluating to true/false.  If no pred, assume *  true pred and include in succeeded set.  Returns Pair of sets. * *  Create a new set so as not to alter the incoming parameter. * *  Assumption: the input stream has been restored to the starting point *  prediction, which is where predicates need to evaluate. */",1341,1362,[0],0,[0],0,[0],0,0,0,0,"splitAccordingToSemanticValidity(ATNConfigSet, ParserRuleContext)",org.antlr.v4.runtime.atn.ParserATNSimulator,"splitAccordingToSemanticValidity/2[org.antlr.v4.runtime.atn.ATNConfigSet,org.antlr.v4.runtime.ParserRuleContext]",False,1344,4,5,1,4,4,2,19,1,3,2,2,1,1,1,1,0,0,0,0,3,0,3,0,0,0,63,4,0,True
459,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\atn\ParserATNSimulator.java,org.antlr.v4.runtime.atn.ParserATNSimulator,"BitSet evalSemanticContext(DFAState.PredPrediction[], ParserRuleContext, boolean)","/**
 * Look through a list of predicate/alt pairs, returning alts for the
 *  pairs that win. A {@code NONE} predicate indicates an alt containing an
 *  unpredicated config which behaves as ""always true."" If !complete
 *  then we stop at the first predicate that evaluates to true. This
 *  includes pairs with null predicates.
 */
protected BitSet evalSemanticContext(DFAState.PredPrediction[] predPredictions, ParserRuleContext outerContext, boolean complete) {
    BitSet predictions = new BitSet();
    for (DFAState.PredPrediction pair : predPredictions) {
        if (pair.pred == SemanticContext.Empty.Instance) {
            predictions.set(pair.alt);
            if (!complete) {
                break;
            }
            continue;
        }
        // in dfa
        boolean fullCtx = false;
        boolean predicateEvaluationResult = evalSemanticContext(pair.pred, outerContext, pair.alt, fullCtx);
        if (debug || dfa_debug) {
            System.out.println(""eval pred "" + pair + ""="" + predicateEvaluationResult);
        }
        if (predicateEvaluationResult) {
            if (debug || dfa_debug)
                System.out.println(""PREDICT "" + pair.alt);
            predictions.set(pair.alt);
            if (!complete) {
                break;
            }
        }
    }
    return predictions;
}","/**
 * Look through a list of predicate/alt pairs, returning alts for the
 *  pairs that win. A {@code NONE} predicate indicates an alt containing an
 *  unpredicated config which behaves as ""always true."" If !complete
 *  then we stop at the first predicate that evaluates to true. This
 *  includes pairs with null predicates.
 */
","// in dfa
","/** * Look through a list of predicate/alt pairs, returning alts for the *  pairs that win. A {@code NONE} predicate indicates an alt containing an *  unpredicated config which behaves as ""always true."" If !complete *  then we stop at the first predicate that evaluates to true. This *  includes pairs with null predicates. */[[SEP]]// in dfa",1370,1400,[0],0,[0],0,"[0, 0]",0,0,0,0,"evalSemanticContext(PredPrediction[], ParserRuleContext, boolean)",org.antlr.v4.runtime.atn.ParserATNSimulator,"evalSemanticContext/3[org.antlr.v4.runtime.dfa.DFAState.PredPrediction[],org.antlr.v4.runtime.ParserRuleContext,boolean]",False,1373,3,2,1,1,10,3,25,1,3,3,3,1,1,1,1,0,0,3,0,3,2,3,0,0,0,53,4,0,True
460,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\atn\ParserATNSimulator.java,org.antlr.v4.runtime.atn.ParserATNSimulator,"boolean evalSemanticContext(SemanticContext, ParserRuleContext, int, boolean)","/**
 * Evaluate a semantic context within a specific parser context.
 *
 * <p>
 * This method might not be called for every semantic context evaluated
 * during the prediction process. In particular, we currently do not
 * evaluate the following but it may change in the future:</p>
 *
 * <ul>
 * <li>Precedence predicates (represented by
 * {@link SemanticContext.PrecedencePredicate}) are not currently evaluated
 * through this method.</li>
 * <li>Operator predicates (represented by {@link SemanticContext.AND} and
 * {@link SemanticContext.OR}) are evaluated as a single semantic
 * context, rather than evaluating the operands individually.
 * Implementations which require evaluation results from individual
 * predicates should override this method to explicitly handle evaluation of
 * the operands within operator predicates.</li>
 * </ul>
 *
 * @param pred The semantic context to evaluate
 * @param parserCallStack The parser context in which to evaluate the
 * semantic context
 * @param alt The alternative which is guarded by {@code pred}
 * @param fullCtx {@code true} if the evaluation is occurring during LL
 * prediction; otherwise, {@code false} if the evaluation is occurring
 * during SLL prediction
 *
 * @since 4.3
 */
protected boolean evalSemanticContext(SemanticContext pred, ParserRuleContext parserCallStack, int alt, boolean fullCtx) {
    return pred.eval(parser, parserCallStack);
}","/**
 * Evaluate a semantic context within a specific parser context.
 *
 * <p>
 * This method might not be called for every semantic context evaluated
 * during the prediction process. In particular, we currently do not
 * evaluate the following but it may change in the future:</p>
 *
 * <ul>
 * <li>Precedence predicates (represented by
 * {@link SemanticContext.PrecedencePredicate}) are not currently evaluated
 * through this method.</li>
 * <li>Operator predicates (represented by {@link SemanticContext.AND} and
 * {@link SemanticContext.OR}) are evaluated as a single semantic
 * context, rather than evaluating the operands individually.
 * Implementations which require evaluation results from individual
 * predicates should override this method to explicitly handle evaluation of
 * the operands within operator predicates.</li>
 * </ul>
 *
 * @param pred The semantic context to evaluate
 * @param parserCallStack The parser context in which to evaluate the
 * semantic context
 * @param alt The alternative which is guarded by {@code pred}
 * @param fullCtx {@code true} if the evaluation is occurring during LL
 * prediction; otherwise, {@code false} if the evaluation is occurring
 * during SLL prediction
 *
 * @since 4.3
 */
", ,"/** * Evaluate a semantic context within a specific parser context. * * <p> * This method might not be called for every semantic context evaluated * during the prediction process. In particular, we currently do not * evaluate the following but it may change in the future:</p> * * <ul> * <li>Precedence predicates (represented by * {@link SemanticContext.PrecedencePredicate}) are not currently evaluated * through this method.</li> * <li>Operator predicates (represented by {@link SemanticContext.AND} and * {@link SemanticContext.OR}) are evaluated as a single semantic * context, rather than evaluating the operands individually. * Implementations which require evaluation results from individual * predicates should override this method to explicitly handle evaluation of * the operands within operator predicates.</li> * </ul> * * @param pred The semantic context to evaluate * @param parserCallStack The parser context in which to evaluate the * semantic context * @param alt The alternative which is guarded by {@code pred} * @param fullCtx {@code true} if the evaluation is occurring during LL * prediction; otherwise, {@code false} if the evaluation is occurring * during SLL prediction * * @since 4.3 */",1432,1434,[0],0,[0],0,[0],0,0,0,0,"evalSemanticContext(SemanticContext, ParserRuleContext, int, boolean)",org.antlr.v4.runtime.atn.ParserATNSimulator,"evalSemanticContext/4[org.antlr.v4.runtime.atn.SemanticContext,org.antlr.v4.runtime.ParserRuleContext,int,boolean]",False,1432,2,5,4,1,1,1,3,1,0,4,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,80,4,0,True
461,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\atn\ParserATNSimulator.java,org.antlr.v4.runtime.atn.ParserATNSimulator,"void closureCheckingStopState(ATNConfig, ATNConfigSet, Set<ATNConfig>, boolean, boolean, int, boolean)","protected void closureCheckingStopState(ATNConfig config, ATNConfigSet configs, Set<ATNConfig> closureBusy, boolean collectPredicates, boolean fullCtx, int depth, boolean treatEofAsEpsilon) {
    if (debug)
        System.out.println(""closure("" + config.toString(parser, true) + "")"");
    if (config.state instanceof RuleStopState) {
        // We hit rule end. If we have context info, use it
        // run thru all possible stack tops in ctx
        if (!config.context.isEmpty()) {
            for (int i = 0; i < config.context.size(); i++) {
                if (config.context.getReturnState(i) == PredictionContext.EMPTY_RETURN_STATE) {
                    if (fullCtx) {
                        configs.add(new ATNConfig(config, config.state, EmptyPredictionContext.Instance), mergeCache);
                        continue;
                    } else {
                        // we have no context info, just chase follow links (if greedy)
                        if (debug)
                            System.out.println(""FALLING off rule "" + getRuleName(config.state.ruleIndex));
                        closure_(config, configs, closureBusy, collectPredicates, fullCtx, depth, treatEofAsEpsilon);
                    }
                    continue;
                }
                ATNState returnState = atn.states.get(config.context.getReturnState(i));
                // ""pop"" return state
                PredictionContext newContext = config.context.getParent(i);
                ATNConfig c = new ATNConfig(returnState, config.alt, newContext, config.semanticContext);
                // While we have context to pop back from, we may have
                // gotten that context AFTER having falling off a rule.
                // Make sure we track that we are now out of context.
                // 
                // This assignment also propagates the
                // isPrecedenceFilterSuppressed() value to the new
                // configuration.
                c.reachesIntoOuterContext = config.reachesIntoOuterContext;
                assert depth > Integer.MIN_VALUE;
                closureCheckingStopState(c, configs, closureBusy, collectPredicates, fullCtx, depth - 1, treatEofAsEpsilon);
            }
            return;
        } else if (fullCtx) {
            // reached end of start rule
            configs.add(config, mergeCache);
            return;
        } else {
            // else if we have no context info, just chase follow links (if greedy)
            if (debug)
                System.out.println(""FALLING off rule "" + getRuleName(config.state.ruleIndex));
        }
    }
    closure_(config, configs, closureBusy, collectPredicates, fullCtx, depth, treatEofAsEpsilon);
}", ,"// We hit rule end. If we have context info, use it
[[SEP]]// run thru all possible stack tops in ctx
[[SEP]]// While we have context to pop back from, we may have
[[SEP]]// gotten that context AFTER having falling off a rule.
[[SEP]]// Make sure we track that we are now out of context.
[[SEP]]// 
[[SEP]]// This assignment also propagates the
[[SEP]]// isPrecedenceFilterSuppressed() value to the new
[[SEP]]// we have no context info, just chase follow links (if greedy)
[[SEP]]// ""pop"" return state
[[SEP]]// configuration.
[[SEP]]// reached end of start rule
[[SEP]]// else if we have no context info, just chase follow links (if greedy)
","// We hit rule end. If we have context info, use it// run thru all possible stack tops in ctx[[SEP]]// we have no context info, just chase follow links (if greedy)[[SEP]]// ""pop"" return state[[SEP]]// While we have context to pop back from, we may have// gotten that context AFTER having falling off a rule.// Make sure we track that we are now out of context.//// This assignment also propagates the// isPrecedenceFilterSuppressed() value to the new// configuration.[[SEP]]// reached end of start rule[[SEP]]// else if we have no context info, just chase follow links (if greedy)",1457,1518,[0],0,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]",0,"[0, 0, 0, 0, 0, 0]",0,0,0,0,"closureCheckingStopState(ATNConfig, ATNConfigSet, Set<ATNConfig>, boolean, boolean, int, boolean)",org.antlr.v4.runtime.atn.ParserATNSimulator,"closureCheckingStopState/7[org.antlr.v4.runtime.atn.ATNConfig,org.antlr.v4.runtime.atn.ATNConfigSet,java.util.Set<org.antlr.v4.runtime.atn.ATNConfig>,boolean,boolean,int,boolean]",False,1464,6,14,3,11,10,11,35,2,4,7,11,3,6,1,1,0,0,4,2,5,4,6,0,0,0,29,4,0,False
462,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\atn\ParserATNSimulator.java,org.antlr.v4.runtime.atn.ParserATNSimulator,"void closure_(ATNConfig, ATNConfigSet, Set<ATNConfig>, boolean, boolean, int, boolean)","/**
 * Do the actual work of walking epsilon edges
 */
protected void closure_(ATNConfig config, ATNConfigSet configs, Set<ATNConfig> closureBusy, boolean collectPredicates, boolean fullCtx, int depth, boolean treatEofAsEpsilon) {
    ATNState p = config.state;
    // optimization
    if (!p.onlyHasEpsilonTransitions()) {
        configs.add(config, mergeCache);
        // make sure to not return here, because EOF transitions can act as
        // both epsilon transitions and non-epsilon transitions.
        // if ( debug ) System.out.println(""added config ""+configs);
    }
    for (int i = 0; i < p.getNumberOfTransitions(); i++) {
        if (i == 0 && canDropLoopEntryEdgeInLeftRecursiveRule(config))
            continue;
        Transition t = p.transition(i);
        boolean continueCollecting = !(t instanceof ActionTransition) && collectPredicates;
        ATNConfig c = getEpsilonTarget(config, t, continueCollecting, depth == 0, fullCtx, treatEofAsEpsilon);
        if (c != null) {
            int newDepth = depth;
            if (config.state instanceof RuleStopState) {
                assert !fullCtx;
                // target fell off end of rule; mark resulting c as having dipped into outer context
                // We can't get here if incoming config was rule stop and we had context
                // track how far we dip into outer context.  Might
                // come in handy and we avoid evaluating context dependent
                // preds if this is > 0.
                if (_dfa != null && _dfa.isPrecedenceDfa()) {
                    int outermostPrecedenceReturn = ((EpsilonTransition) t).outermostPrecedenceReturn();
                    if (outermostPrecedenceReturn == _dfa.atnStartState.ruleIndex) {
                        c.setPrecedenceFilterSuppressed(true);
                    }
                }
                c.reachesIntoOuterContext++;
                if (!closureBusy.add(c)) {
                    // avoid infinite recursion for right-recursive rules
                    continue;
                }
                // TODO: can remove? only care when we add to set per middle of this method
                configs.dipsIntoOuterContext = true;
                assert newDepth > Integer.MIN_VALUE;
                newDepth--;
                if (debug)
                    System.out.println(""dips into outer ctx: "" + c);
            } else {
                if (!t.isEpsilon() && !closureBusy.add(c)) {
                    // avoid infinite recursion for EOF* and EOF+
                    continue;
                }
                if (t instanceof RuleTransition) {
                    // latch when newDepth goes negative - once we step out of the entry context we can't return
                    if (newDepth >= 0) {
                        newDepth++;
                    }
                }
            }
            closureCheckingStopState(c, configs, closureBusy, continueCollecting, fullCtx, newDepth, treatEofAsEpsilon);
        }
    }
}","/**
 * Do the actual work of walking epsilon edges
 */
","// optimization
[[SEP]]// make sure to not return here, because EOF transitions can act as
[[SEP]]// both epsilon transitions and non-epsilon transitions.
[[SEP]]// if ( debug ) System.out.println(""added config ""+configs);
[[SEP]]// target fell off end of rule; mark resulting c as having dipped into outer context
[[SEP]]// We can't get here if incoming config was rule stop and we had context
[[SEP]]// track how far we dip into outer context.  Might
[[SEP]]// come in handy and we avoid evaluating context dependent
[[SEP]]// preds if this is > 0.
[[SEP]]// avoid infinite recursion for right-recursive rules
[[SEP]]// TODO: can remove? only care when we add to set per middle of this method
[[SEP]]// avoid infinite recursion for EOF* and EOF+
[[SEP]]// latch when newDepth goes negative - once we step out of the entry context we can't return
","/** * Do the actual work of walking epsilon edges */[[SEP]]// optimization[[SEP]]// make sure to not return here, because EOF transitions can act as// both epsilon transitions and non-epsilon transitions.// if ( debug ) System.out.println(""added config ""+configs);[[SEP]]// target fell off end of rule; mark resulting c as having dipped into outer context// We can't get here if incoming config was rule stop and we had context// track how far we dip into outer context.  Might// come in handy and we avoid evaluating context dependent// preds if this is > 0.[[SEP]]// avoid infinite recursion for right-recursive rules[[SEP]]// TODO: can remove? only care when we add to set per middle of this method[[SEP]]// avoid infinite recursion for EOF* and EOF+[[SEP]]// latch when newDepth goes negative - once we step out of the entry context we can't return",1521,1593,[0],0,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0]",1,"[0, 0, 0, 0, 0, 1, 0, 0]",1,1,1,1,"closure_(ATNConfig, ATNConfigSet, Set<ATNConfig>, boolean, boolean, int, boolean)",org.antlr.v4.runtime.atn.ParserATNSimulator,"closure_/7[org.antlr.v4.runtime.atn.ATNConfig,org.antlr.v4.runtime.atn.ATNConfigSet,java.util.Set<org.antlr.v4.runtime.atn.ATNConfig>,boolean,boolean,int,boolean]",False,1528,10,12,1,11,16,13,43,0,7,7,13,3,6,1,5,0,2,1,4,8,1,5,0,0,0,58,4,0,True
463,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\atn\ParserATNSimulator.java,org.antlr.v4.runtime.atn.ParserATNSimulator,boolean canDropLoopEntryEdgeInLeftRecursiveRule(ATNConfig),"/**
 * Implements first-edge (loop entry) elimination as an optimization
 *  during closure operations.  See antlr/antlr4#1398.
 *
 * The optimization is to avoid adding the loop entry config when
 * the exit path can only lead back to the same
 * StarLoopEntryState after popping context at the rule end state
 * (traversing only epsilon edges, so we're still in closure, in
 * this same rule).
 *
 * We need to detect any state that can reach loop entry on
 * epsilon w/o exiting rule. We don't have to look at FOLLOW
 * links, just ensure that all stack tops for config refer to key
 * states in LR rule.
 *
 * To verify we are in the right situation we must first check
 * closure is at a StarLoopEntryState generated during LR removal.
 * Then we check that each stack top of context is a return state
 * from one of these cases:
 *
 *   1. 'not' expr, '(' type ')' expr. The return state points at loop entry state
 *   2. expr op expr. The return state is the block end of internal block of (...)*
 *   3. 'between' expr 'and' expr. The return state of 2nd expr reference.
 *      That state points at block end of internal block of (...)*.
 *   4. expr '?' expr ':' expr. The return state points at block end,
 *      which points at loop entry state.
 *
 * If any is true for each stack top, then closure does not add a
 * config to the current config set for edge[0], the loop entry branch.
 *
 *  Conditions fail if any context for the current config is:
 *
 *   a. empty (we'd fall out of expr to do a global FOLLOW which could
 *      even be to some weird spot in expr) or,
 *   b. lies outside of expr or,
 *   c. lies within expr but at a state not the BlockEndState
 *   generated during LR removal
 *
 * Do we need to evaluate predicates ever in closure for this case?
 *
 * No. Predicates, including precedence predicates, are only
 * evaluated when computing a DFA start state. I.e., only before
 * the lookahead (but not parser) consumes a token.
 *
 * There are no epsilon edges allowed in LR rule alt blocks or in
 * the ""primary"" part (ID here). If closure is in
 * StarLoopEntryState any lookahead operation will have consumed a
 * token as there are no epsilon-paths that lead to
 * StarLoopEntryState. We do not have to evaluate predicates
 * therefore if we are in the generated StarLoopEntryState of a LR
 * rule. Note that when making a prediction starting at that
 * decision point, decision d=2, compute-start-state performs
 * closure starting at edges[0], edges[1] emanating from
 * StarLoopEntryState. That means it is not performing closure on
 * StarLoopEntryState during compute-start-state.
 *
 * How do we know this always gives same prediction answer?
 *
 * Without predicates, loop entry and exit paths are ambiguous
 * upon remaining input +b (in, say, a+b). Either paths lead to
 * valid parses. Closure can lead to consuming + immediately or by
 * falling out of this call to expr back into expr and loop back
 * again to StarLoopEntryState to match +b. In this special case,
 * we choose the more efficient path, which is to take the bypass
 * path.
 *
 * The lookahead language has not changed because closure chooses
 * one path over the other. Both paths lead to consuming the same
 * remaining input during a lookahead operation. If the next token
 * is an operator, lookahead will enter the choice block with
 * operators. If it is not, lookahead will exit expr. Same as if
 * closure had chosen to enter the choice block immediately.
 *
 * Closure is examining one config (some loopentrystate, some alt,
 * context) which means it is considering exactly one alt. Closure
 * always copies the same alt to any derived configs.
 *
 * How do we know this optimization doesn't mess up precedence in
 * our parse trees?
 *
 * Looking through expr from left edge of stat only has to confirm
 * that an input, say, a+b+c; begins with any valid interpretation
 * of an expression. The precedence actually doesn't matter when
 * making a decision in stat seeing through expr. It is only when
 * parsing rule expr that we must use the precedence to get the
 * right interpretation and, hence, parse tree.
 *
 * @since 4.6
 */
protected boolean canDropLoopEntryEdgeInLeftRecursiveRule(ATNConfig config) {
    if (TURN_OFF_LR_LOOP_ENTRY_BRANCH_OPT)
        return false;
    ATNState p = config.state;
    // First check to see if we are in StarLoopEntryState generated during
    // left-recursion elimination. For efficiency, also check if
    // the context has an empty stack case. If so, it would mean
    // global FOLLOW so we can't perform optimization
    if (p.getStateType() != ATNState.STAR_LOOP_ENTRY || // Are we the special loop entry/exit state?
    !((StarLoopEntryState) p).isPrecedenceDecision || // If SLL wildcard
    config.context.isEmpty() || config.context.hasEmptyPath()) {
        return false;
    }
    // Require all return states to return back to the same rule
    // that p is in.
    int numCtxs = config.context.size();
    for (int i = 0; i < numCtxs; i++) {
        // for each stack context
        ATNState returnState = atn.states.get(config.context.getReturnState(i));
        if (returnState.ruleIndex != p.ruleIndex)
            return false;
    }
    BlockStartState decisionStartState = (BlockStartState) p.transition(0).target;
    int blockEndStateNum = decisionStartState.endState.stateNumber;
    BlockEndState blockEndState = (BlockEndState) atn.states.get(blockEndStateNum);
    // Verify that the top of each stack context leads to loop entry/exit
    // state through epsilon edges and w/o leaving rule.
    for (int i = 0; i < numCtxs; i++) {
        // for each stack context
        int returnStateNumber = config.context.getReturnState(i);
        ATNState returnState = atn.states.get(returnStateNumber);
        // all states must have single outgoing epsilon edge
        if (returnState.getNumberOfTransitions() != 1 || !returnState.transition(0).isEpsilon()) {
            return false;
        }
        // Look for prefix op case like 'not expr', (' type ')' expr
        ATNState returnStateTarget = returnState.transition(0).target;
        if (returnState.getStateType() == BLOCK_END && returnStateTarget == p) {
            continue;
        }
        // Look for 'expr op expr' or case where expr's return state is block end
        // of (...)* internal block; the block end points to loop back
        // which points to p but we don't need to check that
        if (returnState == blockEndState) {
            continue;
        }
        // Look for ternary expr ? expr : expr. The return state points at block end,
        // which points at loop entry state
        if (returnStateTarget == blockEndState) {
            continue;
        }
        // Look for complex prefix 'between expr and expr' case where 2nd expr's
        // return state points at block end state of (...)* internal block
        if (returnStateTarget.getStateType() == BLOCK_END && returnStateTarget.getNumberOfTransitions() == 1 && returnStateTarget.transition(0).isEpsilon() && returnStateTarget.transition(0).target == p) {
            continue;
        }
        // anything else ain't conforming
        return false;
    }
    return true;
}","/**
 * Implements first-edge (loop entry) elimination as an optimization
 *  during closure operations.  See antlr/antlr4#1398.
 *
 * The optimization is to avoid adding the loop entry config when
 * the exit path can only lead back to the same
 * StarLoopEntryState after popping context at the rule end state
 * (traversing only epsilon edges, so we're still in closure, in
 * this same rule).
 *
 * We need to detect any state that can reach loop entry on
 * epsilon w/o exiting rule. We don't have to look at FOLLOW
 * links, just ensure that all stack tops for config refer to key
 * states in LR rule.
 *
 * To verify we are in the right situation we must first check
 * closure is at a StarLoopEntryState generated during LR removal.
 * Then we check that each stack top of context is a return state
 * from one of these cases:
 *
 *   1. 'not' expr, '(' type ')' expr. The return state points at loop entry state
 *   2. expr op expr. The return state is the block end of internal block of (...)*
 *   3. 'between' expr 'and' expr. The return state of 2nd expr reference.
 *      That state points at block end of internal block of (...)*.
 *   4. expr '?' expr ':' expr. The return state points at block end,
 *      which points at loop entry state.
 *
 * If any is true for each stack top, then closure does not add a
 * config to the current config set for edge[0], the loop entry branch.
 *
 *  Conditions fail if any context for the current config is:
 *
 *   a. empty (we'd fall out of expr to do a global FOLLOW which could
 *      even be to some weird spot in expr) or,
 *   b. lies outside of expr or,
 *   c. lies within expr but at a state not the BlockEndState
 *   generated during LR removal
 *
 * Do we need to evaluate predicates ever in closure for this case?
 *
 * No. Predicates, including precedence predicates, are only
 * evaluated when computing a DFA start state. I.e., only before
 * the lookahead (but not parser) consumes a token.
 *
 * There are no epsilon edges allowed in LR rule alt blocks or in
 * the ""primary"" part (ID here). If closure is in
 * StarLoopEntryState any lookahead operation will have consumed a
 * token as there are no epsilon-paths that lead to
 * StarLoopEntryState. We do not have to evaluate predicates
 * therefore if we are in the generated StarLoopEntryState of a LR
 * rule. Note that when making a prediction starting at that
 * decision point, decision d=2, compute-start-state performs
 * closure starting at edges[0], edges[1] emanating from
 * StarLoopEntryState. That means it is not performing closure on
 * StarLoopEntryState during compute-start-state.
 *
 * How do we know this always gives same prediction answer?
 *
 * Without predicates, loop entry and exit paths are ambiguous
 * upon remaining input +b (in, say, a+b). Either paths lead to
 * valid parses. Closure can lead to consuming + immediately or by
 * falling out of this call to expr back into expr and loop back
 * again to StarLoopEntryState to match +b. In this special case,
 * we choose the more efficient path, which is to take the bypass
 * path.
 *
 * The lookahead language has not changed because closure chooses
 * one path over the other. Both paths lead to consuming the same
 * remaining input during a lookahead operation. If the next token
 * is an operator, lookahead will enter the choice block with
 * operators. If it is not, lookahead will exit expr. Same as if
 * closure had chosen to enter the choice block immediately.
 *
 * Closure is examining one config (some loopentrystate, some alt,
 * context) which means it is considering exactly one alt. Closure
 * always copies the same alt to any derived configs.
 *
 * How do we know this optimization doesn't mess up precedence in
 * our parse trees?
 *
 * Looking through expr from left edge of stat only has to confirm
 * that an input, say, a+b+c; begins with any valid interpretation
 * of an expression. The precedence actually doesn't matter when
 * making a decision in stat seeing through expr. It is only when
 * parsing rule expr that we must use the precedence to get the
 * right interpretation and, hence, parse tree.
 *
 * @since 4.6
 */
","// First check to see if we are in StarLoopEntryState generated during
[[SEP]]// left-recursion elimination. For efficiency, also check if
[[SEP]]// the context has an empty stack case. If so, it would mean
[[SEP]]// Require all return states to return back to the same rule
[[SEP]]// Verify that the top of each stack context leads to loop entry/exit
[[SEP]]// global FOLLOW so we can't perform optimization
[[SEP]]// Are we the special loop entry/exit state?
[[SEP]]// If SLL wildcard
[[SEP]]// that p is in.
[[SEP]]// for each stack context
[[SEP]]// state through epsilon edges and w/o leaving rule.
[[SEP]]// Look for 'expr op expr' or case where expr's return state is block end
[[SEP]]// of (...)* internal block; the block end points to loop back
[[SEP]]// Look for ternary expr ? expr : expr. The return state points at block end,
[[SEP]]// Look for complex prefix 'between expr and expr' case where 2nd expr's
[[SEP]]// for each stack context
[[SEP]]// all states must have single outgoing epsilon edge
[[SEP]]// Look for prefix op case like 'not expr', (' type ')' expr
[[SEP]]// which points to p but we don't need to check that
[[SEP]]// which points at loop entry state
[[SEP]]// return state points at block end state of (...)* internal block
[[SEP]]// anything else ain't conforming
","/** * Implements first-edge (loop entry) elimination as an optimization *  during closure operations.  See antlr/antlr4#1398. * * The optimization is to avoid adding the loop entry config when * the exit path can only lead back to the same * StarLoopEntryState after popping context at the rule end state * (traversing only epsilon edges, so we're still in closure, in * this same rule). * * We need to detect any state that can reach loop entry on * epsilon w/o exiting rule. We don't have to look at FOLLOW * links, just ensure that all stack tops for config refer to key * states in LR rule. * * To verify we are in the right situation we must first check * closure is at a StarLoopEntryState generated during LR removal. * Then we check that each stack top of context is a return state * from one of these cases: * *   1. 'not' expr, '(' type ')' expr. The return state points at loop entry state *   2. expr op expr. The return state is the block end of internal block of (...)* *   3. 'between' expr 'and' expr. The return state of 2nd expr reference. *      That state points at block end of internal block of (...)*. *   4. expr '?' expr ':' expr. The return state points at block end, *      which points at loop entry state. * * If any is true for each stack top, then closure does not add a * config to the current config set for edge[0], the loop entry branch. * *  Conditions fail if any context for the current config is: * *   a. empty (we'd fall out of expr to do a global FOLLOW which could *      even be to some weird spot in expr) or, *   b. lies outside of expr or, *   c. lies within expr but at a state not the BlockEndState *   generated during LR removal * * Do we need to evaluate predicates ever in closure for this case? * * No. Predicates, including precedence predicates, are only * evaluated when computing a DFA start state. I.e., only before * the lookahead (but not parser) consumes a token. * * There are no epsilon edges allowed in LR rule alt blocks or in * the ""primary"" part (ID here). If closure is in * StarLoopEntryState any lookahead operation will have consumed a * token as there are no epsilon-paths that lead to * StarLoopEntryState. We do not have to evaluate predicates * therefore if we are in the generated StarLoopEntryState of a LR * rule. Note that when making a prediction starting at that * decision point, decision d=2, compute-start-state performs * closure starting at edges[0], edges[1] emanating from * StarLoopEntryState. That means it is not performing closure on * StarLoopEntryState during compute-start-state. * * How do we know this always gives same prediction answer? * * Without predicates, loop entry and exit paths are ambiguous * upon remaining input +b (in, say, a+b). Either paths lead to * valid parses. Closure can lead to consuming + immediately or by * falling out of this call to expr back into expr and loop back * again to StarLoopEntryState to match +b. In this special case, * we choose the more efficient path, which is to take the bypass * path. * * The lookahead language has not changed because closure chooses * one path over the other. Both paths lead to consuming the same * remaining input during a lookahead operation. If the next token * is an operator, lookahead will enter the choice block with * operators. If it is not, lookahead will exit expr. Same as if * closure had chosen to enter the choice block immediately. * * Closure is examining one config (some loopentrystate, some alt, * context) which means it is considering exactly one alt. Closure * always copies the same alt to any derived configs. * * How do we know this optimization doesn't mess up precedence in * our parse trees? * * Looking through expr from left edge of stat only has to confirm * that an input, say, a+b+c; begins with any valid interpretation * of an expression. The precedence actually doesn't matter when * making a decision in stat seeing through expr. It is only when * parsing rule expr that we must use the precedence to get the * right interpretation and, hence, parse tree. * * @since 4.6 */[[SEP]]// First check to see if we are in StarLoopEntryState generated during// left-recursion elimination. For efficiency, also check if// the context has an empty stack case. If so, it would mean// global FOLLOW so we can't perform optimization[[SEP]]// Are we the special loop entry/exit state?[[SEP]]// If SLL wildcard[[SEP]]// Require all return states to return back to the same rule// that p is in.[[SEP]]// for each stack context[[SEP]]// Verify that the top of each stack context leads to loop entry/exit// state through epsilon edges and w/o leaving rule.[[SEP]]// for each stack context[[SEP]]// all states must have single outgoing epsilon edge[[SEP]]// Look for prefix op case like 'not expr', (' type ')' expr[[SEP]]// Look for 'expr op expr' or case where expr's return state is block end// of (...)* internal block; the block end points to loop back// which points to p but we don't need to check that[[SEP]]// Look for ternary expr ? expr : expr. The return state points at block end,// which points at loop entry state[[SEP]]// Look for complex prefix 'between expr and expr' case where 2nd expr's// return state points at block end state of (...)* internal block[[SEP]]// anything else ain't conforming",1683,1752,[0],0,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]",0,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]",0,0,0,1,canDropLoopEntryEdgeInLeftRecursiveRule(ATNConfig),org.antlr.v4.runtime.atn.ParserATNSimulator,canDropLoopEntryEdgeInLeftRecursiveRule/1[org.antlr.v4.runtime.atn.ATNConfig],False,1683,7,9,1,8,19,9,37,6,11,1,9,0,0,2,10,0,1,0,9,11,0,2,0,0,0,260,4,0,True
464,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\atn\ParserATNSimulator.java,org.antlr.v4.runtime.atn.ParserATNSimulator,"ATNConfig getEpsilonTarget(ATNConfig, Transition, boolean, boolean, boolean, boolean)","protected ATNConfig getEpsilonTarget(ATNConfig config, Transition t, boolean collectPredicates, boolean inContext, boolean fullCtx, boolean treatEofAsEpsilon) {
    switch(t.getSerializationType()) {
        case Transition.RULE:
            return ruleTransition(config, (RuleTransition) t);
        case Transition.PRECEDENCE:
            return precedenceTransition(config, (PrecedencePredicateTransition) t, collectPredicates, inContext, fullCtx);
        case Transition.PREDICATE:
            return predTransition(config, (PredicateTransition) t, collectPredicates, inContext, fullCtx);
        case Transition.ACTION:
            return actionTransition(config, (ActionTransition) t);
        case Transition.EPSILON:
            return new ATNConfig(config, t.target);
        case Transition.ATOM:
        case Transition.RANGE:
        case Transition.SET:
            // EOF transitions act like epsilon transitions after the first EOF
            // transition is traversed
            if (treatEofAsEpsilon) {
                if (t.matches(Token.EOF, 0, 1)) {
                    return new ATNConfig(config, t.target);
                }
            }
            return null;
        default:
            return null;
    }
}", ,"// EOF transitions act like epsilon transitions after the first EOF
[[SEP]]// transition is traversed
",// EOF transitions act like epsilon transitions after the first EOF// transition is traversed,1761,1803,[0],0,"[0, 0]",0,[0],0,0,0,0,"getEpsilonTarget(ATNConfig, Transition, boolean, boolean, boolean, boolean)",org.antlr.v4.runtime.atn.ParserATNSimulator,"getEpsilonTarget/6[org.antlr.v4.runtime.atn.ATNConfig,org.antlr.v4.runtime.atn.Transition,boolean,boolean,boolean,boolean]",False,1767,7,8,1,7,11,6,25,8,0,6,6,4,4,0,0,0,0,0,2,0,0,3,0,0,0,21,4,0,False
465,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\atn\ParserATNSimulator.java,org.antlr.v4.runtime.atn.ParserATNSimulator,"ATNConfig precedenceTransition(ATNConfig, PrecedencePredicateTransition, boolean, boolean, boolean)","public ATNConfig precedenceTransition(ATNConfig config, PrecedencePredicateTransition pt, boolean collectPredicates, boolean inContext, boolean fullCtx) {
    if (debug) {
        System.out.println(""PRED (collectPredicates="" + collectPredicates + "") "" + pt.precedence + "">=_p"" + "", ctx dependent=true"");
        if (parser != null) {
            System.out.println(""context surrounding pred is "" + parser.getRuleInvocationStack());
        }
    }
    ATNConfig c = null;
    if (collectPredicates && inContext) {
        if (fullCtx) {
            // In full context mode, we can evaluate predicates on-the-fly
            // during closure, which dramatically reduces the size of
            // the config sets. It also obviates the need to test predicates
            // later during conflict resolution.
            int currentPosition = _input.index();
            _input.seek(_startIndex);
            boolean predSucceeds = evalSemanticContext(pt.getPredicate(), _outerContext, config.alt, fullCtx);
            _input.seek(currentPosition);
            if (predSucceeds) {
                // no pred context
                c = new ATNConfig(config, pt.target);
            }
        } else {
            SemanticContext newSemCtx = SemanticContext.and(config.semanticContext, pt.getPredicate());
            c = new ATNConfig(config, pt.target, newSemCtx);
        }
    } else {
        c = new ATNConfig(config, pt.target);
    }
    if (debug)
        System.out.println(""config from pred transition="" + c);
    return c;
}", ,"// In full context mode, we can evaluate predicates on-the-fly
[[SEP]]// during closure, which dramatically reduces the size of
[[SEP]]// the config sets. It also obviates the need to test predicates
[[SEP]]// later during conflict resolution.
[[SEP]]// no pred context
","// In full context mode, we can evaluate predicates on-the-fly// during closure, which dramatically reduces the size of// the config sets. It also obviates the need to test predicates// later during conflict resolution.[[SEP]]// no pred context",1812,1855,[0],0,"[0, 0, 0, 0, 0]",0,"[0, 0]",0,0,0,0,"precedenceTransition(ATNConfig, PrecedencePredicateTransition, boolean, boolean, boolean)",org.antlr.v4.runtime.atn.ParserATNSimulator,"precedenceTransition/5[org.antlr.v4.runtime.atn.ATNConfig,org.antlr.v4.runtime.atn.PrecedencePredicateTransition,boolean,boolean,boolean]",False,1817,6,9,1,8,8,7,29,1,4,5,7,1,1,0,1,0,0,6,0,7,3,3,0,0,0,32,1,0,False
466,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\atn\ParserATNSimulator.java,org.antlr.v4.runtime.atn.ParserATNSimulator,"ATNConfig predTransition(ATNConfig, PredicateTransition, boolean, boolean, boolean)","protected ATNConfig predTransition(ATNConfig config, PredicateTransition pt, boolean collectPredicates, boolean inContext, boolean fullCtx) {
    if (debug) {
        System.out.println(""PRED (collectPredicates="" + collectPredicates + "") "" + pt.ruleIndex + "":"" + pt.predIndex + "", ctx dependent="" + pt.isCtxDependent);
        if (parser != null) {
            System.out.println(""context surrounding pred is "" + parser.getRuleInvocationStack());
        }
    }
    ATNConfig c = null;
    if (collectPredicates && (!pt.isCtxDependent || (pt.isCtxDependent && inContext))) {
        if (fullCtx) {
            // In full context mode, we can evaluate predicates on-the-fly
            // during closure, which dramatically reduces the size of
            // the config sets. It also obviates the need to test predicates
            // later during conflict resolution.
            int currentPosition = _input.index();
            _input.seek(_startIndex);
            boolean predSucceeds = evalSemanticContext(pt.getPredicate(), _outerContext, config.alt, fullCtx);
            _input.seek(currentPosition);
            if (predSucceeds) {
                // no pred context
                c = new ATNConfig(config, pt.target);
            }
        } else {
            SemanticContext newSemCtx = SemanticContext.and(config.semanticContext, pt.getPredicate());
            c = new ATNConfig(config, pt.target, newSemCtx);
        }
    } else {
        c = new ATNConfig(config, pt.target);
    }
    if (debug)
        System.out.println(""config from pred transition="" + c);
    return c;
}", ,"// In full context mode, we can evaluate predicates on-the-fly
[[SEP]]// during closure, which dramatically reduces the size of
[[SEP]]// the config sets. It also obviates the need to test predicates
[[SEP]]// later during conflict resolution.
[[SEP]]// no pred context
","// In full context mode, we can evaluate predicates on-the-fly// during closure, which dramatically reduces the size of// the config sets. It also obviates the need to test predicates// later during conflict resolution.[[SEP]]// no pred context",1858,1903,[0],0,"[0, 0, 0, 0, 0]",0,"[0, 0]",0,0,0,0,"predTransition(ATNConfig, PredicateTransition, boolean, boolean, boolean)",org.antlr.v4.runtime.atn.ParserATNSimulator,"predTransition/5[org.antlr.v4.runtime.atn.ATNConfig,org.antlr.v4.runtime.atn.PredicateTransition,boolean,boolean,boolean]",False,1863,6,9,1,8,10,7,29,1,4,5,7,1,1,0,1,0,2,6,0,7,3,3,0,0,0,31,4,0,False
467,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\atn\ParserATNSimulator.java,org.antlr.v4.runtime.atn.ParserATNSimulator,BitSet getConflictingAlts(ATNConfigSet),"/**
 * Gets a {@link BitSet} containing the alternatives in {@code configs}
 * which are part of one or more conflicting alternative subsets.
 *
 * @param configs The {@link ATNConfigSet} to analyze.
 * @return The alternatives in {@code configs} which are part of one or more
 * conflicting alternative subsets. If {@code configs} does not contain any
 * conflicting subsets, this method returns an empty {@link BitSet}.
 */
protected BitSet getConflictingAlts(ATNConfigSet configs) {
    Collection<BitSet> altsets = PredictionMode.getConflictingAltSubsets(configs);
    return PredictionMode.getAlts(altsets);
}","/**
 * Gets a {@link BitSet} containing the alternatives in {@code configs}
 * which are part of one or more conflicting alternative subsets.
 *
 * @param configs The {@link ATNConfigSet} to analyze.
 * @return The alternatives in {@code configs} which are part of one or more
 * conflicting alternative subsets. If {@code configs} does not contain any
 * conflicting subsets, this method returns an empty {@link BitSet}.
 */
", ,"/** * Gets a {@link BitSet} containing the alternatives in {@code configs} * which are part of one or more conflicting alternative subsets. * * @param configs The {@link ATNConfigSet} to analyze. * @return The alternatives in {@code configs} which are part of one or more * conflicting alternative subsets. If {@code configs} does not contain any * conflicting subsets, this method returns an empty {@link BitSet}. */",1927,1930,[0],0,[0],0,[0],0,0,0,0,getConflictingAlts(ATNConfigSet),org.antlr.v4.runtime.atn.ParserATNSimulator,getConflictingAlts/1[org.antlr.v4.runtime.atn.ATNConfigSet],False,1927,2,3,1,2,1,2,4,1,1,1,2,0,0,0,0,0,0,0,0,1,0,0,0,0,0,38,4,0,True
468,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\atn\ParserATNSimulator.java,org.antlr.v4.runtime.atn.ParserATNSimulator,BitSet getConflictingAltsOrUniqueAlt(ATNConfigSet),"/**
 * 	 Sam pointed out a problem with the previous definition, v3, of
 * 	 ambiguous states. If we have another state associated with conflicting
 * 	 alternatives, we should keep going. For example, the following grammar
 *
 * 	 s : (ID | ID ID?) ';' ;
 *
 * 	 When the ATN simulation reaches the state before ';', it has a DFA
 * 	 state that looks like: [12|1|[], 6|2|[], 12|2|[]]. Naturally
 * 	 12|1|[] and 12|2|[] conflict, but we cannot stop processing this node
 * 	 because alternative to has another way to continue, via [6|2|[]].
 * 	 The key is that we have a single state that has config's only associated
 * 	 with a single alternative, 2, and crucially the state transitions
 * 	 among the configurations are all non-epsilon transitions. That means
 * 	 we don't consider any conflicts that include alternative 2. So, we
 * 	 ignore the conflict between alts 1 and 2. We ignore a set of
 * 	 conflicting alts when there is an intersection with an alternative
 * 	 associated with a single alt state in the state&rarr;config-list map.
 *
 * 	 It's also the case that we might have two conflicting configurations but
 * 	 also a 3rd nonconflicting configuration for a different alternative:
 * 	 [1|1|[], 1|2|[], 8|3|[]]. This can come about from grammar:
 *
 * 	 a : A | A | A B ;
 *
 * 	 After matching input A, we reach the stop state for rule A, state 1.
 * 	 State 8 is the state right before B. Clearly alternatives 1 and 2
 * 	 conflict and no amount of further lookahead will separate the two.
 * 	 However, alternative 3 will be able to continue and so we do not
 * 	 stop working on this state. In the previous example, we're concerned
 * 	 with states associated with the conflicting alternatives. Here alt
 * 	 3 is not associated with the conflicting configs, but since we can continue
 * 	 looking for input reasonably, I don't declare the state done. We
 * 	 ignore a set of conflicting alts when we have an alternative
 * 	 that we still need to pursue.
 */
protected BitSet getConflictingAltsOrUniqueAlt(ATNConfigSet configs) {
    BitSet conflictingAlts;
    if (configs.uniqueAlt != ATN.INVALID_ALT_NUMBER) {
        conflictingAlts = new BitSet();
        conflictingAlts.set(configs.uniqueAlt);
    } else {
        conflictingAlts = configs.conflictingAlts;
    }
    return conflictingAlts;
}","/**
 * 	 Sam pointed out a problem with the previous definition, v3, of
 * 	 ambiguous states. If we have another state associated with conflicting
 * 	 alternatives, we should keep going. For example, the following grammar
 *
 * 	 s : (ID | ID ID?) ';' ;
 *
 * 	 When the ATN simulation reaches the state before ';', it has a DFA
 * 	 state that looks like: [12|1|[], 6|2|[], 12|2|[]]. Naturally
 * 	 12|1|[] and 12|2|[] conflict, but we cannot stop processing this node
 * 	 because alternative to has another way to continue, via [6|2|[]].
 * 	 The key is that we have a single state that has config's only associated
 * 	 with a single alternative, 2, and crucially the state transitions
 * 	 among the configurations are all non-epsilon transitions. That means
 * 	 we don't consider any conflicts that include alternative 2. So, we
 * 	 ignore the conflict between alts 1 and 2. We ignore a set of
 * 	 conflicting alts when there is an intersection with an alternative
 * 	 associated with a single alt state in the state&rarr;config-list map.
 *
 * 	 It's also the case that we might have two conflicting configurations but
 * 	 also a 3rd nonconflicting configuration for a different alternative:
 * 	 [1|1|[], 1|2|[], 8|3|[]]. This can come about from grammar:
 *
 * 	 a : A | A | A B ;
 *
 * 	 After matching input A, we reach the stop state for rule A, state 1.
 * 	 State 8 is the state right before B. Clearly alternatives 1 and 2
 * 	 conflict and no amount of further lookahead will separate the two.
 * 	 However, alternative 3 will be able to continue and so we do not
 * 	 stop working on this state. In the previous example, we're concerned
 * 	 with states associated with the conflicting alternatives. Here alt
 * 	 3 is not associated with the conflicting configs, but since we can continue
 * 	 looking for input reasonably, I don't declare the state done. We
 * 	 ignore a set of conflicting alts when we have an alternative
 * 	 that we still need to pursue.
 */
", ,"/** * 	 Sam pointed out a problem with the previous definition, v3, of * 	 ambiguous states. If we have another state associated with conflicting * 	 alternatives, we should keep going. For example, the following grammar * * 	 s : (ID | ID ID?) ';' ; * * 	 When the ATN simulation reaches the state before ';', it has a DFA * 	 state that looks like: [12|1|[], 6|2|[], 12|2|[]]. Naturally * 	 12|1|[] and 12|2|[] conflict, but we cannot stop processing this node * 	 because alternative to has another way to continue, via [6|2|[]]. * 	 The key is that we have a single state that has config's only associated * 	 with a single alternative, 2, and crucially the state transitions * 	 among the configurations are all non-epsilon transitions. That means * 	 we don't consider any conflicts that include alternative 2. So, we * 	 ignore the conflict between alts 1 and 2. We ignore a set of * 	 conflicting alts when there is an intersection with an alternative * 	 associated with a single alt state in the state&rarr;config-list map. * * 	 It's also the case that we might have two conflicting configurations but * 	 also a 3rd nonconflicting configuration for a different alternative: * 	 [1|1|[], 1|2|[], 8|3|[]]. This can come about from grammar: * * 	 a : A | A | A B ; * * 	 After matching input A, we reach the stop state for rule A, state 1. * 	 State 8 is the state right before B. Clearly alternatives 1 and 2 * 	 conflict and no amount of further lookahead will separate the two. * 	 However, alternative 3 will be able to continue and so we do not * 	 stop working on this state. In the previous example, we're concerned * 	 with states associated with the conflicting alternatives. Here alt * 	 3 is not associated with the conflicting configs, but since we can continue * 	 looking for input reasonably, I don't declare the state done. We * 	 ignore a set of conflicting alts when we have an alternative * 	 that we still need to pursue. */",1968,1978,[1],1,[0],0,[1],1,0,1,1,getConflictingAltsOrUniqueAlt(ATNConfigSet),org.antlr.v4.runtime.atn.ParserATNSimulator,getConflictingAltsOrUniqueAlt/1[org.antlr.v4.runtime.atn.ATNConfigSet],False,1968,1,1,1,0,2,1,11,1,1,1,1,0,0,0,1,0,0,0,0,2,0,1,0,0,0,136,4,0,True
469,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\atn\ParserATNSimulator.java,org.antlr.v4.runtime.atn.ParserATNSimulator,void dumpDeadEndConfigs(NoViableAltException),"/**
 * Used for debugging in adaptivePredict around execATN but I cut
 *  it out for clarity now that alg. works well. We can leave this
 *  ""dead"" code for a bit.
 */
public void dumpDeadEndConfigs(NoViableAltException nvae) {
    System.err.println(""dead end configs: "");
    for (ATNConfig c : nvae.getDeadEndConfigs()) {
        String trans = ""no edges"";
        if (c.state.getNumberOfTransitions() > 0) {
            Transition t = c.state.transition(0);
            if (t instanceof AtomTransition) {
                AtomTransition at = (AtomTransition) t;
                trans = ""Atom "" + getTokenName(at.label);
            } else if (t instanceof SetTransition) {
                SetTransition st = (SetTransition) t;
                boolean not = st instanceof NotSetTransition;
                trans = (not ? ""~"" : """") + ""Set "" + st.set.toString();
            }
        }
        System.err.println(c.toString(parser, true) + "":"" + trans);
    }
}","/**
 * Used for debugging in adaptivePredict around execATN but I cut
 *  it out for clarity now that alg. works well. We can leave this
 *  ""dead"" code for a bit.
 */
", ,"/** * Used for debugging in adaptivePredict around execATN but I cut *  it out for clarity now that alg. works well. We can leave this *  ""dead"" code for a bit. */",2003,2021,[1],1,[0],0,[1],1,0,1,1,dumpDeadEndConfigs(NoViableAltException),org.antlr.v4.runtime.atn.ParserATNSimulator,dumpDeadEndConfigs/1[org.antlr.v4.runtime.NoViableAltException],False,2003,9,6,0,6,6,7,19,0,5,1,7,1,1,1,0,0,1,7,2,7,3,3,0,0,0,48,1,0,True
470,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\atn\ParserATNSimulator.java,org.antlr.v4.runtime.atn.ParserATNSimulator,int getUniqueAlt(ATNConfigSet),"protected static int getUniqueAlt(ATNConfigSet configs) {
    int alt = ATN.INVALID_ALT_NUMBER;
    for (ATNConfig c : configs) {
        if (alt == ATN.INVALID_ALT_NUMBER) {
            // found first alt
            alt = c.alt;
        } else if (c.alt != alt) {
            return ATN.INVALID_ALT_NUMBER;
        }
    }
    return alt;
}", ,"// found first alt
",// found first alt,2035,2046,[0],0,[0],0,[0],0,0,0,0,getUniqueAlt(ATNConfigSet),org.antlr.v4.runtime.atn.ParserATNSimulator,getUniqueAlt/1[org.antlr.v4.runtime.atn.ATNConfigSet],False,2035,1,3,3,0,4,0,12,2,1,1,0,0,0,1,2,0,0,0,0,2,0,2,0,0,0,11,12,0,False
471,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\atn\ParserATNSimulator.java,org.antlr.v4.runtime.atn.ParserATNSimulator,"DFAState addDFAEdge(DFA, DFAState, int, DFAState)","/**
 * Add an edge to the DFA, if possible. This method calls
 * {@link #addDFAState} to ensure the {@code to} state is present in the
 * DFA. If {@code from} is {@code null}, or if {@code t} is outside the
 * range of edges that can be represented in the DFA tables, this method
 * returns without adding the edge to the DFA.
 *
 * <p>If {@code to} is {@code null}, this method returns {@code null}.
 * Otherwise, this method returns the {@link DFAState} returned by calling
 * {@link #addDFAState} for the {@code to} state.</p>
 *
 * @param dfa The DFA
 * @param from The source state for the edge
 * @param t The input symbol
 * @param to The target state for the edge
 *
 * @return If {@code to} is {@code null}, this method returns {@code null};
 * otherwise this method returns the result of calling {@link #addDFAState}
 * on {@code to}
 */
protected DFAState addDFAEdge(DFA dfa, DFAState from, int t, DFAState to) {
    if (debug) {
        System.out.println(""EDGE "" + from + "" -> "" + to + "" upon "" + getTokenName(t));
    }
    if (to == null) {
        return null;
    }
    // used existing if possible not incoming
    to = addDFAState(dfa, to);
    if (from == null || t < -1 || t > atn.maxTokenType) {
        return to;
    }
    synchronized (from) {
        if (from.edges == null) {
            from.edges = new DFAState[atn.maxTokenType + 1 + 1];
        }
        // connect
        from.edges[t + 1] = to;
    }
    if (debug) {
        System.out.println(""DFA=\n"" + dfa.toString(parser != null ? parser.getVocabulary() : VocabularyImpl.EMPTY_VOCABULARY));
    }
    return to;
}","/**
 * Add an edge to the DFA, if possible. This method calls
 * {@link #addDFAState} to ensure the {@code to} state is present in the
 * DFA. If {@code from} is {@code null}, or if {@code t} is outside the
 * range of edges that can be represented in the DFA tables, this method
 * returns without adding the edge to the DFA.
 *
 * <p>If {@code to} is {@code null}, this method returns {@code null}.
 * Otherwise, this method returns the {@link DFAState} returned by calling
 * {@link #addDFAState} for the {@code to} state.</p>
 *
 * @param dfa The DFA
 * @param from The source state for the edge
 * @param t The input symbol
 * @param to The target state for the edge
 *
 * @return If {@code to} is {@code null}, this method returns {@code null};
 * otherwise this method returns the result of calling {@link #addDFAState}
 * on {@code to}
 */
","// used existing if possible not incoming
[[SEP]]// connect
","/** * Add an edge to the DFA, if possible. This method calls * {@link #addDFAState} to ensure the {@code to} state is present in the * DFA. If {@code from} is {@code null}, or if {@code t} is outside the * range of edges that can be represented in the DFA tables, this method * returns without adding the edge to the DFA. * * <p>If {@code to} is {@code null}, this method returns {@code null}. * Otherwise, this method returns the {@link DFAState} returned by calling * {@link #addDFAState} for the {@code to} state.</p> * * @param dfa The DFA * @param from The source state for the edge * @param t The input symbol * @param to The target state for the edge * * @return If {@code to} is {@code null}, this method returns {@code null}; * otherwise this method returns the result of calling {@link #addDFAState} * on {@code to} */[[SEP]]// used existing if possible not incoming[[SEP]]// connect",2068,2099,[0],0,"[0, 0]",0,"[0, 0, 0]",0,0,0,0,"addDFAEdge(DFA, DFAState, int, DFAState)",org.antlr.v4.runtime.atn.ParserATNSimulator,"addDFAEdge/4[org.antlr.v4.runtime.dfa.DFA,org.antlr.v4.runtime.dfa.DFAState,int,org.antlr.v4.runtime.dfa.DFAState]",False,2072,4,5,1,4,9,5,22,3,0,4,5,2,1,0,4,0,0,4,4,3,4,2,0,0,0,54,4,0,True
472,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\atn\ParserATNSimulator.java,org.antlr.v4.runtime.atn.ParserATNSimulator,"DFAState addDFAState(DFA, DFAState)","/**
 * Add state {@code D} to the DFA if it is not already present, and return
 * the actual instance stored in the DFA. If a state equivalent to {@code D}
 * is already in the DFA, the existing state is returned. Otherwise this
 * method returns {@code D} after adding it to the DFA.
 *
 * <p>If {@code D} is {@link #ERROR}, this method returns {@link #ERROR} and
 * does not change the DFA.</p>
 *
 * @param dfa The dfa
 * @param D The DFA state to add
 * @return The state stored in the DFA. This will be either the existing
 * state if {@code D} is already in the DFA, or {@code D} itself if the
 * state was not already present.
 */
protected DFAState addDFAState(DFA dfa, DFAState D) {
    if (D == ERROR) {
        return D;
    }
    synchronized (dfa.states) {
        DFAState existing = dfa.states.get(D);
        if (existing != null)
            return existing;
        D.stateNumber = dfa.states.size();
        if (!D.configs.isReadonly()) {
            D.configs.optimizeConfigs(this);
            D.configs.setReadonly(true);
        }
        dfa.states.put(D, D);
        if (debug)
            System.out.println(""adding new DFA state: "" + D);
        return D;
    }
}","/**
 * Add state {@code D} to the DFA if it is not already present, and return
 * the actual instance stored in the DFA. If a state equivalent to {@code D}
 * is already in the DFA, the existing state is returned. Otherwise this
 * method returns {@code D} after adding it to the DFA.
 *
 * <p>If {@code D} is {@link #ERROR}, this method returns {@link #ERROR} and
 * does not change the DFA.</p>
 *
 * @param dfa The dfa
 * @param D The DFA state to add
 * @return The state stored in the DFA. This will be either the existing
 * state if {@code D} is already in the DFA, or {@code D} itself if the
 * state was not already present.
 */
", ,"/** * Add state {@code D} to the DFA if it is not already present, and return * the actual instance stored in the DFA. If a state equivalent to {@code D} * is already in the DFA, the existing state is returned. Otherwise this * method returns {@code D} after adding it to the DFA. * * <p>If {@code D} is {@link #ERROR}, this method returns {@link #ERROR} and * does not change the DFA.</p> * * @param dfa The dfa * @param D The DFA state to add * @return The state stored in the DFA. This will be either the existing * state if {@code D} is already in the DFA, or {@code D} itself if the * state was not already present. */",2116,2134,[0],0,[0],0,[0],0,0,0,0,"addDFAState(DFA, DFAState)",org.antlr.v4.runtime.atn.ParserATNSimulator,"addDFAState/2[org.antlr.v4.runtime.dfa.DFA,org.antlr.v4.runtime.dfa.DFAState]",False,2116,3,5,2,3,5,7,17,3,1,2,7,0,0,0,2,0,0,1,0,2,1,2,0,0,0,48,4,0,True
473,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\atn\ParserATNSimulator.java,org.antlr.v4.runtime.atn.ParserATNSimulator,"void reportAmbiguity(DFA, DFAState, int, int, boolean, BitSet, ATNConfigSet)","/**
 * If context sensitive parsing, we know it's ambiguity not conflict
 */
protected void reportAmbiguity(DFA dfa, // the DFA state from execATN() that had SLL conflicts
DFAState D, int startIndex, int stopIndex, boolean exact, BitSet ambigAlts, // configs that LL not SLL considered conflicting
ATNConfigSet configs) {
    if (debug || retry_debug) {
        Interval interval = Interval.of(startIndex, stopIndex);
        System.out.println(""reportAmbiguity "" + ambigAlts + "":"" + configs + "", input="" + parser.getTokenStream().getText(interval));
    }
    if (parser != null)
        parser.getErrorListenerDispatch().reportAmbiguity(parser, dfa, startIndex, stopIndex, exact, ambigAlts, configs);
}","/**
 * If context sensitive parsing, we know it's ambiguity not conflict
 */
","// the DFA state from execATN() that had SLL conflicts
[[SEP]]// configs that LL not SLL considered conflicting
","/** * If context sensitive parsing, we know it's ambiguity not conflict */[[SEP]]// the DFA state from execATN() that had SLL conflicts[[SEP]]// configs that LL not SLL considered conflicting",2155,2170,[0],0,"[0, 0]",0,"[0, 0, 0]",0,0,0,0,"reportAmbiguity(DFA, DFAState, int, int, boolean, BitSet, ATNConfigSet)",org.antlr.v4.runtime.atn.ParserATNSimulator,"reportAmbiguity/7[org.antlr.v4.runtime.dfa.DFA,org.antlr.v4.runtime.dfa.DFAState,int,int,boolean,java.util.BitSet,org.antlr.v4.runtime.atn.ATNConfigSet]",False,2161,8,7,2,5,4,6,7,0,1,7,6,0,0,0,1,0,0,3,0,1,1,1,0,0,0,23,4,0,True
474,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\atn\ParserATNSimulator.java,org.antlr.v4.runtime.atn.ParserATNSimulator,Parser getParser(),"/**
 * @since 4.3
 */
public Parser getParser() {
    return parser;
}","/**
 * @since 4.3
 */
", ,/** * @since 4.3 */,2184,2186,[0],0,[0],0,[0],0,0,0,0,getParser(),org.antlr.v4.runtime.atn.ParserATNSimulator,getParser/0,False,2184,1,0,0,0,1,0,3,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,3,1,0,True
475,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\atn\PredictionContext.java,org.antlr.v4.runtime.atn.PredictionContext,"PredictionContext fromRuleContext(ATN, RuleContext)","/**
 * Convert a {@link RuleContext} tree to a {@link PredictionContext} graph.
 *  Return {@link EmptyPredictionContext#Instance} if {@code outerContext} is empty or null.
 */
public static PredictionContext fromRuleContext(ATN atn, RuleContext outerContext) {
    if (outerContext == null)
        outerContext = ParserRuleContext.EMPTY;
    // if we are in RuleContext of start rule, s, then PredictionContext
    // is EMPTY. Nobody called us. (if we are empty, return empty)
    if (outerContext.parent == null || outerContext == ParserRuleContext.EMPTY) {
        return EmptyPredictionContext.Instance;
    }
    // If we have a parent, convert it to a PredictionContext graph
    PredictionContext parent = EmptyPredictionContext.Instance;
    parent = PredictionContext.fromRuleContext(atn, outerContext.parent);
    ATNState state = atn.states.get(outerContext.invokingState);
    RuleTransition transition = (RuleTransition) state.transition(0);
    return SingletonPredictionContext.create(parent, transition.followState.stateNumber);
}","/**
 * Convert a {@link RuleContext} tree to a {@link PredictionContext} graph.
 *  Return {@link EmptyPredictionContext#Instance} if {@code outerContext} is empty or null.
 */
","// if we are in RuleContext of start rule, s, then PredictionContext
[[SEP]]// is EMPTY. Nobody called us. (if we are empty, return empty)
[[SEP]]// If we have a parent, convert it to a PredictionContext graph
","/** * Convert a {@link RuleContext} tree to a {@link PredictionContext} graph. *  Return {@link EmptyPredictionContext#Instance} if {@code outerContext} is empty or null. */[[SEP]]// if we are in RuleContext of start rule, s, then PredictionContext// is EMPTY. Nobody called us. (if we are empty, return empty)[[SEP]]// If we have a parent, convert it to a PredictionContext graph",68,84,[0],0,"[0, 0, 0]",0,"[0, 0, 0]",0,0,0,0,"fromRuleContext(ATN, RuleContext)",org.antlr.v4.runtime.atn.PredictionContext,"fromRuleContext/2[org.antlr.v4.runtime.atn.ATN,org.antlr.v4.runtime.RuleContext]",False,68,7,6,3,3,4,4,11,2,3,2,4,1,0,0,3,0,0,0,1,5,0,1,0,0,0,21,9,0,True
476,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\atn\PredictionContext.java,org.antlr.v4.runtime.atn.PredictionContext,boolean isEmpty(),"/**
 * This means only the {@link EmptyPredictionContext#Instance} (wildcard? not sure) context is in set.
 */
public boolean isEmpty() {
    return this == EmptyPredictionContext.Instance;
}","/**
 * This means only the {@link EmptyPredictionContext#Instance} (wildcard? not sure) context is in set.
 */
", ,/** * This means only the {@link EmptyPredictionContext#Instance} (wildcard? not sure) context is in set. */,93,95,[0],0,[0],0,[0],0,0,0,0,isEmpty(),org.antlr.v4.runtime.atn.PredictionContext,isEmpty/0,False,93,0,7,7,0,2,0,3,1,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,10,1,0,True
477,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\atn\PredictionContext.java,org.antlr.v4.runtime.atn.PredictionContext,boolean hasEmptyPath(),"public boolean hasEmptyPath() {
    // since EMPTY_RETURN_STATE can only appear in the last position, we check last one
    return getReturnState(size() - 1) == EMPTY_RETURN_STATE;
}", ,"// since EMPTY_RETURN_STATE can only appear in the last position, we check last one
","// since EMPTY_RETURN_STATE can only appear in the last position, we check last one",97,100,[0],0,[0],0,[0],0,0,0,0,hasEmptyPath(),org.antlr.v4.runtime.atn.PredictionContext,hasEmptyPath/0,False,97,1,6,4,2,2,2,3,1,0,0,2,2,1,0,1,0,0,0,1,0,1,0,0,0,0,18,1,0,False
478,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\atn\PredictionContext.java,org.antlr.v4.runtime.atn.PredictionContext,"PredictionContext merge(PredictionContext, PredictionContext, boolean, DoubleKeyMap<PredictionContext, PredictionContext, PredictionContext>)","// dispatch
public static PredictionContext merge(PredictionContext a, PredictionContext b, boolean rootIsWildcard, DoubleKeyMap<PredictionContext, PredictionContext, PredictionContext> mergeCache) {
    // must be empty context, never null
    assert a != null && b != null;
    // share same graph if both same
    if (a == b || a.equals(b))
        return a;
    if (a instanceof SingletonPredictionContext && b instanceof SingletonPredictionContext) {
        return mergeSingletons((SingletonPredictionContext) a, (SingletonPredictionContext) b, rootIsWildcard, mergeCache);
    }
    // At least one of a or b is array
    // If one is $ and rootIsWildcard, return $ as * wildcard
    if (rootIsWildcard) {
        if (a instanceof EmptyPredictionContext)
            return a;
        if (b instanceof EmptyPredictionContext)
            return b;
    }
    // convert singleton so both are arrays to normalize
    if (a instanceof SingletonPredictionContext) {
        a = new ArrayPredictionContext((SingletonPredictionContext) a);
    }
    if (b instanceof SingletonPredictionContext) {
        b = new ArrayPredictionContext((SingletonPredictionContext) b);
    }
    return mergeArrays((ArrayPredictionContext) a, (ArrayPredictionContext) b, rootIsWildcard, mergeCache);
}","// dispatch
","// At least one of a or b is array
[[SEP]]// must be empty context, never null
[[SEP]]// share same graph if both same
[[SEP]]// If one is $ and rootIsWildcard, return $ as * wildcard
[[SEP]]// convert singleton so both are arrays to normalize
","// dispatch[[SEP]]// must be empty context, never null[[SEP]]// share same graph if both same[[SEP]]// At least one of a or b is array// If one is $ and rootIsWildcard, return $ as * wildcard[[SEP]]// convert singleton so both are arrays to normalize",140,172,[0],0,"[0, 0, 0, 0, 0]",0,"[0, 0, 0, 0, 0]",0,0,0,0,"merge(PredictionContext, PredictionContext, boolean, DoubleKeyMap<PredictionContext, PredictionContext, PredictionContext>)",org.antlr.v4.runtime.atn.PredictionContext,"merge/4[org.antlr.v4.runtime.atn.PredictionContext,org.antlr.v4.runtime.atn.PredictionContext,boolean,org.antlr.v4.runtime.misc.DoubleKeyMap<org.antlr.v4.runtime.atn.PredictionContext,org.antlr.v4.runtime.atn.PredictionContext,org.antlr.v4.runtime.atn.PredictionContext>]",False,144,5,7,3,4,12,3,18,5,0,4,3,3,3,0,3,0,0,0,0,2,0,2,0,0,0,16,9,0,False
479,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\atn\PredictionContext.java,org.antlr.v4.runtime.atn.PredictionContext,"PredictionContext mergeSingletons(SingletonPredictionContext, SingletonPredictionContext, boolean, DoubleKeyMap<PredictionContext, PredictionContext, PredictionContext>)","/**
 * Merge two {@link SingletonPredictionContext} instances.
 *
 * <p>Stack tops equal, parents merge is same; return left graph.<br>
 * <embed src=""images/SingletonMerge_SameRootSamePar.svg"" type=""image/svg+xml""/></p>
 *
 * <p>Same stack top, parents differ; merge parents giving array node, then
 * remainders of those graphs. A new root node is created to point to the
 * merged parents.<br>
 * <embed src=""images/SingletonMerge_SameRootDiffPar.svg"" type=""image/svg+xml""/></p>
 *
 * <p>Different stack tops pointing to same parent. Make array node for the
 * root where both element in the root point to the same (original)
 * parent.<br>
 * <embed src=""images/SingletonMerge_DiffRootSamePar.svg"" type=""image/svg+xml""/></p>
 *
 * <p>Different stack tops pointing to different parents. Make array node for
 * the root where each element points to the corresponding original
 * parent.<br>
 * <embed src=""images/SingletonMerge_DiffRootDiffPar.svg"" type=""image/svg+xml""/></p>
 *
 * @param a the first {@link SingletonPredictionContext}
 * @param b the second {@link SingletonPredictionContext}
 * @param rootIsWildcard {@code true} if this is a local-context merge,
 * otherwise false to indicate a full-context merge
 * @param mergeCache
 */
public static PredictionContext mergeSingletons(SingletonPredictionContext a, SingletonPredictionContext b, boolean rootIsWildcard, DoubleKeyMap<PredictionContext, PredictionContext, PredictionContext> mergeCache) {
    if (mergeCache != null) {
        PredictionContext previous = mergeCache.get(a, b);
        if (previous != null)
            return previous;
        previous = mergeCache.get(b, a);
        if (previous != null)
            return previous;
    }
    PredictionContext rootMerge = mergeRoot(a, b, rootIsWildcard);
    if (rootMerge != null) {
        if (mergeCache != null)
            mergeCache.put(a, b, rootMerge);
        return rootMerge;
    }
    if (a.returnState == b.returnState) {
        // a == b
        PredictionContext parent = merge(a.parent, b.parent, rootIsWildcard, mergeCache);
        // if parent is same as existing a or b parent or reduced to a parent, return it
        // ax + bx = ax, if a=b
        if (parent == a.parent)
            return a;
        // ax + bx = bx, if a=b
        if (parent == b.parent)
            return b;
        // else: ax + ay = a'[x,y]
        // merge parents x and y, giving array node with x,y then remainders
        // of those graphs.  dup a, a' points at merged array
        // new joined parent so create new singleton pointing to it, a'
        PredictionContext a_ = SingletonPredictionContext.create(parent, a.returnState);
        if (mergeCache != null)
            mergeCache.put(a, b, a_);
        return a_;
    } else {
        // a != b payloads differ
        // see if we can collapse parents due to $+x parents if local ctx
        PredictionContext singleParent = null;
        if (a == b || (a.parent != null && a.parent.equals(b.parent))) {
            // ax + bx = [a,b]x
            singleParent = a.parent;
        }
        if (singleParent != null) {
            // parents are same
            // sort payloads and use same parent
            int[] payloads = { a.returnState, b.returnState };
            if (a.returnState > b.returnState) {
                payloads[0] = b.returnState;
                payloads[1] = a.returnState;
            }
            PredictionContext[] parents = { singleParent, singleParent };
            PredictionContext a_ = new ArrayPredictionContext(parents, payloads);
            if (mergeCache != null)
                mergeCache.put(a, b, a_);
            return a_;
        }
        // parents differ and can't merge them. Just pack together
        // into array; can't merge.
        // ax + by = [ax,by]
        int[] payloads = { a.returnState, b.returnState };
        PredictionContext[] parents = { a.parent, b.parent };
        if (a.returnState > b.returnState) {
            // sort by payload
            payloads[0] = b.returnState;
            payloads[1] = a.returnState;
            parents = new PredictionContext[] { b.parent, a.parent };
        }
        PredictionContext a_ = new ArrayPredictionContext(parents, payloads);
        if (mergeCache != null)
            mergeCache.put(a, b, a_);
        return a_;
    }
}","/**
 * Merge two {@link SingletonPredictionContext} instances.
 *
 * <p>Stack tops equal, parents merge is same; return left graph.<br>
 * <embed src=""images/SingletonMerge_SameRootSamePar.svg"" type=""image/svg+xml""/></p>
 *
 * <p>Same stack top, parents differ; merge parents giving array node, then
 * remainders of those graphs. A new root node is created to point to the
 * merged parents.<br>
 * <embed src=""images/SingletonMerge_SameRootDiffPar.svg"" type=""image/svg+xml""/></p>
 *
 * <p>Different stack tops pointing to same parent. Make array node for the
 * root where both element in the root point to the same (original)
 * parent.<br>
 * <embed src=""images/SingletonMerge_DiffRootSamePar.svg"" type=""image/svg+xml""/></p>
 *
 * <p>Different stack tops pointing to different parents. Make array node for
 * the root where each element points to the corresponding original
 * parent.<br>
 * <embed src=""images/SingletonMerge_DiffRootDiffPar.svg"" type=""image/svg+xml""/></p>
 *
 * @param a the first {@link SingletonPredictionContext}
 * @param b the second {@link SingletonPredictionContext}
 * @param rootIsWildcard {@code true} if this is a local-context merge,
 * otherwise false to indicate a full-context merge
 * @param mergeCache
 */
","// if parent is same as existing a or b parent or reduced to a parent, return it
[[SEP]]// else: ax + ay = a'[x,y]
[[SEP]]// merge parents x and y, giving array node with x,y then remainders
[[SEP]]// of those graphs.  dup a, a' points at merged array
[[SEP]]// a == b
[[SEP]]// ax + bx = ax, if a=b
[[SEP]]// ax + bx = bx, if a=b
[[SEP]]// new joined parent so create new singleton pointing to it, a'
[[SEP]]// a != b payloads differ
[[SEP]]// parents differ and can't merge them. Just pack together
[[SEP]]// into array; can't merge.
[[SEP]]// see if we can collapse parents due to $+x parents if local ctx
[[SEP]]// ax + bx = [a,b]x
[[SEP]]// parents are same
[[SEP]]// sort payloads and use same parent
[[SEP]]// ax + by = [ax,by]
[[SEP]]// sort by payload
","/** * Merge two {@link SingletonPredictionContext} instances. * * <p>Stack tops equal, parents merge is same; return left graph.<br> * <embed src=""images/SingletonMerge_SameRootSamePar.svg"" type=""image/svg+xml""/></p> * * <p>Same stack top, parents differ; merge parents giving array node, then * remainders of those graphs. A new root node is created to point to the * merged parents.<br> * <embed src=""images/SingletonMerge_SameRootDiffPar.svg"" type=""image/svg+xml""/></p> * * <p>Different stack tops pointing to same parent. Make array node for the * root where both element in the root point to the same (original) * parent.<br> * <embed src=""images/SingletonMerge_DiffRootSamePar.svg"" type=""image/svg+xml""/></p> * * <p>Different stack tops pointing to different parents. Make array node for * the root where each element points to the corresponding original * parent.<br> * <embed src=""images/SingletonMerge_DiffRootDiffPar.svg"" type=""image/svg+xml""/></p> * * @param a the first {@link SingletonPredictionContext} * @param b the second {@link SingletonPredictionContext} * @param rootIsWildcard {@code true} if this is a local-context merge, * otherwise false to indicate a full-context merge * @param mergeCache */[[SEP]]// a == b[[SEP]]// if parent is same as existing a or b parent or reduced to a parent, return it// ax + bx = ax, if a=b[[SEP]]// ax + bx = bx, if a=b[[SEP]]// else: ax + ay = a'[x,y]// merge parents x and y, giving array node with x,y then remainders// of those graphs.  dup a, a' points at merged array// new joined parent so create new singleton pointing to it, a'[[SEP]]// a != b payloads differ// see if we can collapse parents due to $+x parents if local ctx[[SEP]]// ax + bx = [a,b]x[[SEP]]// parents are same// sort payloads and use same parent[[SEP]]// parents differ and can't merge them. Just pack together// into array; can't merge.// ax + by = [ax,by][[SEP]]// sort by payload",201,265,[0],0,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]",0,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]",0,0,0,0,"mergeSingletons(SingletonPredictionContext, SingletonPredictionContext, boolean, DoubleKeyMap<PredictionContext, PredictionContext, PredictionContext>)",org.antlr.v4.runtime.atn.PredictionContext,"mergeSingletons/4[org.antlr.v4.runtime.atn.SingletonPredictionContext,org.antlr.v4.runtime.atn.SingletonPredictionContext,boolean,org.antlr.v4.runtime.misc.DoubleKeyMap<org.antlr.v4.runtime.atn.PredictionContext,org.antlr.v4.runtime.atn.PredictionContext,org.antlr.v4.runtime.atn.PredictionContext>]",False,206,5,8,1,7,18,6,48,8,11,4,6,3,3,0,14,0,1,0,4,18,0,3,0,0,0,68,9,0,True
480,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\atn\PredictionContext.java,org.antlr.v4.runtime.atn.PredictionContext,"PredictionContext mergeRoot(SingletonPredictionContext, SingletonPredictionContext, boolean)","/**
 * Handle case where at least one of {@code a} or {@code b} is
 * {@link EmptyPredictionContext#Instance}. In the following diagrams, the symbol {@code $} is used
 * to represent {@link EmptyPredictionContext#Instance}.
 *
 * <h2>Local-Context Merges</h2>
 *
 * <p>These local-context merge operations are used when {@code rootIsWildcard}
 * is true.</p>
 *
 * <p>{@link EmptyPredictionContext#Instance} is superset of any graph; return {@link EmptyPredictionContext#Instance}.<br>
 * <embed src=""images/LocalMerge_EmptyRoot.svg"" type=""image/svg+xml""/></p>
 *
 * <p>{@link EmptyPredictionContext#Instance} and anything is {@code #EMPTY}, so merged parent is
 * {@code #EMPTY}; return left graph.<br>
 * <embed src=""images/LocalMerge_EmptyParent.svg"" type=""image/svg+xml""/></p>
 *
 * <p>Special case of last merge if local context.<br>
 * <embed src=""images/LocalMerge_DiffRoots.svg"" type=""image/svg+xml""/></p>
 *
 * <h2>Full-Context Merges</h2>
 *
 * <p>These full-context merge operations are used when {@code rootIsWildcard}
 * is false.</p>
 *
 * <p><embed src=""images/FullMerge_EmptyRoots.svg"" type=""image/svg+xml""/></p>
 *
 * <p>Must keep all contexts; {@link EmptyPredictionContext#Instance} in array is a special value (and
 * null parent).<br>
 * <embed src=""images/FullMerge_EmptyRoot.svg"" type=""image/svg+xml""/></p>
 *
 * <p><embed src=""images/FullMerge_SameRoot.svg"" type=""image/svg+xml""/></p>
 *
 * @param a the first {@link SingletonPredictionContext}
 * @param b the second {@link SingletonPredictionContext}
 * @param rootIsWildcard {@code true} if this is a local-context merge,
 * otherwise false to indicate a full-context merge
 */
public static PredictionContext mergeRoot(SingletonPredictionContext a, SingletonPredictionContext b, boolean rootIsWildcard) {
    if (rootIsWildcard) {
        // * + b = *
        if (a == EmptyPredictionContext.Instance)
            return EmptyPredictionContext.Instance;
        // a + * = *
        if (b == EmptyPredictionContext.Instance)
            return EmptyPredictionContext.Instance;
    } else {
        // $ + $ = $
        if (a == EmptyPredictionContext.Instance && b == EmptyPredictionContext.Instance)
            return EmptyPredictionContext.Instance;
        if (a == EmptyPredictionContext.Instance) {
            // $ + x = [x,$]
            int[] payloads = { b.returnState, EMPTY_RETURN_STATE };
            PredictionContext[] parents = { b.parent, null };
            PredictionContext joined = new ArrayPredictionContext(parents, payloads);
            return joined;
        }
        if (b == EmptyPredictionContext.Instance) {
            // x + $ = [x,$] ($ is always last if present)
            int[] payloads = { a.returnState, EMPTY_RETURN_STATE };
            PredictionContext[] parents = { a.parent, null };
            PredictionContext joined = new ArrayPredictionContext(parents, payloads);
            return joined;
        }
    }
    return null;
}","/**
 * Handle case where at least one of {@code a} or {@code b} is
 * {@link EmptyPredictionContext#Instance}. In the following diagrams, the symbol {@code $} is used
 * to represent {@link EmptyPredictionContext#Instance}.
 *
 * <h2>Local-Context Merges</h2>
 *
 * <p>These local-context merge operations are used when {@code rootIsWildcard}
 * is true.</p>
 *
 * <p>{@link EmptyPredictionContext#Instance} is superset of any graph; return {@link EmptyPredictionContext#Instance}.<br>
 * <embed src=""images/LocalMerge_EmptyRoot.svg"" type=""image/svg+xml""/></p>
 *
 * <p>{@link EmptyPredictionContext#Instance} and anything is {@code #EMPTY}, so merged parent is
 * {@code #EMPTY}; return left graph.<br>
 * <embed src=""images/LocalMerge_EmptyParent.svg"" type=""image/svg+xml""/></p>
 *
 * <p>Special case of last merge if local context.<br>
 * <embed src=""images/LocalMerge_DiffRoots.svg"" type=""image/svg+xml""/></p>
 *
 * <h2>Full-Context Merges</h2>
 *
 * <p>These full-context merge operations are used when {@code rootIsWildcard}
 * is false.</p>
 *
 * <p><embed src=""images/FullMerge_EmptyRoots.svg"" type=""image/svg+xml""/></p>
 *
 * <p>Must keep all contexts; {@link EmptyPredictionContext#Instance} in array is a special value (and
 * null parent).<br>
 * <embed src=""images/FullMerge_EmptyRoot.svg"" type=""image/svg+xml""/></p>
 *
 * <p><embed src=""images/FullMerge_SameRoot.svg"" type=""image/svg+xml""/></p>
 *
 * @param a the first {@link SingletonPredictionContext}
 * @param b the second {@link SingletonPredictionContext}
 * @param rootIsWildcard {@code true} if this is a local-context merge,
 * otherwise false to indicate a full-context merge
 */
","// * + b = *
[[SEP]]// a + * = *
[[SEP]]// $ + $ = $
[[SEP]]// $ + x = [x,$]
[[SEP]]// x + $ = [x,$] ($ is always last if present)
","/** * Handle case where at least one of {@code a} or {@code b} is * {@link EmptyPredictionContext#Instance}. In the following diagrams, the symbol {@code $} is used * to represent {@link EmptyPredictionContext#Instance}. * * <h2>Local-Context Merges</h2> * * <p>These local-context merge operations are used when {@code rootIsWildcard} * is true.</p> * * <p>{@link EmptyPredictionContext#Instance} is superset of any graph; return {@link EmptyPredictionContext#Instance}.<br> * <embed src=""images/LocalMerge_EmptyRoot.svg"" type=""image/svg+xml""/></p> * * <p>{@link EmptyPredictionContext#Instance} and anything is {@code #EMPTY}, so merged parent is * {@code #EMPTY}; return left graph.<br> * <embed src=""images/LocalMerge_EmptyParent.svg"" type=""image/svg+xml""/></p> * * <p>Special case of last merge if local context.<br> * <embed src=""images/LocalMerge_DiffRoots.svg"" type=""image/svg+xml""/></p> * * <h2>Full-Context Merges</h2> * * <p>These full-context merge operations are used when {@code rootIsWildcard} * is false.</p> * * <p><embed src=""images/FullMerge_EmptyRoots.svg"" type=""image/svg+xml""/></p> * * <p>Must keep all contexts; {@link EmptyPredictionContext#Instance} in array is a special value (and * null parent).<br> * <embed src=""images/FullMerge_EmptyRoot.svg"" type=""image/svg+xml""/></p> * * <p><embed src=""images/FullMerge_SameRoot.svg"" type=""image/svg+xml""/></p> * * @param a the first {@link SingletonPredictionContext} * @param b the second {@link SingletonPredictionContext} * @param rootIsWildcard {@code true} if this is a local-context merge, * otherwise false to indicate a full-context merge */[[SEP]]// * + b = *[[SEP]]// a + * = *[[SEP]]// $ + $ = $[[SEP]]// $ + x = [x,$][[SEP]]// x + $ = [x,$] ($ is always last if present)",305,331,[0],0,"[0, 0, 0, 0, 0]",0,"[0, 0, 0, 0, 0, 0]",0,0,0,0,"mergeRoot(SingletonPredictionContext, SingletonPredictionContext, boolean)",org.antlr.v4.runtime.atn.PredictionContext,"mergeRoot/3[org.antlr.v4.runtime.atn.SingletonPredictionContext,org.antlr.v4.runtime.atn.SingletonPredictionContext,boolean]",False,308,5,2,1,1,8,0,22,6,6,3,0,0,0,0,6,0,0,0,0,6,0,2,0,0,0,70,9,0,True
481,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\atn\PredictionContext.java,org.antlr.v4.runtime.atn.PredictionContext,"PredictionContext mergeArrays(ArrayPredictionContext, ArrayPredictionContext, boolean, DoubleKeyMap<PredictionContext, PredictionContext, PredictionContext>)","/**
 * Merge two {@link ArrayPredictionContext} instances.
 *
 * <p>Different tops, different parents.<br>
 * <embed src=""images/ArrayMerge_DiffTopDiffPar.svg"" type=""image/svg+xml""/></p>
 *
 * <p>Shared top, same parents.<br>
 * <embed src=""images/ArrayMerge_ShareTopSamePar.svg"" type=""image/svg+xml""/></p>
 *
 * <p>Shared top, different parents.<br>
 * <embed src=""images/ArrayMerge_ShareTopDiffPar.svg"" type=""image/svg+xml""/></p>
 *
 * <p>Shared top, all shared parents.<br>
 * <embed src=""images/ArrayMerge_ShareTopSharePar.svg"" type=""image/svg+xml""/></p>
 *
 * <p>Equal tops, merge parents and reduce top to
 * {@link SingletonPredictionContext}.<br>
 * <embed src=""images/ArrayMerge_EqualTop.svg"" type=""image/svg+xml""/></p>
 */
public static PredictionContext mergeArrays(ArrayPredictionContext a, ArrayPredictionContext b, boolean rootIsWildcard, DoubleKeyMap<PredictionContext, PredictionContext, PredictionContext> mergeCache) {
    if (mergeCache != null) {
        PredictionContext previous = mergeCache.get(a, b);
        if (previous != null)
            return previous;
        previous = mergeCache.get(b, a);
        if (previous != null)
            return previous;
    }
    // merge sorted payloads a + b => M
    // walks a
    int i = 0;
    // walks b
    int j = 0;
    // walks target M array
    int k = 0;
    int[] mergedReturnStates = new int[a.returnStates.length + b.returnStates.length];
    PredictionContext[] mergedParents = new PredictionContext[a.returnStates.length + b.returnStates.length];
    // walk and merge to yield mergedParents, mergedReturnStates
    while (i < a.returnStates.length && j < b.returnStates.length) {
        PredictionContext a_parent = a.parents[i];
        PredictionContext b_parent = b.parents[j];
        if (a.returnStates[i] == b.returnStates[j]) {
            // same payload (stack tops are equal), must yield merged singleton
            int payload = a.returnStates[i];
            // $+$ = $
            boolean both$ = payload == EMPTY_RETURN_STATE && a_parent == null && b_parent == null;
            boolean ax_ax = (a_parent != null && b_parent != null) && // ax+ax -> ax
            a_parent.equals(b_parent);
            if (both$ || ax_ax) {
                // choose left
                mergedParents[k] = a_parent;
                mergedReturnStates[k] = payload;
            } else {
                // ax+ay -> a'[x,y]
                PredictionContext mergedParent = merge(a_parent, b_parent, rootIsWildcard, mergeCache);
                mergedParents[k] = mergedParent;
                mergedReturnStates[k] = payload;
            }
            // hop over left one as usual
            i++;
            // but also skip one in right side since we merge
            j++;
        } else if (a.returnStates[i] < b.returnStates[j]) {
            // copy a[i] to M
            mergedParents[k] = a_parent;
            mergedReturnStates[k] = a.returnStates[i];
            i++;
        } else {
            // b > a, copy b[j] to M
            mergedParents[k] = b_parent;
            mergedReturnStates[k] = b.returnStates[j];
            j++;
        }
        k++;
    }
    // copy over any payloads remaining in either array
    if (i < a.returnStates.length) {
        for (int p = i; p < a.returnStates.length; p++) {
            mergedParents[k] = a.parents[p];
            mergedReturnStates[k] = a.returnStates[p];
            k++;
        }
    } else {
        for (int p = j; p < b.returnStates.length; p++) {
            mergedParents[k] = b.parents[p];
            mergedReturnStates[k] = b.returnStates[p];
            k++;
        }
    }
    // trim merged if we combined a few that had same stack tops
    if (k < mergedParents.length) {
        // write index < last position; trim
        if (k == 1) {
            // for just one merged element, return singleton top
            PredictionContext a_ = SingletonPredictionContext.create(mergedParents[0], mergedReturnStates[0]);
            if (mergeCache != null)
                mergeCache.put(a, b, a_);
            return a_;
        }
        mergedParents = Arrays.copyOf(mergedParents, k);
        mergedReturnStates = Arrays.copyOf(mergedReturnStates, k);
    }
    PredictionContext M = new ArrayPredictionContext(mergedParents, mergedReturnStates);
    // if we created same array as a or b, return that instead
    // TODO: track whether this is possible above during merge sort for speed
    if (M.equals(a)) {
        if (mergeCache != null)
            mergeCache.put(a, b, a);
        return a;
    }
    if (M.equals(b)) {
        if (mergeCache != null)
            mergeCache.put(a, b, b);
        return b;
    }
    combineCommonParents(mergedParents);
    if (mergeCache != null)
        mergeCache.put(a, b, M);
    return M;
}","/**
 * Merge two {@link ArrayPredictionContext} instances.
 *
 * <p>Different tops, different parents.<br>
 * <embed src=""images/ArrayMerge_DiffTopDiffPar.svg"" type=""image/svg+xml""/></p>
 *
 * <p>Shared top, same parents.<br>
 * <embed src=""images/ArrayMerge_ShareTopSamePar.svg"" type=""image/svg+xml""/></p>
 *
 * <p>Shared top, different parents.<br>
 * <embed src=""images/ArrayMerge_ShareTopDiffPar.svg"" type=""image/svg+xml""/></p>
 *
 * <p>Shared top, all shared parents.<br>
 * <embed src=""images/ArrayMerge_ShareTopSharePar.svg"" type=""image/svg+xml""/></p>
 *
 * <p>Equal tops, merge parents and reduce top to
 * {@link SingletonPredictionContext}.<br>
 * <embed src=""images/ArrayMerge_EqualTop.svg"" type=""image/svg+xml""/></p>
 */
","// merge sorted payloads a + b => M
[[SEP]]// if we created same array as a or b, return that instead
[[SEP]]// walks a
[[SEP]]// walks b
[[SEP]]// walks target M array
[[SEP]]// walk and merge to yield mergedParents, mergedReturnStates
[[SEP]]// same payload (stack tops are equal), must yield merged singleton
[[SEP]]// $+$ = $
[[SEP]]// ax+ax -> ax
[[SEP]]// choose left
[[SEP]]// ax+ay -> a'[x,y]
[[SEP]]// hop over left one as usual
[[SEP]]// but also skip one in right side since we merge
[[SEP]]// copy a[i] to M
[[SEP]]// b > a, copy b[j] to M
[[SEP]]// copy over any payloads remaining in either array
[[SEP]]// trim merged if we combined a few that had same stack tops
[[SEP]]// write index < last position; trim
[[SEP]]// for just one merged element, return singleton top
[[SEP]]// TODO: track whether this is possible above during merge sort for speed
","/** * Merge two {@link ArrayPredictionContext} instances. * * <p>Different tops, different parents.<br> * <embed src=""images/ArrayMerge_DiffTopDiffPar.svg"" type=""image/svg+xml""/></p> * * <p>Shared top, same parents.<br> * <embed src=""images/ArrayMerge_ShareTopSamePar.svg"" type=""image/svg+xml""/></p> * * <p>Shared top, different parents.<br> * <embed src=""images/ArrayMerge_ShareTopDiffPar.svg"" type=""image/svg+xml""/></p> * * <p>Shared top, all shared parents.<br> * <embed src=""images/ArrayMerge_ShareTopSharePar.svg"" type=""image/svg+xml""/></p> * * <p>Equal tops, merge parents and reduce top to * {@link SingletonPredictionContext}.<br> * <embed src=""images/ArrayMerge_EqualTop.svg"" type=""image/svg+xml""/></p> */[[SEP]]// merge sorted payloads a + b => M// walks a[[SEP]]// walks b[[SEP]]// walks target M array[[SEP]]// walk and merge to yield mergedParents, mergedReturnStates[[SEP]]// same payload (stack tops are equal), must yield merged singleton[[SEP]]// $+$ = $[[SEP]]// ax+ax -> ax[[SEP]]// choose left[[SEP]]// ax+ay -> a'[x,y][[SEP]]// hop over left one as usual[[SEP]]// but also skip one in right side since we merge[[SEP]]// copy a[i] to M[[SEP]]// b > a, copy b[j] to M[[SEP]]// copy over any payloads remaining in either array[[SEP]]// trim merged if we combined a few that had same stack tops[[SEP]]// write index < last position; trim[[SEP]]// for just one merged element, return singleton top[[SEP]]// if we created same array as a or b, return that instead// TODO: track whether this is possible above during merge sort for speed",352,459,[0],0,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]",1,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]",1,1,1,1,"mergeArrays(ArrayPredictionContext, ArrayPredictionContext, boolean, DoubleKeyMap<PredictionContext, PredictionContext, PredictionContext>)",org.antlr.v4.runtime.atn.PredictionContext,"mergeArrays/4[org.antlr.v4.runtime.atn.ArrayPredictionContext,org.antlr.v4.runtime.atn.ArrayPredictionContext,boolean,org.antlr.v4.runtime.misc.DoubleKeyMap<org.antlr.v4.runtime.atn.PredictionContext,org.antlr.v4.runtime.atn.PredictionContext,org.antlr.v4.runtime.atn.PredictionContext>]",False,357,5,8,1,7,21,8,79,6,16,4,8,3,3,3,14,0,1,0,6,31,2,3,0,0,0,53,9,0,True
482,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\atn\PredictionContext.java,org.antlr.v4.runtime.atn.PredictionContext,void combineCommonParents(PredictionContext[]),"/**
 * Make pass over all <em>M</em> {@code parents}; merge any {@code equals()}
 * ones.
 */
protected static void combineCommonParents(PredictionContext[] parents) {
    Map<PredictionContext, PredictionContext> uniqueParents = new HashMap<PredictionContext, PredictionContext>();
    for (int p = 0; p < parents.length; p++) {
        PredictionContext parent = parents[p];
        if (!uniqueParents.containsKey(parent)) {
            // don't replace
            uniqueParents.put(parent, parent);
        }
    }
    for (int p = 0; p < parents.length; p++) {
        parents[p] = uniqueParents.get(parents[p]);
    }
}","/**
 * Make pass over all <em>M</em> {@code parents}; merge any {@code equals()}
 * ones.
 */
","// don't replace
",/** * Make pass over all <em>M</em> {@code parents}; merge any {@code equals()} * ones. */[[SEP]]// don't replace,465,479,[0],0,[0],0,"[0, 0]",0,0,0,0,combineCommonParents(PredictionContext[]),org.antlr.v4.runtime.atn.PredictionContext,combineCommonParents/1[org.antlr.v4.runtime.atn.PredictionContext[]],False,465,1,1,1,0,4,3,12,0,4,1,3,0,0,2,0,0,0,0,2,5,0,2,0,0,0,17,12,0,True
483,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\atn\PredictionContext.java,org.antlr.v4.runtime.atn.PredictionContext,"PredictionContext getCachedContext(PredictionContext, PredictionContextCache, IdentityHashMap<PredictionContext, PredictionContext>)","// From Sam
public static PredictionContext getCachedContext(PredictionContext context, PredictionContextCache contextCache, IdentityHashMap<PredictionContext, PredictionContext> visited) {
    if (context.isEmpty()) {
        return context;
    }
    PredictionContext existing = visited.get(context);
    if (existing != null) {
        return existing;
    }
    existing = contextCache.get(context);
    if (existing != null) {
        visited.put(context, existing);
        return existing;
    }
    boolean changed = false;
    PredictionContext[] parents = new PredictionContext[context.size()];
    for (int i = 0; i < parents.length; i++) {
        PredictionContext parent = getCachedContext(context.getParent(i), contextCache, visited);
        if (changed || parent != context.getParent(i)) {
            if (!changed) {
                parents = new PredictionContext[context.size()];
                for (int j = 0; j < context.size(); j++) {
                    parents[j] = context.getParent(j);
                }
                changed = true;
            }
            parents[i] = parent;
        }
    }
    if (!changed) {
        contextCache.add(context);
        visited.put(context, context);
        return context;
    }
    PredictionContext updated;
    if (parents.length == 0) {
        updated = EmptyPredictionContext.Instance;
    } else if (parents.length == 1) {
        updated = SingletonPredictionContext.create(parents[0], context.getReturnState(0));
    } else {
        ArrayPredictionContext arrayPredictionContext = (ArrayPredictionContext) context;
        updated = new ArrayPredictionContext(parents, arrayPredictionContext.returnStates);
    }
    contextCache.add(updated);
    visited.put(updated, updated);
    visited.put(context, updated);
    return updated;
}","// From Sam
", ,// From Sam,538,599,[0],0,[0],0,[0],0,0,0,0,"getCachedContext(PredictionContext, PredictionContextCache, IdentityHashMap<PredictionContext, PredictionContext>)",org.antlr.v4.runtime.atn.PredictionContext,"getCachedContext/3[org.antlr.v4.runtime.atn.PredictionContext,org.antlr.v4.runtime.atn.PredictionContextCache,java.util.IdentityHashMap<org.antlr.v4.runtime.atn.PredictionContext,org.antlr.v4.runtime.atn.PredictionContext>]",False,542,4,11,2,9,12,10,49,5,8,3,10,5,1,2,5,0,0,0,6,15,0,4,0,0,0,18,9,0,False
484,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\atn\PredictionContext.java,org.antlr.v4.runtime.atn.PredictionContext,List<PredictionContext> getAllContextNodes(PredictionContext),"// // extra structures, but cut/paste/morphed works, so leave it.
// // seems to do a breadth-first walk
// public static List<PredictionContext> getAllNodes(PredictionContext context) {
// Map<PredictionContext, PredictionContext> visited =
// new IdentityHashMap<PredictionContext, PredictionContext>();
// Deque<PredictionContext> workList = new ArrayDeque<PredictionContext>();
// workList.add(context);
// visited.put(context, context);
// List<PredictionContext> nodes = new ArrayList<PredictionContext>();
// while (!workList.isEmpty()) {
// PredictionContext current = workList.pop();
// nodes.add(current);
// for (int i = 0; i < current.size(); i++) {
// PredictionContext parent = current.getParent(i);
// if ( parent!=null && visited.put(parent, parent) == null) {
// workList.push(parent);
// }
// }
// }
// return nodes;
// }
// ter's recursive version of Sam's getAllNodes()
public static List<PredictionContext> getAllContextNodes(PredictionContext context) {
    List<PredictionContext> nodes = new ArrayList<PredictionContext>();
    Map<PredictionContext, PredictionContext> visited = new IdentityHashMap<PredictionContext, PredictionContext>();
    getAllContextNodes_(context, nodes, visited);
    return nodes;
}","// ter's recursive version of Sam's getAllNodes()
", ,"// // extra structures, but cut/paste/morphed works, so leave it.// // seems to do a breadth-first walk// public static List<PredictionContext> getAllNodes(PredictionContext context) {// Map<PredictionContext, PredictionContext> visited =// new IdentityHashMap<PredictionContext, PredictionContext>();// Deque<PredictionContext> workList = new ArrayDeque<PredictionContext>();// workList.add(context);// visited.put(context, context);// List<PredictionContext> nodes = new ArrayList<PredictionContext>();// while (!workList.isEmpty()) {// PredictionContext current = workList.pop();// nodes.add(current);// for (int i = 0; i < current.size(); i++) {// PredictionContext parent = current.getParent(i);// if ( parent!=null && visited.put(parent, parent) == null) {// workList.push(parent);// }// }// }// return nodes;// }// ter's recursive version of Sam's getAllNodes()",624,630,[0],0,[0],0,[0],0,0,0,0,getAllContextNodes(PredictionContext),org.antlr.v4.runtime.atn.PredictionContext,getAllContextNodes/1[org.antlr.v4.runtime.atn.PredictionContext],False,624,1,2,1,1,1,1,6,1,2,1,1,1,2,0,0,0,0,0,0,2,0,0,0,0,0,9,9,0,False
485,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\atn\PredictionContext.java,org.antlr.v4.runtime.atn.PredictionContext,"String toString(Recognizer<?, ?>)","public String toString(Recognizer<?, ?> recog) {
    return toString();
    // return toString(recog, ParserRuleContext.EMPTY);
}", ,"// return toString(recog, ParserRuleContext.EMPTY);
","// return toString(recog, ParserRuleContext.EMPTY);",644,647,[0],0,[0],0,[0],0,0,0,0,"toString(Recognizer<?, ?>)",org.antlr.v4.runtime.atn.PredictionContext,"toString/1[org.antlr.v4.runtime.Recognizer<?,?>]",False,644,1,0,0,0,1,1,3,1,0,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,3,1,0,False
486,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\atn\PredictionContext.java,org.antlr.v4.runtime.atn.PredictionContext,"String[] toStrings(Recognizer<?, ?>, PredictionContext, int)","// FROM SAM
public String[] toStrings(Recognizer<?, ?> recognizer, PredictionContext stop, int currentState) {
    List<String> result = new ArrayList<String>();
    outer: for (int perm = 0; ; perm++) {
        int offset = 0;
        boolean last = true;
        PredictionContext p = this;
        int stateNumber = currentState;
        StringBuilder localBuffer = new StringBuilder();
        localBuffer.append(""["");
        while (!p.isEmpty() && p != stop) {
            int index = 0;
            if (p.size() > 0) {
                int bits = 1;
                while ((1 << bits) < p.size()) {
                    bits++;
                }
                int mask = (1 << bits) - 1;
                index = (perm >> offset) & mask;
                last &= index >= p.size() - 1;
                if (index >= p.size()) {
                    continue outer;
                }
                offset += bits;
            }
            if (recognizer != null) {
                if (localBuffer.length() > 1) {
                    // first char is '[', if more than that this isn't the first rule
                    localBuffer.append(' ');
                }
                ATN atn = recognizer.getATN();
                ATNState s = atn.states.get(stateNumber);
                String ruleName = recognizer.getRuleNames()[s.ruleIndex];
                localBuffer.append(ruleName);
            } else if (p.getReturnState(index) != EMPTY_RETURN_STATE) {
                if (!p.isEmpty()) {
                    if (localBuffer.length() > 1) {
                        // first char is '[', if more than that this isn't the first rule
                        localBuffer.append(' ');
                    }
                    localBuffer.append(p.getReturnState(index));
                }
            }
            stateNumber = p.getReturnState(index);
            p = p.getParent(index);
        }
        localBuffer.append(""]"");
        result.add(localBuffer.toString());
        if (last) {
            break;
        }
    }
    return result.toArray(new String[0]);
}","// FROM SAM
","// first char is '[', if more than that this isn't the first rule
[[SEP]]// first char is '[', if more than that this isn't the first rule
","// FROM SAM[[SEP]]// first char is '[', if more than that this isn't the first rule[[SEP]]// first char is '[', if more than that this isn't the first rule",654,715,[0],0,"[0, 0]",0,"[0, 0, 0]",0,0,0,0,"toStrings(Recognizer<?, ?>, PredictionContext, int)",org.antlr.v4.runtime.atn.PredictionContext,"toStrings/3[org.antlr.v4.runtime.Recognizer<?,?>,org.antlr.v4.runtime.atn.PredictionContext,int]",False,654,4,7,1,6,13,14,52,1,13,3,14,4,1,3,3,0,3,2,12,18,5,5,0,0,0,40,1,0,False
487,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\atn\PredictionContextCache.java,org.antlr.v4.runtime.atn.PredictionContextCache,PredictionContext add(PredictionContext),"/**
 * Add a context to the cache and return it. If the context already exists,
 *  return that one instead and do not add a new context to the cache.
 *  Protect shared cache from unsafe thread access.
 */
public PredictionContext add(PredictionContext ctx) {
    if (ctx == EmptyPredictionContext.Instance)
        return EmptyPredictionContext.Instance;
    PredictionContext existing = cache.get(ctx);
    if (existing != null) {
        // System.out.println(name+"" reuses ""+existing);
        return existing;
    }
    cache.put(ctx, ctx);
    return ctx;
}","/**
 * Add a context to the cache and return it. If the context already exists,
 *  return that one instead and do not add a new context to the cache.
 *  Protect shared cache from unsafe thread access.
 */
","// System.out.println(name+"" reuses ""+existing);
","/** * Add a context to the cache and return it. If the context already exists, *  return that one instead and do not add a new context to the cache. *  Protect shared cache from unsafe thread access. */[[SEP]]// System.out.println(name+"" reuses ""+existing);",24,33,[0],0,[0],0,"[0, 0]",0,0,0,0,add(PredictionContext),org.antlr.v4.runtime.atn.PredictionContextCache,add/1[org.antlr.v4.runtime.atn.PredictionContext],False,24,2,1,1,0,3,2,9,3,1,1,2,0,0,0,2,0,0,0,0,1,0,1,0,0,0,24,1,0,True
488,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\atn\PredictionMode.java,org.antlr.v4.runtime.atn.PredictionMode.AltAndContextConfigEqualityComparator,int hashCode(ATNConfig),"/**
 * The hash code is only a function of the {@link ATNState#stateNumber}
 * and {@link ATNConfig#context}.
 */
@Override
public int hashCode(ATNConfig o) {
    int hashCode = MurmurHash.initialize(7);
    hashCode = MurmurHash.update(hashCode, o.state.stateNumber);
    hashCode = MurmurHash.update(hashCode, o.context);
    hashCode = MurmurHash.finish(hashCode, 2);
    return hashCode;
}","/**
 * The hash code is only a function of the {@link ATNState#stateNumber}
 * and {@link ATNConfig#context}.
 */
", ,/** * The hash code is only a function of the {@link ATNState#stateNumber} * and {@link ATNConfig#context}. */,102,109,[0],0,[0],0,[0],0,0,0,0,hashCode(ATNConfig),org.antlr.v4.runtime.atn.PredictionMode$AltAndContextConfigEqualityComparator,hashCode/1[org.antlr.v4.runtime.atn.ATNConfig],False,103,2,4,0,4,1,4,7,1,1,1,4,0,0,0,0,0,0,0,2,4,0,0,0,0,0,16,1,0,True
489,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\atn\ProfilingATNSimulator.java,org.antlr.v4.runtime.atn.ProfilingATNSimulator,"int adaptivePredict(TokenStream, int, ParserRuleContext)","@Override
public int adaptivePredict(TokenStream input, int decision, ParserRuleContext outerContext) {
    try {
        this._sllStopIndex = -1;
        this._llStopIndex = -1;
        this.currentDecision = decision;
        // expensive but useful info
        long start = System.nanoTime();
        int alt = super.adaptivePredict(input, decision, outerContext);
        long stop = System.nanoTime();
        decisions[decision].timeInPrediction += (stop - start);
        decisions[decision].invocations++;
        int SLL_k = _sllStopIndex - _startIndex + 1;
        decisions[decision].SLL_TotalLook += SLL_k;
        decisions[decision].SLL_MinLook = decisions[decision].SLL_MinLook == 0 ? SLL_k : Math.min(decisions[decision].SLL_MinLook, SLL_k);
        if (SLL_k > decisions[decision].SLL_MaxLook) {
            decisions[decision].SLL_MaxLook = SLL_k;
            decisions[decision].SLL_MaxLookEvent = new LookaheadEventInfo(decision, null, alt, input, _startIndex, _sllStopIndex, false);
        }
        if (_llStopIndex >= 0) {
            int LL_k = _llStopIndex - _startIndex + 1;
            decisions[decision].LL_TotalLook += LL_k;
            decisions[decision].LL_MinLook = decisions[decision].LL_MinLook == 0 ? LL_k : Math.min(decisions[decision].LL_MinLook, LL_k);
            if (LL_k > decisions[decision].LL_MaxLook) {
                decisions[decision].LL_MaxLook = LL_k;
                decisions[decision].LL_MaxLookEvent = new LookaheadEventInfo(decision, null, alt, input, _startIndex, _llStopIndex, true);
            }
        }
        return alt;
    } finally {
        this.currentDecision = -1;
    }
}", ,"// expensive but useful info
",// expensive but useful info,55,92,[0],0,[0],0,[0],0,0,0,0,"adaptivePredict(TokenStream, int, ParserRuleContext)",org.antlr.v4.runtime.atn.ProfilingATNSimulator,"adaptivePredict/3[org.antlr.v4.runtime.TokenStream,int,org.antlr.v4.runtime.ParserRuleContext]",False,56,3,1,0,1,6,3,32,1,5,3,3,0,0,0,2,1,1,0,8,18,5,3,0,0,0,21,1,0,False
490,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\atn\ProfilingATNSimulator.java,org.antlr.v4.runtime.atn.ProfilingATNSimulator,"DFAState getExistingTargetState(DFAState, int)","@Override
protected DFAState getExistingTargetState(DFAState previousD, int t) {
    // this method is called after each time the input position advances
    // during SLL prediction
    _sllStopIndex = _input.index();
    DFAState existingTargetState = super.getExistingTargetState(previousD, t);
    if (existingTargetState != null) {
        // count only if we transition over a DFA state
        decisions[currentDecision].SLL_DFATransitions++;
        if (existingTargetState == ERROR) {
            decisions[currentDecision].errors.add(new ErrorInfo(currentDecision, previousD.configs, _input, _startIndex, _sllStopIndex, false));
        }
    }
    currentState = existingTargetState;
    return existingTargetState;
}", ,"// this method is called after each time the input position advances
[[SEP]]// during SLL prediction
[[SEP]]// count only if we transition over a DFA state
",// this method is called after each time the input position advances// during SLL prediction[[SEP]]// count only if we transition over a DFA state,94,112,[0],0,"[0, 0, 0]",0,"[0, 0]",0,0,0,0,"getExistingTargetState(DFAState, int)",org.antlr.v4.runtime.atn.ProfilingATNSimulator,"getExistingTargetState/2[org.antlr.v4.runtime.dfa.DFAState,int]",False,95,3,2,0,2,3,3,12,1,1,2,3,0,0,0,2,0,0,0,0,3,0,2,0,0,0,19,4,0,False
491,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\atn\ProfilingATNSimulator.java,org.antlr.v4.runtime.atn.ProfilingATNSimulator,"ATNConfigSet computeReachSet(ATNConfigSet, int, boolean)","@Override
protected ATNConfigSet computeReachSet(ATNConfigSet closure, int t, boolean fullCtx) {
    if (fullCtx) {
        // this method is called after each time the input position advances
        // during full context prediction
        _llStopIndex = _input.index();
    }
    ATNConfigSet reachConfigs = super.computeReachSet(closure, t, fullCtx);
    if (fullCtx) {
        // count computation even if error
        decisions[currentDecision].LL_ATNTransitions++;
        if (reachConfigs != null) {
        } else {
            // no reach on current lookahead symbol. ERROR.
            // TODO: does not handle delayed errors per getSynValidOrSemInvalidAltThatFinishedDecisionEntryRule()
            decisions[currentDecision].errors.add(new ErrorInfo(currentDecision, closure, _input, _startIndex, _llStopIndex, true));
        }
    } else {
        decisions[currentDecision].SLL_ATNTransitions++;
        if (reachConfigs != null) {
        } else {
            // no reach on current lookahead symbol. ERROR.
            decisions[currentDecision].errors.add(new ErrorInfo(currentDecision, closure, _input, _startIndex, _sllStopIndex, false));
        }
    }
    return reachConfigs;
}", ,"// this method is called after each time the input position advances
[[SEP]]// during full context prediction
[[SEP]]// count computation even if error
[[SEP]]// no reach on current lookahead symbol. ERROR.
[[SEP]]// TODO: does not handle delayed errors per getSynValidOrSemInvalidAltThatFinishedDecisionEntryRule()
[[SEP]]// no reach on current lookahead symbol. ERROR.
",// this method is called after each time the input position advances// during full context prediction[[SEP]]// count computation even if error[[SEP]]// no reach on current lookahead symbol. ERROR.// TODO: does not handle delayed errors per getSynValidOrSemInvalidAltThatFinishedDecisionEntryRule()[[SEP]]// no reach on current lookahead symbol. ERROR.,121,152,[0],0,"[0, 0, 0, 0, 1, 0]",1,"[0, 0, 1, 0]",1,1,1,1,"computeReachSet(ATNConfigSet, int, boolean)",org.antlr.v4.runtime.atn.ProfilingATNSimulator,"computeReachSet/3[org.antlr.v4.runtime.atn.ATNConfigSet,int,boolean]",False,122,3,2,0,2,5,3,23,1,1,3,3,0,0,0,2,0,0,0,0,2,0,2,0,0,0,17,4,0,False
492,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\atn\ProfilingATNSimulator.java,org.antlr.v4.runtime.atn.ProfilingATNSimulator,"void reportAmbiguity(DFA, DFAState, int, int, boolean, BitSet, ATNConfigSet)","@Override
protected void reportAmbiguity(DFA dfa, DFAState D, int startIndex, int stopIndex, boolean exact, BitSet ambigAlts, ATNConfigSet configs) {
    int prediction;
    if (ambigAlts != null) {
        prediction = ambigAlts.nextSetBit(0);
    } else {
        prediction = configs.getAlts().nextSetBit(0);
    }
    if (configs.fullCtx && prediction != conflictingAltResolvedBySLL) {
        // Even though this is an ambiguity we are reporting, we can
        // still detect some context sensitivities.  Both SLL and LL
        // are showing a conflict, hence an ambiguity, but if they resolve
        // to different minimum alternatives we have also identified a
        // context sensitivity.
        decisions[currentDecision].contextSensitivities.add(new ContextSensitivityInfo(currentDecision, configs, _input, startIndex, stopIndex));
    }
    decisions[currentDecision].ambiguities.add(new AmbiguityInfo(currentDecision, configs, ambigAlts, _input, startIndex, stopIndex, configs.fullCtx));
    super.reportAmbiguity(dfa, D, startIndex, stopIndex, exact, ambigAlts, configs);
}", ,"// Even though this is an ambiguity we are reporting, we can
[[SEP]]// still detect some context sensitivities.  Both SLL and LL
[[SEP]]// are showing a conflict, hence an ambiguity, but if they resolve
[[SEP]]// to different minimum alternatives we have also identified a
[[SEP]]// context sensitivity.
","// Even though this is an ambiguity we are reporting, we can// still detect some context sensitivities.  Both SLL and LL// are showing a conflict, hence an ambiguity, but if they resolve// to different minimum alternatives we have also identified a// context sensitivity.",190,216,[0],0,"[0, 0, 0, 0, 0]",0,[0],0,0,0,0,"reportAmbiguity(DFA, DFAState, int, int, boolean, BitSet, ATNConfigSet)",org.antlr.v4.runtime.atn.ProfilingATNSimulator,"reportAmbiguity/7[org.antlr.v4.runtime.dfa.DFA,org.antlr.v4.runtime.dfa.DFAState,int,int,boolean,java.util.BitSet,org.antlr.v4.runtime.atn.ATNConfigSet]",False,193,5,3,0,3,4,5,14,0,1,7,5,0,0,0,2,0,0,0,2,2,0,1,0,0,0,19,4,0,False
493,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\atn\SemanticContext.java,org.antlr.v4.runtime.atn.SemanticContext,"boolean eval(Recognizer<?, ?>, RuleContext)","/**
 * For context independent predicates, we evaluate them without a local
 * context (i.e., null context). That way, we can evaluate them without
 * having to create proper rule-specific context during prediction (as
 * opposed to the parser, which creates them naturally). In a practical
 * sense, this avoids a cast exception from RuleContext to myruleContext.
 *
 * <p>For context dependent predicates, we must pass in a local context so that
 * references such as $arg evaluate properly as _localctx.arg. We only
 * capture context dependent predicates in the context in which we begin
 * prediction, so we passed in the outer context here in case of context
 * dependent predicate evaluation.</p>
 */
public abstract boolean eval(Recognizer<?, ?> parser, RuleContext parserCallStack);","/**
 * For context independent predicates, we evaluate them without a local
 * context (i.e., null context). That way, we can evaluate them without
 * having to create proper rule-specific context during prediction (as
 * opposed to the parser, which creates them naturally). In a practical
 * sense, this avoids a cast exception from RuleContext to myruleContext.
 *
 * <p>For context dependent predicates, we must pass in a local context so that
 * references such as $arg evaluate properly as _localctx.arg. We only
 * capture context dependent predicates in the context in which we begin
 * prediction, so we passed in the outer context here in case of context
 * dependent predicate evaluation.</p>
 */
", ,"/** * For context independent predicates, we evaluate them without a local * context (i.e., null context). That way, we can evaluate them without * having to create proper rule-specific context during prediction (as * opposed to the parser, which creates them naturally). In a practical * sense, this avoids a cast exception from RuleContext to myruleContext. * * <p>For context dependent predicates, we must pass in a local context so that * references such as $arg evaluate properly as _localctx.arg. We only * capture context dependent predicates in the context in which we begin * prediction, so we passed in the outer context here in case of context * dependent predicate evaluation.</p> */",44,44,[0],0,[0],0,[0],0,0,0,0,"eval(Recognizer<?, ?>, RuleContext)",org.antlr.v4.runtime.atn.SemanticContext,"eval/2[org.antlr.v4.runtime.Recognizer<?,?>,org.antlr.v4.runtime.RuleContext]",False,31,2,3,3,0,1,0,1,0,0,2,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,58,1025,0,True
494,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\atn\SemanticContext.java,org.antlr.v4.runtime.atn.SemanticContext,"SemanticContext evalPrecedence(Recognizer<?, ?>, RuleContext)","/**
 * Evaluate the precedence predicates for the context and reduce the result.
 *
 * @param parser The parser instance.
 * @param parserCallStack
 * @return The simplified semantic context after precedence predicates are
 * evaluated, which will be one of the following values.
 * <ul>
 * <li>{@link Empty#Instance}: if the predicate simplifies to {@code true} after
 * precedence predicates are evaluated.</li>
 * <li>{@code null}: if the predicate simplifies to {@code false} after
 * precedence predicates are evaluated.</li>
 * <li>{@code this}: if the semantic context is not changed as a result of
 * precedence predicate evaluation.</li>
 * <li>A non-{@code null} {@link SemanticContext}: the new simplified
 * semantic context after precedence predicates are evaluated.</li>
 * </ul>
 */
public SemanticContext evalPrecedence(Recognizer<?, ?> parser, RuleContext parserCallStack) {
    return this;
}","/**
 * Evaluate the precedence predicates for the context and reduce the result.
 *
 * @param parser The parser instance.
 * @param parserCallStack
 * @return The simplified semantic context after precedence predicates are
 * evaluated, which will be one of the following values.
 * <ul>
 * <li>{@link Empty#Instance}: if the predicate simplifies to {@code true} after
 * precedence predicates are evaluated.</li>
 * <li>{@code null}: if the predicate simplifies to {@code false} after
 * precedence predicates are evaluated.</li>
 * <li>{@code this}: if the semantic context is not changed as a result of
 * precedence predicate evaluation.</li>
 * <li>A non-{@code null} {@link SemanticContext}: the new simplified
 * semantic context after precedence predicates are evaluated.</li>
 * </ul>
 */
", ,"/** * Evaluate the precedence predicates for the context and reduce the result. * * @param parser The parser instance. * @param parserCallStack * @return The simplified semantic context after precedence predicates are * evaluated, which will be one of the following values. * <ul> * <li>{@link Empty#Instance}: if the predicate simplifies to {@code true} after * precedence predicates are evaluated.</li> * <li>{@code null}: if the predicate simplifies to {@code false} after * precedence predicates are evaluated.</li> * <li>{@code this}: if the semantic context is not changed as a result of * precedence predicate evaluation.</li> * <li>A non-{@code null} {@link SemanticContext}: the new simplified * semantic context after precedence predicates are evaluated.</li> * </ul> */",64,66,[0],0,[0],0,[0],0,0,0,0,"evalPrecedence(Recognizer<?, ?>, RuleContext)",org.antlr.v4.runtime.atn.SemanticContext,"evalPrecedence/2[org.antlr.v4.runtime.Recognizer<?,?>,org.antlr.v4.runtime.RuleContext]",False,64,3,3,3,0,1,0,3,1,0,2,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,42,1,0,True
495,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\atn\SemanticContext.java,org.antlr.v4.runtime.atn.SemanticContext,"SemanticContext or(SemanticContext, SemanticContext)","/**
 *  @see ParserATNSimulator#getPredsForAmbigAlts
 */
public static SemanticContext or(SemanticContext a, SemanticContext b) {
    if (a == null)
        return b;
    if (b == null)
        return a;
    if (a == Empty.Instance || b == Empty.Instance)
        return Empty.Instance;
    OR result = new OR(a, b);
    if (result.opnds.length == 1) {
        return result.opnds[0];
    }
    return result;
}","/**
 *  @see ParserATNSimulator#getPredsForAmbigAlts
 */
", ,/** *  @see ParserATNSimulator#getPredsForAmbigAlts */,417,427,[0],0,[0],0,[0],0,0,0,0,"or(SemanticContext, SemanticContext)",org.antlr.v4.runtime.atn.SemanticContext,"or/2[org.antlr.v4.runtime.atn.SemanticContext,org.antlr.v4.runtime.atn.SemanticContext]",False,417,3,3,2,1,6,0,10,5,1,2,0,0,0,0,5,0,0,0,2,1,0,1,0,0,0,9,9,0,True
496,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\atn\SemanticContext.java,org.antlr.v4.runtime.atn.SemanticContext.PrecedencePredicate,String toString(),"@Override
public // precedence >= _precedenceStack.peek()
String toString() {
    return ""{"" + precedence + "">=prec}?"";
}", ,"// precedence >= _precedenceStack.peek()
",// precedence >= _precedenceStack.peek(),182,186,[0],0,[0],0,[0],0,0,0,0,toString(),org.antlr.v4.runtime.atn.SemanticContext$PrecedencePredicate,toString/0,False,184,0,0,0,0,1,0,3,1,0,0,0,0,0,0,0,0,0,2,0,0,1,0,0,0,0,4,1,0,False
497,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\atn\SemanticContext.java,org.antlr.v4.runtime.atn.SemanticContext.AND,"boolean eval(Recognizer<?, ?>, RuleContext)","/**
 * {@inheritDoc}
 *
 * <p>
 * The evaluation of predicates by this context is short-circuiting, but
 * unordered.</p>
 */
@Override
public boolean eval(Recognizer<?, ?> parser, RuleContext parserCallStack) {
    for (SemanticContext opnd : opnds) {
        if (!opnd.eval(parser, parserCallStack))
            return false;
    }
    return true;
}","/**
 * {@inheritDoc}
 *
 * <p>
 * The evaluation of predicates by this context is short-circuiting, but
 * unordered.</p>
 */
", ,"/** * {@inheritDoc} * * <p> * The evaluation of predicates by this context is short-circuiting, but * unordered.</p> */",257,263,[0],0,[0],0,[0],0,0,0,0,"eval(Recognizer<?, ?>, RuleContext)",org.antlr.v4.runtime.atn.SemanticContext$AND,"eval/2[org.antlr.v4.runtime.Recognizer<?,?>,org.antlr.v4.runtime.RuleContext]",False,258,3,1,0,1,3,1,6,2,0,2,1,0,0,1,0,0,0,0,0,0,0,2,0,0,0,19,1,0,True
498,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\atn\SemanticContext.java,org.antlr.v4.runtime.atn.SemanticContext.AND,"SemanticContext evalPrecedence(Recognizer<?, ?>, RuleContext)","@Override
public SemanticContext evalPrecedence(Recognizer<?, ?> parser, RuleContext parserCallStack) {
    boolean differs = false;
    List<SemanticContext> operands = new ArrayList<SemanticContext>();
    for (SemanticContext context : opnds) {
        SemanticContext evaluated = context.evalPrecedence(parser, parserCallStack);
        differs |= (evaluated != context);
        if (evaluated == null) {
            // The AND context is false if any element is false
            return null;
        } else if (evaluated != Empty.Instance) {
            // Reduce the result by skipping true elements
            operands.add(evaluated);
        }
    }
    if (!differs) {
        return this;
    }
    if (operands.isEmpty()) {
        // all elements were true, so the AND context is true
        return Empty.Instance;
    }
    SemanticContext result = operands.get(0);
    for (int i = 1; i < operands.size(); i++) {
        result = SemanticContext.and(result, operands.get(i));
    }
    return result;
}", ,"// The AND context is false if any element is false
[[SEP]]// Reduce the result by skipping true elements
[[SEP]]// all elements were true, so the AND context is true
","// The AND context is false if any element is false[[SEP]]// Reduce the result by skipping true elements[[SEP]]// all elements were true, so the AND context is true",265,297,[0],0,"[0, 0, 0]",0,"[0, 0, 0]",0,0,0,0,"evalPrecedence(Recognizer<?, ?>, RuleContext)",org.antlr.v4.runtime.atn.SemanticContext$AND,"evalPrecedence/2[org.antlr.v4.runtime.Recognizer<?,?>,org.antlr.v4.runtime.RuleContext]",False,266,5,2,0,2,7,6,25,4,5,2,6,0,0,2,3,0,1,0,2,7,0,2,0,0,0,16,1,0,False
499,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\atn\SemanticContext.java,org.antlr.v4.runtime.atn.SemanticContext.OR,"boolean eval(Recognizer<?, ?>, RuleContext)","/**
 * {@inheritDoc}
 *
 * <p>
 * The evaluation of predicates by this context is short-circuiting, but
 * unordered.</p>
 */
@Override
public boolean eval(Recognizer<?, ?> parser, RuleContext parserCallStack) {
    for (SemanticContext opnd : opnds) {
        if (opnd.eval(parser, parserCallStack))
            return true;
    }
    return false;
}","/**
 * {@inheritDoc}
 *
 * <p>
 * The evaluation of predicates by this context is short-circuiting, but
 * unordered.</p>
 */
", ,"/** * {@inheritDoc} * * <p> * The evaluation of predicates by this context is short-circuiting, but * unordered.</p> */",354,360,[0],0,[0],0,[0],0,0,0,0,"eval(Recognizer<?, ?>, RuleContext)",org.antlr.v4.runtime.atn.SemanticContext$OR,"eval/2[org.antlr.v4.runtime.Recognizer<?,?>,org.antlr.v4.runtime.RuleContext]",False,355,3,1,0,1,3,1,6,2,0,2,1,0,0,1,0,0,0,0,0,0,0,2,0,0,0,19,1,0,True
500,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\atn\SemanticContext.java,org.antlr.v4.runtime.atn.SemanticContext.OR,"SemanticContext evalPrecedence(Recognizer<?, ?>, RuleContext)","@Override
public SemanticContext evalPrecedence(Recognizer<?, ?> parser, RuleContext parserCallStack) {
    boolean differs = false;
    List<SemanticContext> operands = new ArrayList<SemanticContext>();
    for (SemanticContext context : opnds) {
        SemanticContext evaluated = context.evalPrecedence(parser, parserCallStack);
        differs |= (evaluated != context);
        if (evaluated == Empty.Instance) {
            // The OR context is true if any element is true
            return Empty.Instance;
        } else if (evaluated != null) {
            // Reduce the result by skipping false elements
            operands.add(evaluated);
        }
    }
    if (!differs) {
        return this;
    }
    if (operands.isEmpty()) {
        // all elements were false, so the OR context is false
        return null;
    }
    SemanticContext result = operands.get(0);
    for (int i = 1; i < operands.size(); i++) {
        result = SemanticContext.or(result, operands.get(i));
    }
    return result;
}", ,"// The OR context is true if any element is true
[[SEP]]// Reduce the result by skipping false elements
[[SEP]]// all elements were false, so the OR context is false
","// The OR context is true if any element is true[[SEP]]// Reduce the result by skipping false elements[[SEP]]// all elements were false, so the OR context is false",362,394,[0],0,"[0, 0, 0]",0,"[0, 0, 0]",0,0,0,0,"evalPrecedence(Recognizer<?, ?>, RuleContext)",org.antlr.v4.runtime.atn.SemanticContext$OR,"evalPrecedence/2[org.antlr.v4.runtime.Recognizer<?,?>,org.antlr.v4.runtime.RuleContext]",False,363,5,2,0,2,7,6,25,4,5,2,6,0,0,2,3,0,1,0,2,7,0,2,0,0,0,16,1,0,False
501,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\atn\SingletonPredictionContext.java,org.antlr.v4.runtime.atn.SingletonPredictionContext,"SingletonPredictionContext create(PredictionContext, int)","public static SingletonPredictionContext create(PredictionContext parent, int returnState) {
    if (returnState == EMPTY_RETURN_STATE && parent == null) {
        // someone can pass in the bits of an array ctx that mean $
        return EmptyPredictionContext.Instance;
    }
    return new SingletonPredictionContext(parent, returnState);
}", ,"// someone can pass in the bits of an array ctx that mean $
",// someone can pass in the bits of an array ctx that mean $,20,26,[0],0,[0],0,[0],0,0,0,0,"create(PredictionContext, int)",org.antlr.v4.runtime.atn.SingletonPredictionContext,"create/2[org.antlr.v4.runtime.atn.PredictionContext,int]",False,20,3,8,7,1,3,0,6,2,0,2,0,0,0,0,2,0,0,0,0,0,0,1,0,0,0,19,9,0,False
502,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\atn\SingletonPredictionContext.java,org.antlr.v4.runtime.atn.SingletonPredictionContext,boolean equals(Object),"@Override
public boolean equals(Object o) {
    if (this == o) {
        return true;
    } else if (!(o instanceof SingletonPredictionContext)) {
        return false;
    }
    if (this.hashCode() != o.hashCode()) {
        // can't be same if hash is different
        return false;
    }
    SingletonPredictionContext s = (SingletonPredictionContext) o;
    return returnState == s.returnState && (parent != null && parent.equals(s.parent));
}", ,"// can't be same if hash is different
",// can't be same if hash is different,45,61,[0],0,[0],0,[0],0,0,0,0,equals(Object),org.antlr.v4.runtime.atn.SingletonPredictionContext,equals/1[java.lang.Object],False,46,2,2,0,2,6,3,13,4,1,1,3,0,0,0,4,0,2,0,0,1,0,1,0,0,0,13,1,0,False
503,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\atn\Transition.java,org.antlr.v4.runtime.atn.Transition,boolean isEpsilon(),"/**
 * Determines if the transition is an ""epsilon"" transition.
 *
 * <p>The default implementation returns {@code false}.</p>
 *
 * @return {@code true} if traversing this transition in the ATN does not
 * consume an input symbol; otherwise, {@code false} if traversing this
 * transition consumes (matches) an input symbol.
 */
public boolean isEpsilon() {
    return false;
}","/**
 * Determines if the transition is an ""epsilon"" transition.
 *
 * <p>The default implementation returns {@code false}.</p>
 *
 * @return {@code true} if traversing this transition in the ATN does not
 * consume an input symbol; otherwise, {@code false} if traversing this
 * transition consumes (matches) an input symbol.
 */
", ,"/** * Determines if the transition is an ""epsilon"" transition. * * <p>The default implementation returns {@code false}.</p> * * @return {@code true} if traversing this transition in the ATN does not * consume an input symbol; otherwise, {@code false} if traversing this * transition consumes (matches) an input symbol. */",95,97,[0],0,[0],0,[0],0,0,0,0,isEpsilon(),org.antlr.v4.runtime.atn.Transition,isEpsilon/0,False,95,0,5,5,0,1,0,3,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,24,1,0,True
504,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\dfa\DFA.java,org.antlr.v4.runtime.dfa.DFA,boolean isPrecedenceDfa(),"/**
 * Gets whether this DFA is a precedence DFA. Precedence DFAs use a special
 * start state {@link #s0} which is not stored in {@link #states}. The
 * {@link DFAState#edges} array for this start state contains outgoing edges
 * supplying individual start states corresponding to specific precedence
 * values.
 *
 * @return {@code true} if this is a precedence DFA; otherwise,
 * {@code false}.
 * @see Parser#getPrecedence()
 */
public final boolean isPrecedenceDfa() {
    return precedenceDfa;
}","/**
 * Gets whether this DFA is a precedence DFA. Precedence DFAs use a special
 * start state {@link #s0} which is not stored in {@link #states}. The
 * {@link DFAState#edges} array for this start state contains outgoing edges
 * supplying individual start states corresponding to specific precedence
 * values.
 *
 * @return {@code true} if this is a precedence DFA; otherwise,
 * {@code false}.
 * @see Parser#getPrecedence()
 */
", ,"/** * Gets whether this DFA is a precedence DFA. Precedence DFAs use a special * start state {@link #s0} which is not stored in {@link #states}. The * {@link DFAState#edges} array for this start state contains outgoing edges * supplying individual start states corresponding to specific precedence * values. * * @return {@code true} if this is a precedence DFA; otherwise, * {@code false}. * @see Parser#getPrecedence() */",79,81,[0],0,[0],0,[0],0,0,0,0,isPrecedenceDfa(),org.antlr.v4.runtime.dfa.DFA,isPrecedenceDfa/0,False,79,0,5,5,0,1,0,3,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,31,17,0,True
505,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\dfa\DFA.java,org.antlr.v4.runtime.dfa.DFA,DFAState getPrecedenceStartState(int),"/**
 * Get the start state for a specific precedence value.
 *
 * @param precedence The current precedence.
 * @return The start state corresponding to the specified precedence, or
 * {@code null} if no start state exists for the specified precedence.
 *
 * @throws IllegalStateException if this is not a precedence DFA.
 * @see #isPrecedenceDfa()
 */
@SuppressWarnings(""null"")
public final DFAState getPrecedenceStartState(int precedence) {
    if (!isPrecedenceDfa()) {
        throw new IllegalStateException(""Only precedence DFAs may contain a precedence start state."");
    }
    // s0.edges is never null for a precedence DFA
    if (precedence < 0 || precedence >= s0.edges.length) {
        return null;
    }
    return s0.edges[precedence];
}","/**
 * Get the start state for a specific precedence value.
 *
 * @param precedence The current precedence.
 * @return The start state corresponding to the specified precedence, or
 * {@code null} if no start state exists for the specified precedence.
 *
 * @throws IllegalStateException if this is not a precedence DFA.
 * @see #isPrecedenceDfa()
 */
","// s0.edges is never null for a precedence DFA
","/** * Get the start state for a specific precedence value. * * @param precedence The current precedence. * @return The start state corresponding to the specified precedence, or * {@code null} if no start state exists for the specified precedence. * * @throws IllegalStateException if this is not a precedence DFA. * @see #isPrecedenceDfa() */[[SEP]]// s0.edges is never null for a precedence DFA",93,105,[0],0,[0],0,"[0, 0]",0,0,0,0,getPrecedenceStartState(int),org.antlr.v4.runtime.dfa.DFA,getPrecedenceStartState/1[int],False,94,2,2,1,1,4,1,9,2,0,1,1,1,1,0,0,0,0,2,1,0,0,1,0,0,0,31,17,0,True
506,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\dfa\DFA.java,org.antlr.v4.runtime.dfa.DFA,"void setPrecedenceStartState(int, DFAState)","/**
 * Set the start state for a specific precedence value.
 *
 * @param precedence The current precedence.
 * @param startState The start state corresponding to the specified
 * precedence.
 *
 * @throws IllegalStateException if this is not a precedence DFA.
 * @see #isPrecedenceDfa()
 */
@SuppressWarnings({ ""SynchronizeOnNonFinalField"", ""null"" })
public final void setPrecedenceStartState(int precedence, DFAState startState) {
    if (!isPrecedenceDfa()) {
        throw new IllegalStateException(""Only precedence DFAs may contain a precedence start state."");
    }
    if (precedence < 0) {
        return;
    }
    // synchronization on s0 here is ok. when the DFA is turned into a
    // precedence DFA, s0 will be initialized once and not updated again
    synchronized (s0) {
        // s0.edges is never null for a precedence DFA
        if (precedence >= s0.edges.length) {
            s0.edges = Arrays.copyOf(s0.edges, precedence + 1);
        }
        s0.edges[precedence] = startState;
    }
}","/**
 * Set the start state for a specific precedence value.
 *
 * @param precedence The current precedence.
 * @param startState The start state corresponding to the specified
 * precedence.
 *
 * @throws IllegalStateException if this is not a precedence DFA.
 * @see #isPrecedenceDfa()
 */
","// synchronization on s0 here is ok. when the DFA is turned into a
[[SEP]]// precedence DFA, s0 will be initialized once and not updated again
[[SEP]]// s0.edges is never null for a precedence DFA
","/** * Set the start state for a specific precedence value. * * @param precedence The current precedence. * @param startState The start state corresponding to the specified * precedence. * * @throws IllegalStateException if this is not a precedence DFA. * @see #isPrecedenceDfa() */[[SEP]]// synchronization on s0 here is ok. when the DFA is turned into a// precedence DFA, s0 will be initialized once and not updated again[[SEP]]// s0.edges is never null for a precedence DFA",117,137,[0],0,"[0, 0, 0]",0,"[0, 0, 0]",0,0,0,0,"setPrecedenceStartState(int, DFAState)",org.antlr.v4.runtime.dfa.DFA,"setPrecedenceStartState/2[int,org.antlr.v4.runtime.dfa.DFAState]",False,118,2,2,1,1,4,2,14,1,0,2,2,1,1,0,0,0,0,3,2,2,1,2,0,0,0,26,17,0,True
507,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\dfa\DFA.java,org.antlr.v4.runtime.dfa.DFA,void setPrecedenceDfa(boolean),"/**
 * Sets whether this is a precedence DFA.
 *
 * @param precedenceDfa {@code true} if this is a precedence DFA; otherwise,
 * {@code false}
 *
 * @throws UnsupportedOperationException if {@code precedenceDfa} does not
 * match the value of {@link #isPrecedenceDfa} for the current DFA.
 *
 * @deprecated This method no longer performs any action.
 */
@Deprecated
public final void setPrecedenceDfa(boolean precedenceDfa) {
    if (precedenceDfa != isPrecedenceDfa()) {
        throw new UnsupportedOperationException(""The precedenceDfa field cannot change after a DFA is constructed."");
    }
}","/**
 * Sets whether this is a precedence DFA.
 *
 * @param precedenceDfa {@code true} if this is a precedence DFA; otherwise,
 * {@code false}
 *
 * @throws UnsupportedOperationException if {@code precedenceDfa} does not
 * match the value of {@link #isPrecedenceDfa} for the current DFA.
 *
 * @deprecated This method no longer performs any action.
 */
", ,"/** * Sets whether this is a precedence DFA. * * @param precedenceDfa {@code true} if this is a precedence DFA; otherwise, * {@code false} * * @throws UnsupportedOperationException if {@code precedenceDfa} does not * match the value of {@link #isPrecedenceDfa} for the current DFA. * * @deprecated This method no longer performs any action. */",150,155,[1],1,[0],0,[1],1,0,0,0,setPrecedenceDfa(boolean),org.antlr.v4.runtime.dfa.DFA,setPrecedenceDfa/1[boolean],False,151,1,1,0,1,2,1,5,0,0,1,1,1,1,0,1,0,0,1,0,0,0,1,0,0,0,32,17,0,True
508,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\dfa\DFA.java,org.antlr.v4.runtime.dfa.DFA,String toString(String[]),"/**
 * @deprecated Use {@link #toString(Vocabulary)} instead.
 */
@Deprecated
public String toString(String[] tokenNames) {
    if (s0 == null)
        return """";
    DFASerializer serializer = new DFASerializer(this, tokenNames);
    return serializer.toString();
}","/**
 * @deprecated Use {@link #toString(Vocabulary)} instead.
 */
", ,/** * @deprecated Use {@link #toString(Vocabulary)} instead. */,179,184,[1],1,[0],0,[1],1,0,0,0,toString(String[]),org.antlr.v4.runtime.dfa.DFA,toString/1[java.lang.String[]],False,180,1,2,0,2,2,1,5,2,1,1,1,0,0,0,1,0,0,1,0,1,0,1,0,0,0,13,1,0,True
509,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\dfa\DFASerializer.java,org.antlr.v4.runtime.dfa.DFASerializer,String toString(),"@Override
public String toString() {
    if (dfa.s0 == null)
        return null;
    StringBuilder buf = new StringBuilder();
    List<DFAState> states = dfa.getStates();
    for (DFAState s : states) {
        int n = 0;
        if (s.edges != null)
            n = s.edges.length;
        for (int i = 0; i < n; i++) {
            DFAState t = s.edges[i];
            if (t != null && t.stateNumber != Integer.MAX_VALUE) {
                buf.append(getStateString(s));
                String label = getEdgeLabel(i);
                buf.append(""-"").append(label).append(""->"").append(getStateString(t)).append('\n');
            }
        }
    }
    String output = buf.toString();
    if (output.length() == 0)
        return null;
    // return Utils.sortLinesInString(output);
    return output;
}", ,"// return Utils.sortLinesInString(output);
",// return Utils.sortLinesInString(output);,35,57,[0],0,[0],0,[0],0,0,0,0,toString(),org.antlr.v4.runtime.dfa.DFASerializer,toString/0,False,36,3,6,3,3,8,7,20,3,7,0,7,2,1,2,5,0,0,2,3,8,0,3,0,0,0,19,1,0,False
510,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\dfa\DFAState.java,org.antlr.v4.runtime.dfa.DFAState,Set<Integer> getAltSet(),"/**
 * Get the set of all alts mentioned by all ATN configurations in this
 *  DFA state.
 */
public Set<Integer> getAltSet() {
    Set<Integer> alts = new HashSet<Integer>();
    if (configs != null) {
        for (ATNConfig c : configs) {
            alts.add(c.alt);
        }
    }
    if (alts.isEmpty())
        return null;
    return alts;
}","/**
 * Get the set of all alts mentioned by all ATN configurations in this
 *  DFA state.
 */
", ,/** * Get the set of all alts mentioned by all ATN configurations in this *  DFA state. */,115,124,[0],0,[0],0,[0],0,0,0,0,getAltSet(),org.antlr.v4.runtime.dfa.DFAState,getAltSet/0,False,115,0,0,0,0,4,2,10,2,1,0,2,0,0,1,1,0,0,0,0,1,0,2,0,0,0,22,1,0,True
511,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\dfa\DFAState.java,org.antlr.v4.runtime.dfa.DFAState,boolean equals(Object),"/**
 * Two {@link DFAState} instances are equal if their ATN configuration sets
 * are the same. This method is used to see if a state already exists.
 *
 * <p>Because the number of alternatives and number of ATN configurations are
 * finite, there is a finite number of DFA states that can be processed.
 * This is necessary to show that the algorithm terminates.</p>
 *
 * <p>Cannot test the DFA state numbers here because in
 * {@link ParserATNSimulator#addDFAState} we need to know if any other state
 * exists that has this exact set of ATN configurations. The
 * {@link #stateNumber} is irrelevant.</p>
 */
@Override
public boolean equals(Object o) {
    // compare set of ATN configurations in this set with other
    if (this == o)
        return true;
    if (!(o instanceof DFAState)) {
        return false;
    }
    DFAState other = (DFAState) o;
    // TODO (sam): what to do when configs==null?
    boolean sameSet = this.configs.equals(other.configs);
    // System.out.println(""DFAState.equals: ""+configs+(sameSet?""=="":""!="")+other.configs);
    return sameSet;
}","/**
 * Two {@link DFAState} instances are equal if their ATN configuration sets
 * are the same. This method is used to see if a state already exists.
 *
 * <p>Because the number of alternatives and number of ATN configurations are
 * finite, there is a finite number of DFA states that can be processed.
 * This is necessary to show that the algorithm terminates.</p>
 *
 * <p>Cannot test the DFA state numbers here because in
 * {@link ParserATNSimulator#addDFAState} we need to know if any other state
 * exists that has this exact set of ATN configurations. The
 * {@link #stateNumber} is irrelevant.</p>
 */
","// compare set of ATN configurations in this set with other
[[SEP]]// TODO (sam): what to do when configs==null?
[[SEP]]// System.out.println(""DFAState.equals: ""+configs+(sameSet?""=="":""!="")+other.configs);
","/** * Two {@link DFAState} instances are equal if their ATN configuration sets * are the same. This method is used to see if a state already exists. * * <p>Because the number of alternatives and number of ATN configurations are * finite, there is a finite number of DFA states that can be processed. * This is necessary to show that the algorithm terminates.</p> * * <p>Cannot test the DFA state numbers here because in * {@link ParserATNSimulator#addDFAState} we need to know if any other state * exists that has this exact set of ATN configurations. The * {@link #stateNumber} is irrelevant.</p> */[[SEP]]// compare set of ATN configurations in this set with other[[SEP]]// TODO (sam): what to do when configs==null?[[SEP]]// System.out.println(""DFAState.equals: ""+configs+(sameSet?""=="":""!="")+other.configs);",147,161,[0],0,"[0, 1, 0]",1,"[0, 0, 1, 0]",1,1,1,1,equals(Object),org.antlr.v4.runtime.dfa.DFAState,equals/1[java.lang.Object],False,148,2,1,0,1,3,1,9,3,2,1,1,0,0,0,1,0,1,0,0,2,0,1,0,0,0,62,1,0,True
512,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\misc\Array2DHashSet.java,org.antlr.v4.runtime.misc.Array2DHashSet,T getOrAdd(T),"/**
 * Add {@code o} to set if not there; return existing value if already
 * there. This method performs the same operation as {@link #add} aside from
 * the return value.
 */
public final T getOrAdd(T o) {
    if (n > threshold)
        expand();
    return getOrAddImpl(o);
}","/**
 * Add {@code o} to set if not there; return existing value if already
 * there. This method performs the same operation as {@link #add} aside from
 * the return value.
 */
", ,/** * Add {@code o} to set if not there; return existing value if already * there. This method performs the same operation as {@link #add} aside from * the return value. */,61,64,[0],0,[0],0,[0],0,0,0,0,getOrAdd(T),org.antlr.v4.runtime.misc.Array2DHashSet,getOrAdd/1[T],False,61,2,2,0,2,2,2,4,1,0,1,2,0,0,0,0,0,0,0,0,0,0,1,0,0,0,24,17,0,True
513,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\misc\Array2DHashSet.java,org.antlr.v4.runtime.misc.Array2DHashSet,T getOrAddImpl(T),"protected T getOrAddImpl(T o) {
    int b = getBucket(o);
    T[] bucket = buckets[b];
    // NEW BUCKET
    if (bucket == null) {
        bucket = createBucket(initialBucketCapacity);
        bucket[0] = o;
        buckets[b] = bucket;
        n++;
        return o;
    }
    // LOOK FOR IT IN BUCKET
    for (int i = 0; i < bucket.length; i++) {
        T existing = bucket[i];
        if (existing == null) {
            // empty slot; not there, add.
            bucket[i] = o;
            n++;
            return o;
        }
        // found existing, quit
        if (comparator.equals(existing, o))
            return existing;
    }
    // FULL BUCKET, expand and add to end
    int oldLength = bucket.length;
    bucket = Arrays.copyOf(bucket, bucket.length * 2);
    buckets[b] = bucket;
    // add to end
    bucket[oldLength] = o;
    n++;
    return o;
}", ,"// NEW BUCKET
[[SEP]]// LOOK FOR IT IN BUCKET
[[SEP]]// empty slot; not there, add.
[[SEP]]// found existing, quit
[[SEP]]// FULL BUCKET, expand and add to end
[[SEP]]// add to end
","// NEW BUCKET[[SEP]]// LOOK FOR IT IN BUCKET[[SEP]]// empty slot; not there, add.[[SEP]]// found existing, quit[[SEP]]// FULL BUCKET, expand and add to end[[SEP]]// add to end",66,97,[0],0,"[0, 0, 0, 0, 0, 0]",0,"[0, 0, 0, 0, 0, 0]",0,0,0,0,getOrAddImpl(T),org.antlr.v4.runtime.misc.Array2DHashSet,getOrAddImpl/1[T],False,66,3,3,0,3,5,4,26,4,5,1,4,0,0,1,2,0,0,0,3,12,1,2,0,0,0,18,4,0,False
514,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\misc\Array2DHashSet.java,org.antlr.v4.runtime.misc.Array2DHashSet,T get(T),"public T get(T o) {
    if (o == null)
        return o;
    int b = getBucket(o);
    T[] bucket = buckets[b];
    // no bucket
    if (bucket == null)
        return null;
    for (T e : bucket) {
        // empty slot; not there
        if (e == null)
            return null;
        if (comparator.equals(e, o))
            return e;
    }
    return null;
}", ,"// no bucket
[[SEP]]// empty slot; not there
",// no bucket[[SEP]]// empty slot; not there,99,109,[0],0,"[0, 0]",0,"[0, 0]",0,0,0,0,get(T),org.antlr.v4.runtime.misc.Array2DHashSet,get/1[T],False,99,3,2,0,2,6,2,11,5,2,1,2,0,0,1,3,0,0,0,0,2,0,2,0,0,0,8,1,0,False
515,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\misc\Array2DHashSet.java,org.antlr.v4.runtime.misc.Array2DHashSet,int getBucket(T),"protected final int getBucket(T o) {
    int hash = comparator.hashCode(o);
    // assumes len is power of 2
    int b = hash & (buckets.length - 1);
    return b;
}", ,"// assumes len is power of 2
",// assumes len is power of 2,111,115,[0],0,[0],0,[0],0,0,0,0,getBucket(T),org.antlr.v4.runtime.misc.Array2DHashSet,getBucket/1[T],False,111,2,1,0,1,1,1,5,1,2,1,1,0,0,0,0,0,1,0,1,2,1,0,0,0,0,6,20,0,False
516,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\misc\Array2DHashSet.java,org.antlr.v4.runtime.misc.Array2DHashSet,void expand(),"protected void expand() {
    T[][] old = buckets;
    currentPrime += 4;
    int newCapacity = buckets.length * 2;
    T[][] newTable = createBuckets(newCapacity);
    int[] newBucketLengths = new int[newTable.length];
    buckets = newTable;
    threshold = (int) (newCapacity * LOAD_FACTOR);
    // System.out.println(""new size=""+newCapacity+"", thres=""+threshold);
    // rehash all existing entries
    int oldSize = size();
    for (T[] bucket : old) {
        if (bucket == null) {
            continue;
        }
        for (T o : bucket) {
            if (o == null) {
                break;
            }
            int b = getBucket(o);
            int bucketLength = newBucketLengths[b];
            T[] newBucket;
            if (bucketLength == 0) {
                // new bucket
                newBucket = createBucket(initialBucketCapacity);
                newTable[b] = newBucket;
            } else {
                newBucket = newTable[b];
                if (bucketLength == newBucket.length) {
                    // expand
                    newBucket = Arrays.copyOf(newBucket, newBucket.length * 2);
                    newTable[b] = newBucket;
                }
            }
            newBucket[bucketLength] = o;
            newBucketLengths[b]++;
        }
    }
    assert n == oldSize;
}", ,"// System.out.println(""new size=""+newCapacity+"", thres=""+threshold);
[[SEP]]// rehash all existing entries
[[SEP]]// new bucket
[[SEP]]// expand
","// System.out.println(""new size=""+newCapacity+"", thres=""+threshold);// rehash all existing entries[[SEP]]// new bucket[[SEP]]// expand",142,186,[0],0,"[0, 0, 0, 0]",0,"[0, 0, 0]",0,0,0,0,expand(),org.antlr.v4.runtime.misc.Array2DHashSet,expand/0,False,142,3,4,0,4,8,5,37,0,8,0,5,0,0,2,5,0,1,0,4,16,3,4,0,0,0,33,4,0,False
517,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\misc\Array2DHashSet.java,org.antlr.v4.runtime.misc.Array2DHashSet,U[] toArray(U[]),"@Override
public <U> U[] toArray(U[] a) {
    if (a.length < size()) {
        a = Arrays.copyOf(a, size());
    }
    int i = 0;
    for (T[] bucket : buckets) {
        if (bucket == null) {
            continue;
        }
        for (T o : bucket) {
            if (o == null) {
                break;
            }
            // array store will check this
            @SuppressWarnings(""unchecked"")
            U targetElement = (U) o;
            a[i++] = targetElement;
        }
    }
    return a;
}", ,"// array store will check this
",// array store will check this,243,266,[0],0,[0],0,[0],0,0,0,0,toArray(U[]),org.antlr.v4.runtime.misc.Array2DHashSet,toArray/1[U[]],False,244,2,1,0,1,6,2,19,1,2,1,2,0,0,2,2,0,0,1,1,4,0,3,0,0,0,13,1,0,False
518,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\misc\Array2DHashSet.java,org.antlr.v4.runtime.misc.Array2DHashSet,boolean removeFast(T),"public boolean removeFast(T obj) {
    if (obj == null) {
        return false;
    }
    int b = getBucket(obj);
    T[] bucket = buckets[b];
    if (bucket == null) {
        // no bucket
        return false;
    }
    for (int i = 0; i < bucket.length; i++) {
        T e = bucket[i];
        if (e == null) {
            // empty slot; not there
            return false;
        }
        if (comparator.equals(e, obj)) {
            // found it
            // shift all elements to the right down one
            System.arraycopy(bucket, i + 1, bucket, i, bucket.length - i - 1);
            bucket[bucket.length - 1] = null;
            n--;
            return true;
        }
    }
    return false;
}", ,"// no bucket
[[SEP]]// empty slot; not there
[[SEP]]// found it
[[SEP]]// shift all elements to the right down one
",// no bucket[[SEP]]// empty slot; not there[[SEP]]// found it// shift all elements to the right down one,273,302,[0],0,"[0, 0, 0, 0]",0,"[0, 0, 0]",0,0,0,0,removeFast(T),org.antlr.v4.runtime.misc.Array2DHashSet,removeFast/1[T],False,273,3,2,0,2,6,3,23,5,4,1,3,0,0,1,3,0,0,0,4,5,3,2,0,0,0,14,1,0,False
519,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\misc\Array2DHashSet.java,org.antlr.v4.runtime.misc.Array2DHashSet,boolean retainAll(Collection<?>),"@Override
public boolean retainAll(Collection<?> c) {
    int newsize = 0;
    for (T[] bucket : buckets) {
        if (bucket == null) {
            continue;
        }
        int i;
        int j;
        for (i = 0, j = 0; i < bucket.length; i++) {
            if (bucket[i] == null) {
                break;
            }
            if (!c.contains(bucket[i])) {
                // removed
                continue;
            }
            // keep
            if (i != j) {
                bucket[j] = bucket[i];
            }
            j++;
            newsize++;
        }
        newsize += j;
        while (j < i) {
            bucket[j] = null;
            j++;
        }
    }
    boolean changed = newsize != n;
    n = newsize;
    return changed;
}", ,"// removed
[[SEP]]// keep
",// removed[[SEP]]// keep,334,374,[0],0,"[0, 0]",0,"[0, 0]",0,0,0,0,retainAll(Collection<?>),org.antlr.v4.runtime.misc.Array2DHashSet,retainAll/1[java.util.Collection<?>],False,335,0,0,0,0,9,1,31,1,4,1,1,0,0,3,4,0,0,0,3,8,0,3,0,0,0,11,1,0,False
520,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\misc\Array2DHashSet.java,org.antlr.v4.runtime.misc.Array2DHashSet,T asElementType(Object),"/**
 * Return {@code o} as an instance of the element type {@code T}. If
 * {@code o} is non-null but known to not be an instance of {@code T}, this
 * method returns {@code null}. The base implementation does not perform any
 * type checks; override this method to provide strong type checks for the
 * {@link #contains} and {@link #remove} methods to ensure the arguments to
 * the {@link EqualityComparator} for the set always have the expected
 * types.
 *
 * @param o the object to try and cast to the element type of the set
 * @return {@code o} if it could be an instance of {@code T}, otherwise
 * {@code null}.
 */
@SuppressWarnings(""unchecked"")
protected T asElementType(Object o) {
    return (T) o;
}","/**
 * Return {@code o} as an instance of the element type {@code T}. If
 * {@code o} is non-null but known to not be an instance of {@code T}, this
 * method returns {@code null}. The base implementation does not perform any
 * type checks; override this method to provide strong type checks for the
 * {@link #contains} and {@link #remove} methods to ensure the arguments to
 * the {@link EqualityComparator} for the set always have the expected
 * types.
 *
 * @param o the object to try and cast to the element type of the set
 * @return {@code o} if it could be an instance of {@code T}, otherwise
 * {@code null}.
 */
", ,"/** * Return {@code o} as an instance of the element type {@code T}. If * {@code o} is non-null but known to not be an instance of {@code T}, this * method returns {@code null}. The base implementation does not perform any * type checks; override this method to provide strong type checks for the * {@link #contains} and {@link #remove} methods to ensure the arguments to * the {@link EqualityComparator} for the set always have the expected * types. * * @param o the object to try and cast to the element type of the set * @return {@code o} if it could be an instance of {@code T}, otherwise * {@code null}. */",446,449,[0],0,[0],0,[0],0,0,0,0,asElementType(Object),org.antlr.v4.runtime.misc.Array2DHashSet,asElementType/1[java.lang.Object],False,447,1,0,0,0,1,0,3,1,0,1,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,49,4,0,True
521,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\misc\Array2DHashSet.java,org.antlr.v4.runtime.misc.Array2DHashSet,T[][] createBuckets(int),"/**
 * Return an array of {@code T[]} with length {@code capacity}.
 *
 * @param capacity the length of the array to return
 * @return the newly constructed array
 */
@SuppressWarnings(""unchecked"")
protected T[][] createBuckets(int capacity) {
    return (T[][]) new Object[capacity][];
}","/**
 * Return an array of {@code T[]} with length {@code capacity}.
 *
 * @param capacity the length of the array to return
 * @return the newly constructed array
 */
", ,/** * Return an array of {@code T[]} with length {@code capacity}. * * @param capacity the length of the array to return * @return the newly constructed array */,457,460,[0],0,[0],0,[0],0,0,0,0,createBuckets(int),org.antlr.v4.runtime.misc.Array2DHashSet,createBuckets/1[int],False,458,1,0,0,0,1,0,3,1,0,1,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,13,4,0,True
522,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\misc\Array2DHashSet.java,org.antlr.v4.runtime.misc.Array2DHashSet,T[] createBucket(int),"/**
 * Return an array of {@code T} with length {@code capacity}.
 *
 * @param capacity the length of the array to return
 * @return the newly constructed array
 */
@SuppressWarnings(""unchecked"")
protected T[] createBucket(int capacity) {
    return (T[]) new Object[capacity];
}","/**
 * Return an array of {@code T} with length {@code capacity}.
 *
 * @param capacity the length of the array to return
 * @return the newly constructed array
 */
", ,/** * Return an array of {@code T} with length {@code capacity}. * * @param capacity the length of the array to return * @return the newly constructed array */,468,471,[0],0,[0],0,[0],0,0,0,0,createBucket(int),org.antlr.v4.runtime.misc.Array2DHashSet,createBucket/1[int],False,469,1,0,0,0,1,0,3,1,0,1,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,14,4,0,True
523,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\misc\DoubleKeyMap.java,org.antlr.v4.runtime.misc.DoubleKeyMap,Collection<Value> values(Key1),"/**
 * Get all values associated with primary key
 */
public Collection<Value> values(Key1 k1) {
    Map<Key2, Value> data2 = data.get(k1);
    if (data2 == null)
        return null;
    return data2.values();
}","/**
 * Get all values associated with primary key
 */
", ,/** * Get all values associated with primary key */,44,48,[0],0,[0],0,[0],0,0,0,0,values(Key1),org.antlr.v4.runtime.misc.DoubleKeyMap,values/1[Key1],False,44,3,0,0,0,2,2,5,2,1,1,2,0,0,0,1,0,0,0,0,1,0,1,0,0,0,11,1,0,True
524,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\misc\DoubleKeyMap.java,org.antlr.v4.runtime.misc.DoubleKeyMap,Set<Key1> keySet(),"/**
 * get all primary keys
 */
public Set<Key1> keySet() {
    return data.keySet();
}","/**
 * get all primary keys
 */
", ,/** * get all primary keys */,51,53,[0],0,[0],0,[0],0,0,0,0,keySet(),org.antlr.v4.runtime.misc.DoubleKeyMap,keySet/0,False,51,1,0,0,0,1,1,3,1,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,6,1,0,True
525,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\misc\DoubleKeyMap.java,org.antlr.v4.runtime.misc.DoubleKeyMap,Set<Key2> keySet(Key1),"/**
 * get all secondary keys associated with a primary key
 */
public Set<Key2> keySet(Key1 k1) {
    Map<Key2, Value> data2 = data.get(k1);
    if (data2 == null)
        return null;
    return data2.keySet();
}","/**
 * get all secondary keys associated with a primary key
 */
", ,/** * get all secondary keys associated with a primary key */,56,60,[0],0,[0],0,[0],0,0,0,0,keySet(Key1),org.antlr.v4.runtime.misc.DoubleKeyMap,keySet/1[Key1],False,56,3,0,0,0,2,2,5,2,1,1,2,0,0,0,1,0,0,0,0,1,0,1,0,0,0,14,1,0,True
526,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\misc\EqualityComparator.java,org.antlr.v4.runtime.misc.EqualityComparator,int hashCode(T),"/**
 * This method returns a hash code for the specified object.
 *
 * @param obj The object.
 * @return The hash code for {@code obj}.
 */
int hashCode(T obj);","/**
 * This method returns a hash code for the specified object.
 *
 * @param obj The object.
 * @return The hash code for {@code obj}.
 */
", ,/** * This method returns a hash code for the specified object. * * @param obj The object. * @return The hash code for {@code obj}. */,24,24,[0],0,[0],0,[0],0,0,0,0,hashCode(T),org.antlr.v4.runtime.misc.EqualityComparator,hashCode/1[T],False,18,1,0,0,0,1,0,1,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,12,0,0,True
527,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\misc\EqualityComparator.java,org.antlr.v4.runtime.misc.EqualityComparator,"boolean equals(T, T)","/**
 * This method tests if two objects are equal.
 *
 * @param a The first object to compare.
 * @param b The second object to compare.
 * @return {@code true} if {@code a} equals {@code b}, otherwise {@code false}.
 */
boolean equals(T a, T b);","/**
 * This method tests if two objects are equal.
 *
 * @param a The first object to compare.
 * @param b The second object to compare.
 * @return {@code true} if {@code a} equals {@code b}, otherwise {@code false}.
 */
", ,"/** * This method tests if two objects are equal. * * @param a The first object to compare. * @param b The second object to compare. * @return {@code true} if {@code a} equals {@code b}, otherwise {@code false}. */",33,33,[0],0,[0],0,[0],0,0,0,0,"equals(T, T)",org.antlr.v4.runtime.misc.EqualityComparator,"equals/2[T,T]",False,26,1,0,0,0,1,0,1,0,0,2,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,18,0,0,True
528,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\misc\FlexibleHashMap.java,org.antlr.v4.runtime.misc.FlexibleHashMap,int getBucket(K),"protected int getBucket(K key) {
    int hash = comparator.hashCode(key);
    // assumes len is power of 2
    int b = hash & (buckets.length - 1);
    return b;
}", ,"// assumes len is power of 2
",// assumes len is power of 2,77,81,[0],0,[0],0,[0],0,0,0,0,getBucket(K),org.antlr.v4.runtime.misc.FlexibleHashMap,getBucket/1[K],False,77,2,1,0,1,1,1,5,1,2,1,1,0,0,0,0,0,1,0,1,2,1,0,0,0,0,6,4,0,False
529,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\misc\FlexibleHashMap.java,org.antlr.v4.runtime.misc.FlexibleHashMap,V get(Object),"@Override
public V get(Object key) {
    @SuppressWarnings(""unchecked"")
    K typedKey = (K) key;
    if (key == null)
        return null;
    int b = getBucket(typedKey);
    LinkedList<Entry<K, V>> bucket = buckets[b];
    // no bucket
    if (bucket == null)
        return null;
    for (Entry<K, V> e : bucket) {
        if (comparator.equals(e.key, typedKey)) {
            return e.value;
        }
    }
    return null;
}", ,"// no bucket
",// no bucket,83,97,[0],0,[0],0,[0],0,0,0,0,get(Object),org.antlr.v4.runtime.misc.FlexibleHashMap,get/1[java.lang.Object],False,84,5,2,0,2,5,2,13,4,3,1,2,0,0,1,2,0,0,1,0,3,0,2,0,0,0,12,1,0,False
530,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\misc\FlexibleHashMap.java,org.antlr.v4.runtime.misc.FlexibleHashMap,"V put(K, V)","@Override
public V put(K key, V value) {
    if (key == null)
        return null;
    if (n > threshold)
        expand();
    int b = getBucket(key);
    LinkedList<Entry<K, V>> bucket = buckets[b];
    if (bucket == null) {
        bucket = buckets[b] = new LinkedList<Entry<K, V>>();
    }
    for (Entry<K, V> e : bucket) {
        if (comparator.equals(e.key, key)) {
            V prev = e.value;
            e.value = value;
            n++;
            return prev;
        }
    }
    // not there
    bucket.add(new Entry<K, V>(key, value));
    n++;
    return null;
}", ,"// not there
",// not there,99,120,[0],0,[0],0,[0],0,0,0,0,"put(K, V)",org.antlr.v4.runtime.misc.FlexibleHashMap,"put/2[K,V]",False,100,5,4,0,4,6,4,20,3,3,2,4,0,0,1,2,0,0,0,0,6,0,2,0,0,0,15,1,0,False
531,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\misc\FlexibleHashMap.java,org.antlr.v4.runtime.misc.FlexibleHashMap,void expand(),"protected void expand() {
    LinkedList<Entry<K, V>>[] old = buckets;
    currentPrime += 4;
    int newCapacity = buckets.length * 2;
    LinkedList<Entry<K, V>>[] newTable = createEntryListArray(newCapacity);
    buckets = newTable;
    threshold = (int) (newCapacity * LOAD_FACTOR);
    // System.out.println(""new size=""+newCapacity+"", thres=""+threshold);
    // rehash all existing entries
    int oldSize = size();
    for (LinkedList<Entry<K, V>> bucket : old) {
        if (bucket == null)
            continue;
        for (Entry<K, V> e : bucket) {
            if (e == null)
                break;
            put(e.key, e.value);
        }
    }
    n = oldSize;
}", ,"// System.out.println(""new size=""+newCapacity+"", thres=""+threshold);
[[SEP]]// rehash all existing entries
","// System.out.println(""new size=""+newCapacity+"", thres=""+threshold);// rehash all existing entries",184,202,[0],0,"[0, 0]",0,[0],0,0,0,0,expand(),org.antlr.v4.runtime.misc.FlexibleHashMap,expand/0,False,184,4,3,0,3,5,3,17,0,4,0,3,0,0,2,2,0,1,0,2,8,2,3,0,0,0,29,4,0,False
532,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\misc\IntSet.java,org.antlr.v4.runtime.misc.IntSet,void add(int),"/**
 * Adds the specified value to the current set.
 *
 * @param el the value to add
 *
 * @exception IllegalStateException if the current set is read-only
 */
void add(int el);","/**
 * Adds the specified value to the current set.
 *
 * @param el the value to add
 *
 * @exception IllegalStateException if the current set is read-only
 */
", ,/** * Adds the specified value to the current set. * * @param el the value to add * * @exception IllegalStateException if the current set is read-only */,24,24,[0],0,[0],0,[0],0,0,0,0,add(int),org.antlr.v4.runtime.misc.IntSet,add/1[int],False,17,0,0,0,0,1,0,1,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,15,0,0,True
533,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\misc\IntSet.java,org.antlr.v4.runtime.misc.IntSet,int size(),"/**
 * Return the total number of elements represented by the current set.
 *
 * @return the total number of elements represented by the current set,
 * regardless of the manner in which the elements are stored.
 */
int size();","/**
 * Return the total number of elements represented by the current set.
 *
 * @return the total number of elements represented by the current set,
 * regardless of the manner in which the elements are stored.
 */
", ,"/** * Return the total number of elements represented by the current set. * * @return the total number of elements represented by the current set, * regardless of the manner in which the elements are stored. */",115,115,[0],0,[0],0,[0],0,0,0,0,size(),org.antlr.v4.runtime.misc.IntSet,size/0,False,109,0,0,0,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,14,0,0,True
534,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\misc\IntSet.java,org.antlr.v4.runtime.misc.IntSet,boolean isNil(),"/**
 * Returns {@code true} if this set contains no elements.
 *
 * @return {@code true} if the current set contains no elements; otherwise,
 * {@code false}.
 */
boolean isNil();","/**
 * Returns {@code true} if this set contains no elements.
 *
 * @return {@code true} if the current set contains no elements; otherwise,
 * {@code false}.
 */
", ,"/** * Returns {@code true} if this set contains no elements. * * @return {@code true} if the current set contains no elements; otherwise, * {@code false}. */",123,123,[0],0,[0],0,[0],0,0,0,0,isNil(),org.antlr.v4.runtime.misc.IntSet,isNil/0,False,117,0,2,2,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,11,0,0,True
535,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\misc\IntSet.java,org.antlr.v4.runtime.misc.IntSet,boolean equals(Object),"/**
 * {@inheritDoc}
 */
@Override
boolean equals(Object obj);","/**
 * {@inheritDoc}
 */
", ,/** * {@inheritDoc} */,128,129,[0],0,[0],0,[0],0,0,0,0,equals(Object),org.antlr.v4.runtime.misc.IntSet,equals/1[java.lang.Object],False,125,0,0,0,0,1,0,1,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,3,0,0,True
536,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\misc\IntSet.java,org.antlr.v4.runtime.misc.IntSet,boolean contains(int),"/**
 * Returns {@code true} if the set contains the specified element.
 *
 * @param el The element to check for.
 * @return {@code true} if the set contains {@code el}; otherwise {@code false}.
 */
boolean contains(int el);","/**
 * Returns {@code true} if the set contains the specified element.
 *
 * @param el The element to check for.
 * @return {@code true} if the set contains {@code el}; otherwise {@code false}.
 */
", ,/** * Returns {@code true} if the set contains the specified element. * * @param el The element to check for. * @return {@code true} if the set contains {@code el}; otherwise {@code false}. */,137,137,[0],0,[0],0,[0],0,0,0,0,contains(int),org.antlr.v4.runtime.misc.IntSet,contains/1[int],False,131,0,0,0,0,1,0,1,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,13,0,0,True
537,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\misc\IntSet.java,org.antlr.v4.runtime.misc.IntSet,void remove(int),"/**
 * Removes the specified value from the current set. If the current set does
 * not contain the element, no changes are made.
 *
 * @param el the value to remove
 *
 * @exception IllegalStateException if the current set is read-only
 */
void remove(int el);","/**
 * Removes the specified value from the current set. If the current set does
 * not contain the element, no changes are made.
 *
 * @param el the value to remove
 *
 * @exception IllegalStateException if the current set is read-only
 */
", ,"/** * Removes the specified value from the current set. If the current set does * not contain the element, no changes are made. * * @param el the value to remove * * @exception IllegalStateException if the current set is read-only */",147,147,[0],0,[0],0,[0],0,0,0,0,remove(int),org.antlr.v4.runtime.misc.IntSet,remove/1[int],False,139,0,0,0,0,1,0,1,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,23,0,0,True
538,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\misc\IntSet.java,org.antlr.v4.runtime.misc.IntSet,String toString(),"/**
 * {@inheritDoc}
 */
@Override
String toString();","/**
 * {@inheritDoc}
 */
", ,/** * {@inheritDoc} */,162,163,[0],0,[0],0,[0],0,0,0,0,toString(),org.antlr.v4.runtime.misc.IntSet,toString/0,False,159,0,0,0,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,0,0,True
539,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\misc\IntegerList.java,org.antlr.v4.runtime.misc.IntegerList,boolean equals(Object),"/**
 * Compares the specified object with this list for equality.  Returns
 * {@code true} if and only if the specified object is also an {@link IntegerList},
 * both lists have the same size, and all corresponding pairs of elements in
 * the two lists are equal.  In other words, two lists are defined to be
 * equal if they contain the same elements in the same order.
 * <p>
 * This implementation first checks if the specified object is this
 * list. If so, it returns {@code true}; if not, it checks if the
 * specified object is an {@link IntegerList}. If not, it returns {@code false};
 * if so, it checks the size of both lists. If the lists are not the same size,
 * it returns {@code false}; otherwise it iterates over both lists, comparing
 * corresponding pairs of elements.  If any comparison returns {@code false},
 * this method returns {@code false}.
 *
 * @param o the object to be compared for equality with this list
 * @return {@code true} if the specified object is equal to this list
 */
@Override
public boolean equals(Object o) {
    if (o == this) {
        return true;
    }
    if (!(o instanceof IntegerList)) {
        return false;
    }
    IntegerList other = (IntegerList) o;
    if (_size != other._size) {
        return false;
    }
    for (int i = 0; i < _size; i++) {
        if (_data[i] != other._data[i]) {
            return false;
        }
    }
    return true;
}","/**
 * Compares the specified object with this list for equality.  Returns
 * {@code true} if and only if the specified object is also an {@link IntegerList},
 * both lists have the same size, and all corresponding pairs of elements in
 * the two lists are equal.  In other words, two lists are defined to be
 * equal if they contain the same elements in the same order.
 * <p>
 * This implementation first checks if the specified object is this
 * list. If so, it returns {@code true}; if not, it checks if the
 * specified object is an {@link IntegerList}. If not, it returns {@code false};
 * if so, it checks the size of both lists. If the lists are not the same size,
 * it returns {@code false}; otherwise it iterates over both lists, comparing
 * corresponding pairs of elements.  If any comparison returns {@code false},
 * this method returns {@code false}.
 *
 * @param o the object to be compared for equality with this list
 * @return {@code true} if the specified object is equal to this list
 */
", ,"/** * Compares the specified object with this list for equality.  Returns * {@code true} if and only if the specified object is also an {@link IntegerList}, * both lists have the same size, and all corresponding pairs of elements in * the two lists are equal.  In other words, two lists are defined to be * equal if they contain the same elements in the same order. * <p> * This implementation first checks if the specified object is this * list. If so, it returns {@code true}; if not, it checks if the * specified object is an {@link IntegerList}. If not, it returns {@code false}; * if so, it checks the size of both lists. If the lists are not the same size, * it returns {@code false}; otherwise it iterates over both lists, comparing * corresponding pairs of elements.  If any comparison returns {@code false}, * this method returns {@code false}. * * @param o the object to be compared for equality with this list * @return {@code true} if the specified object is equal to this list */",190,212,[0],0,[0],0,[0],0,0,0,0,equals(Object),org.antlr.v4.runtime.misc.IntegerList,equals/1[java.lang.Object],False,191,1,0,0,0,6,0,18,5,2,1,0,0,0,1,3,0,1,0,1,2,0,2,0,0,0,59,1,0,True
540,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\misc\IntegerList.java,org.antlr.v4.runtime.misc.IntegerList,int hashCode(),"/**
 * Returns the hash code value for this list.
 *
 * <p>This implementation uses exactly the code that is used to define the
 * list hash function in the documentation for the {@link List#hashCode}
 * method.</p>
 *
 * @return the hash code value for this list
 */
@Override
public int hashCode() {
    int hashCode = 1;
    for (int i = 0; i < _size; i++) {
        hashCode = 31 * hashCode + _data[i];
    }
    return hashCode;
}","/**
 * Returns the hash code value for this list.
 *
 * <p>This implementation uses exactly the code that is used to define the
 * list hash function in the documentation for the {@link List#hashCode}
 * method.</p>
 *
 * @return the hash code value for this list
 */
", ,/** * Returns the hash code value for this list. * * <p>This implementation uses exactly the code that is used to define the * list hash function in the documentation for the {@link List#hashCode} * method.</p> * * @return the hash code value for this list */,223,231,[0],0,[0],0,[0],0,0,0,0,hashCode(),org.antlr.v4.runtime.misc.IntegerList,hashCode/0,False,224,0,0,0,0,2,0,7,1,2,0,0,0,0,1,0,0,0,0,3,3,2,1,0,0,0,22,1,0,True
541,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\misc\IntegerList.java,org.antlr.v4.runtime.misc.IntegerList,String toString(),"/**
 * Returns a string representation of this list.
 */
@Override
public String toString() {
    return Arrays.toString(toArray());
}","/**
 * Returns a string representation of this list.
 */
", ,/** * Returns a string representation of this list. */,236,239,[0],0,[0],0,[0],0,0,0,0,toString(),org.antlr.v4.runtime.misc.IntegerList,toString/0,False,237,1,1,0,1,1,2,3,1,0,0,2,1,1,0,0,0,0,0,0,0,0,0,0,0,0,8,1,0,True
542,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\misc\IntegerList.java,org.antlr.v4.runtime.misc.IntegerList,char[] toCharArray(),"/**
 * Convert the int list to a char array where values > 0x7FFFF take 2 bytes. TODO?????
 *  If all values are less
 *  than the 0x7FFF 16-bit code point limit (1 bit taken to indicatethen this is just a char array
 *  of 16-bit char as usual. For values in the supplementary range, encode
 * them as two UTF-16 code units.
 */
public final char[] toCharArray() {
    // Optimize for the common case (all data values are
    // < 0xFFFF) to avoid an extra scan
    char[] resultArray = new char[_size];
    int resultIdx = 0;
    boolean calculatedPreciseResultSize = false;
    for (int i = 0; i < _size; i++) {
        int codePoint = _data[i];
        // Calculate the precise result size if we encounter
        // a code point > 0xFFFF
        if (!calculatedPreciseResultSize && Character.isSupplementaryCodePoint(codePoint)) {
            resultArray = Arrays.copyOf(resultArray, charArraySize());
            calculatedPreciseResultSize = true;
        }
        // This will throw IllegalArgumentException if
        // the code point is not a valid Unicode code point
        int charsWritten = Character.toChars(codePoint, resultArray, resultIdx);
        resultIdx += charsWritten;
    }
    return resultArray;
}","/**
 * Convert the int list to a char array where values > 0x7FFFF take 2 bytes. TODO?????
 *  If all values are less
 *  than the 0x7FFF 16-bit code point limit (1 bit taken to indicatethen this is just a char array
 *  of 16-bit char as usual. For values in the supplementary range, encode
 * them as two UTF-16 code units.
 */
","// Optimize for the common case (all data values are
[[SEP]]// < 0xFFFF) to avoid an extra scan
[[SEP]]// Calculate the precise result size if we encounter
[[SEP]]// This will throw IllegalArgumentException if
[[SEP]]// a code point > 0xFFFF
[[SEP]]// the code point is not a valid Unicode code point
","/** * Convert the int list to a char array where values > 0x7FFFF take 2 bytes. TODO????? *  If all values are less *  than the 0x7FFF 16-bit code point limit (1 bit taken to indicatethen this is just a char array *  of 16-bit char as usual. For values in the supplementary range, encode * them as two UTF-16 code units. */[[SEP]]// Optimize for the common case (all data values are// < 0xFFFF) to avoid an extra scan[[SEP]]// Calculate the precise result size if we encounter// a code point > 0xFFFF[[SEP]]// This will throw IllegalArgumentException if// the code point is not a valid Unicode code point",285,306,[1],1,"[0, 0, 0, 0, 0, 0]",0,"[1, 0, 0, 0]",1,1,1,1,toCharArray(),org.antlr.v4.runtime.misc.IntegerList,toCharArray/0,False,285,2,6,5,1,4,4,15,1,6,0,4,1,1,1,0,0,0,0,2,9,0,2,0,0,0,49,17,0,True
543,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\misc\InterpreterDataReader.java,org.antlr.v4.runtime.misc.InterpreterDataReader,InterpreterData parseFile(String),"/**
 * The structure of the data file is very simple. Everything is line based with empty lines
 * separating the different parts. For lexers the layout is:
 * token literal names:
 * ...
 *
 * token symbolic names:
 * ...
 *
 * rule names:
 * ...
 *
 * channel names:
 * ...
 *
 * mode names:
 * ...
 *
 * atn:
 * <a single line with comma separated int values> enclosed in a pair of squared brackets.
 *
 * Data for a parser does not contain channel and mode names.
 */
public static InterpreterData parseFile(String fileName) {
    InterpreterData result = new InterpreterData();
    result.ruleNames = new ArrayList<String>();
    try (BufferedReader br = new BufferedReader(new FileReader(fileName))) {
        String line;
        List<String> literalNames = new ArrayList<String>();
        List<String> symbolicNames = new ArrayList<String>();
        line = br.readLine();
        if (!line.equals(""token literal names:""))
            throw new RuntimeException(""Unexpected data entry"");
        while ((line = br.readLine()) != null) {
            if (line.isEmpty())
                break;
            literalNames.add(line.equals(""null"") ? """" : line);
        }
        line = br.readLine();
        if (!line.equals(""token symbolic names:""))
            throw new RuntimeException(""Unexpected data entry"");
        while ((line = br.readLine()) != null) {
            if (line.isEmpty())
                break;
            symbolicNames.add(line.equals(""null"") ? """" : line);
        }
        result.vocabulary = new VocabularyImpl(literalNames.toArray(new String[0]), symbolicNames.toArray(new String[0]));
        line = br.readLine();
        if (!line.equals(""rule names:""))
            throw new RuntimeException(""Unexpected data entry"");
        while ((line = br.readLine()) != null) {
            if (line.isEmpty())
                break;
            result.ruleNames.add(line);
        }
        line = br.readLine();
        if (line.equals(""channel names:"")) {
            // Additional lexer data.
            result.channels = new ArrayList<String>();
            while ((line = br.readLine()) != null) {
                if (line.isEmpty())
                    break;
                result.channels.add(line);
            }
            line = br.readLine();
            if (!line.equals(""mode names:""))
                throw new RuntimeException(""Unexpected data entry"");
            result.modes = new ArrayList<String>();
            while ((line = br.readLine()) != null) {
                if (line.isEmpty())
                    break;
                result.modes.add(line);
            }
        }
        line = br.readLine();
        if (!line.equals(""atn:""))
            throw new RuntimeException(""Unexpected data entry"");
        line = br.readLine();
        String[] elements = line.substring(1, line.length() - 1).split("","");
        int[] serializedATN = new int[elements.length];
        for (int i = 0; i < elements.length; ++i) {
            // ignore [...] on ends
            serializedATN[i] = Integer.parseInt(elements[i].trim());
        }
        ATNDeserializer deserializer = new ATNDeserializer();
        result.atn = deserializer.deserialize(serializedATN);
    } catch (java.io.IOException e) {
        // We just swallow the error and return empty objects instead.
    }
    return result;
}","/**
 * The structure of the data file is very simple. Everything is line based with empty lines
 * separating the different parts. For lexers the layout is:
 * token literal names:
 * ...
 *
 * token symbolic names:
 * ...
 *
 * rule names:
 * ...
 *
 * channel names:
 * ...
 *
 * mode names:
 * ...
 *
 * atn:
 * <a single line with comma separated int values> enclosed in a pair of squared brackets.
 *
 * Data for a parser does not contain channel and mode names.
 */
","// Additional lexer data.
[[SEP]]// ignore [...] on ends
[[SEP]]// We just swallow the error and return empty objects instead.
",/** * The structure of the data file is very simple. Everything is line based with empty lines * separating the different parts. For lexers the layout is: * token literal names: * ... * * token symbolic names: * ... * * rule names: * ... * * channel names: * ... * * mode names: * ... * * atn: * <a single line with comma separated int values> enclosed in a pair of squared brackets. * * Data for a parser does not contain channel and mode names. */[[SEP]]// Additional lexer data.[[SEP]]// ignore [...] on ends[[SEP]]// We just swallow the error and return empty objects instead.,55,132,[0],0,"[0, 0, 0]",0,"[0, 0, 0, 0]",0,0,0,0,parseFile(String),org.antlr.v4.runtime.misc.InterpreterDataReader,parseFile/1[java.lang.String],False,55,4,5,1,4,21,11,56,1,9,1,11,0,0,6,5,1,5,16,5,26,1,4,0,0,0,63,9,0,True
544,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\misc\Interval.java,org.antlr.v4.runtime.misc.Interval,"Interval of(int, int)","/**
 * Interval objects are used readonly so share all with the
 *  same single value a==b up to some max size.  Use an array as a perfect hash.
 *  Return shared object for 0..INTERVAL_POOL_MAX_VALUE or a new
 *  Interval object with a..a in it.  On Java.g4, 218623 IntervalSets
 *  have a..a (set with 1 element).
 */
public static Interval of(int a, int b) {
    // cache just a..a
    if (a != b || a < 0 || a > INTERVAL_POOL_MAX_VALUE) {
        return new Interval(a, b);
    }
    if (cache[a] == null) {
        cache[a] = new Interval(a, a);
    }
    return cache[a];
}","/**
 * Interval objects are used readonly so share all with the
 *  same single value a==b up to some max size.  Use an array as a perfect hash.
 *  Return shared object for 0..INTERVAL_POOL_MAX_VALUE or a new
 *  Interval object with a..a in it.  On Java.g4, 218623 IntervalSets
 *  have a..a (set with 1 element).
 */
","// cache just a..a
","/** * Interval objects are used readonly so share all with the *  same single value a==b up to some max size.  Use an array as a perfect hash. *  Return shared object for 0..INTERVAL_POOL_MAX_VALUE or a new *  Interval object with a..a in it.  On Java.g4, 218623 IntervalSets *  have a..a (set with 1 element). */[[SEP]]// cache just a..a",27,36,[0],0,[0],0,"[0, 0]",0,0,0,0,"of(int, int)",org.antlr.v4.runtime.misc.Interval,"of/2[int,int]",False,27,1,31,30,1,5,0,9,2,0,2,0,0,0,0,2,0,0,0,1,1,0,1,0,0,0,50,9,0,True
545,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\misc\Interval.java,org.antlr.v4.runtime.misc.Interval,int length(),"/**
 * return number of elements between a and b inclusively. x..x is length 1.
 *  if b &lt; a, then length is 0.  9..10 has length 2.
 */
public int length() {
    if (b < a)
        return 0;
    return b - a + 1;
}","/**
 * return number of elements between a and b inclusively. x..x is length 1.
 *  if b &lt; a, then length is 0.  9..10 has length 2.
 */
", ,"/** * return number of elements between a and b inclusively. x..x is length 1. *  if b &lt; a, then length is 0.  9..10 has length 2. */",41,44,[0],0,[0],0,[0],0,0,1,0,length(),org.antlr.v4.runtime.misc.Interval,length/0,False,41,0,2,2,0,2,0,4,2,0,0,0,0,0,0,0,0,0,0,2,0,2,1,0,0,0,12,1,0,True
546,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\misc\Interval.java,org.antlr.v4.runtime.misc.Interval,boolean startsBeforeDisjoint(Interval),"/**
 * Does this start completely before other? Disjoint
 */
public boolean startsBeforeDisjoint(Interval other) {
    return this.a < other.a && this.b < other.a;
}","/**
 * Does this start completely before other? Disjoint
 */
", ,/** * Does this start completely before other? Disjoint */,64,66,[0],0,[0],0,[0],0,0,0,0,startsBeforeDisjoint(Interval),org.antlr.v4.runtime.misc.Interval,startsBeforeDisjoint/1[org.antlr.v4.runtime.misc.Interval],False,64,1,3,3,0,3,0,3,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,9,1,0,True
547,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\misc\Interval.java,org.antlr.v4.runtime.misc.Interval,boolean startsBeforeNonDisjoint(Interval),"/**
 * Does this start at or before other? Nondisjoint
 */
public boolean startsBeforeNonDisjoint(Interval other) {
    return this.a <= other.a && this.b >= other.a;
}","/**
 * Does this start at or before other? Nondisjoint
 */
", ,/** * Does this start at or before other? Nondisjoint */,69,71,[0],0,[0],0,[0],0,0,0,0,startsBeforeNonDisjoint(Interval),org.antlr.v4.runtime.misc.Interval,startsBeforeNonDisjoint/1[org.antlr.v4.runtime.misc.Interval],False,69,1,1,1,0,3,0,3,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,12,1,0,True
548,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\misc\Interval.java,org.antlr.v4.runtime.misc.Interval,boolean startsAfter(Interval),"/**
 * Does this.a start after other.b? May or may not be disjoint
 */
public boolean startsAfter(Interval other) {
    return this.a > other.a;
}","/**
 * Does this.a start after other.b? May or may not be disjoint
 */
", ,/** * Does this.a start after other.b? May or may not be disjoint */,74,74,[0],0,[0],0,[0],0,0,0,0,startsAfter(Interval),org.antlr.v4.runtime.misc.Interval,startsAfter/1[org.antlr.v4.runtime.misc.Interval],False,74,1,0,0,0,2,0,3,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,13,1,0,True
549,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\misc\Interval.java,org.antlr.v4.runtime.misc.Interval,boolean startsAfterDisjoint(Interval),"/**
 * Does this start completely after other? Disjoint
 */
public boolean startsAfterDisjoint(Interval other) {
    return this.a > other.b;
}","/**
 * Does this start completely after other? Disjoint
 */
", ,/** * Does this start completely after other? Disjoint */,77,79,[0],0,[0],0,[0],0,0,0,0,startsAfterDisjoint(Interval),org.antlr.v4.runtime.misc.Interval,startsAfterDisjoint/1[org.antlr.v4.runtime.misc.Interval],False,77,1,1,1,0,2,0,3,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,9,1,0,True
550,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\misc\Interval.java,org.antlr.v4.runtime.misc.Interval,boolean startsAfterNonDisjoint(Interval),"/**
 * Does this start after other? NonDisjoint
 */
public boolean startsAfterNonDisjoint(Interval other) {
    // this.b>=other.b implied
    return this.a > other.a && this.a <= other.b;
}","/**
 * Does this start after other? NonDisjoint
 */
","// this.b>=other.b implied
",/** * Does this start after other? NonDisjoint */[[SEP]]// this.b>=other.b implied,82,84,[0],0,[0],0,"[0, 0]",0,0,0,0,startsAfterNonDisjoint(Interval),org.antlr.v4.runtime.misc.Interval,startsAfterNonDisjoint/1[org.antlr.v4.runtime.misc.Interval],False,82,1,2,2,0,3,0,3,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,9,1,0,True
551,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\misc\Interval.java,org.antlr.v4.runtime.misc.Interval,boolean disjoint(Interval),"/**
 * Are both ranges disjoint? I.e., no overlap?
 */
public boolean disjoint(Interval other) {
    return startsBeforeDisjoint(other) || startsAfterDisjoint(other);
}","/**
 * Are both ranges disjoint? I.e., no overlap?
 */
", ,"/** * Are both ranges disjoint? I.e., no overlap? */",87,89,[0],0,[0],0,[0],0,0,0,0,disjoint(Interval),org.antlr.v4.runtime.misc.Interval,disjoint/1[org.antlr.v4.runtime.misc.Interval],False,87,1,4,2,2,1,2,3,1,0,1,2,2,1,0,0,0,0,0,0,0,0,0,0,0,0,11,1,0,True
552,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\misc\Interval.java,org.antlr.v4.runtime.misc.Interval,boolean adjacent(Interval),"/**
 * Are two intervals adjacent such as 0..41 and 42..42?
 */
public boolean adjacent(Interval other) {
    return this.a == other.b + 1 || this.b == other.a - 1;
}","/**
 * Are two intervals adjacent such as 0..41 and 42..42?
 */
", ,/** * Are two intervals adjacent such as 0..41 and 42..42? */,92,94,[0],0,[0],0,[0],0,0,0,0,adjacent(Interval),org.antlr.v4.runtime.misc.Interval,adjacent/1[org.antlr.v4.runtime.misc.Interval],False,92,1,1,1,0,3,0,3,1,0,1,0,0,0,0,2,0,0,0,2,0,2,0,0,0,0,9,1,0,True
553,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\misc\Interval.java,org.antlr.v4.runtime.misc.Interval,Interval union(Interval),"/**
 * Return the interval computed from combining this and other
 */
public Interval union(Interval other) {
    return Interval.of(Math.min(a, other.a), Math.max(b, other.b));
}","/**
 * Return the interval computed from combining this and other
 */
", ,/** * Return the interval computed from combining this and other */,101,103,[0],0,[0],0,[0],0,0,0,0,union(Interval),org.antlr.v4.runtime.misc.Interval,union/1[org.antlr.v4.runtime.misc.Interval],False,101,1,2,1,1,1,3,3,1,0,1,3,1,1,0,0,0,0,0,0,0,0,0,0,0,0,10,1,0,True
554,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\misc\Interval.java,org.antlr.v4.runtime.misc.Interval,Interval intersection(Interval),"/**
 * Return the interval in common between this and o
 */
public Interval intersection(Interval other) {
    return Interval.of(Math.max(a, other.a), Math.min(b, other.b));
}","/**
 * Return the interval in common between this and o
 */
", ,/** * Return the interval in common between this and o */,106,108,[0],0,[0],0,[0],0,0,0,0,intersection(Interval),org.antlr.v4.runtime.misc.Interval,intersection/1[org.antlr.v4.runtime.misc.Interval],False,106,1,2,1,1,1,3,3,1,0,1,3,1,1,0,0,0,0,0,0,0,0,0,0,0,0,11,1,0,True
555,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\misc\Interval.java,org.antlr.v4.runtime.misc.Interval,Interval differenceNotProperlyContained(Interval),"/**
 * Return the interval with elements from this not in other;
 *  other must not be totally enclosed (properly contained)
 *  within this, which would result in two disjoint intervals
 *  instead of the single one returned by this method.
 */
public Interval differenceNotProperlyContained(Interval other) {
    Interval diff = null;
    // other.a to left of this.a (or same)
    if (other.startsBeforeNonDisjoint(this)) {
        diff = Interval.of(Math.max(this.a, other.b + 1), this.b);
    } else // other.a to right of this.a
    if (other.startsAfterNonDisjoint(this)) {
        diff = Interval.of(this.a, other.a - 1);
    }
    return diff;
}","/**
 * Return the interval with elements from this not in other;
 *  other must not be totally enclosed (properly contained)
 *  within this, which would result in two disjoint intervals
 *  instead of the single one returned by this method.
 */
","// other.a to left of this.a (or same)
[[SEP]]// other.a to right of this.a
","/** * Return the interval with elements from this not in other; *  other must not be totally enclosed (properly contained) *  within this, which would result in two disjoint intervals *  instead of the single one returned by this method. */[[SEP]]// other.a to left of this.a (or same)[[SEP]]// other.a to right of this.a",115,128,[0],0,"[0, 0]",0,"[0, 0, 0]",0,0,0,0,differenceNotProperlyContained(Interval),org.antlr.v4.runtime.misc.Interval,differenceNotProperlyContained/1[org.antlr.v4.runtime.misc.Interval],False,115,1,3,0,3,3,4,10,1,1,1,4,3,1,0,0,0,0,0,2,3,2,1,0,0,0,35,1,0,True
556,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\misc\IntervalSet.java,org.antlr.v4.runtime.misc.IntervalSet,"IntervalSet of(int, int)","/**
 * Create a set with all ints within range [a..b] (inclusive)
 */
public static IntervalSet of(int a, int b) {
    IntervalSet s = new IntervalSet();
    s.add(a, b);
    return s;
}","/**
 * Create a set with all ints within range [a..b] (inclusive)
 */
", ,/** * Create a set with all ints within range [a..b] (inclusive) */,76,80,[0],0,[0],0,[0],0,0,0,0,"of(int, int)",org.antlr.v4.runtime.misc.IntervalSet,"of/2[int,int]",False,76,1,5,3,2,1,1,5,1,1,2,1,1,2,0,0,0,0,0,0,1,0,0,0,0,0,14,9,0,True
557,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\misc\IntervalSet.java,org.antlr.v4.runtime.misc.IntervalSet,void add(int),"/**
 * Add a single element to the set.  An isolated element is stored
 *  as a range el..el.
 */
@Override
public void add(int el) {
    if (readonly)
        throw new IllegalStateException(""can't alter readonly IntervalSet"");
    add(el, el);
}","/**
 * Add a single element to the set.  An isolated element is stored
 *  as a range el..el.
 */
", ,/** * Add a single element to the set.  An isolated element is stored *  as a range el..el. */,90,94,[0],0,[0],0,[0],0,0,0,0,add(int),org.antlr.v4.runtime.misc.IntervalSet,add/1[int],False,91,1,12,11,1,2,1,4,0,0,1,1,1,2,0,0,0,0,1,0,0,0,1,0,0,0,19,1,0,True
558,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\misc\IntervalSet.java,org.antlr.v4.runtime.misc.IntervalSet,"void add(int, int)","/**
 * Add interval; i.e., add all integers from a to b to set.
 *  If b&lt;a, do nothing.
 *  Keep list in sorted order (by left range value).
 *  If overlap, combine ranges.  For example,
 *  If this is {1..5, 10..20}, adding 6..7 yields
 *  {1..5, 6..7, 10..20}.  Adding 4..8 yields {1..8, 10..20}.
 */
public void add(int a, int b) {
    add(Interval.of(a, b));
}","/**
 * Add interval; i.e., add all integers from a to b to set.
 *  If b&lt;a, do nothing.
 *  Keep list in sorted order (by left range value).
 *  If overlap, combine ranges.  For example,
 *  If this is {1..5, 10..20}, adding 6..7 yields
 *  {1..5, 6..7, 10..20}.  Adding 4..8 yields {1..8, 10..20}.
 */
", ,"/** * Add interval; i.e., add all integers from a to b to set. *  If b&lt;a, do nothing. *  Keep list in sorted order (by left range value). *  If overlap, combine ranges.  For example, *  If this is {1..5, 10..20}, adding 6..7 yields *  {1..5, 6..7, 10..20}.  Adding 4..8 yields {1..8, 10..20}. */",103,105,[0],0,[0],0,[0],0,0,0,0,"add(int, int)",org.antlr.v4.runtime.misc.IntervalSet,"add/2[int,int]",False,103,2,10,8,2,1,2,3,0,0,2,2,1,1,0,0,0,0,0,0,0,0,0,0,0,0,26,1,0,True
559,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\misc\IntervalSet.java,org.antlr.v4.runtime.misc.IntervalSet,void add(Interval),"// copy on write so we can cache a..a intervals and sets of that
protected void add(Interval addition) {
    if (readonly)
        throw new IllegalStateException(""can't alter readonly IntervalSet"");
    // System.out.println(""add ""+addition+"" to ""+intervals.toString());
    if (addition.b < addition.a) {
        return;
    }
    // find position in list
    // Use iterators as we modify list in place
    for (ListIterator<Interval> iter = intervals.listIterator(); iter.hasNext(); ) {
        Interval r = iter.next();
        if (addition.equals(r)) {
            return;
        }
        if (addition.adjacent(r) || !addition.disjoint(r)) {
            // next to each other, make a single larger interval
            Interval bigger = addition.union(r);
            iter.set(bigger);
            // make sure we didn't just create an interval that
            // should be merged with next interval in list
            while (iter.hasNext()) {
                Interval next = iter.next();
                if (!bigger.adjacent(next) && bigger.disjoint(next)) {
                    break;
                }
                // if we bump up against or overlap next, merge
                // remove this one
                iter.remove();
                // move backwards to what we just set
                iter.previous();
                // set to 3 merged ones
                iter.set(bigger.union(next));
                // first call to next after previous duplicates the result
                iter.next();
            }
            return;
        }
        if (addition.startsBeforeDisjoint(r)) {
            // insert before r
            iter.previous();
            iter.add(addition);
            return;
        }
        // if disjoint and after r, a future iteration will handle it
    }
    // ok, must be after last interval (and disjoint from last interval)
    // just add it
    intervals.add(addition);
}","// copy on write so we can cache a..a intervals and sets of that
","// find position in list
[[SEP]]// ok, must be after last interval (and disjoint from last interval)
[[SEP]]// System.out.println(""add ""+addition+"" to ""+intervals.toString());
[[SEP]]// Use iterators as we modify list in place
[[SEP]]// if disjoint and after r, a future iteration will handle it
[[SEP]]// make sure we didn't just create an interval that
[[SEP]]// next to each other, make a single larger interval
[[SEP]]// should be merged with next interval in list
[[SEP]]// if we bump up against or overlap next, merge
[[SEP]]// remove this one
[[SEP]]// move backwards to what we just set
[[SEP]]// set to 3 merged ones
[[SEP]]// first call to next after previous duplicates the result
[[SEP]]// insert before r
[[SEP]]// just add it
","// copy on write so we can cache a..a intervals and sets of that[[SEP]]// System.out.println(""add ""+addition+"" to ""+intervals.toString());[[SEP]]// find position in list// Use iterators as we modify list in place[[SEP]]// next to each other, make a single larger interval[[SEP]]// make sure we didn't just create an interval that// should be merged with next interval in list[[SEP]]// if we bump up against or overlap next, merge// remove this one[[SEP]]// move backwards to what we just set[[SEP]]// set to 3 merged ones[[SEP]]// first call to next after previous duplicates the result[[SEP]]// insert before r[[SEP]]// if disjoint and after r, a future iteration will handle it[[SEP]]// ok, must be after last interval (and disjoint from last interval)// just add it",108,152,[0],0,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]",0,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]",0,0,0,0,add(Interval),org.antlr.v4.runtime.misc.IntervalSet,add/1[org.antlr.v4.runtime.misc.Interval],False,108,1,8,3,5,11,13,33,4,4,1,13,0,0,2,0,0,0,1,0,4,0,4,0,0,0,12,4,0,False
560,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\misc\IntervalSet.java,org.antlr.v4.runtime.misc.IntervalSet,IntervalSet or(IntervalSet[]),"/**
 * combine all sets in the array returned the or'd value
 */
public static IntervalSet or(IntervalSet[] sets) {
    IntervalSet r = new IntervalSet();
    for (IntervalSet s : sets) r.addAll(s);
    return r;
}","/**
 * combine all sets in the array returned the or'd value
 */
", ,/** * combine all sets in the array returned the or'd value */,155,159,[0],0,[0],0,[0],0,0,0,0,or(IntervalSet[]),org.antlr.v4.runtime.misc.IntervalSet,or/1[org.antlr.v4.runtime.misc.IntervalSet[]],False,155,1,3,1,2,2,1,5,1,1,1,1,1,3,1,0,0,0,0,0,1,0,1,0,0,0,13,9,0,True
561,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\misc\IntervalSet.java,org.antlr.v4.runtime.misc.IntervalSet,IntervalSet addAll(IntSet),"@Override
public IntervalSet addAll(IntSet set) {
    if (set == null) {
        return this;
    }
    if (set instanceof IntervalSet) {
        IntervalSet other = (IntervalSet) set;
        // walk set and add each interval
        int n = other.intervals.size();
        for (int i = 0; i < n; i++) {
            Interval I = other.intervals.get(i);
            this.add(I.a, I.b);
        }
    } else {
        for (int value : set.toList()) {
            add(value);
        }
    }
    return this;
}", ,"// walk set and add each interval
",// walk set and add each interval,161,183,[0],0,[0],0,[0],0,0,0,0,addAll(IntSet),org.antlr.v4.runtime.misc.IntervalSet,addAll/1[org.antlr.v4.runtime.misc.IntSet],False,162,3,15,12,3,5,5,19,2,4,1,5,2,2,2,1,0,0,0,1,4,0,2,0,0,0,12,1,0,False
562,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\misc\IntervalSet.java,org.antlr.v4.runtime.misc.IntervalSet,IntervalSet complement(IntSet),"/**
 * {@inheritDoc}
 */
@Override
public IntervalSet complement(IntSet vocabulary) {
    if (vocabulary == null || vocabulary.isNil()) {
        // nothing in common with null set
        return null;
    }
    IntervalSet vocabularyIS;
    if (vocabulary instanceof IntervalSet) {
        vocabularyIS = (IntervalSet) vocabulary;
    } else {
        vocabularyIS = new IntervalSet();
        vocabularyIS.addAll(vocabulary);
    }
    return vocabularyIS.subtract(this);
}","/**
 * {@inheritDoc}
 */
","// nothing in common with null set
",/** * {@inheritDoc} */[[SEP]]// nothing in common with null set,190,206,[0],0,[0],0,"[0, 0]",0,0,0,0,complement(IntSet),org.antlr.v4.runtime.misc.IntervalSet,complement/1[org.antlr.v4.runtime.misc.IntSet],False,191,2,7,3,4,4,3,14,2,1,1,3,2,5,0,1,0,0,0,0,2,0,1,0,0,0,8,1,0,True
563,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\misc\IntervalSet.java,org.antlr.v4.runtime.misc.IntervalSet,"IntervalSet subtract(IntervalSet, IntervalSet)","/**
 * Compute the set difference between two interval sets. The specific
 * operation is {@code left - right}. If either of the input sets is
 * {@code null}, it is treated as though it was an empty set.
 */
public static IntervalSet subtract(IntervalSet left, IntervalSet right) {
    if (left == null || left.isNil()) {
        return new IntervalSet();
    }
    IntervalSet result = new IntervalSet(left);
    if (right == null || right.isNil()) {
        // right set has no elements; just return the copy of the current set
        return result;
    }
    int resultI = 0;
    int rightI = 0;
    while (resultI < result.intervals.size() && rightI < right.intervals.size()) {
        Interval resultInterval = result.intervals.get(resultI);
        Interval rightInterval = right.intervals.get(rightI);
        // operation: (resultInterval - rightInterval) and update indexes
        if (rightInterval.b < resultInterval.a) {
            rightI++;
            continue;
        }
        if (rightInterval.a > resultInterval.b) {
            resultI++;
            continue;
        }
        Interval beforeCurrent = null;
        Interval afterCurrent = null;
        if (rightInterval.a > resultInterval.a) {
            beforeCurrent = new Interval(resultInterval.a, rightInterval.a - 1);
        }
        if (rightInterval.b < resultInterval.b) {
            afterCurrent = new Interval(rightInterval.b + 1, resultInterval.b);
        }
        if (beforeCurrent != null) {
            if (afterCurrent != null) {
                // split the current interval into two
                result.intervals.set(resultI, beforeCurrent);
                result.intervals.add(resultI + 1, afterCurrent);
                resultI++;
                rightI++;
                continue;
            } else {
                // replace the current interval
                result.intervals.set(resultI, beforeCurrent);
                resultI++;
                continue;
            }
        } else {
            if (afterCurrent != null) {
                // replace the current interval
                result.intervals.set(resultI, afterCurrent);
                rightI++;
                continue;
            } else {
                // remove the current interval (thus no need to increment resultI)
                result.intervals.remove(resultI);
                continue;
            }
        }
    }
    // If rightI reached right.intervals.size(), no more intervals to subtract from result.
    // If resultI reached result.intervals.size(), we would be subtracting from an empty set.
    // Either way, we are done.
    return result;
}", ,"// If rightI reached right.intervals.size(), no more intervals to subtract from result.
[[SEP]]// If resultI reached result.intervals.size(), we would be subtracting from an empty set.
[[SEP]]// right set has no elements; just return the copy of the current set
[[SEP]]// operation: (resultInterval - rightInterval) and update indexes
[[SEP]]// split the current interval into two
[[SEP]]// replace the current interval
[[SEP]]// replace the current interval
[[SEP]]// remove the current interval (thus no need to increment resultI)
[[SEP]]// Either way, we are done.
","/** * Compute the set difference between two interval sets. The specific * operation is {@code left - right}. If either of the input sets is * {@code null}, it is treated as though it was an empty set. */[[SEP]]// right set has no elements; just return the copy of the current set[[SEP]]// operation: (resultInterval - rightInterval) and update indexes[[SEP]]// split the current interval into two[[SEP]]// replace the current interval[[SEP]]// replace the current interval[[SEP]]// remove the current interval (thus no need to increment resultI)[[SEP]]// If rightI reached right.intervals.size(), no more intervals to subtract from result.// If resultI reached result.intervals.size(), we would be subtracting from an empty set.// Either way, we are done.",229,303,[0],0,"[0, 0, 0, 0, 0, 0, 0, 0, 0]",0,"[0, 0, 0, 0, 0, 0, 0, 0]",0,0,0,0,"subtract(IntervalSet, IntervalSet)",org.antlr.v4.runtime.misc.IntervalSet,"subtract/2[org.antlr.v4.runtime.misc.IntervalSet,org.antlr.v4.runtime.misc.IntervalSet]",False,229,2,5,1,4,14,6,57,3,7,2,6,1,1,1,5,0,0,0,5,9,3,3,0,0,0,34,9,0,True
564,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\misc\IntervalSet.java,org.antlr.v4.runtime.misc.IntervalSet,IntervalSet and(IntSet),"/**
 * {@inheritDoc}
 */
@Override
public IntervalSet and(IntSet other) {
    if (other == null) {
        // || !(other instanceof IntervalSet) ) {
        // nothing in common with null set
        return null;
    }
    List<Interval> myIntervals = this.intervals;
    List<Interval> theirIntervals = ((IntervalSet) other).intervals;
    IntervalSet intersection = null;
    int mySize = myIntervals.size();
    int theirSize = theirIntervals.size();
    int i = 0;
    int j = 0;
    // iterate down both interval lists looking for nondisjoint intervals
    while (i < mySize && j < theirSize) {
        Interval mine = myIntervals.get(i);
        Interval theirs = theirIntervals.get(j);
        // System.out.println(""mine=""+mine+"" and theirs=""+theirs);
        if (mine.startsBeforeDisjoint(theirs)) {
            // move this iterator looking for interval that might overlap
            i++;
        } else if (theirs.startsBeforeDisjoint(mine)) {
            // move other iterator looking for interval that might overlap
            j++;
        } else if (mine.properlyContains(theirs)) {
            // overlap, add intersection, get next theirs
            if (intersection == null) {
                intersection = new IntervalSet();
            }
            intersection.add(mine.intersection(theirs));
            j++;
        } else if (theirs.properlyContains(mine)) {
            // overlap, add intersection, get next mine
            if (intersection == null) {
                intersection = new IntervalSet();
            }
            intersection.add(mine.intersection(theirs));
            i++;
        } else if (!mine.disjoint(theirs)) {
            // overlap, add intersection
            if (intersection == null) {
                intersection = new IntervalSet();
            }
            intersection.add(mine.intersection(theirs));
            // Move the iterator of lower range [a..b], but not
            // the upper range as it may contain elements that will collide
            // with the next iterator. So, if mine=[0..115] and
            // theirs=[115..200], then intersection is 115 and move mine
            // but not theirs as theirs may collide with the next range
            // in thisIter.
            // move both iterators to next ranges
            if (mine.startsAfterNonDisjoint(theirs)) {
                j++;
            } else if (theirs.startsAfterNonDisjoint(mine)) {
                i++;
            }
        }
    }
    if (intersection == null) {
        return new IntervalSet();
    }
    return intersection;
}","/**
 * {@inheritDoc}
 */
","// || !(other instanceof IntervalSet) ) {
[[SEP]]// nothing in common with null set
[[SEP]]// iterate down both interval lists looking for nondisjoint intervals
[[SEP]]// System.out.println(""mine=""+mine+"" and theirs=""+theirs);
[[SEP]]// move this iterator looking for interval that might overlap
[[SEP]]// move other iterator looking for interval that might overlap
[[SEP]]// overlap, add intersection, get next theirs
[[SEP]]// overlap, add intersection, get next mine
[[SEP]]// Move the iterator of lower range [a..b], but not
[[SEP]]// the upper range as it may contain elements that will collide
[[SEP]]// with the next iterator. So, if mine=[0..115] and
[[SEP]]// theirs=[115..200], then intersection is 115 and move mine
[[SEP]]// but not theirs as theirs may collide with the next range
[[SEP]]// in thisIter.
[[SEP]]// overlap, add intersection
[[SEP]]// move both iterators to next ranges
","/** * {@inheritDoc} */[[SEP]]// || !(other instanceof IntervalSet) ) {// nothing in common with null set[[SEP]]// iterate down both interval lists looking for nondisjoint intervals[[SEP]]// System.out.println(""mine=""+mine+"" and theirs=""+theirs);[[SEP]]// move this iterator looking for interval that might overlap[[SEP]]// move other iterator looking for interval that might overlap[[SEP]]// overlap, add intersection, get next theirs[[SEP]]// overlap, add intersection, get next mine[[SEP]]// overlap, add intersection[[SEP]]// Move the iterator of lower range [a..b], but not// the upper range as it may contain elements that will collide// with the next iterator. So, if mine=[0..115] and// theirs=[115..200], then intersection is 115 and move mine// but not theirs as theirs may collide with the next range// in thisIter.// move both iterators to next ranges",314,381,[0],0,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]",0,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]",0,0,0,0,and(IntSet),org.antlr.v4.runtime.misc.IntervalSet,and/1[org.antlr.v4.runtime.misc.IntSet],False,315,3,8,1,7,15,8,52,3,9,1,8,1,1,1,5,0,1,0,2,12,0,3,0,0,0,15,1,0,True
565,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\misc\IntervalSet.java,org.antlr.v4.runtime.misc.IntervalSet,boolean contains(int),"/**
 * {@inheritDoc}
 */
@Override
public boolean contains(int el) {
    int n = intervals.size();
    int l = 0;
    int r = n - 1;
    // Binary search for the element in the (sorted,
    // disjoint) array of intervals.
    while (l <= r) {
        int m = (l + r) / 2;
        Interval I = intervals.get(m);
        int a = I.a;
        int b = I.b;
        if (b < el) {
            l = m + 1;
        } else if (a > el) {
            r = m - 1;
        } else {
            // el >= a && el <= b
            return true;
        }
    }
    return false;
}","/**
 * {@inheritDoc}
 */
","// Binary search for the element in the (sorted,
[[SEP]]// disjoint) array of intervals.
[[SEP]]// el >= a && el <= b
","/** * {@inheritDoc} */[[SEP]]// Binary search for the element in the (sorted,// disjoint) array of intervals.[[SEP]]// el >= a && el <= b",384,405,[0],0,"[0, 0, 0]",0,"[0, 0, 0]",0,0,0,0,contains(int),org.antlr.v4.runtime.misc.IntervalSet,contains/1[int],False,385,1,16,16,0,4,2,21,2,7,1,2,0,0,1,0,0,1,0,5,9,5,2,0,0,0,12,1,0,True
566,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\misc\IntervalSet.java,org.antlr.v4.runtime.misc.IntervalSet,boolean isNil(),"/**
 * {@inheritDoc}
 */
@Override
public boolean isNil() {
    return intervals == null || intervals.isEmpty();
}","/**
 * {@inheritDoc}
 */
", ,/** * {@inheritDoc} */,408,411,[0],0,[0],0,[0],0,0,0,0,isNil(),org.antlr.v4.runtime.misc.IntervalSet,isNil/0,False,409,0,8,8,0,2,1,3,1,0,0,1,0,0,0,1,0,0,0,0,0,0,0,0,0,0,4,1,0,True
567,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\misc\IntervalSet.java,org.antlr.v4.runtime.misc.IntervalSet,int getMaxElement(),"/**
 * Returns the maximum value contained in the set if not isNil().
 *
 * @return the maximum value contained in the set.
 * @throws RuntimeException if set is empty
 */
public int getMaxElement() {
    if (isNil()) {
        throw new RuntimeException(""set is empty"");
    }
    Interval last = intervals.get(intervals.size() - 1);
    return last.b;
}","/**
 * Returns the maximum value contained in the set if not isNil().
 *
 * @return the maximum value contained in the set.
 * @throws RuntimeException if set is empty
 */
", ,/** * Returns the maximum value contained in the set if not isNil(). * * @return the maximum value contained in the set. * @throws RuntimeException if set is empty */,419,425,[0],0,[0],0,[0],0,0,0,0,getMaxElement(),org.antlr.v4.runtime.misc.IntervalSet,getMaxElement/0,False,419,2,1,0,1,2,3,7,1,1,0,3,1,1,0,0,0,0,1,1,1,1,1,0,0,0,18,1,0,True
568,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\misc\IntervalSet.java,org.antlr.v4.runtime.misc.IntervalSet,int getMinElement(),"/**
 * Returns the minimum value contained in the set if not isNil().
 *
 * @return the minimum value contained in the set.
 * @throws RuntimeException if set is empty
 */
public int getMinElement() {
    if (isNil()) {
        throw new RuntimeException(""set is empty"");
    }
    return intervals.get(0).a;
}","/**
 * Returns the minimum value contained in the set if not isNil().
 *
 * @return the minimum value contained in the set.
 * @throws RuntimeException if set is empty
 */
", ,/** * Returns the minimum value contained in the set if not isNil(). * * @return the minimum value contained in the set. * @throws RuntimeException if set is empty */,433,439,[0],0,[0],0,[0],0,0,0,0,getMinElement(),org.antlr.v4.runtime.misc.IntervalSet,getMinElement/0,False,433,1,5,4,1,2,2,6,1,0,0,2,1,1,0,0,0,0,1,1,0,0,1,0,0,0,16,1,0,True
569,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\misc\IntervalSet.java,org.antlr.v4.runtime.misc.IntervalSet,List<Interval> getIntervals(),"/**
 * Return a list of Interval objects.
 */
public List<Interval> getIntervals() {
    return intervals;
}","/**
 * Return a list of Interval objects.
 */
", ,/** * Return a list of Interval objects. */,442,444,[0],0,[0],0,[0],0,0,0,0,getIntervals(),org.antlr.v4.runtime.misc.IntervalSet,getIntervals/0,False,442,1,4,4,0,1,0,3,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,8,1,0,True
570,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\misc\IntervalSet.java,org.antlr.v4.runtime.misc.IntervalSet,boolean equals(Object),"/**
 * Are two IntervalSets equal?  Because all intervals are sorted
 *  and disjoint, equals is a simple linear walk over both lists
 *  to make sure they are the same.  Interval.equals() is used
 *  by the List.equals() method to check the ranges.
 */
@Override
public boolean equals(Object obj) {
    if (obj == null || !(obj instanceof IntervalSet)) {
        return false;
    }
    IntervalSet other = (IntervalSet) obj;
    return this.intervals.equals(other.intervals);
}","/**
 * Are two IntervalSets equal?  Because all intervals are sorted
 *  and disjoint, equals is a simple linear walk over both lists
 *  to make sure they are the same.  Interval.equals() is used
 *  by the List.equals() method to check the ranges.
 */
", ,"/** * Are two IntervalSets equal?  Because all intervals are sorted *  and disjoint, equals is a simple linear walk over both lists *  to make sure they are the same.  Interval.equals() is used *  by the List.equals() method to check the ranges. */",463,470,[0],0,[0],0,[0],0,0,0,0,equals(Object),org.antlr.v4.runtime.misc.IntervalSet,equals/1[java.lang.Object],False,464,1,1,1,0,3,1,7,2,1,1,1,0,0,0,1,0,1,0,0,1,0,1,0,0,0,34,1,0,True
571,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\misc\IntervalSet.java,org.antlr.v4.runtime.misc.IntervalSet,String toString(String[]),"/**
 * @deprecated Use {@link #toString(Vocabulary)} instead.
 */
@Deprecated
public String toString(String[] tokenNames) {
    return toString(VocabularyImpl.fromTokenNames(tokenNames));
}","/**
 * @deprecated Use {@link #toString(Vocabulary)} instead.
 */
", ,/** * @deprecated Use {@link #toString(Vocabulary)} instead. */,510,513,[1],1,[0],0,[1],1,0,0,0,toString(String[]),org.antlr.v4.runtime.misc.IntervalSet,toString/1[java.lang.String[]],False,511,2,7,5,2,1,2,3,1,0,1,2,1,2,0,0,0,0,0,0,0,0,0,0,0,0,6,1,0,True
572,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\misc\IntervalSet.java,org.antlr.v4.runtime.misc.IntervalSet,"String elementName(String[], int)","/**
 * @deprecated Use {@link #elementName(Vocabulary, int)} instead.
 */
@Deprecated
protected String elementName(String[] tokenNames, int a) {
    return elementName(VocabularyImpl.fromTokenNames(tokenNames), a);
}","/**
 * @deprecated Use {@link #elementName(Vocabulary, int)} instead.
 */
", ,"/** * @deprecated Use {@link #elementName(Vocabulary, int)} instead. */",550,553,[1],1,[0],0,[1],1,0,0,0,"elementName(String[], int)",org.antlr.v4.runtime.misc.IntervalSet,"elementName/2[java.lang.String[],int]",False,551,2,2,0,2,1,2,3,1,0,2,2,1,1,0,0,0,0,0,0,0,0,0,0,0,0,6,4,0,True
573,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\misc\IntervalSet.java,org.antlr.v4.runtime.misc.IntervalSet,int get(int),"/**
 * Get the ith element of ordered set.  Used only by RandomPhrase so
 *  don't bother to implement if you're not doing that for a new
 *  ANTLR code gen target.
 */
public int get(int i) {
    int n = intervals.size();
    int index = 0;
    for (int j = 0; j < n; j++) {
        Interval I = intervals.get(j);
        int a = I.a;
        int b = I.b;
        for (int v = a; v <= b; v++) {
            if (index == i) {
                return v;
            }
            index++;
        }
    }
    return -1;
}","/**
 * Get the ith element of ordered set.  Used only by RandomPhrase so
 *  don't bother to implement if you're not doing that for a new
 *  ANTLR code gen target.
 */
", ,/** * Get the ith element of ordered set.  Used only by RandomPhrase so *  don't bother to implement if you're not doing that for a new *  ANTLR code gen target. */,628,643,[0],0,[0],0,[0],0,0,0,0,get(int),org.antlr.v4.runtime.misc.IntervalSet,get/1[int],False,628,1,0,0,0,4,2,16,2,7,1,2,0,0,2,1,0,0,0,3,7,0,3,0,0,0,35,1,0,True
574,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\misc\IntervalSet.java,org.antlr.v4.runtime.misc.IntervalSet,void remove(int),"@Override
public void remove(int el) {
    if (readonly)
        throw new IllegalStateException(""can't alter readonly IntervalSet"");
    int n = intervals.size();
    for (int i = 0; i < n; i++) {
        Interval I = intervals.get(i);
        int a = I.a;
        int b = I.b;
        if (el < a) {
            // list is sorted and el is before this interval; not here
            break;
        }
        // if whole interval x..x, rm
        if (el == a && el == b) {
            intervals.remove(i);
            break;
        }
        // if on left edge x..b, adjust left
        if (el == a) {
            I.a++;
            break;
        }
        // if on right edge a..x, adjust right
        if (el == b) {
            I.b--;
            break;
        }
        // if in middle a..x..b, split interval
        if (el > a && el < b) {
            // found in this interval
            int oldb = I.b;
            // [a..x-1]
            I.b = el - 1;
            // add [x+1..b]
            add(el + 1, oldb);
        }
    }
}", ,"// list is sorted and el is before this interval; not here
[[SEP]]// if whole interval x..x, rm
[[SEP]]// if on left edge x..b, adjust left
[[SEP]]// if on right edge a..x, adjust right
[[SEP]]// if in middle a..x..b, split interval
[[SEP]]// found in this interval
[[SEP]]// [a..x-1]
[[SEP]]// add [x+1..b]
","// list is sorted and el is before this interval; not here[[SEP]]// if whole interval x..x, rm[[SEP]]// if on left edge x..b, adjust left[[SEP]]// if on right edge a..x, adjust right[[SEP]]// if in middle a..x..b, split interval[[SEP]]// found in this interval[[SEP]]// [a..x-1][[SEP]]// add [x+1..b]",649,682,[0],0,"[0, 0, 0, 0, 0, 0, 0, 0]",0,"[0, 0, 0, 0, 0, 0, 0, 0]",0,0,0,0,remove(int),org.antlr.v4.runtime.misc.IntervalSet,remove/1[int],False,650,2,3,2,1,10,4,29,0,6,1,4,1,2,1,4,0,0,1,3,7,2,2,0,0,0,15,1,0,False
575,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\misc\LogManager.java,org.antlr.v4.runtime.misc.LogManager,String save(),"public String save() throws IOException {
    // String dir = System.getProperty(""java.io.tmpdir"");
    String dir = ""."";
    String defaultFilename = dir + ""/antlr-"" + new SimpleDateFormat(""yyyy-MM-dd-HH.mm.ss"").format(new Date()) + "".log"";
    save(defaultFilename);
    return defaultFilename;
}", ,"// String dir = System.getProperty(""java.io.tmpdir"");
","// String dir = System.getProperty(""java.io.tmpdir"");",69,77,[0],0,[0],0,[0],0,0,0,0,save(),org.antlr.v4.runtime.misc.LogManager,save/0,False,69,1,2,1,1,1,2,6,1,2,0,2,1,2,0,0,0,0,4,0,2,1,0,0,0,0,13,1,0,False
576,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\misc\MurmurHash.java,org.antlr.v4.runtime.misc.MurmurHash,int initialize(),"/**
 * Initialize the hash using the default seed value.
 *
 * @return the intermediate hash value
 */
public static int initialize() {
    return initialize(DEFAULT_SEED);
}","/**
 * Initialize the hash using the default seed value.
 *
 * @return the intermediate hash value
 */
", ,/** * Initialize the hash using the default seed value. * * @return the intermediate hash value */,22,24,[0],0,[0],0,[0],0,0,0,0,initialize(),org.antlr.v4.runtime.misc.MurmurHash,initialize/0,False,22,1,18,17,1,1,1,3,1,0,0,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,17,9,0,True
577,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\misc\MurmurHash.java,org.antlr.v4.runtime.misc.MurmurHash,int initialize(int),"/**
 * Initialize the hash using the specified {@code seed}.
 *
 * @param seed the seed
 * @return the intermediate hash value
 */
public static int initialize(int seed) {
    return seed;
}","/**
 * Initialize the hash using the specified {@code seed}.
 *
 * @param seed the seed
 * @return the intermediate hash value
 */
", ,/** * Initialize the hash using the specified {@code seed}. * * @param seed the seed * @return the intermediate hash value */,32,34,[0],0,[0],0,[0],0,0,0,0,initialize(int),org.antlr.v4.runtime.misc.MurmurHash,initialize/1[int],False,32,0,9,9,0,1,0,3,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,9,9,0,True
578,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\misc\MurmurHash.java,org.antlr.v4.runtime.misc.MurmurHash,"int update(int, int)","/**
 * Update the intermediate hash value for the next input {@code value}.
 *
 * @param hash the intermediate hash value
 * @param value the value to add to the current hash
 * @return the updated intermediate hash value
 */
public static int update(int hash, int value) {
    final int c1 = 0xCC9E2D51;
    final int c2 = 0x1B873593;
    final int r1 = 15;
    final int r2 = 13;
    final int m = 5;
    final int n = 0xE6546B64;
    int k = value;
    k = k * c1;
    k = (k << r1) | (k >>> (32 - r1));
    k = k * c2;
    hash = hash ^ k;
    hash = (hash << r2) | (hash >>> (32 - r2));
    hash = hash * m + n;
    return hash;
}","/**
 * Update the intermediate hash value for the next input {@code value}.
 *
 * @param hash the intermediate hash value
 * @param value the value to add to the current hash
 * @return the updated intermediate hash value
 */
", ,/** * Update the intermediate hash value for the next input {@code value}. * * @param hash the intermediate hash value * @param value the value to add to the current hash * @return the updated intermediate hash value */,43,61,[0],0,[0],0,[0],0,0,0,0,"update(int, int)",org.antlr.v4.runtime.misc.MurmurHash,"update/2[int,int]",False,43,0,20,20,0,1,0,16,1,7,2,0,0,0,0,0,0,6,0,8,13,10,0,0,0,0,28,9,0,True
579,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\misc\MurmurHash.java,org.antlr.v4.runtime.misc.MurmurHash,"int update(int, Object)","/**
 * Update the intermediate hash value for the next input {@code value}.
 *
 * @param hash the intermediate hash value
 * @param value the value to add to the current hash
 * @return the updated intermediate hash value
 */
public static int update(int hash, Object value) {
    return update(hash, value != null ? value.hashCode() : 0);
}","/**
 * Update the intermediate hash value for the next input {@code value}.
 *
 * @param hash the intermediate hash value
 * @param value the value to add to the current hash
 * @return the updated intermediate hash value
 */
", ,/** * Update the intermediate hash value for the next input {@code value}. * * @param hash the intermediate hash value * @param value the value to add to the current hash * @return the updated intermediate hash value */,70,72,[0],0,[0],0,[0],0,0,0,0,"update(int, Object)",org.antlr.v4.runtime.misc.MurmurHash,"update/2[int,java.lang.Object]",False,70,1,12,11,1,2,2,3,1,0,2,2,1,1,0,1,0,0,0,1,0,0,0,0,0,0,13,9,0,True
580,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\misc\MurmurHash.java,org.antlr.v4.runtime.misc.MurmurHash,"int finish(int, int)","/**
 * Apply the final computation steps to the intermediate value {@code hash}
 * to form the final result of the MurmurHash 3 hash function.
 *
 * @param hash the intermediate hash value
 * @param numberOfWords the number of integer values added to the hash
 * @return the final hash result
 */
public static int finish(int hash, int numberOfWords) {
    hash = hash ^ (numberOfWords * 4);
    hash = hash ^ (hash >>> 16);
    hash = hash * 0x85EBCA6B;
    hash = hash ^ (hash >>> 13);
    hash = hash * 0xC2B2AE35;
    hash = hash ^ (hash >>> 16);
    return hash;
}","/**
 * Apply the final computation steps to the intermediate value {@code hash}
 * to form the final result of the MurmurHash 3 hash function.
 *
 * @param hash the intermediate hash value
 * @param numberOfWords the number of integer values added to the hash
 * @return the final hash result
 */
", ,/** * Apply the final computation steps to the intermediate value {@code hash} * to form the final result of the MurmurHash 3 hash function. * * @param hash the intermediate hash value * @param numberOfWords the number of integer values added to the hash * @return the final hash result */,82,90,[0],0,[0],0,[0],0,0,0,0,"finish(int, int)",org.antlr.v4.runtime.misc.MurmurHash,"finish/2[int,int]",False,82,0,25,25,0,1,0,9,1,0,2,0,0,0,0,0,0,4,0,6,6,6,0,0,0,0,30,9,0,True
581,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\misc\MurmurHash.java,org.antlr.v4.runtime.misc.MurmurHash,"int hashCode(T[], int)","/**
 * Utility function to compute the hash code of an array using the
 * MurmurHash algorithm.
 *
 * @param <T> the array element type
 * @param data the array data
 * @param seed the seed for the MurmurHash algorithm
 * @return the hash code of the data
 */
public static <T> int hashCode(T[] data, int seed) {
    int hash = initialize(seed);
    for (T value : data) {
        hash = update(hash, value);
    }
    hash = finish(hash, data.length);
    return hash;
}","/**
 * Utility function to compute the hash code of an array using the
 * MurmurHash algorithm.
 *
 * @param <T> the array element type
 * @param data the array data
 * @param seed the seed for the MurmurHash algorithm
 * @return the hash code of the data
 */
", ,/** * Utility function to compute the hash code of an array using the * MurmurHash algorithm. * * @param <T> the array element type * @param data the array data * @param seed the seed for the MurmurHash algorithm * @return the hash code of the data */,101,109,[0],0,[0],0,[0],0,0,0,0,"hashCode(T[], int)",org.antlr.v4.runtime.misc.MurmurHash,"hashCode/2[T[],int]",False,101,2,3,0,3,2,3,8,1,1,2,3,3,2,1,0,0,0,0,0,3,0,1,0,0,0,24,9,0,True
582,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\misc\ObjectEqualityComparator.java,org.antlr.v4.runtime.misc.ObjectEqualityComparator,int hashCode(Object),"/**
 * {@inheritDoc}
 *
 * <p>This implementation returns
 * {@code obj.}{@link Object#hashCode hashCode()}.</p>
 */
@Override
public int hashCode(Object obj) {
    if (obj == null) {
        return 0;
    }
    return obj.hashCode();
}","/**
 * {@inheritDoc}
 *
 * <p>This implementation returns
 * {@code obj.}{@link Object#hashCode hashCode()}.</p>
 */
", ,/** * {@inheritDoc} * * <p>This implementation returns * {@code obj.}{@link Object#hashCode hashCode()}.</p> */,23,30,[0],0,[0],0,[0],0,0,0,0,hashCode(Object),org.antlr.v4.runtime.misc.ObjectEqualityComparator,hashCode/1[java.lang.Object],False,24,0,0,0,0,2,1,6,2,0,1,1,0,0,0,1,0,0,0,1,0,0,1,0,0,0,9,1,0,True
583,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\misc\ObjectEqualityComparator.java,org.antlr.v4.runtime.misc.ObjectEqualityComparator,"boolean equals(Object, Object)","/**
 * {@inheritDoc}
 *
 * <p>This implementation relies on object equality. If both objects are
 * {@code null}, this method returns {@code true}. Otherwise if only
 * {@code a} is {@code null}, this method returns {@code false}. Otherwise,
 * this method returns the result of
 * {@code a.}{@link Object#equals equals}{@code (b)}.</p>
 */
@Override
public boolean equals(Object a, Object b) {
    if (a == null) {
        return b == null;
    }
    return a.equals(b);
}","/**
 * {@inheritDoc}
 *
 * <p>This implementation relies on object equality. If both objects are
 * {@code null}, this method returns {@code true}. Otherwise if only
 * {@code a} is {@code null}, this method returns {@code false}. Otherwise,
 * this method returns the result of
 * {@code a.}{@link Object#equals equals}{@code (b)}.</p>
 */
", ,"/** * {@inheritDoc} * * <p>This implementation relies on object equality. If both objects are * {@code null}, this method returns {@code true}. Otherwise if only * {@code a} is {@code null}, this method returns {@code false}. Otherwise, * this method returns the result of * {@code a.}{@link Object#equals equals}{@code (b)}.</p> */",41,48,[0],0,[0],0,[0],0,0,0,0,"equals(Object, Object)",org.antlr.v4.runtime.misc.ObjectEqualityComparator,"equals/2[java.lang.Object,java.lang.Object]",False,42,0,3,3,0,2,1,6,2,0,2,1,0,0,0,2,0,0,0,0,0,0,1,0,0,0,25,1,0,True
584,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\misc\OrderedHashSet.java,org.antlr.v4.runtime.misc.OrderedHashSet,"T set(int, T)","/**
 * Replace an existing value with a new value; updates the element
 *  list and the hash table, but not the key as that has not changed.
 */
public T set(int i, T value) {
    T oldElement = elements.get(i);
    // update list
    elements.set(i, value);
    // now update the set: remove/add
    super.remove(oldElement);
    super.add(value);
    return oldElement;
}","/**
 * Replace an existing value with a new value; updates the element
 *  list and the hash table, but not the key as that has not changed.
 */
","// update list
[[SEP]]// now update the set: remove/add
","/** * Replace an existing value with a new value; updates the element *  list and the hash table, but not the key as that has not changed. */[[SEP]]// update list[[SEP]]// now update the set: remove/add",30,36,[0],0,"[0, 0]",0,"[0, 0, 0]",0,0,0,0,"set(int, T)",org.antlr.v4.runtime.misc.OrderedHashSet,"set/2[int,T]",False,30,1,0,0,0,1,4,7,1,1,2,4,0,0,0,0,0,0,0,0,1,0,0,0,0,0,23,1,0,True
585,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\misc\OrderedHashSet.java,org.antlr.v4.runtime.misc.OrderedHashSet,boolean add(T),"/**
 * Add a value to list; keep in hashtable for consistency also;
 *  Key is object itself.  Good for say asking if a certain string is in
 *  a list of strings.
 */
@Override
public boolean add(T value) {
    boolean result = super.add(value);
    if (result) {
        // only track if new element not in set
        elements.add(value);
    }
    return result;
}","/**
 * Add a value to list; keep in hashtable for consistency also;
 *  Key is object itself.  Good for say asking if a certain string is in
 *  a list of strings.
 */
","// only track if new element not in set
",/** * Add a value to list; keep in hashtable for consistency also; *  Key is object itself.  Good for say asking if a certain string is in *  a list of strings. */[[SEP]]// only track if new element not in set,47,54,[0],0,[0],0,"[0, 0]",0,0,0,0,add(T),org.antlr.v4.runtime.misc.OrderedHashSet,add/1[T],False,48,1,0,0,0,2,2,7,1,1,1,2,0,0,0,0,0,0,0,0,1,0,1,0,0,0,22,1,0,True
586,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\misc\OrderedHashSet.java,org.antlr.v4.runtime.misc.OrderedHashSet,boolean equals(Object),"@Override
public boolean equals(Object o) {
    if (!(o instanceof OrderedHashSet<?>)) {
        return false;
    }
    // System.out.print(""equals "" + this + "", "" + o+"" = "");
    boolean same = elements != null && elements.equals(((OrderedHashSet<?>) o).elements);
    // System.out.println(same);
    return same;
}", ,"// System.out.print(""equals "" + this + "", "" + o+"" = "");
[[SEP]]// System.out.println(same);
","// System.out.print(""equals "" + this + "", "" + o+"" = "");[[SEP]]// System.out.println(same);",72,82,[0],0,"[0, 0]",0,"[0, 0]",0,0,0,0,equals(Object),org.antlr.v4.runtime.misc.OrderedHashSet,equals/1[java.lang.Object],False,73,1,0,0,0,3,1,7,2,1,1,1,0,0,0,1,0,2,0,0,1,0,1,0,0,0,7,1,0,False
587,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\misc\OrderedHashSet.java,org.antlr.v4.runtime.misc.OrderedHashSet,List<T> elements(),"/**
 * Return the List holding list of table elements.  Note that you are
 *  NOT getting a copy so don't write to the list.
 */
public List<T> elements() {
    return elements;
}","/**
 * Return the List holding list of table elements.  Note that you are
 *  NOT getting a copy so don't write to the list.
 */
", ,/** * Return the List holding list of table elements.  Note that you are *  NOT getting a copy so don't write to the list. */,92,94,[0],0,[0],0,[0],0,0,0,0,elements(),org.antlr.v4.runtime.misc.OrderedHashSet,elements/0,False,92,1,0,0,0,1,0,3,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,21,1,0,True
588,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\misc\OrderedHashSet.java,org.antlr.v4.runtime.misc.OrderedHashSet,Object clone(),"@Override
public Object clone() {
    // safe (result of clone)
    @SuppressWarnings(""unchecked"")
    OrderedHashSet<T> dup = (OrderedHashSet<T>) super.clone();
    dup.elements = new ArrayList<T>(this.elements);
    return dup;
}", ,"// safe (result of clone)
",// safe (result of clone),96,102,[0],0,[0],0,[0],0,0,0,0,clone(),org.antlr.v4.runtime.misc.OrderedHashSet,clone/0,False,97,2,0,0,0,1,1,5,1,1,0,1,0,0,0,0,0,0,1,0,2,0,0,0,0,0,3,1,0,False
589,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\misc\Utils.java,org.antlr.v4.runtime.misc.Utils,"String join(Iterator<T>, String)","// Seriously: why isn't this built in to java? ugh!
public static <T> String join(Iterator<T> iter, String separator) {
    StringBuilder buf = new StringBuilder();
    while (iter.hasNext()) {
        buf.append(iter.next());
        if (iter.hasNext()) {
            buf.append(separator);
        }
    }
    return buf.toString();
}","// Seriously: why isn't this built in to java? ugh!
", ,// Seriously: why isn't this built in to java? ugh!,24,33,[1],1,[0],0,[1],1,0,1,1,"join(Iterator<T>, String)",org.antlr.v4.runtime.misc.Utils,"join/2[java.util.Iterator<T>,java.lang.String]",False,24,1,0,0,0,3,5,10,1,1,2,5,0,0,1,0,0,0,0,0,1,0,2,0,0,0,5,9,0,False
590,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\misc\Utils.java,org.antlr.v4.runtime.misc.Utils,"Map<String, Integer> toMap(String[])","/**
 * Convert array of strings to string&rarr;index map. Useful for
 *  converting rulenames to name&rarr;ruleindex map.
 */
public static Map<String, Integer> toMap(String[] keys) {
    Map<String, Integer> m = new HashMap<String, Integer>();
    for (int i = 0; i < keys.length; i++) {
        m.put(keys[i], i);
    }
    return m;
}","/**
 * Convert array of strings to string&rarr;index map. Useful for
 *  converting rulenames to name&rarr;ruleindex map.
 */
", ,/** * Convert array of strings to string&rarr;index map. Useful for *  converting rulenames to name&rarr;ruleindex map. */,130,136,[0],0,[0],0,[0],0,0,0,0,toMap(String[]),org.antlr.v4.runtime.misc.Utils,toMap/1[java.lang.String[]],False,130,0,1,1,0,2,1,7,1,2,1,1,0,0,1,0,0,0,0,1,2,0,1,0,0,0,17,9,0,True
591,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\misc\Utils.java,org.antlr.v4.runtime.misc.Utils,"String expandTabs(String, int)","/**
 * @since 4.6
 */
public static String expandTabs(String s, int tabSize) {
    if (s == null)
        return null;
    StringBuilder buf = new StringBuilder();
    int col = 0;
    for (int i = 0; i < s.length(); i++) {
        char c = s.charAt(i);
        switch(c) {
            case '\n':
                col = 0;
                buf.append(c);
                break;
            case '\t':
                int n = tabSize - col % tabSize;
                col += n;
                buf.append(spaces(n));
                break;
            default:
                col++;
                buf.append(c);
                break;
        }
    }
    return buf.toString();
}","/**
 * @since 4.6
 */
", ,/** * @since 4.6 */,154,177,[0],0,[0],0,[0],0,0,0,0,"expandTabs(String, int)",org.antlr.v4.runtime.misc.Utils,"expandTabs/2[java.lang.String,int]",False,154,1,1,0,1,5,6,24,2,5,2,6,1,2,1,1,0,0,0,3,7,2,2,0,0,0,14,9,0,True
592,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\misc\Utils.java,org.antlr.v4.runtime.misc.Utils,String spaces(int),"/**
 * @since 4.6
 */
public static String spaces(int n) {
    return sequence(n, "" "");
}","/**
 * @since 4.6
 */
", ,/** * @since 4.6 */,180,182,[0],0,[0],0,[0],0,0,0,0,spaces(int),org.antlr.v4.runtime.misc.Utils,spaces/1[int],False,180,1,2,1,1,1,1,3,1,0,1,1,1,1,0,0,0,0,1,0,0,0,0,0,0,0,3,9,0,True
593,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\misc\Utils.java,org.antlr.v4.runtime.misc.Utils,String newlines(int),"/**
 * @since 4.6
 */
public static String newlines(int n) {
    return sequence(n, ""\n"");
}","/**
 * @since 4.6
 */
", ,/** * @since 4.6 */,185,187,[0],0,[0],0,[0],0,0,0,0,newlines(int),org.antlr.v4.runtime.misc.Utils,newlines/1[int],False,185,1,1,0,1,1,1,3,1,0,1,1,1,1,0,0,0,0,1,0,0,0,0,0,0,0,3,9,0,True
594,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\misc\Utils.java,org.antlr.v4.runtime.misc.Utils,"String sequence(int, String)","/**
 * @since 4.6
 */
public static String sequence(int n, String s) {
    StringBuilder buf = new StringBuilder();
    for (int sp = 1; sp <= n; sp++) buf.append(s);
    return buf.toString();
}","/**
 * @since 4.6
 */
", ,/** * @since 4.6 */,190,194,[0],0,[0],0,[0],0,0,0,0,"sequence(int, String)",org.antlr.v4.runtime.misc.Utils,"sequence/2[int,java.lang.String]",False,190,0,2,2,0,2,2,5,1,2,2,2,0,0,1,0,0,0,0,1,2,0,1,0,0,0,7,9,0,True
595,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\misc\Utils.java,org.antlr.v4.runtime.misc.Utils,"int count(String, char)","/**
 * @since 4.6
 */
public static int count(String s, char x) {
    int n = 0;
    for (int i = 0; i < s.length(); i++) {
        if (s.charAt(i) == x) {
            n++;
        }
    }
    return n;
}","/**
 * @since 4.6
 */
", ,/** * @since 4.6 */,197,205,[0],0,[0],0,[0],0,0,0,0,"count(String, char)",org.antlr.v4.runtime.misc.Utils,"count/2[java.lang.String,char]",False,197,0,0,0,0,3,2,9,1,2,2,2,0,0,1,1,0,0,0,2,2,0,2,0,0,0,4,9,0,True
596,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\tree\AbstractParseTreeVisitor.java,org.antlr.v4.runtime.tree.AbstractParseTreeVisitor,T visit(ParseTree),"/**
 * {@inheritDoc}
 *
 * <p>The default implementation calls {@link ParseTree#accept} on the
 * specified tree.</p>
 */
@Override
public T visit(ParseTree tree) {
    return tree.accept(this);
}","/**
 * {@inheritDoc}
 *
 * <p>The default implementation calls {@link ParseTree#accept} on the
 * specified tree.</p>
 */
", ,/** * {@inheritDoc} * * <p>The default implementation calls {@link ParseTree#accept} on the * specified tree.</p> */,16,19,[0],0,[0],0,[0],0,0,0,0,visit(ParseTree),org.antlr.v4.runtime.tree.AbstractParseTreeVisitor,visit/1[org.antlr.v4.runtime.tree.ParseTree],False,17,2,1,0,1,1,1,3,1,0,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,11,1,0,True
597,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\tree\AbstractParseTreeVisitor.java,org.antlr.v4.runtime.tree.AbstractParseTreeVisitor,T visitChildren(RuleNode),"/**
 * {@inheritDoc}
 *
 * <p>The default implementation initializes the aggregate result to
 * {@link #defaultResult defaultResult()}. Before visiting each child, it
 * calls {@link #shouldVisitNextChild shouldVisitNextChild}; if the result
 * is {@code false} no more children are visited and the current aggregate
 * result is returned. After visiting a child, the aggregate result is
 * updated by calling {@link #aggregateResult aggregateResult} with the
 * previous aggregate result and the result of visiting the child.</p>
 *
 * <p>The default implementation is not safe for use in visitors that modify
 * the tree structure. Visitors that modify the tree should override this
 * method to behave properly in respect to the specific algorithm in use.</p>
 */
@Override
public T visitChildren(RuleNode node) {
    T result = defaultResult();
    int n = node.getChildCount();
    for (int i = 0; i < n; i++) {
        if (!shouldVisitNextChild(node, result)) {
            break;
        }
        ParseTree c = node.getChild(i);
        T childResult = c.accept(this);
        result = aggregateResult(result, childResult);
    }
    return result;
}","/**
 * {@inheritDoc}
 *
 * <p>The default implementation initializes the aggregate result to
 * {@link #defaultResult defaultResult()}. Before visiting each child, it
 * calls {@link #shouldVisitNextChild shouldVisitNextChild}; if the result
 * is {@code false} no more children are visited and the current aggregate
 * result is returned. After visiting a child, the aggregate result is
 * updated by calling {@link #aggregateResult aggregateResult} with the
 * previous aggregate result and the result of visiting the child.</p>
 *
 * <p>The default implementation is not safe for use in visitors that modify
 * the tree structure. Visitors that modify the tree should override this
 * method to behave properly in respect to the specific algorithm in use.</p>
 */
", ,"/** * {@inheritDoc} * * <p>The default implementation initializes the aggregate result to * {@link #defaultResult defaultResult()}. Before visiting each child, it * calls {@link #shouldVisitNextChild shouldVisitNextChild}; if the result * is {@code false} no more children are visited and the current aggregate * result is returned. After visiting a child, the aggregate result is * updated by calling {@link #aggregateResult aggregateResult} with the * previous aggregate result and the result of visiting the child.</p> * * <p>The default implementation is not safe for use in visitors that modify * the tree structure. Visitors that modify the tree should override this * method to behave properly in respect to the specific algorithm in use.</p> */",36,51,[0],0,[0],0,[0],0,0,0,0,visitChildren(RuleNode),org.antlr.v4.runtime.tree.AbstractParseTreeVisitor,visitChildren/1[org.antlr.v4.runtime.tree.RuleNode],False,37,5,6,0,6,3,6,13,1,5,1,6,0,0,1,0,0,0,0,1,6,0,2,0,0,0,65,1,0,True
598,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\tree\AbstractParseTreeVisitor.java,org.antlr.v4.runtime.tree.AbstractParseTreeVisitor,T visitTerminal(TerminalNode),"/**
 * {@inheritDoc}
 *
 * <p>The default implementation returns the result of
 * {@link #defaultResult defaultResult}.</p>
 */
@Override
public T visitTerminal(TerminalNode node) {
    return defaultResult();
}","/**
 * {@inheritDoc}
 *
 * <p>The default implementation returns the result of
 * {@link #defaultResult defaultResult}.</p>
 */
", ,/** * {@inheritDoc} * * <p>The default implementation returns the result of * {@link #defaultResult defaultResult}.</p> */,59,62,[0],0,[0],0,[0],0,0,0,0,visitTerminal(TerminalNode),org.antlr.v4.runtime.tree.AbstractParseTreeVisitor,visitTerminal/1[org.antlr.v4.runtime.tree.TerminalNode],False,60,3,1,0,1,1,1,3,1,0,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,14,1,0,True
599,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\tree\AbstractParseTreeVisitor.java,org.antlr.v4.runtime.tree.AbstractParseTreeVisitor,T visitErrorNode(ErrorNode),"/**
 * {@inheritDoc}
 *
 * <p>The default implementation returns the result of
 * {@link #defaultResult defaultResult}.</p>
 */
@Override
public T visitErrorNode(ErrorNode node) {
    return defaultResult();
}","/**
 * {@inheritDoc}
 *
 * <p>The default implementation returns the result of
 * {@link #defaultResult defaultResult}.</p>
 */
", ,/** * {@inheritDoc} * * <p>The default implementation returns the result of * {@link #defaultResult defaultResult}.</p> */,70,73,[0],0,[0],0,[0],0,0,0,0,visitErrorNode(ErrorNode),org.antlr.v4.runtime.tree.AbstractParseTreeVisitor,visitErrorNode/1[org.antlr.v4.runtime.tree.ErrorNode],False,71,3,1,0,1,1,1,3,1,0,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,14,1,0,True
600,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\tree\AbstractParseTreeVisitor.java,org.antlr.v4.runtime.tree.AbstractParseTreeVisitor,T defaultResult(),"/**
 * Gets the default value returned by visitor methods. This value is
 * returned by the default implementations of
 * {@link #visitTerminal visitTerminal}, {@link #visitErrorNode visitErrorNode}.
 * The default implementation of {@link #visitChildren visitChildren}
 * initializes its aggregate result to this value.
 *
 * <p>The base implementation returns {@code null}.</p>
 *
 * @return The default value returned by visitor methods.
 */
protected T defaultResult() {
    return null;
}","/**
 * Gets the default value returned by visitor methods. This value is
 * returned by the default implementations of
 * {@link #visitTerminal visitTerminal}, {@link #visitErrorNode visitErrorNode}.
 * The default implementation of {@link #visitChildren visitChildren}
 * initializes its aggregate result to this value.
 *
 * <p>The base implementation returns {@code null}.</p>
 *
 * @return The default value returned by visitor methods.
 */
", ,"/** * Gets the default value returned by visitor methods. This value is * returned by the default implementations of * {@link #visitTerminal visitTerminal}, {@link #visitErrorNode visitErrorNode}. * The default implementation of {@link #visitChildren visitChildren} * initializes its aggregate result to this value. * * <p>The base implementation returns {@code null}.</p> * * @return The default value returned by visitor methods. */",86,88,[0],0,[0],0,[0],0,0,0,0,defaultResult(),org.antlr.v4.runtime.tree.AbstractParseTreeVisitor,defaultResult/0,False,86,1,0,0,0,1,0,3,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,29,4,0,True
601,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\tree\AbstractParseTreeVisitor.java,org.antlr.v4.runtime.tree.AbstractParseTreeVisitor,"T aggregateResult(T, T)","/**
 * Aggregates the results of visiting multiple children of a node. After
 * either all children are visited or {@link #shouldVisitNextChild} returns
 * {@code false}, the aggregate value is returned as the result of
 * {@link #visitChildren}.
 *
 * <p>The default implementation returns {@code nextResult}, meaning
 * {@link #visitChildren} will return the result of the last child visited
 * (or return the initial value if the node has no children).</p>
 *
 * @param aggregate The previous aggregate value. In the default
 * implementation, the aggregate value is initialized to
 * {@link #defaultResult}, which is passed as the {@code aggregate} argument
 * to this method after the first child node is visited.
 * @param nextResult The result of the immediately preceeding call to visit
 * a child node.
 *
 * @return The updated aggregate result.
 */
protected T aggregateResult(T aggregate, T nextResult) {
    return nextResult;
}","/**
 * Aggregates the results of visiting multiple children of a node. After
 * either all children are visited or {@link #shouldVisitNextChild} returns
 * {@code false}, the aggregate value is returned as the result of
 * {@link #visitChildren}.
 *
 * <p>The default implementation returns {@code nextResult}, meaning
 * {@link #visitChildren} will return the result of the last child visited
 * (or return the initial value if the node has no children).</p>
 *
 * @param aggregate The previous aggregate value. In the default
 * implementation, the aggregate value is initialized to
 * {@link #defaultResult}, which is passed as the {@code aggregate} argument
 * to this method after the first child node is visited.
 * @param nextResult The result of the immediately preceeding call to visit
 * a child node.
 *
 * @return The updated aggregate result.
 */
", ,"/** * Aggregates the results of visiting multiple children of a node. After * either all children are visited or {@link #shouldVisitNextChild} returns * {@code false}, the aggregate value is returned as the result of * {@link #visitChildren}. * * <p>The default implementation returns {@code nextResult}, meaning * {@link #visitChildren} will return the result of the last child visited * (or return the initial value if the node has no children).</p> * * @param aggregate The previous aggregate value. In the default * implementation, the aggregate value is initialized to * {@link #defaultResult}, which is passed as the {@code aggregate} argument * to this method after the first child node is visited. * @param nextResult The result of the immediately preceeding call to visit * a child node. * * @return The updated aggregate result. */",109,111,[0],0,[0],0,[0],0,0,0,0,"aggregateResult(T, T)",org.antlr.v4.runtime.tree.AbstractParseTreeVisitor,"aggregateResult/2[T,T]",False,109,1,0,0,0,1,0,3,1,0,2,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,51,4,0,True
602,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\tree\AbstractParseTreeVisitor.java,org.antlr.v4.runtime.tree.AbstractParseTreeVisitor,"boolean shouldVisitNextChild(RuleNode, T)","/**
 * This method is called after visiting each child in
 * {@link #visitChildren}. This method is first called before the first
 * child is visited; at that point {@code currentResult} will be the initial
 * value (in the default implementation, the initial value is returned by a
 * call to {@link #defaultResult}. This method is not called after the last
 * child is visited.
 *
 * <p>The default implementation always returns {@code true}, indicating that
 * {@code visitChildren} should only return after all children are visited.
 * One reason to override this method is to provide a ""short circuit""
 * evaluation option for situations where the result of visiting a single
 * child has the potential to determine the result of the visit operation as
 * a whole.</p>
 *
 * @param node The {@link RuleNode} whose children are currently being
 * visited.
 * @param currentResult The current aggregate result of the children visited
 * to the current point.
 *
 * @return {@code true} to continue visiting children. Otherwise return
 * {@code false} to stop visiting children and immediately return the
 * current aggregate result from {@link #visitChildren}.
 */
protected boolean shouldVisitNextChild(RuleNode node, T currentResult) {
    return true;
}","/**
 * This method is called after visiting each child in
 * {@link #visitChildren}. This method is first called before the first
 * child is visited; at that point {@code currentResult} will be the initial
 * value (in the default implementation, the initial value is returned by a
 * call to {@link #defaultResult}. This method is not called after the last
 * child is visited.
 *
 * <p>The default implementation always returns {@code true}, indicating that
 * {@code visitChildren} should only return after all children are visited.
 * One reason to override this method is to provide a ""short circuit""
 * evaluation option for situations where the result of visiting a single
 * child has the potential to determine the result of the visit operation as
 * a whole.</p>
 *
 * @param node The {@link RuleNode} whose children are currently being
 * visited.
 * @param currentResult The current aggregate result of the children visited
 * to the current point.
 *
 * @return {@code true} to continue visiting children. Otherwise return
 * {@code false} to stop visiting children and immediately return the
 * current aggregate result from {@link #visitChildren}.
 */
", ,"/** * This method is called after visiting each child in * {@link #visitChildren}. This method is first called before the first * child is visited; at that point {@code currentResult} will be the initial * value (in the default implementation, the initial value is returned by a * call to {@link #defaultResult}. This method is not called after the last * child is visited. * * <p>The default implementation always returns {@code true}, indicating that * {@code visitChildren} should only return after all children are visited. * One reason to override this method is to provide a ""short circuit"" * evaluation option for situations where the result of visiting a single * child has the potential to determine the result of the visit operation as * a whole.</p> * * @param node The {@link RuleNode} whose children are currently being * visited. * @param currentResult The current aggregate result of the children visited * to the current point. * * @return {@code true} to continue visiting children. Otherwise return * {@code false} to stop visiting children and immediately return the * current aggregate result from {@link #visitChildren}. */",137,139,[0],0,[0],0,[0],0,0,0,0,"shouldVisitNextChild(RuleNode, T)",org.antlr.v4.runtime.tree.AbstractParseTreeVisitor,"shouldVisitNextChild/2[org.antlr.v4.runtime.tree.RuleNode,T]",False,137,2,0,0,0,1,0,3,1,0,2,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,76,4,0,True
603,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\tree\IterativeParseTreeWalker.java,org.antlr.v4.runtime.tree.IterativeParseTreeWalker,"void walk(ParseTreeListener, ParseTree)","@Override
public void walk(ParseTreeListener listener, ParseTree t) {
    final Deque<ParseTree> nodeStack = new ArrayDeque<ParseTree>();
    final IntegerStack indexStack = new IntegerStack();
    ParseTree currentNode = t;
    int currentIndex = 0;
    while (currentNode != null) {
        // pre-order visit
        if (currentNode instanceof ErrorNode) {
            listener.visitErrorNode((ErrorNode) currentNode);
        } else if (currentNode instanceof TerminalNode) {
            listener.visitTerminal((TerminalNode) currentNode);
        } else {
            final RuleNode r = (RuleNode) currentNode;
            enterRule(listener, r);
        }
        // Move down to first child, if exists
        if (currentNode.getChildCount() > 0) {
            nodeStack.push(currentNode);
            indexStack.push(currentIndex);
            currentIndex = 0;
            currentNode = currentNode.getChild(0);
            continue;
        }
        // No child nodes, so walk tree
        do {
            // post-order visit
            if (currentNode instanceof RuleNode) {
                exitRule(listener, (RuleNode) currentNode);
            }
            // No parent, so no siblings
            if (nodeStack.isEmpty()) {
                currentNode = null;
                currentIndex = 0;
                break;
            }
            // Move to next sibling if possible
            currentNode = nodeStack.peek().getChild(++currentIndex);
            if (currentNode != null) {
                break;
            }
            // No next, sibling, so move up
            currentNode = nodeStack.pop();
            currentIndex = indexStack.pop();
        } while (currentNode != null);
    }
}", ,"// pre-order visit
[[SEP]]// Move down to first child, if exists
[[SEP]]// No child nodes, so walk tree
[[SEP]]// post-order visit
[[SEP]]// No parent, so no siblings
[[SEP]]// Move to next sibling if possible
[[SEP]]// No next, sibling, so move up
","// pre-order visit[[SEP]]// Move down to first child, if exists[[SEP]]// No child nodes, so walk tree[[SEP]]// post-order visit[[SEP]]// No parent, so no siblings[[SEP]]// Move to next sibling if possible[[SEP]]// No next, sibling, so move up",21,80,[0],0,"[0, 0, 0, 0, 0, 0, 0]",0,"[0, 0, 0, 0, 0, 0, 0]",0,0,0,0,"walk(ParseTreeListener, ParseTree)",org.antlr.v4.runtime.tree.IterativeParseTreeWalker,"walk/2[org.antlr.v4.runtime.tree.ParseTreeListener,org.antlr.v4.runtime.tree.ParseTree]",False,22,8,9,0,9,9,12,42,0,5,2,12,0,0,2,3,0,0,0,5,12,0,3,0,0,0,19,1,0,False
604,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\tree\ParseTree.java,org.antlr.v4.runtime.tree.ParseTree,ParseTree getParent(),"// the following methods narrow the return type; they are not additional methods
@Override
ParseTree getParent();","// the following methods narrow the return type; they are not additional methods
", ,// the following methods narrow the return type; they are not additional methods,22,23,[0],0,[0],0,[0],0,0,0,0,getParent(),org.antlr.v4.runtime.tree.ParseTree,getParent/0,False,22,1,0,0,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,4,0,0,False
605,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\tree\ParseTree.java,org.antlr.v4.runtime.tree.ParseTree,void setParent(RuleContext),"/**
 * Set the parent for this node.
 *
 *  This is not backward compatible as it changes
 *  the interface but no one was able to create custom
 *  nodes anyway so I'm adding as it improves internal
 *  code quality.
 *
 *  One could argue for a restructuring of
 *  the class/interface hierarchy so that
 *  setParent, addChild are moved up to Tree
 *  but that's a major change. So I'll do the
 *  minimal change, which is to add this method.
 *
 *  @since 4.7
 */
void setParent(RuleContext parent);","/**
 * Set the parent for this node.
 *
 *  This is not backward compatible as it changes
 *  the interface but no one was able to create custom
 *  nodes anyway so I'm adding as it improves internal
 *  code quality.
 *
 *  One could argue for a restructuring of
 *  the class/interface hierarchy so that
 *  setParent, addChild are moved up to Tree
 *  but that's a major change. So I'll do the
 *  minimal change, which is to add this method.
 *
 *  @since 4.7
 */
", ,"/** * Set the parent for this node. * *  This is not backward compatible as it changes *  the interface but no one was able to create custom *  nodes anyway so I'm adding as it improves internal *  code quality. * *  One could argue for a restructuring of *  the class/interface hierarchy so that *  setParent, addChild are moved up to Tree *  but that's a major change. So I'll do the *  minimal change, which is to add this method. * *  @since 4.7 */",43,43,[0],0,[0],0,[0],0,0,0,0,setParent(RuleContext),org.antlr.v4.runtime.tree.ParseTree,setParent/1[org.antlr.v4.runtime.RuleContext],False,28,1,2,2,0,1,0,1,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,48,0,0,True
606,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\tree\ParseTree.java,org.antlr.v4.runtime.tree.ParseTree,T accept(ParseTreeVisitor<? extends T>),"/**
 * The {@link ParseTreeVisitor} needs a double dispatch method.
 */
<T> T accept(ParseTreeVisitor<? extends T> visitor);","/**
 * The {@link ParseTreeVisitor} needs a double dispatch method.
 */
", ,/** * The {@link ParseTreeVisitor} needs a double dispatch method. */,46,46,[0],0,[0],0,[0],0,0,0,0,accept(ParseTreeVisitor<?T>),org.antlr.v4.runtime.tree.ParseTree,accept/1[org.antlr.v4.runtime.tree.ParseTreeVisitor<? extends T>],False,45,2,2,2,0,1,0,1,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,10,0,0,True
607,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\tree\ParseTree.java,org.antlr.v4.runtime.tree.ParseTree,String getText(),"/**
 * Return the combined text of all leaf nodes. Does not get any
 *  off-channel tokens (if any) so won't return whitespace and
 *  comments if they are sent to parser on hidden channel.
 */
String getText();","/**
 * Return the combined text of all leaf nodes. Does not get any
 *  off-channel tokens (if any) so won't return whitespace and
 *  comments if they are sent to parser on hidden channel.
 */
", ,/** * Return the combined text of all leaf nodes. Does not get any *  off-channel tokens (if any) so won't return whitespace and *  comments if they are sent to parser on hidden channel. */,52,52,[0],0,[0],0,[0],0,0,0,0,getText(),org.antlr.v4.runtime.tree.ParseTree,getText/0,False,48,0,2,2,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,26,0,0,True
608,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\tree\ParseTree.java,org.antlr.v4.runtime.tree.ParseTree,String toStringTree(Parser),"/**
 * Specialize toStringTree so that it can print out more information
 * 	based upon the parser.
 */
String toStringTree(Parser parser);","/**
 * Specialize toStringTree so that it can print out more information
 * 	based upon the parser.
 */
", ,/** * Specialize toStringTree so that it can print out more information * 	based upon the parser. */,57,57,[0],0,[0],0,[0],0,0,0,0,toStringTree(Parser),org.antlr.v4.runtime.tree.ParseTree,toStringTree/1[org.antlr.v4.runtime.Parser],False,54,1,1,1,0,1,0,1,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,17,0,0,True
609,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\tree\ParseTreeVisitor.java,org.antlr.v4.runtime.tree.ParseTreeVisitor,T visit(ParseTree),"/**
 * Visit a parse tree, and return a user-defined result of the operation.
 *
 * @param tree The {@link ParseTree} to visit.
 * @return The result of visiting the parse tree.
 */
T visit(ParseTree tree);","/**
 * Visit a parse tree, and return a user-defined result of the operation.
 *
 * @param tree The {@link ParseTree} to visit.
 * @return The result of visiting the parse tree.
 */
", ,"/** * Visit a parse tree, and return a user-defined result of the operation. * * @param tree The {@link ParseTree} to visit. * @return The result of visiting the parse tree. */",25,25,[0],0,[0],0,[0],0,0,0,0,visit(ParseTree),org.antlr.v4.runtime.tree.ParseTreeVisitor,visit/1[org.antlr.v4.runtime.tree.ParseTree],False,19,2,0,0,0,1,0,1,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,17,0,0,True
610,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\tree\ParseTreeVisitor.java,org.antlr.v4.runtime.tree.ParseTreeVisitor,T visitChildren(RuleNode),"/**
 * Visit the children of a node, and return a user-defined result of the
 * operation.
 *
 * @param node The {@link RuleNode} whose children should be visited.
 * @return The result of visiting the children of the node.
 */
T visitChildren(RuleNode node);","/**
 * Visit the children of a node, and return a user-defined result of the
 * operation.
 *
 * @param node The {@link RuleNode} whose children should be visited.
 * @return The result of visiting the children of the node.
 */
", ,"/** * Visit the children of a node, and return a user-defined result of the * operation. * * @param node The {@link RuleNode} whose children should be visited. * @return The result of visiting the children of the node. */",34,34,[0],0,[0],0,[0],0,0,0,0,visitChildren(RuleNode),org.antlr.v4.runtime.tree.ParseTreeVisitor,visitChildren/1[org.antlr.v4.runtime.tree.RuleNode],False,27,2,0,0,0,1,0,1,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,20,0,0,True
611,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\tree\ParseTreeVisitor.java,org.antlr.v4.runtime.tree.ParseTreeVisitor,T visitTerminal(TerminalNode),"/**
 * Visit a terminal node, and return a user-defined result of the operation.
 *
 * @param node The {@link TerminalNode} to visit.
 * @return The result of visiting the node.
 */
T visitTerminal(TerminalNode node);","/**
 * Visit a terminal node, and return a user-defined result of the operation.
 *
 * @param node The {@link TerminalNode} to visit.
 * @return The result of visiting the node.
 */
", ,"/** * Visit a terminal node, and return a user-defined result of the operation. * * @param node The {@link TerminalNode} to visit. * @return The result of visiting the node. */",42,42,[0],0,[0],0,[0],0,0,0,0,visitTerminal(TerminalNode),org.antlr.v4.runtime.tree.ParseTreeVisitor,visitTerminal/1[org.antlr.v4.runtime.tree.TerminalNode],False,36,2,0,0,0,1,0,1,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,17,0,0,True
612,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\tree\ParseTreeVisitor.java,org.antlr.v4.runtime.tree.ParseTreeVisitor,T visitErrorNode(ErrorNode),"/**
 * Visit an error node, and return a user-defined result of the operation.
 *
 * @param node The {@link ErrorNode} to visit.
 * @return The result of visiting the node.
 */
T visitErrorNode(ErrorNode node);","/**
 * Visit an error node, and return a user-defined result of the operation.
 *
 * @param node The {@link ErrorNode} to visit.
 * @return The result of visiting the node.
 */
", ,"/** * Visit an error node, and return a user-defined result of the operation. * * @param node The {@link ErrorNode} to visit. * @return The result of visiting the node. */",50,50,[0],0,[0],0,[0],0,0,0,0,visitErrorNode(ErrorNode),org.antlr.v4.runtime.tree.ParseTreeVisitor,visitErrorNode/1[org.antlr.v4.runtime.tree.ErrorNode],False,44,2,0,0,0,1,0,1,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,18,0,0,True
613,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\tree\ParseTreeWalker.java,org.antlr.v4.runtime.tree.ParseTreeWalker,"void walk(ParseTreeListener, ParseTree)","/**
 * Performs a walk on the given parse tree starting at the root and going down recursively
 * with depth-first search. On each node, {@link ParseTreeWalker#enterRule} is called before
 * recursively walking down into child nodes, then
 * {@link ParseTreeWalker#exitRule} is called after the recursive call to wind up.
 * @param listener The listener used by the walker to process grammar rules
 * @param t The parse tree to be walked on
 */
public void walk(ParseTreeListener listener, ParseTree t) {
    if (t instanceof ErrorNode) {
        listener.visitErrorNode((ErrorNode) t);
        return;
    } else if (t instanceof TerminalNode) {
        listener.visitTerminal((TerminalNode) t);
        return;
    }
    RuleNode r = (RuleNode) t;
    enterRule(listener, r);
    int n = r.getChildCount();
    for (int i = 0; i < n; i++) {
        walk(listener, r.getChild(i));
    }
    exitRule(listener, r);
}","/**
 * Performs a walk on the given parse tree starting at the root and going down recursively
 * with depth-first search. On each node, {@link ParseTreeWalker#enterRule} is called before
 * recursively walking down into child nodes, then
 * {@link ParseTreeWalker#exitRule} is called after the recursive call to wind up.
 * @param listener The listener used by the walker to process grammar rules
 * @param t The parse tree to be walked on
 */
", ,"/** * Performs a walk on the given parse tree starting at the root and going down recursively * with depth-first search. On each node, {@link ParseTreeWalker#enterRule} is called before * recursively walking down into child nodes, then * {@link ParseTreeWalker#exitRule} is called after the recursive call to wind up. * @param listener The listener used by the walker to process grammar rules * @param t The parse tree to be walked on */",23,39,[0],0,[0],0,[0],0,0,0,0,"walk(ParseTreeListener, ParseTree)",org.antlr.v4.runtime.tree.ParseTreeWalker,"walk/2[org.antlr.v4.runtime.tree.ParseTreeListener,org.antlr.v4.runtime.tree.ParseTree]",False,23,7,8,1,7,4,7,17,2,3,2,7,3,1,1,0,0,0,0,1,3,0,1,0,0,0,55,1,0,True
614,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\tree\ParseTreeWalker.java,org.antlr.v4.runtime.tree.ParseTreeWalker,"void enterRule(ParseTreeListener, RuleNode)","/**
 * Enters a grammar rule by first triggering the generic event {@link ParseTreeListener#enterEveryRule}
 * then by triggering the event specific to the given parse tree node
 * @param listener The listener responding to the trigger events
 * @param r The grammar rule containing the rule context
 */
protected void enterRule(ParseTreeListener listener, RuleNode r) {
    ParserRuleContext ctx = (ParserRuleContext) r.getRuleContext();
    listener.enterEveryRule(ctx);
    ctx.enterRule(listener);
}","/**
 * Enters a grammar rule by first triggering the generic event {@link ParseTreeListener#enterEveryRule}
 * then by triggering the event specific to the given parse tree node
 * @param listener The listener responding to the trigger events
 * @param r The grammar rule containing the rule context
 */
", ,/** * Enters a grammar rule by first triggering the generic event {@link ParseTreeListener#enterEveryRule} * then by triggering the event specific to the given parse tree node * @param listener The listener responding to the trigger events * @param r The grammar rule containing the rule context */,47,51,[0],0,[0],0,[0],0,0,0,0,"enterRule(ParseTreeListener, RuleNode)",org.antlr.v4.runtime.tree.ParseTreeWalker,"enterRule/2[org.antlr.v4.runtime.tree.ParseTreeListener,org.antlr.v4.runtime.tree.RuleNode]",False,47,3,5,2,3,1,3,5,0,1,2,3,0,0,0,0,0,0,0,0,1,0,0,0,0,0,33,4,0,True
615,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\tree\ParseTreeWalker.java,org.antlr.v4.runtime.tree.ParseTreeWalker,"void exitRule(ParseTreeListener, RuleNode)","/**
 * Exits a grammar rule by first triggering the event specific to the given parse tree node
 * then by triggering the generic event {@link ParseTreeListener#exitEveryRule}
 * @param listener The listener responding to the trigger events
 * @param r The grammar rule containing the rule context
 */
protected void exitRule(ParseTreeListener listener, RuleNode r) {
    ParserRuleContext ctx = (ParserRuleContext) r.getRuleContext();
    ctx.exitRule(listener);
    listener.exitEveryRule(ctx);
}","/**
 * Exits a grammar rule by first triggering the event specific to the given parse tree node
 * then by triggering the generic event {@link ParseTreeListener#exitEveryRule}
 * @param listener The listener responding to the trigger events
 * @param r The grammar rule containing the rule context
 */
", ,/** * Exits a grammar rule by first triggering the event specific to the given parse tree node * then by triggering the generic event {@link ParseTreeListener#exitEveryRule} * @param listener The listener responding to the trigger events * @param r The grammar rule containing the rule context */,60,64,[0],0,[0],0,[0],0,0,0,0,"exitRule(ParseTreeListener, RuleNode)",org.antlr.v4.runtime.tree.ParseTreeWalker,"exitRule/2[org.antlr.v4.runtime.tree.ParseTreeListener,org.antlr.v4.runtime.tree.RuleNode]",False,60,3,5,2,3,1,3,5,0,1,2,3,0,0,0,0,0,0,0,0,1,0,0,0,0,0,33,4,0,True
616,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\tree\SyntaxTree.java,org.antlr.v4.runtime.tree.SyntaxTree,Interval getSourceInterval(),"/**
 * Return an {@link Interval} indicating the index in the
 * {@link TokenStream} of the first and last token associated with this
 * subtree. If this node is a leaf, then the interval represents a single
 * token and has interval i..i for token index i.
 *
 * <p>An interval of i..i-1 indicates an empty interval at position
 * i in the input stream, where 0 &lt;= i &lt;= the size of the input
 * token stream.  Currently, the code base can only have i=0..n-1 but
 * in concept one could have an empty interval after EOF. </p>
 *
 * <p>If source interval is unknown, this returns {@link Interval#INVALID}.</p>
 *
 * <p>As a weird special case, the source interval for rules matched after
 * EOF is unspecified.</p>
 */
Interval getSourceInterval();","/**
 * Return an {@link Interval} indicating the index in the
 * {@link TokenStream} of the first and last token associated with this
 * subtree. If this node is a leaf, then the interval represents a single
 * token and has interval i..i for token index i.
 *
 * <p>An interval of i..i-1 indicates an empty interval at position
 * i in the input stream, where 0 &lt;= i &lt;= the size of the input
 * token stream.  Currently, the code base can only have i=0..n-1 but
 * in concept one could have an empty interval after EOF. </p>
 *
 * <p>If source interval is unknown, this returns {@link Interval#INVALID}.</p>
 *
 * <p>As a weird special case, the source interval for rules matched after
 * EOF is unspecified.</p>
 */
", ,"/** * Return an {@link Interval} indicating the index in the * {@link TokenStream} of the first and last token associated with this * subtree. If this node is a leaf, then the interval represents a single * token and has interval i..i for token index i. * * <p>An interval of i..i-1 indicates an empty interval at position * i in the input stream, where 0 &lt;= i &lt;= the size of the input * token stream.  Currently, the code base can only have i=0..n-1 but * in concept one could have an empty interval after EOF. </p> * * <p>If source interval is unknown, this returns {@link Interval#INVALID}.</p> * * <p>As a weird special case, the source interval for rules matched after * EOF is unspecified.</p> */",33,33,[0],0,[0],0,[0],0,0,0,0,getSourceInterval(),org.antlr.v4.runtime.tree.SyntaxTree,getSourceInterval/0,False,17,1,1,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,58,0,0,True
617,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\tree\Tree.java,org.antlr.v4.runtime.tree.Tree,Tree getParent(),"/**
 * The parent of this node. If the return value is null, then this
 *  node is the root of the tree.
 */
Tree getParent();","/**
 * The parent of this node. If the return value is null, then this
 *  node is the root of the tree.
 */
", ,"/** * The parent of this node. If the return value is null, then this *  node is the root of the tree. */",19,19,[0],0,[0],0,[0],0,0,0,0,getParent(),org.antlr.v4.runtime.tree.Tree,getParent/0,False,16,1,3,3,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,13,0,0,True
618,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\tree\Tree.java,org.antlr.v4.runtime.tree.Tree,Object getPayload(),"/**
 * This method returns whatever object represents the data at this node. For
 * example, for parse trees, the payload can be a {@link Token} representing
 * a leaf node or a {@link RuleContext} object representing a rule
 * invocation. For abstract syntax trees (ASTs), this is a {@link Token}
 * object.
 */
Object getPayload();","/**
 * This method returns whatever object represents the data at this node. For
 * example, for parse trees, the payload can be a {@link Token} representing
 * a leaf node or a {@link RuleContext} object representing a rule
 * invocation. For abstract syntax trees (ASTs), this is a {@link Token}
 * object.
 */
", ,"/** * This method returns whatever object represents the data at this node. For * example, for parse trees, the payload can be a {@link Token} representing * a leaf node or a {@link RuleContext} object representing a rule * invocation. For abstract syntax trees (ASTs), this is a {@link Token} * object. */",28,28,[0],0,[0],0,[0],0,0,0,0,getPayload(),org.antlr.v4.runtime.tree.Tree,getPayload/0,False,21,0,1,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,32,0,0,True
619,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\tree\Tree.java,org.antlr.v4.runtime.tree.Tree,Tree getChild(int),"/**
 * If there are children, get the {@code i}th value indexed from 0.
 */
Tree getChild(int i);","/**
 * If there are children, get the {@code i}th value indexed from 0.
 */
", ,"/** * If there are children, get the {@code i}th value indexed from 0. */",31,31,[0],0,[0],0,[0],0,0,0,0,getChild(int),org.antlr.v4.runtime.tree.Tree,getChild/1[int],False,30,1,8,8,0,1,0,1,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,12,0,0,True
620,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\tree\Tree.java,org.antlr.v4.runtime.tree.Tree,int getChildCount(),"/**
 * How many children are there? If there is none, then this
 *  node represents a leaf node.
 */
int getChildCount();","/**
 * How many children are there? If there is none, then this
 *  node represents a leaf node.
 */
", ,"/** * How many children are there? If there is none, then this *  node represents a leaf node. */",36,36,[0],0,[0],0,[0],0,0,0,0,getChildCount(),org.antlr.v4.runtime.tree.Tree,getChildCount/0,False,33,0,16,16,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,15,0,0,True
621,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\tree\Tree.java,org.antlr.v4.runtime.tree.Tree,String toStringTree(),"/**
 * Print out a whole tree, not just a node, in LISP format
 *  {@code (root child1 .. childN)}. Print just a node if this is a leaf.
 */
String toStringTree();","/**
 * Print out a whole tree, not just a node, in LISP format
 *  {@code (root child1 .. childN)}. Print just a node if this is a leaf.
 */
", ,"/** * Print out a whole tree, not just a node, in LISP format *  {@code (root child1 .. childN)}. Print just a node if this is a leaf. */",41,41,[0],0,[0],0,[0],0,0,0,0,toStringTree(),org.antlr.v4.runtime.tree.Tree,toStringTree/0,False,38,0,0,0,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,21,0,0,True
622,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\tree\Trees.java,org.antlr.v4.runtime.tree.Trees,String toStringTree(Tree),"/**
 * Print out a whole tree in LISP form. {@link #getNodeText} is used on the
 *  node payloads to get the text for the nodes.  Detect
 *  parse trees and extract data appropriately.
 */
public static String toStringTree(Tree t) {
    return toStringTree(t, (List<String>) null);
}","/**
 * Print out a whole tree in LISP form. {@link #getNodeText} is used on the
 *  node payloads to get the text for the nodes.  Detect
 *  parse trees and extract data appropriately.
 */
", ,/** * Print out a whole tree in LISP form. {@link #getNodeText} is used on the *  node payloads to get the text for the nodes.  Detect *  parse trees and extract data appropriately. */,31,33,[0],0,[0],0,[0],0,0,0,0,toStringTree(Tree),org.antlr.v4.runtime.tree.Trees,toStringTree/1[org.antlr.v4.runtime.tree.Tree],False,31,2,1,0,1,1,1,3,1,0,1,1,1,2,0,0,0,0,0,0,0,0,0,0,0,0,29,9,0,True
623,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\tree\Trees.java,org.antlr.v4.runtime.tree.Trees,"String toStringTree(Tree, Parser)","/**
 * Print out a whole tree in LISP form. {@link #getNodeText} is used on the
 *  node payloads to get the text for the nodes.  Detect
 *  parse trees and extract data appropriately.
 */
public static String toStringTree(Tree t, Parser recog) {
    String[] ruleNames = recog != null ? recog.getRuleNames() : null;
    List<String> ruleNamesList = ruleNames != null ? Arrays.asList(ruleNames) : null;
    return toStringTree(t, ruleNamesList);
}","/**
 * Print out a whole tree in LISP form. {@link #getNodeText} is used on the
 *  node payloads to get the text for the nodes.  Detect
 *  parse trees and extract data appropriately.
 */
", ,/** * Print out a whole tree in LISP form. {@link #getNodeText} is used on the *  node payloads to get the text for the nodes.  Detect *  parse trees and extract data appropriately. */,39,43,[0],0,[0],0,[0],0,0,0,0,"toStringTree(Tree, Parser)",org.antlr.v4.runtime.tree.Trees,"toStringTree/2[org.antlr.v4.runtime.tree.Tree,org.antlr.v4.runtime.Parser]",False,39,4,3,1,2,3,3,5,1,2,2,3,1,2,0,2,0,0,0,0,2,0,0,0,0,0,32,9,0,True
624,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\tree\Trees.java,org.antlr.v4.runtime.tree.Trees,"String toStringTree(Tree, List<String>)","/**
 * Print out a whole tree in LISP form. {@link #getNodeText} is used on the
 *  node payloads to get the text for the nodes.
 */
public static String toStringTree(final Tree t, final List<String> ruleNames) {
    String s = Utils.escapeWhitespace(getNodeText(t, ruleNames), false);
    if (t.getChildCount() == 0)
        return s;
    StringBuilder buf = new StringBuilder();
    buf.append(""("");
    s = Utils.escapeWhitespace(getNodeText(t, ruleNames), false);
    buf.append(s);
    buf.append(' ');
    for (int i = 0; i < t.getChildCount(); i++) {
        if (i > 0)
            buf.append(' ');
        buf.append(toStringTree(t.getChild(i), ruleNames));
    }
    buf.append("")"");
    return buf.toString();
}","/**
 * Print out a whole tree in LISP form. {@link #getNodeText} is used on the
 *  node payloads to get the text for the nodes.
 */
", ,/** * Print out a whole tree in LISP form. {@link #getNodeText} is used on the *  node payloads to get the text for the nodes. */,48,62,[0],0,[0],0,[0],0,0,0,0,"toStringTree(Tree, List<String>)",org.antlr.v4.runtime.tree.Trees,"toStringTree/2[org.antlr.v4.runtime.tree.Tree,java.util.List<java.lang.String>]",False,48,3,9,4,5,4,8,15,2,3,2,8,2,1,1,1,0,0,2,3,4,0,2,0,0,0,29,9,0,True
625,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\tree\Trees.java,org.antlr.v4.runtime.tree.Trees,"String getNodeText(Tree, List<String>)","public static String getNodeText(Tree t, List<String> ruleNames) {
    if (ruleNames != null) {
        if (t instanceof RuleContext) {
            int ruleIndex = ((RuleContext) t).getRuleContext().getRuleIndex();
            String ruleName = ruleNames.get(ruleIndex);
            int altNumber = ((RuleContext) t).getAltNumber();
            if (altNumber != ATN.INVALID_ALT_NUMBER) {
                return ruleName + "":"" + altNumber;
            }
            return ruleName;
        } else if (t instanceof ErrorNode) {
            return t.toString();
        } else if (t instanceof TerminalNode) {
            Token symbol = ((TerminalNode) t).getSymbol();
            if (symbol != null) {
                String s = symbol.getText();
                return s;
            }
        }
    }
    // no recog for rule names
    Object payload = t.getPayload();
    if (payload instanceof Token) {
        return ((Token) payload).getText();
    }
    return t.getPayload().toString();
}", ,"// no recog for rule names
",// no recog for rule names,70,98,[0],0,[0],0,[0],0,0,0,0,"getNodeText(Tree, List<String>)",org.antlr.v4.runtime.tree.Trees,"getNodeText/2[org.antlr.v4.runtime.tree.Tree,java.util.List<java.lang.String>]",False,70,5,9,3,6,8,8,28,6,6,2,8,0,0,0,3,0,4,1,0,6,1,3,0,0,0,21,9,0,False
626,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\tree\Trees.java,org.antlr.v4.runtime.tree.Trees,List<Tree> getChildren(Tree),"/**
 * Return ordered list of all children of this node
 */
public static List<Tree> getChildren(Tree t) {
    List<Tree> kids = new ArrayList<Tree>();
    for (int i = 0; i < t.getChildCount(); i++) {
        kids.add(t.getChild(i));
    }
    return kids;
}","/**
 * Return ordered list of all children of this node
 */
", ,/** * Return ordered list of all children of this node */,101,107,[0],0,[0],0,[0],0,0,0,0,getChildren(Tree),org.antlr.v4.runtime.tree.Trees,getChildren/1[org.antlr.v4.runtime.tree.Tree],False,101,1,5,3,2,2,3,7,1,2,1,3,0,0,1,0,0,0,0,1,2,0,1,0,0,0,13,9,0,True
627,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\tree\Trees.java,org.antlr.v4.runtime.tree.Trees,List<? extends Tree> getAncestors(Tree),"/**
 * Return a list of all ancestors of this node.  The first node of
 *  list is the root and the last is the parent of this node.
 *
 *  @since 4.5.1
 */
public static List<? extends Tree> getAncestors(Tree t) {
    if (t.getParent() == null)
        return Collections.emptyList();
    List<Tree> ancestors = new ArrayList<Tree>();
    t = t.getParent();
    while (t != null) {
        // insert at start
        ancestors.add(0, t);
        t = t.getParent();
    }
    return ancestors;
}","/**
 * Return a list of all ancestors of this node.  The first node of
 *  list is the root and the last is the parent of this node.
 *
 *  @since 4.5.1
 */
","// insert at start
",/** * Return a list of all ancestors of this node.  The first node of *  list is the root and the last is the parent of this node. * *  @since 4.5.1 */[[SEP]]// insert at start,114,123,[0],0,[0],0,"[0, 0]",0,0,0,0,getAncestors(Tree),org.antlr.v4.runtime.tree.Trees,getAncestors/1[org.antlr.v4.runtime.tree.Tree],False,114,1,1,0,1,3,3,10,2,1,1,3,0,0,1,2,0,0,0,1,3,0,1,0,0,0,20,9,0,True
628,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\tree\Trees.java,org.antlr.v4.runtime.tree.Trees,"boolean isAncestorOf(Tree, Tree)","/**
 * Return true if t is u's parent or a node on path to root from u.
 *  Use == not equals().
 *
 *  @since 4.5.1
 */
public static boolean isAncestorOf(Tree t, Tree u) {
    if (t == null || u == null || t.getParent() == null)
        return false;
    Tree p = u.getParent();
    while (p != null) {
        if (t == p)
            return true;
        p = p.getParent();
    }
    return false;
}","/**
 * Return true if t is u's parent or a node on path to root from u.
 *  Use == not equals().
 *
 *  @since 4.5.1
 */
", ,/** * Return true if t is u's parent or a node on path to root from u. *  Use == not equals(). * *  @since 4.5.1 */,130,138,[0],0,[0],0,[0],0,0,0,0,"isAncestorOf(Tree, Tree)",org.antlr.v4.runtime.tree.Trees,"isAncestorOf/2[org.antlr.v4.runtime.tree.Tree,org.antlr.v4.runtime.tree.Tree]",False,130,1,2,1,1,6,1,9,3,1,2,1,0,0,1,5,0,0,0,0,2,0,2,0,0,0,23,9,0,True
629,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\tree\Trees.java,org.antlr.v4.runtime.tree.Trees,"void _findAllNodes(ParseTree, int, boolean, List<? super ParseTree>)","public static void _findAllNodes(ParseTree t, int index, boolean findTokens, List<? super ParseTree> nodes) {
    // check this node (the root) first
    if (findTokens && t instanceof TerminalNode) {
        TerminalNode tnode = (TerminalNode) t;
        if (tnode.getSymbol().getType() == index)
            nodes.add(t);
    } else if (!findTokens && t instanceof ParserRuleContext) {
        ParserRuleContext ctx = (ParserRuleContext) t;
        if (ctx.getRuleIndex() == index)
            nodes.add(t);
    }
    // check children
    for (int i = 0; i < t.getChildCount(); i++) {
        _findAllNodes(t.getChild(i), index, findTokens, nodes);
    }
}", ,"// check this node (the root) first
[[SEP]]// check children
",// check this node (the root) first[[SEP]]// check children,154,170,[0],0,"[0, 0]",0,"[0, 0]",0,0,0,0,"_findAllNodes(ParseTree, int, boolean, List<?ParseTree>)",org.antlr.v4.runtime.tree.Trees,"_findAllNodes/4[org.antlr.v4.runtime.tree.ParseTree,int,boolean,java.util.List<? super org.antlr.v4.runtime.tree.ParseTree>]",False,156,7,8,2,6,8,7,13,0,3,4,7,1,0,1,2,0,0,0,1,3,0,2,0,0,0,18,9,0,False
630,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\tree\Trees.java,org.antlr.v4.runtime.tree.Trees,List<ParseTree> getDescendants(ParseTree),"/**
 * Get all descendents; includes t itself.
 *
 * @since 4.5.1
 */
public static List<ParseTree> getDescendants(ParseTree t) {
    List<ParseTree> nodes = new ArrayList<ParseTree>();
    nodes.add(t);
    int n = t.getChildCount();
    for (int i = 0; i < n; i++) {
        nodes.addAll(getDescendants(t.getChild(i)));
    }
    return nodes;
}","/**
 * Get all descendents; includes t itself.
 *
 * @since 4.5.1
 */
", ,/** * Get all descendents; includes t itself. * * @since 4.5.1 */,176,185,[0],0,[0],0,[0],0,0,0,0,getDescendants(ParseTree),org.antlr.v4.runtime.tree.Trees,getDescendants/1[org.antlr.v4.runtime.tree.ParseTree],False,176,3,6,3,3,2,5,9,1,3,1,5,1,0,1,0,0,0,0,1,3,0,1,0,0,0,12,9,0,True
631,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\tree\Trees.java,org.antlr.v4.runtime.tree.Trees,List<ParseTree> descendants(ParseTree),"/**
 * @deprecated
 */
@Deprecated
public static List<ParseTree> descendants(ParseTree t) {
    return getDescendants(t);
}","/**
 * @deprecated
 */
", ,/** * @deprecated */,188,191,[1],1,[0],0,[1],1,0,0,0,descendants(ParseTree),org.antlr.v4.runtime.tree.Trees,descendants/1[org.antlr.v4.runtime.tree.ParseTree],False,189,2,1,0,1,1,1,3,1,0,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,6,9,0,True
632,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\tree\Trees.java,org.antlr.v4.runtime.tree.Trees,"ParserRuleContext getRootOfSubtreeEnclosingRegion(ParseTree, int, int)","/**
 * Find smallest subtree of t enclosing range startTokenIndex..stopTokenIndex
 *  inclusively using postorder traversal.  Recursive depth-first-search.
 *
 *  @since 4.5.1
 */
public static ParserRuleContext getRootOfSubtreeEnclosingRegion(ParseTree t, // inclusive
int startTokenIndex, // inclusive
int stopTokenIndex) {
    int n = t.getChildCount();
    for (int i = 0; i < n; i++) {
        ParseTree child = t.getChild(i);
        ParserRuleContext r = getRootOfSubtreeEnclosingRegion(child, startTokenIndex, stopTokenIndex);
        if (r != null)
            return r;
    }
    if (t instanceof ParserRuleContext) {
        ParserRuleContext r = (ParserRuleContext) t;
        if (// is range fully contained in t?
        startTokenIndex >= r.getStart().getTokenIndex() && (r.getStop() == null || stopTokenIndex <= r.getStop().getTokenIndex())) {
            // note: r.getStop()==null likely implies that we bailed out of parser and there's nothing to the right
            return r;
        }
    }
    return null;
}","/**
 * Find smallest subtree of t enclosing range startTokenIndex..stopTokenIndex
 *  inclusively using postorder traversal.  Recursive depth-first-search.
 *
 *  @since 4.5.1
 */
","// inclusive
[[SEP]]// inclusive
[[SEP]]// is range fully contained in t?
[[SEP]]// note: r.getStop()==null likely implies that we bailed out of parser and there's nothing to the right
",/** * Find smallest subtree of t enclosing range startTokenIndex..stopTokenIndex *  inclusively using postorder traversal.  Recursive depth-first-search. * *  @since 4.5.1 */[[SEP]]// inclusive[[SEP]]// inclusive[[SEP]]// is range fully contained in t?[[SEP]]// note: r.getStop()==null likely implies that we bailed out of parser and there's nothing to the right,198,218,[0],0,"[0, 0, 0, 0]",0,"[0, 0, 0, 0, 0]",0,0,0,0,"getRootOfSubtreeEnclosingRegion(ParseTree, int, int)",org.antlr.v4.runtime.tree.Trees,"getRootOfSubtreeEnclosingRegion/3[org.antlr.v4.runtime.tree.ParseTree,int,int]",False,201,5,7,1,6,7,6,15,3,5,3,6,1,0,1,2,0,1,0,1,5,0,2,0,0,0,33,9,0,True
633,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\tree\Trees.java,org.antlr.v4.runtime.tree.Trees,"void stripChildrenOutOfRange(ParserRuleContext, ParserRuleContext, int, int)","/**
 * Replace any subtree siblings of root that are completely to left
 *  or right of lookahead range with a CommonToken(Token.INVALID_TYPE,""..."")
 *  node. The source interval for t is not altered to suit smaller range!
 *
 *  WARNING: destructive to t.
 *
 *  @since 4.5.1
 */
public static void stripChildrenOutOfRange(ParserRuleContext t, ParserRuleContext root, int startIndex, int stopIndex) {
    if (t == null)
        return;
    for (int i = 0; i < t.getChildCount(); i++) {
        ParseTree child = t.getChild(i);
        Interval range = child.getSourceInterval();
        if (child instanceof ParserRuleContext && (range.b < startIndex || range.a > stopIndex)) {
            if (isAncestorOf(child, root)) {
                // replace only if subtree doesn't have displayed root
                CommonToken abbrev = new CommonToken(Token.INVALID_TYPE, ""..."");
                t.children.set(i, new TerminalNodeImpl(abbrev));
            }
        }
    }
}","/**
 * Replace any subtree siblings of root that are completely to left
 *  or right of lookahead range with a CommonToken(Token.INVALID_TYPE,""..."")
 *  node. The source interval for t is not altered to suit smaller range!
 *
 *  WARNING: destructive to t.
 *
 *  @since 4.5.1
 */
","// replace only if subtree doesn't have displayed root
","/** * Replace any subtree siblings of root that are completely to left *  or right of lookahead range with a CommonToken(Token.INVALID_TYPE,""..."") *  node. The source interval for t is not altered to suit smaller range! * *  WARNING: destructive to t. * *  @since 4.5.1 */[[SEP]]// replace only if subtree doesn't have displayed root",228,244,[0],0,[0],0,"[0, 0]",0,0,0,0,"stripChildrenOutOfRange(ParserRuleContext, ParserRuleContext, int, int)",org.antlr.v4.runtime.tree.Trees,"stripChildrenOutOfRange/4[org.antlr.v4.runtime.ParserRuleContext,org.antlr.v4.runtime.ParserRuleContext,int,int]",False,232,7,6,0,6,7,5,13,1,4,4,5,1,1,1,1,0,1,1,1,4,0,3,0,0,0,51,9,0,True
634,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\tree\Trees.java,org.antlr.v4.runtime.tree.Trees,"Tree findNodeSuchThat(Tree, Predicate<Tree>)","/**
 * Return first node satisfying the pred
 *
 *  @since 4.5.1
 */
public static Tree findNodeSuchThat(Tree t, Predicate<Tree> pred) {
    if (pred.test(t))
        return t;
    if (t == null)
        return null;
    int n = t.getChildCount();
    for (int i = 0; i < n; i++) {
        Tree u = findNodeSuchThat(t.getChild(i), pred);
        if (u != null)
            return u;
    }
    return null;
}","/**
 * Return first node satisfying the pred
 *
 *  @since 4.5.1
 */
", ,/** * Return first node satisfying the pred * *  @since 4.5.1 */,250,261,[0],0,[0],0,[0],0,0,0,0,"findNodeSuchThat(Tree, Predicate<Tree>)",org.antlr.v4.runtime.tree.Trees,"findNodeSuchThat/2[org.antlr.v4.runtime.tree.Tree,org.antlr.v4.runtime.misc.Predicate<org.antlr.v4.runtime.tree.Tree>]",False,250,3,5,1,4,5,4,10,4,3,2,4,1,0,1,2,0,0,0,1,3,0,2,0,0,0,16,9,0,True
635,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\tree\pattern\ParseTreeMatch.java,org.antlr.v4.runtime.tree.pattern.ParseTreeMatch,ParseTree get(String),"/**
 * Get the last node associated with a specific {@code label}.
 *
 * <p>For example, for pattern {@code <id:ID>}, {@code get(""id"")} returns the
 * node matched for that {@code ID}. If more than one node
 * matched the specified label, only the last is returned. If there is
 * no node associated with the label, this returns {@code null}.</p>
 *
 * <p>Pattern tags like {@code <ID>} and {@code <expr>} without labels are
 * considered to be labeled with {@code ID} and {@code expr}, respectively.</p>
 *
 * @param label The label to check.
 *
 * @return The last {@link ParseTree} to match a tag with the specified
 * label, or {@code null} if no parse tree matched a tag with the label.
 */
public ParseTree get(String label) {
    List<ParseTree> parseTrees = labels.get(label);
    if (parseTrees == null || parseTrees.size() == 0) {
        return null;
    }
    // return last if multiple
    return parseTrees.get(parseTrees.size() - 1);
}", ,"// return last if multiple
","/** * Get the last node associated with a specific {@code label}. * * <p>For example, for pattern {@code <id:ID>}, {@code get(""id"")} returns the * node matched for that {@code ID}. If more than one node * matched the specified label, only the last is returned. If there is * no node associated with the label, this returns {@code null}.</p> * * <p>Pattern tags like {@code <ID>} and {@code <expr>} without labels are * considered to be labeled with {@code ID} and {@code expr}, respectively.</p> * * @param label The label to check. * * @return The last {@link ParseTree} to match a tag with the specified * label, or {@code null} if no parse tree matched a tag with the label. */[[SEP]]// return last if multiple",90,97,[0],0,[0],0,"[0, 0]",0,0,0,0,get(String),org.antlr.v4.runtime.tree.pattern.ParseTreeMatch,get/1[java.lang.String],False,90,1,0,0,0,3,3,7,2,1,1,3,0,0,0,2,0,0,0,2,1,1,1,0,0,0,49,1,0,True
636,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\tree\pattern\ParseTreeMatch.java,org.antlr.v4.runtime.tree.pattern.ParseTreeMatch,boolean succeeded(),"/**
 * Gets a value indicating whether the match operation succeeded.
 *
 * @return {@code true} if the match operation succeeded; otherwise,
 * {@code false}.
 */
public boolean succeeded() {
    return mismatchedNode == null;
}","/**
 * Gets a value indicating whether the match operation succeeded.
 *
 * @return {@code true} if the match operation succeeded; otherwise,
 * {@code false}.
 */
", ,"/** * Gets a value indicating whether the match operation succeeded. * * @return {@code true} if the match operation succeeded; otherwise, * {@code false}. */",164,166,[0],0,[0],0,[0],0,0,0,0,succeeded(),org.antlr.v4.runtime.tree.pattern.ParseTreeMatch,succeeded/0,False,164,0,3,3,0,2,0,3,1,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,14,1,0,True
637,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\tree\pattern\ParseTreeMatch.java,org.antlr.v4.runtime.tree.pattern.ParseTreeMatch,String toString(),"/**
 * {@inheritDoc}
 */
@Override
public String toString() {
    return String.format(""Match %s; found %d labels"", succeeded() ? ""succeeded"" : ""failed"", getLabels().size());
}","/**
 * {@inheritDoc}
 */
", ,/** * {@inheritDoc} */,191,197,[0],0,[0],0,[0],0,0,0,0,toString(),org.antlr.v4.runtime.tree.pattern.ParseTreeMatch,toString/0,False,192,1,2,0,2,2,4,3,1,0,0,4,2,1,0,0,0,0,3,0,0,0,0,0,0,0,3,1,0,True
638,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\tree\pattern\ParseTreePattern.java,org.antlr.v4.runtime.tree.pattern.ParseTreePattern,boolean matches(ParseTree),"/**
 * Determine whether or not a parse tree matches this tree pattern.
 *
 * @param tree The parse tree to match against this tree pattern.
 * @return {@code true} if {@code tree} is a match for the current tree
 * pattern; otherwise, {@code false}.
 */
public boolean matches(ParseTree tree) {
    return matcher.match(tree, this).succeeded();
}","/**
 * Determine whether or not a parse tree matches this tree pattern.
 *
 * @param tree The parse tree to match against this tree pattern.
 * @return {@code true} if {@code tree} is a match for the current tree
 * pattern; otherwise, {@code false}.
 */
", ,"/** * Determine whether or not a parse tree matches this tree pattern. * * @param tree The parse tree to match against this tree pattern. * @return {@code true} if {@code tree} is a match for the current tree * pattern; otherwise, {@code false}. */",83,85,[0],0,[0],0,[0],0,0,0,0,matches(ParseTree),org.antlr.v4.runtime.tree.pattern.ParseTreePattern,matches/1[org.antlr.v4.runtime.tree.ParseTree],False,83,3,2,0,2,1,2,3,1,0,1,2,0,0,0,0,0,0,0,0,0,0,0,0,0,0,20,1,0,True
639,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\tree\pattern\ParseTreePattern.java,org.antlr.v4.runtime.tree.pattern.ParseTreePattern,int getPatternRuleIndex(),"/**
 * Get the parser rule which serves as the outermost rule for the tree
 * pattern.
 *
 * @return The parser rule which serves as the outermost rule for the tree
 * pattern.
 */
public int getPatternRuleIndex() {
    return patternRuleIndex;
}","/**
 * Get the parser rule which serves as the outermost rule for the tree
 * pattern.
 *
 * @return The parser rule which serves as the outermost rule for the tree
 * pattern.
 */
", ,/** * Get the parser rule which serves as the outermost rule for the tree * pattern. * * @return The parser rule which serves as the outermost rule for the tree * pattern. */,139,141,[0],0,[0],0,[0],0,0,0,0,getPatternRuleIndex(),org.antlr.v4.runtime.tree.pattern.ParseTreePattern,getPatternRuleIndex/0,False,139,0,0,0,0,1,0,3,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,15,1,0,True
640,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\tree\pattern\ParseTreePatternMatcher.java,org.antlr.v4.runtime.tree.pattern.ParseTreePatternMatcher,"void setDelimiters(String, String, String)","/**
 * Set the delimiters used for marking rule and token tags within concrete
 * syntax used by the tree pattern parser.
 *
 * @param start The start delimiter.
 * @param stop The stop delimiter.
 * @param escapeLeft The escape sequence to use for escaping a start or stop delimiter.
 *
 * @exception IllegalArgumentException if {@code start} is {@code null} or empty.
 * @exception IllegalArgumentException if {@code stop} is {@code null} or empty.
 */
public void setDelimiters(String start, String stop, String escapeLeft) {
    if (start == null || start.isEmpty()) {
        throw new IllegalArgumentException(""start cannot be null or empty"");
    }
    if (stop == null || stop.isEmpty()) {
        throw new IllegalArgumentException(""stop cannot be null or empty"");
    }
    this.start = start;
    this.stop = stop;
    this.escape = escapeLeft;
}","/**
 * Set the delimiters used for marking rule and token tags within concrete
 * syntax used by the tree pattern parser.
 *
 * @param start The start delimiter.
 * @param stop The stop delimiter.
 * @param escapeLeft The escape sequence to use for escaping a start or stop delimiter.
 *
 * @exception IllegalArgumentException if {@code start} is {@code null} or empty.
 * @exception IllegalArgumentException if {@code stop} is {@code null} or empty.
 */
", ,/** * Set the delimiters used for marking rule and token tags within concrete * syntax used by the tree pattern parser. * * @param start The start delimiter. * @param stop The stop delimiter. * @param escapeLeft The escape sequence to use for escaping a start or stop delimiter. * * @exception IllegalArgumentException if {@code start} is {@code null} or empty. * @exception IllegalArgumentException if {@code stop} is {@code null} or empty. */,135,147,[0],0,[0],0,[0],0,0,0,0,"setDelimiters(String, String, String)",org.antlr.v4.runtime.tree.pattern.ParseTreePatternMatcher,"setDelimiters/3[java.lang.String,java.lang.String,java.lang.String]",False,135,0,0,0,0,5,1,11,0,0,3,1,0,0,0,2,0,0,2,0,3,0,1,0,0,0,35,1,0,True
641,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\tree\pattern\ParseTreePatternMatcher.java,org.antlr.v4.runtime.tree.pattern.ParseTreePatternMatcher,"boolean matches(ParseTree, String, int)","/**
 * Does {@code pattern} matched as rule {@code patternRuleIndex} match {@code tree}?
 */
public boolean matches(ParseTree tree, String pattern, int patternRuleIndex) {
    ParseTreePattern p = compile(pattern, patternRuleIndex);
    return matches(tree, p);
}","/**
 * Does {@code pattern} matched as rule {@code patternRuleIndex} match {@code tree}?
 */
", ,/** * Does {@code pattern} matched as rule {@code patternRuleIndex} match {@code tree}? */,150,153,[0],0,[0],0,[0],0,0,0,0,"matches(ParseTree, String, int)",org.antlr.v4.runtime.tree.pattern.ParseTreePatternMatcher,"matches/3[org.antlr.v4.runtime.tree.ParseTree,java.lang.String,int]",False,150,3,2,0,2,1,2,4,1,1,3,2,2,5,0,0,0,0,0,0,1,0,0,0,0,0,15,1,0,True
642,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\tree\pattern\ParseTreePatternMatcher.java,org.antlr.v4.runtime.tree.pattern.ParseTreePatternMatcher,"boolean matches(ParseTree, ParseTreePattern)","/**
 * Does {@code pattern} matched as rule patternRuleIndex match tree? Pass in a
 *  compiled pattern instead of a string representation of a tree pattern.
 */
public boolean matches(ParseTree tree, ParseTreePattern pattern) {
    MultiMap<String, ParseTree> labels = new MultiMap<String, ParseTree>();
    ParseTree mismatchedNode = matchImpl(tree, pattern.getPatternTree(), labels);
    return mismatchedNode == null;
}","/**
 * Does {@code pattern} matched as rule patternRuleIndex match tree? Pass in a
 *  compiled pattern instead of a string representation of a tree pattern.
 */
", ,/** * Does {@code pattern} matched as rule patternRuleIndex match tree? Pass in a *  compiled pattern instead of a string representation of a tree pattern. */,158,162,[0],0,[0],0,[0],0,0,0,0,"matches(ParseTree, ParseTreePattern)",org.antlr.v4.runtime.tree.pattern.ParseTreePatternMatcher,"matches/2[org.antlr.v4.runtime.tree.ParseTree,org.antlr.v4.runtime.tree.pattern.ParseTreePattern]",False,158,4,4,1,3,2,2,5,1,2,2,2,1,2,0,1,0,0,0,0,2,0,0,0,0,0,25,1,0,True
643,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\tree\pattern\ParseTreePatternMatcher.java,org.antlr.v4.runtime.tree.pattern.ParseTreePatternMatcher,"ParseTreeMatch match(ParseTree, String, int)","/**
 * Compare {@code pattern} matched as rule {@code patternRuleIndex} against
 * {@code tree} and return a {@link ParseTreeMatch} object that contains the
 * matched elements, or the node at which the match failed.
 */
public ParseTreeMatch match(ParseTree tree, String pattern, int patternRuleIndex) {
    ParseTreePattern p = compile(pattern, patternRuleIndex);
    return match(tree, p);
}","/**
 * Compare {@code pattern} matched as rule {@code patternRuleIndex} against
 * {@code tree} and return a {@link ParseTreeMatch} object that contains the
 * matched elements, or the node at which the match failed.
 */
", ,"/** * Compare {@code pattern} matched as rule {@code patternRuleIndex} against * {@code tree} and return a {@link ParseTreeMatch} object that contains the * matched elements, or the node at which the match failed. */",169,172,[0],0,[0],0,[0],0,0,0,0,"match(ParseTree, String, int)",org.antlr.v4.runtime.tree.pattern.ParseTreePatternMatcher,"match/3[org.antlr.v4.runtime.tree.ParseTree,java.lang.String,int]",False,169,4,2,0,2,1,2,4,1,1,3,2,2,5,0,0,0,0,0,0,1,0,0,0,0,0,27,1,0,True
644,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\tree\pattern\ParseTreePatternMatcher.java,org.antlr.v4.runtime.tree.pattern.ParseTreePatternMatcher,"ParseTreePattern compile(String, int)","/**
 * For repeated use of a tree pattern, compile it to a
 * {@link ParseTreePattern} using this method.
 */
public ParseTreePattern compile(String pattern, int patternRuleIndex) {
    List<? extends Token> tokenList = tokenize(pattern);
    ListTokenSource tokenSrc = new ListTokenSource(tokenList);
    CommonTokenStream tokens = new CommonTokenStream(tokenSrc);
    ParserInterpreter parserInterp = new ParserInterpreter(parser.getGrammarFileName(), parser.getVocabulary(), Arrays.asList(parser.getRuleNames()), parser.getATNWithBypassAlts(), tokens);
    ParseTree tree = null;
    try {
        parserInterp.setErrorHandler(new BailErrorStrategy());
        tree = parserInterp.parse(patternRuleIndex);
        // System.out.println(""pattern tree = ""+tree.toStringTree(parserInterp));
    } catch (ParseCancellationException e) {
        throw (RecognitionException) e.getCause();
    } catch (RecognitionException re) {
        throw re;
    } catch (Exception e) {
        throw new CannotInvokeStartRule(e);
    }
    // Make sure tree pattern compilation checks for a complete parse
    if (tokens.LA(1) != Token.EOF) {
        throw new StartRuleDoesNotConsumeFullPattern();
    }
    return new ParseTreePattern(this, pattern, patternRuleIndex, tree);
}","/**
 * For repeated use of a tree pattern, compile it to a
 * {@link ParseTreePattern} using this method.
 */
","// System.out.println(""pattern tree = ""+tree.toStringTree(parserInterp));
[[SEP]]// Make sure tree pattern compilation checks for a complete parse
","/** * For repeated use of a tree pattern, compile it to a * {@link ParseTreePattern} using this method. */[[SEP]]// System.out.println(""pattern tree = ""+tree.toStringTree(parserInterp));[[SEP]]// Make sure tree pattern compilation checks for a complete parse",191,224,[0],0,"[0, 0]",0,"[0, 0, 0]",0,0,0,0,"compile(String, int)",org.antlr.v4.runtime.tree.pattern.ParseTreePatternMatcher,"compile/2[java.lang.String,int]",False,191,13,18,3,15,5,10,24,1,5,2,10,1,2,0,1,1,0,0,1,6,0,1,0,0,0,45,1,0,True
645,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\tree\pattern\ParseTreePatternMatcher.java,org.antlr.v4.runtime.tree.pattern.ParseTreePatternMatcher,"ParseTree matchImpl(ParseTree, ParseTree, MultiMap<String, ParseTree>)","// ---- SUPPORT CODE ----
/**
 * Recursively walk {@code tree} against {@code patternTree}, filling
 * {@code match.}{@link ParseTreeMatch#labels labels}.
 *
 * @return the first node encountered in {@code tree} which does not match
 * a corresponding node in {@code patternTree}, or {@code null} if the match
 * was successful. The specific node returned depends on the matching
 * algorithm used by the implementation, and may be overridden.
 */
protected ParseTree matchImpl(ParseTree tree, ParseTree patternTree, MultiMap<String, ParseTree> labels) {
    if (tree == null) {
        throw new IllegalArgumentException(""tree cannot be null"");
    }
    if (patternTree == null) {
        throw new IllegalArgumentException(""patternTree cannot be null"");
    }
    // x and <ID>, x and y, or x and x; or could be mismatched types
    if (tree instanceof TerminalNode && patternTree instanceof TerminalNode) {
        TerminalNode t1 = (TerminalNode) tree;
        TerminalNode t2 = (TerminalNode) patternTree;
        ParseTree mismatchedNode = null;
        // both are tokens and they have same type
        if (t1.getSymbol().getType() == t2.getSymbol().getType()) {
            if (t2.getSymbol() instanceof TokenTagToken) {
                // x and <ID>
                TokenTagToken tokenTagToken = (TokenTagToken) t2.getSymbol();
                // track label->list-of-nodes for both token name and label (if any)
                labels.map(tokenTagToken.getTokenName(), tree);
                if (tokenTagToken.getLabel() != null) {
                    labels.map(tokenTagToken.getLabel(), tree);
                }
            } else if (t1.getText().equals(t2.getText())) {
                // x and x
            } else {
                // x and y
                if (mismatchedNode == null) {
                    mismatchedNode = t1;
                }
            }
        } else {
            if (mismatchedNode == null) {
                mismatchedNode = t1;
            }
        }
        return mismatchedNode;
    }
    if (tree instanceof ParserRuleContext && patternTree instanceof ParserRuleContext) {
        ParserRuleContext r1 = (ParserRuleContext) tree;
        ParserRuleContext r2 = (ParserRuleContext) patternTree;
        ParseTree mismatchedNode = null;
        // (expr ...) and <expr>
        RuleTagToken ruleTagToken = getRuleTagToken(r2);
        if (ruleTagToken != null) {
            ParseTreeMatch m = null;
            if (r1.getRuleContext().getRuleIndex() == r2.getRuleContext().getRuleIndex()) {
                // track label->list-of-nodes for both rule name and label (if any)
                labels.map(ruleTagToken.getRuleName(), tree);
                if (ruleTagToken.getLabel() != null) {
                    labels.map(ruleTagToken.getLabel(), tree);
                }
            } else {
                if (mismatchedNode == null) {
                    mismatchedNode = r1;
                }
            }
            return mismatchedNode;
        }
        // (expr ...) and (expr ...)
        if (r1.getChildCount() != r2.getChildCount()) {
            if (mismatchedNode == null) {
                mismatchedNode = r1;
            }
            return mismatchedNode;
        }
        int n = r1.getChildCount();
        for (int i = 0; i < n; i++) {
            ParseTree childMatch = matchImpl(r1.getChild(i), patternTree.getChild(i), labels);
            if (childMatch != null) {
                return childMatch;
            }
        }
        return mismatchedNode;
    }
    // if nodes aren't both tokens or both rule nodes, can't match
    return tree;
}", ,"// x and <ID>, x and y, or x and x; or could be mismatched types
[[SEP]]// both are tokens and they have same type
[[SEP]]// x and <ID>
[[SEP]]// track label->list-of-nodes for both token name and label (if any)
[[SEP]]// x and x
[[SEP]]// x and y
[[SEP]]// (expr ...) and <expr>
[[SEP]]// track label->list-of-nodes for both rule name and label (if any)
[[SEP]]// (expr ...) and (expr ...)
[[SEP]]// if nodes aren't both tokens or both rule nodes, can't match
","// ---- SUPPORT CODE ----[[SEP]]/** * Recursively walk {@code tree} against {@code patternTree}, filling * {@code match.}{@link ParseTreeMatch#labels labels}. * * @return the first node encountered in {@code tree} which does not match * a corresponding node in {@code patternTree}, or {@code null} if the match * was successful. The specific node returned depends on the matching * algorithm used by the implementation, and may be overridden. */[[SEP]]// x and <ID>, x and y, or x and x; or could be mismatched types[[SEP]]// both are tokens and they have same type[[SEP]]// x and <ID>[[SEP]]// track label->list-of-nodes for both token name and label (if any)[[SEP]]// x and x[[SEP]]// x and y[[SEP]]// (expr ...) and <expr>[[SEP]]// track label->list-of-nodes for both rule name and label (if any)[[SEP]]// (expr ...) and (expr ...)[[SEP]]// if nodes aren't both tokens or both rule nodes, can't match",256,348,[0],0,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]",0,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]",0,0,0,0,"matchImpl(ParseTree, ParseTree, MultiMap<String, ParseTree>)",org.antlr.v4.runtime.tree.pattern.ParseTreePatternMatcher,"matchImpl/3[org.antlr.v4.runtime.tree.ParseTree,org.antlr.v4.runtime.tree.ParseTree,org.antlr.v4.runtime.misc.MultiMap<java.lang.String,org.antlr.v4.runtime.tree.ParseTree>]",False,259,10,18,3,15,21,16,71,6,12,3,16,2,1,1,13,0,0,2,1,16,0,4,0,0,0,60,4,0,True
646,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\tree\pattern\ParseTreePatternMatcher.java,org.antlr.v4.runtime.tree.pattern.ParseTreePatternMatcher,RuleTagToken getRuleTagToken(ParseTree),"/**
 * Is {@code t} {@code (expr <expr>)} subtree?
 */
protected RuleTagToken getRuleTagToken(ParseTree t) {
    if (t instanceof RuleNode) {
        RuleNode r = (RuleNode) t;
        if (r.getChildCount() == 1 && r.getChild(0) instanceof TerminalNode) {
            TerminalNode c = (TerminalNode) r.getChild(0);
            if (c.getSymbol() instanceof RuleTagToken) {
                // System.out.println(""rule tag subtree ""+t.toStringTree(parser));
                return (RuleTagToken) c.getSymbol();
            }
        }
    }
    return null;
}","/**
 * Is {@code t} {@code (expr <expr>)} subtree?
 */
","// System.out.println(""rule tag subtree ""+t.toStringTree(parser));
","/** * Is {@code t} {@code (expr <expr>)} subtree? */[[SEP]]// System.out.println(""rule tag subtree ""+t.toStringTree(parser));",351,363,[0],0,[0],0,"[0, 0]",0,0,0,0,getRuleTagToken(ParseTree),org.antlr.v4.runtime.tree.pattern.ParseTreePatternMatcher,getRuleTagToken/1[org.antlr.v4.runtime.tree.ParseTree],False,351,6,4,1,3,5,3,12,2,2,1,3,0,0,0,1,0,0,0,3,2,0,3,0,0,0,14,4,0,True
647,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\tree\pattern\ParseTreePatternMatcher.java,org.antlr.v4.runtime.tree.pattern.ParseTreePatternMatcher,List<? extends Token> tokenize(String),"public List<? extends Token> tokenize(String pattern) {
    // split pattern into chunks: sea (raw input) and islands (<ID>, <expr>)
    List<Chunk> chunks = split(pattern);
    // create token stream from text and tags
    List<Token> tokens = new ArrayList<Token>();
    for (Chunk chunk : chunks) {
        if (chunk instanceof TagChunk) {
            TagChunk tagChunk = (TagChunk) chunk;
            // add special rule token or conjure up new token from name
            if (Character.isUpperCase(tagChunk.getTag().charAt(0))) {
                Integer ttype = parser.getTokenType(tagChunk.getTag());
                if (ttype == Token.INVALID_TYPE) {
                    throw new IllegalArgumentException(""Unknown token "" + tagChunk.getTag() + "" in pattern: "" + pattern);
                }
                TokenTagToken t = new TokenTagToken(tagChunk.getTag(), ttype, tagChunk.getLabel());
                tokens.add(t);
            } else if (Character.isLowerCase(tagChunk.getTag().charAt(0))) {
                int ruleIndex = parser.getRuleIndex(tagChunk.getTag());
                if (ruleIndex == -1) {
                    throw new IllegalArgumentException(""Unknown rule "" + tagChunk.getTag() + "" in pattern: "" + pattern);
                }
                int ruleImaginaryTokenType = parser.getATNWithBypassAlts().ruleToTokenType[ruleIndex];
                tokens.add(new RuleTagToken(tagChunk.getTag(), ruleImaginaryTokenType, tagChunk.getLabel()));
            } else {
                throw new IllegalArgumentException(""invalid tag: "" + tagChunk.getTag() + "" in pattern: "" + pattern);
            }
        } else {
            TextChunk textChunk = (TextChunk) chunk;
            ANTLRInputStream in = new ANTLRInputStream(textChunk.getText());
            lexer.setInputStream(in);
            Token t = lexer.nextToken();
            while (t.getType() != Token.EOF) {
                tokens.add(t);
                t = lexer.nextToken();
            }
        }
    }
    // System.out.println(""tokens=""+tokens);
    return tokens;
}", ,"// split pattern into chunks: sea (raw input) and islands (<ID>, <expr>)
[[SEP]]// create token stream from text and tags
[[SEP]]// add special rule token or conjure up new token from name
[[SEP]]// System.out.println(""tokens=""+tokens);
","// split pattern into chunks: sea (raw input) and islands (<ID>, <expr>)[[SEP]]// create token stream from text and tags[[SEP]]// add special rule token or conjure up new token from name[[SEP]]// System.out.println(""tokens=""+tokens);",365,409,[0],0,"[0, 0, 0, 0]",0,"[0, 0, 0, 0]",0,0,0,0,tokenize(String),org.antlr.v4.runtime.tree.pattern.ParseTreePatternMatcher,tokenize/1[java.lang.String],False,365,11,14,1,13,8,14,39,1,10,1,14,1,1,2,3,0,0,6,3,11,3,4,0,0,0,32,1,0,False
648,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\tree\pattern\ParseTreePatternMatcher.java,org.antlr.v4.runtime.tree.pattern.ParseTreePatternMatcher,List<Chunk> split(String),"/**
 * Split {@code <ID> = <e:expr> ;} into 4 chunks for tokenizing by {@link #tokenize}.
 */
public List<Chunk> split(String pattern) {
    int p = 0;
    int n = pattern.length();
    List<Chunk> chunks = new ArrayList<Chunk>();
    StringBuilder buf = new StringBuilder();
    // find all start and stop indexes first, then collect
    List<Integer> starts = new ArrayList<Integer>();
    List<Integer> stops = new ArrayList<Integer>();
    while (p < n) {
        if (p == pattern.indexOf(escape + start, p)) {
            p += escape.length() + start.length();
        } else if (p == pattern.indexOf(escape + stop, p)) {
            p += escape.length() + stop.length();
        } else if (p == pattern.indexOf(start, p)) {
            starts.add(p);
            p += start.length();
        } else if (p == pattern.indexOf(stop, p)) {
            stops.add(p);
            p += stop.length();
        } else {
            p++;
        }
    }
    // System.out.println("""");
    // System.out.println(starts);
    // System.out.println(stops);
    if (starts.size() > stops.size()) {
        throw new IllegalArgumentException(""unterminated tag in pattern: "" + pattern);
    }
    if (starts.size() < stops.size()) {
        throw new IllegalArgumentException(""missing start tag in pattern: "" + pattern);
    }
    int ntags = starts.size();
    for (int i = 0; i < ntags; i++) {
        if (starts.get(i) >= stops.get(i)) {
            throw new IllegalArgumentException(""tag delimiters out of order in pattern: "" + pattern);
        }
    }
    // collect into chunks now
    if (ntags == 0) {
        String text = pattern.substring(0, n);
        chunks.add(new TextChunk(text));
    }
    if (ntags > 0 && starts.get(0) > 0) {
        // copy text up to first tag into chunks
        String text = pattern.substring(0, starts.get(0));
        chunks.add(new TextChunk(text));
    }
    for (int i = 0; i < ntags; i++) {
        // copy inside of <tag>
        String tag = pattern.substring(starts.get(i) + start.length(), stops.get(i));
        String ruleOrToken = tag;
        String label = null;
        int colon = tag.indexOf(':');
        if (colon >= 0) {
            label = tag.substring(0, colon);
            ruleOrToken = tag.substring(colon + 1, tag.length());
        }
        chunks.add(new TagChunk(label, ruleOrToken));
        if (i + 1 < ntags) {
            // copy from end of <tag> to start of next
            String text = pattern.substring(stops.get(i) + stop.length(), starts.get(i + 1));
            chunks.add(new TextChunk(text));
        }
    }
    if (ntags > 0) {
        int afterLastTag = stops.get(ntags - 1) + stop.length();
        if (afterLastTag < n) {
            // copy text from end of last tag to end
            String text = pattern.substring(afterLastTag, n);
            chunks.add(new TextChunk(text));
        }
    }
    // strip out the escape sequences from text chunks but not tags
    for (int i = 0; i < chunks.size(); i++) {
        Chunk c = chunks.get(i);
        if (c instanceof TextChunk) {
            TextChunk tc = (TextChunk) c;
            String unescaped = tc.getText().replace(escape, """");
            if (unescaped.length() < tc.getText().length()) {
                chunks.set(i, new TextChunk(unescaped));
            }
        }
    }
    return chunks;
}","/**
 * Split {@code <ID> = <e:expr> ;} into 4 chunks for tokenizing by {@link #tokenize}.
 */
","// System.out.println("""");
[[SEP]]// System.out.println(starts);
[[SEP]]// find all start and stop indexes first, then collect
[[SEP]]// System.out.println(stops);
[[SEP]]// collect into chunks now
[[SEP]]// copy text up to first tag into chunks
[[SEP]]// copy inside of <tag>
[[SEP]]// copy from end of <tag> to start of next
[[SEP]]// copy text from end of last tag to end
[[SEP]]// strip out the escape sequences from text chunks but not tags
","/** * Split {@code <ID> = <e:expr> ;} into 4 chunks for tokenizing by {@link #tokenize}. */[[SEP]]// find all start and stop indexes first, then collect[[SEP]]// System.out.println("""");// System.out.println(starts);// System.out.println(stops);[[SEP]]// collect into chunks now[[SEP]]// copy text up to first tag into chunks[[SEP]]// copy inside of <tag>[[SEP]]// copy from end of <tag> to start of next[[SEP]]// copy text from end of last tag to end[[SEP]]// strip out the escape sequences from text chunks but not tags",412,506,[0],0,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]",0,"[0, 0, 0, 0, 0, 0, 0, 0, 0]",0,0,0,0,split(String),org.antlr.v4.runtime.tree.pattern.ParseTreePatternMatcher,split/1[java.lang.String],False,412,3,4,1,3,21,13,80,1,22,1,13,0,0,4,5,0,0,4,18,28,14,3,0,0,0,42,1,0,True
649,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\tree\pattern\RuleTagToken.java,org.antlr.v4.runtime.tree.pattern.RuleTagToken,int getChannel(),"/**
 * {@inheritDoc}
 *
 * <p>Rule tag tokens are always placed on the {@link #DEFAULT_CHANNEL}.</p>
 */
@Override
public int getChannel() {
    return DEFAULT_CHANNEL;
}","/**
 * {@inheritDoc}
 *
 * <p>Rule tag tokens are always placed on the {@link #DEFAULT_CHANNEL}.</p>
 */
", ,/** * {@inheritDoc} * * <p>Rule tag tokens are always placed on the {@link #DEFAULT_CHANNEL}.</p> */,95,98,[0],0,[0],0,[0],0,0,0,0,getChannel(),org.antlr.v4.runtime.tree.pattern.RuleTagToken,getChannel/0,False,96,0,0,0,0,1,0,3,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,22,1,0,True
650,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\tree\pattern\RuleTagToken.java,org.antlr.v4.runtime.tree.pattern.RuleTagToken,String getText(),"/**
 * {@inheritDoc}
 *
 * <p>This method returns the rule tag formatted with {@code <} and {@code >}
 * delimiters.</p>
 */
@Override
public String getText() {
    if (label != null) {
        return ""<"" + label + "":"" + ruleName + "">"";
    }
    return ""<"" + ruleName + "">"";
}","/**
 * {@inheritDoc}
 *
 * <p>This method returns the rule tag formatted with {@code <} and {@code >}
 * delimiters.</p>
 */
", ,/** * {@inheritDoc} * * <p>This method returns the rule tag formatted with {@code <} and {@code >} * delimiters.</p> */,106,113,[0],0,[0],0,[0],0,0,0,0,getText(),org.antlr.v4.runtime.tree.pattern.RuleTagToken,getText/0,False,107,0,0,0,0,2,0,6,2,0,0,0,0,0,0,1,0,0,5,0,0,2,1,0,0,0,15,1,0,True
651,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\tree\pattern\RuleTagToken.java,org.antlr.v4.runtime.tree.pattern.RuleTagToken,int getType(),"/**
 * {@inheritDoc}
 *
 * <p>Rule tag tokens have types assigned according to the rule bypass
 * transitions created during ATN deserialization.</p>
 */
@Override
public int getType() {
    return bypassTokenType;
}","/**
 * {@inheritDoc}
 *
 * <p>Rule tag tokens have types assigned according to the rule bypass
 * transitions created during ATN deserialization.</p>
 */
", ,/** * {@inheritDoc} * * <p>Rule tag tokens have types assigned according to the rule bypass * transitions created during ATN deserialization.</p> */,121,124,[0],0,[0],0,[0],0,0,0,0,getType(),org.antlr.v4.runtime.tree.pattern.RuleTagToken,getType/0,False,122,0,0,0,0,1,0,3,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,21,1,0,True
652,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\tree\pattern\RuleTagToken.java,org.antlr.v4.runtime.tree.pattern.RuleTagToken,int getLine(),"/**
 * {@inheritDoc}
 *
 * <p>The implementation for {@link RuleTagToken} always returns 0.</p>
 */
@Override
public int getLine() {
    return 0;
}","/**
 * {@inheritDoc}
 *
 * <p>The implementation for {@link RuleTagToken} always returns 0.</p>
 */
", ,/** * {@inheritDoc} * * <p>The implementation for {@link RuleTagToken} always returns 0.</p> */,131,134,[0],0,[0],0,[0],0,0,0,0,getLine(),org.antlr.v4.runtime.tree.pattern.RuleTagToken,getLine/0,False,132,0,0,0,0,1,0,3,1,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,10,1,0,True
653,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\tree\pattern\RuleTagToken.java,org.antlr.v4.runtime.tree.pattern.RuleTagToken,int getCharPositionInLine(),"/**
 * {@inheritDoc}
 *
 * <p>The implementation for {@link RuleTagToken} always returns -1.</p>
 */
@Override
public int getCharPositionInLine() {
    return -1;
}","/**
 * {@inheritDoc}
 *
 * <p>The implementation for {@link RuleTagToken} always returns -1.</p>
 */
", ,/** * {@inheritDoc} * * <p>The implementation for {@link RuleTagToken} always returns -1.</p> */,141,144,[0],0,[0],0,[0],0,0,0,0,getCharPositionInLine(),org.antlr.v4.runtime.tree.pattern.RuleTagToken,getCharPositionInLine/0,False,142,0,0,0,0,1,0,3,1,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,13,1,0,True
654,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\tree\pattern\RuleTagToken.java,org.antlr.v4.runtime.tree.pattern.RuleTagToken,int getTokenIndex(),"/**
 * {@inheritDoc}
 *
 * <p>The implementation for {@link RuleTagToken} always returns -1.</p>
 */
@Override
public int getTokenIndex() {
    return -1;
}","/**
 * {@inheritDoc}
 *
 * <p>The implementation for {@link RuleTagToken} always returns -1.</p>
 */
", ,/** * {@inheritDoc} * * <p>The implementation for {@link RuleTagToken} always returns -1.</p> */,151,154,[0],0,[0],0,[0],0,0,0,0,getTokenIndex(),org.antlr.v4.runtime.tree.pattern.RuleTagToken,getTokenIndex/0,False,152,0,0,0,0,1,0,3,1,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,10,1,0,True
655,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\tree\pattern\RuleTagToken.java,org.antlr.v4.runtime.tree.pattern.RuleTagToken,int getStartIndex(),"/**
 * {@inheritDoc}
 *
 * <p>The implementation for {@link RuleTagToken} always returns -1.</p>
 */
@Override
public int getStartIndex() {
    return -1;
}","/**
 * {@inheritDoc}
 *
 * <p>The implementation for {@link RuleTagToken} always returns -1.</p>
 */
", ,/** * {@inheritDoc} * * <p>The implementation for {@link RuleTagToken} always returns -1.</p> */,161,164,[0],0,[0],0,[0],0,0,0,0,getStartIndex(),org.antlr.v4.runtime.tree.pattern.RuleTagToken,getStartIndex/0,False,162,0,0,0,0,1,0,3,1,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,11,1,0,True
656,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\tree\pattern\RuleTagToken.java,org.antlr.v4.runtime.tree.pattern.RuleTagToken,int getStopIndex(),"/**
 * {@inheritDoc}
 *
 * <p>The implementation for {@link RuleTagToken} always returns -1.</p>
 */
@Override
public int getStopIndex() {
    return -1;
}","/**
 * {@inheritDoc}
 *
 * <p>The implementation for {@link RuleTagToken} always returns -1.</p>
 */
", ,/** * {@inheritDoc} * * <p>The implementation for {@link RuleTagToken} always returns -1.</p> */,171,174,[0],0,[0],0,[0],0,0,0,0,getStopIndex(),org.antlr.v4.runtime.tree.pattern.RuleTagToken,getStopIndex/0,False,172,0,0,0,0,1,0,3,1,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,11,1,0,True
657,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\tree\pattern\RuleTagToken.java,org.antlr.v4.runtime.tree.pattern.RuleTagToken,TokenSource getTokenSource(),"/**
 * {@inheritDoc}
 *
 * <p>The implementation for {@link RuleTagToken} always returns {@code null}.</p>
 */
@Override
public TokenSource getTokenSource() {
    return null;
}","/**
 * {@inheritDoc}
 *
 * <p>The implementation for {@link RuleTagToken} always returns {@code null}.</p>
 */
", ,/** * {@inheritDoc} * * <p>The implementation for {@link RuleTagToken} always returns {@code null}.</p> */,181,184,[0],0,[0],0,[0],0,0,0,0,getTokenSource(),org.antlr.v4.runtime.tree.pattern.RuleTagToken,getTokenSource/0,False,182,1,0,0,0,1,0,3,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,11,1,0,True
658,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\tree\pattern\RuleTagToken.java,org.antlr.v4.runtime.tree.pattern.RuleTagToken,CharStream getInputStream(),"/**
 * {@inheritDoc}
 *
 * <p>The implementation for {@link RuleTagToken} always returns {@code null}.</p>
 */
@Override
public CharStream getInputStream() {
    return null;
}","/**
 * {@inheritDoc}
 *
 * <p>The implementation for {@link RuleTagToken} always returns {@code null}.</p>
 */
", ,/** * {@inheritDoc} * * <p>The implementation for {@link RuleTagToken} always returns {@code null}.</p> */,191,194,[0],0,[0],0,[0],0,0,0,0,getInputStream(),org.antlr.v4.runtime.tree.pattern.RuleTagToken,getInputStream/0,False,192,1,0,0,0,1,0,3,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,13,1,0,True
659,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\tree\pattern\RuleTagToken.java,org.antlr.v4.runtime.tree.pattern.RuleTagToken,String toString(),"/**
 * {@inheritDoc}
 *
 * <p>The implementation for {@link RuleTagToken} returns a string of the form
 * {@code ruleName:bypassTokenType}.</p>
 */
@Override
public String toString() {
    return ruleName + "":"" + bypassTokenType;
}","/**
 * {@inheritDoc}
 *
 * <p>The implementation for {@link RuleTagToken} returns a string of the form
 * {@code ruleName:bypassTokenType}.</p>
 */
", ,/** * {@inheritDoc} * * <p>The implementation for {@link RuleTagToken} returns a string of the form * {@code ruleName:bypassTokenType}.</p> */,202,205,[0],0,[0],0,[0],0,0,0,0,toString(),org.antlr.v4.runtime.tree.pattern.RuleTagToken,toString/0,False,203,0,0,0,0,1,0,3,1,0,0,0,0,0,0,0,0,0,1,0,0,1,0,0,0,0,18,1,0,True
660,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\tree\pattern\TagChunk.java,org.antlr.v4.runtime.tree.pattern.TagChunk,String toString(),"/**
 * This method returns a text representation of the tag chunk. Labeled tags
 * are returned in the form {@code label:tag}, and unlabeled tags are
 * returned as just the tag name.
 */
@Override
public String toString() {
    if (label != null) {
        return label + "":"" + tag;
    }
    return tag;
}","/**
 * This method returns a text representation of the tag chunk. Labeled tags
 * are returned in the form {@code label:tag}, and unlabeled tags are
 * returned as just the tag name.
 */
", ,"/** * This method returns a text representation of the tag chunk. Labeled tags * are returned in the form {@code label:tag}, and unlabeled tags are * returned as just the tag name. */",94,101,[0],0,[0],0,[0],0,0,0,0,toString(),org.antlr.v4.runtime.tree.pattern.TagChunk,toString/0,False,95,0,0,0,0,2,0,6,2,0,0,0,0,0,0,1,0,0,1,0,0,1,1,0,0,0,23,1,0,True
661,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\tree\pattern\TextChunk.java,org.antlr.v4.runtime.tree.pattern.TextChunk,String toString(),"/**
 * {@inheritDoc}
 *
 * <p>The implementation for {@link TextChunk} returns the result of
 * {@link #getText()} in single quotes.</p>
 */
@Override
public String toString() {
    return ""'"" + text + ""'"";
}","/**
 * {@inheritDoc}
 *
 * <p>The implementation for {@link TextChunk} returns the result of
 * {@link #getText()} in single quotes.</p>
 */
", ,/** * {@inheritDoc} * * <p>The implementation for {@link TextChunk} returns the result of * {@link #getText()} in single quotes.</p> */,50,53,[0],0,[0],0,[0],0,0,0,0,toString(),org.antlr.v4.runtime.tree.pattern.TextChunk,toString/0,False,51,0,0,0,0,1,0,3,1,0,0,0,0,0,0,0,0,0,2,0,0,1,0,0,0,0,14,1,0,True
662,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\tree\pattern\TokenTagToken.java,org.antlr.v4.runtime.tree.pattern.TokenTagToken,String getText(),"/**
 * {@inheritDoc}
 *
 * <p>The implementation for {@link TokenTagToken} returns the token tag
 * formatted with {@code <} and {@code >} delimiters.</p>
 */
@Override
public String getText() {
    if (label != null) {
        return ""<"" + label + "":"" + tokenName + "">"";
    }
    return ""<"" + tokenName + "">"";
}","/**
 * {@inheritDoc}
 *
 * <p>The implementation for {@link TokenTagToken} returns the token tag
 * formatted with {@code <} and {@code >} delimiters.</p>
 */
", ,/** * {@inheritDoc} * * <p>The implementation for {@link TokenTagToken} returns the token tag * formatted with {@code <} and {@code >} delimiters.</p> */,81,88,[0],0,[0],0,[0],0,0,0,0,getText(),org.antlr.v4.runtime.tree.pattern.TokenTagToken,getText/0,False,82,0,0,0,0,2,0,6,2,0,0,0,0,0,0,1,0,0,5,0,0,2,1,0,0,0,16,1,0,True
663,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\tree\pattern\TokenTagToken.java,org.antlr.v4.runtime.tree.pattern.TokenTagToken,String toString(),"/**
 * {@inheritDoc}
 *
 * <p>The implementation for {@link TokenTagToken} returns a string of the form
 * {@code tokenName:type}.</p>
 */
@Override
public String toString() {
    return tokenName + "":"" + type;
}","/**
 * {@inheritDoc}
 *
 * <p>The implementation for {@link TokenTagToken} returns a string of the form
 * {@code tokenName:type}.</p>
 */
", ,/** * {@inheritDoc} * * <p>The implementation for {@link TokenTagToken} returns a string of the form * {@code tokenName:type}.</p> */,96,99,[0],0,[0],0,[0],0,0,0,0,toString(),org.antlr.v4.runtime.tree.pattern.TokenTagToken,toString/0,False,97,0,0,0,0,1,0,3,1,0,0,0,0,0,0,0,0,0,1,0,0,1,0,0,0,0,16,1,0,True
664,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\tree\xpath\XPath.java,org.antlr.v4.runtime.tree.xpath.XPath,XPathElement[] split(String),"// TODO: check for invalid token/rule names, bad syntax
public XPathElement[] split(String path) {
    ANTLRInputStream in;
    try {
        in = new ANTLRInputStream(new StringReader(path));
    } catch (IOException ioe) {
        throw new IllegalArgumentException(""Could not read path: "" + path, ioe);
    }
    XPathLexer lexer = new XPathLexer(in) {

        @Override
        public void recover(LexerNoViableAltException e) {
            throw e;
        }
    };
    lexer.removeErrorListeners();
    lexer.addErrorListener(new XPathLexerErrorListener());
    CommonTokenStream tokenStream = new CommonTokenStream(lexer);
    try {
        tokenStream.fill();
    } catch (LexerNoViableAltException e) {
        int pos = lexer.getCharPositionInLine();
        String msg = ""Invalid tokens or characters at index "" + pos + "" in path '"" + path + ""'"";
        throw new IllegalArgumentException(msg, e);
    }
    List<Token> tokens = tokenStream.getTokens();
    // System.out.println(""path=""+path+""=>""+tokens);
    List<XPathElement> elements = new ArrayList<XPathElement>();
    int n = tokens.size();
    int i = 0;
    loop: while (i < n) {
        Token el = tokens.get(i);
        Token next = null;
        switch(el.getType()) {
            case XPathLexer.ROOT:
            case XPathLexer.ANYWHERE:
                boolean anywhere = el.getType() == XPathLexer.ANYWHERE;
                i++;
                next = tokens.get(i);
                boolean invert = next.getType() == XPathLexer.BANG;
                if (invert) {
                    i++;
                    next = tokens.get(i);
                }
                XPathElement pathElement = getXPathElement(next, anywhere);
                pathElement.invert = invert;
                elements.add(pathElement);
                i++;
                break;
            case XPathLexer.TOKEN_REF:
            case XPathLexer.RULE_REF:
            case XPathLexer.WILDCARD:
                elements.add(getXPathElement(el, false));
                i++;
                break;
            case Token.EOF:
                break loop;
            default:
                throw new IllegalArgumentException(""Unknowth path element "" + el);
        }
    }
    return elements.toArray(new XPathElement[0]);
}", ,"// System.out.println(""path=""+path+""=>""+tokens);
","// TODO: check for invalid token/rule names, bad syntax[[SEP]]// System.out.println(""path=""+path+""=>""+tokens);",85,150,[0],0,[0],0,"[1, 0]",1,1,1,1,split(String),org.antlr.v4.runtime.tree.xpath.XPath,split/1[java.lang.String],False,85,9,12,1,11,11,11,62,1,14,1,11,1,1,1,2,2,0,5,2,17,3,3,1,0,0,53,1,0,False
665,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\tree\xpath\XPath.java,org.antlr.v4.runtime.tree.xpath.XPath,"XPathElement getXPathElement(Token, boolean)","/**
 * Convert word like {@code *} or {@code ID} or {@code expr} to a path
 * element. {@code anywhere} is {@code true} if {@code //} precedes the
 * word.
 */
protected XPathElement getXPathElement(Token wordToken, boolean anywhere) {
    if (wordToken.getType() == Token.EOF) {
        throw new IllegalArgumentException(""Missing path element at end of path"");
    }
    String word = wordToken.getText();
    int ttype = parser.getTokenType(word);
    int ruleIndex = parser.getRuleIndex(word);
    switch(wordToken.getType()) {
        case XPathLexer.WILDCARD:
            return anywhere ? new XPathWildcardAnywhereElement() : new XPathWildcardElement();
        case XPathLexer.TOKEN_REF:
        case XPathLexer.STRING:
            if (ttype == Token.INVALID_TYPE) {
                throw new IllegalArgumentException(word + "" at index "" + wordToken.getStartIndex() + "" isn't a valid token name"");
            }
            return anywhere ? new XPathTokenAnywhereElement(word, ttype) : new XPathTokenElement(word, ttype);
        default:
            if (ruleIndex == -1) {
                throw new IllegalArgumentException(word + "" at index "" + wordToken.getStartIndex() + "" isn't a valid rule name"");
            }
            return anywhere ? new XPathRuleAnywhereElement(word, ruleIndex) : new XPathRuleElement(word, ruleIndex);
    }
}","/**
 * Convert word like {@code *} or {@code ID} or {@code expr} to a path
 * element. {@code anywhere} is {@code true} if {@code //} precedes the
 * word.
 */
", ,/** * Convert word like {@code *} or {@code ID} or {@code expr} to a path * element. {@code anywhere} is {@code true} if {@code //} precedes the * word. */,157,191,[0],0,[0],0,[0],0,0,0,0,"getXPathElement(Token, boolean)",org.antlr.v4.runtime.tree.xpath.XPath,"getXPathElement/2[org.antlr.v4.runtime.Token,boolean]",False,157,10,12,1,11,10,5,23,3,3,2,5,0,0,0,3,0,0,5,1,3,2,2,0,0,0,35,4,0,True
666,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\tree\xpath\XPath.java,org.antlr.v4.runtime.tree.xpath.XPath,Collection<ParseTree> evaluate(ParseTree),"/**
 * Return a list of all nodes starting at {@code t} as root that satisfy the
 * path. The root {@code /} is relative to the node passed to
 * {@link #evaluate}.
 */
public Collection<ParseTree> evaluate(final ParseTree t) {
    ParserRuleContext dummyRoot = new ParserRuleContext();
    // don't set t's parent.
    dummyRoot.children = Collections.singletonList(t);
    Collection<ParseTree> work = Collections.<ParseTree>singleton(dummyRoot);
    int i = 0;
    while (i < elements.length) {
        Collection<ParseTree> next = new LinkedHashSet<ParseTree>();
        for (ParseTree node : work) {
            if (node.getChildCount() > 0) {
                // only try to match next element if it has children
                // e.g., //func/*/stat might have a token node for which
                // we can't go looking for stat nodes.
                Collection<? extends ParseTree> matching = elements[i].evaluate(node);
                next.addAll(matching);
            }
        }
        i++;
        work = next;
    }
    return work;
}","/**
 * Return a list of all nodes starting at {@code t} as root that satisfy the
 * path. The root {@code /} is relative to the node passed to
 * {@link #evaluate}.
 */
","// don't set t's parent.
[[SEP]]// only try to match next element if it has children
[[SEP]]// e.g., //func/*/stat might have a token node for which
[[SEP]]// we can't go looking for stat nodes.
","/** * Return a list of all nodes starting at {@code t} as root that satisfy the * path. The root {@code /} is relative to the node passed to * {@link #evaluate}. */[[SEP]]// don't set t's parent.[[SEP]]// only try to match next element if it has children// e.g., //func/*/stat might have a token node for which// we can't go looking for stat nodes.",204,227,[0],0,"[0, 0, 0, 0]",0,"[0, 0, 0]",0,0,0,0,evaluate(ParseTree),org.antlr.v4.runtime.tree.xpath.XPath,evaluate/1[org.antlr.v4.runtime.tree.ParseTree],False,204,4,4,1,3,4,5,18,1,5,1,5,0,0,2,0,0,0,0,2,7,0,3,0,0,0,33,1,0,True
667,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\tree\xpath\XPathElement.java,org.antlr.v4.runtime.tree.xpath.XPathElement,Collection<ParseTree> evaluate(ParseTree),"/**
 * Given tree rooted at {@code t} return all nodes matched by this path
 * element.
 */
public abstract Collection<ParseTree> evaluate(ParseTree t);","/**
 * Given tree rooted at {@code t} return all nodes matched by this path
 * element.
 */
", ,/** * Given tree rooted at {@code t} return all nodes matched by this path * element. */,28,28,[0],0,[0],0,[0],0,0,0,0,evaluate(ParseTree),org.antlr.v4.runtime.tree.xpath.XPathElement,evaluate/1[org.antlr.v4.runtime.tree.ParseTree],False,24,1,1,1,0,1,0,1,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,12,1025,0,True
668,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\tree\xpath\XPathLexer.java,org.antlr.v4.runtime.tree.xpath.XPathLexer,String matchID(),"public String matchID() {
    int start = _input.index();
    // drop start char
    consume();
    while (isNameChar(_input.LA(1))) {
        consume();
    }
    return _input.getText(Interval.of(start, _input.index() - 1));
}", ,"// drop start char
",// drop start char,157,164,[0],0,[0],0,[0],0,0,0,0,matchID(),org.antlr.v4.runtime.tree.xpath.XPathLexer,matchID/0,False,157,4,7,1,6,2,6,8,1,1,0,6,2,1,1,0,0,0,0,2,1,1,1,0,0,0,8,1,0,False
669,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\tree\xpath\XPathLexer.java,org.antlr.v4.runtime.tree.xpath.XPathLexer,String matchString(),"public String matchString() {
    int start = _input.index();
    // drop first quote
    consume();
    while (_input.LA(1) != '\'') {
        consume();
    }
    // drop last quote
    consume();
    return _input.getText(Interval.of(start, _input.index() - 1));
}", ,"// drop first quote
[[SEP]]// drop last quote
",// drop first quote[[SEP]]// drop last quote,166,174,[0],0,"[0, 0]",0,"[0, 0]",0,0,0,0,matchString(),org.antlr.v4.runtime.tree.xpath.XPathLexer,matchString/0,False,166,4,6,1,5,2,5,9,1,1,0,5,1,1,1,1,0,0,0,2,1,1,1,0,0,0,4,1,0,False
670,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\tree\xpath\XPathRuleElement.java,org.antlr.v4.runtime.tree.xpath.XPathRuleElement,Collection<ParseTree> evaluate(ParseTree),"@Override
public Collection<ParseTree> evaluate(ParseTree t) {
    // return all children of t that match nodeName
    List<ParseTree> nodes = new ArrayList<ParseTree>();
    for (Tree c : Trees.getChildren(t)) {
        if (c instanceof ParserRuleContext) {
            ParserRuleContext ctx = (ParserRuleContext) c;
            if ((ctx.getRuleIndex() == ruleIndex && !invert) || (ctx.getRuleIndex() != ruleIndex && invert)) {
                nodes.add(ctx);
            }
        }
    }
    return nodes;
}", ,"// return all children of t that match nodeName
",// return all children of t that match nodeName,25,40,[0],0,[0],0,[0],0,0,0,0,evaluate(ParseTree),org.antlr.v4.runtime.tree.xpath.XPathRuleElement,evaluate/1[org.antlr.v4.runtime.tree.ParseTree],False,26,5,2,0,2,7,3,12,1,2,1,3,0,0,1,2,0,2,0,0,2,0,3,0,0,0,13,1,0,False
671,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\tree\xpath\XPathTokenElement.java,org.antlr.v4.runtime.tree.xpath.XPathTokenElement,Collection<ParseTree> evaluate(ParseTree),"@Override
public Collection<ParseTree> evaluate(ParseTree t) {
    // return all children of t that match nodeName
    List<ParseTree> nodes = new ArrayList<ParseTree>();
    for (Tree c : Trees.getChildren(t)) {
        if (c instanceof TerminalNode) {
            TerminalNode tnode = (TerminalNode) c;
            if ((tnode.getSymbol().getType() == tokenType && !invert) || (tnode.getSymbol().getType() != tokenType && invert)) {
                nodes.add(tnode);
            }
        }
    }
    return nodes;
}", ,"// return all children of t that match nodeName
",// return all children of t that match nodeName,25,40,[0],0,[0],0,[0],0,0,0,0,evaluate(ParseTree),org.antlr.v4.runtime.tree.xpath.XPathTokenElement,evaluate/1[org.antlr.v4.runtime.tree.ParseTree],False,26,5,3,0,3,7,4,12,1,2,1,4,0,0,1,2,0,2,0,0,2,0,3,0,0,0,12,1,0,False
672,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\tree\xpath\XPathWildcardAnywhereElement.java,org.antlr.v4.runtime.tree.xpath.XPathWildcardAnywhereElement,Collection<ParseTree> evaluate(ParseTree),"@Override
public Collection<ParseTree> evaluate(ParseTree t) {
    // !* is weird but valid (empty)
    if (invert)
        return new ArrayList<ParseTree>();
    return Trees.getDescendants(t);
}", ,"// !* is weird but valid (empty)
",// !* is weird but valid (empty),20,24,[0],0,[0],0,[0],0,0,0,0,evaluate(ParseTree),org.antlr.v4.runtime.tree.xpath.XPathWildcardAnywhereElement,evaluate/1[org.antlr.v4.runtime.tree.ParseTree],False,21,2,1,0,1,2,1,4,2,0,1,1,0,0,0,0,0,0,0,0,0,0,1,0,0,0,5,1,0,False
673,..\projects\antlr4-4.11.0\runtime\Java\src\org\antlr\v4\runtime\tree\xpath\XPathWildcardElement.java,org.antlr.v4.runtime.tree.xpath.XPathWildcardElement,Collection<ParseTree> evaluate(ParseTree),"@Override
public Collection<ParseTree> evaluate(final ParseTree t) {
    // !* is weird but valid (empty)
    if (invert)
        return new ArrayList<ParseTree>();
    List<ParseTree> kids = new ArrayList<ParseTree>();
    for (Tree c : Trees.getChildren(t)) {
        kids.add((ParseTree) c);
    }
    return kids;
}", ,"// !* is weird but valid (empty)
",// !* is weird but valid (empty),22,30,[0],0,[0],0,[0],0,0,0,0,evaluate(ParseTree),org.antlr.v4.runtime.tree.xpath.XPathWildcardElement,evaluate/1[org.antlr.v4.runtime.tree.ParseTree],False,23,2,1,0,1,3,2,8,2,1,1,2,0,0,1,0,0,0,0,0,1,0,1,0,0,0,7,1,0,False
674,..\projects\antlr4-4.11.0\tool-testsuite\test\org\antlr\v4\test\tool\ATNDescriber.java,org.antlr.v4.test.tool.ATNDescriber,String decode(int[]),"/**
 * For testing really; gives a human readable version of the ATN
 */
public String decode(int[] data) {
    StringBuilder buf = new StringBuilder();
    int p = 0;
    int version = data[p++];
    if (version != ATNDeserializer.SERIALIZED_VERSION) {
        String reason = String.format(""Could not deserialize ATN with version %d (expected %d)."", version, ATNDeserializer.SERIALIZED_VERSION);
        throw new UnsupportedOperationException(new InvalidClassException(ATN.class.getName(), reason));
    }
    // skip grammarType
    p++;
    int maxType = data[p++];
    buf.append(""max type "").append(maxType).append(""\n"");
    int nstates = data[p++];
    for (int i = 0; i < nstates; i++) {
        int stype = data[p++];
        // ignore bad type of states
        if (stype == ATNState.INVALID_TYPE)
            continue;
        int ruleIndex = data[p++];
        if (ruleIndex == Character.MAX_VALUE) {
            ruleIndex = -1;
        }
        String arg = """";
        if (stype == ATNState.LOOP_END) {
            int loopBackStateNumber = data[p++];
            arg = "" "" + loopBackStateNumber;
        } else if (stype == ATNState.PLUS_BLOCK_START || stype == ATNState.STAR_BLOCK_START || stype == ATNState.BLOCK_START) {
            int endStateNumber = data[p++];
            arg = "" "" + endStateNumber;
        }
        buf.append(i).append("":"").append(ATNState.serializationNames.get(stype)).append("" "").append(ruleIndex).append(arg).append(""\n"");
    }
    // this code is meant to model the form of ATNDeserializer.deserialize,
    // since both need to be updated together whenever a change is made to
    // the serialization format. The ""dead"" code is only used in debugging
    // and testing scenarios, so the form you see here was kept for
    // improved maintainability.
    // start
    int numNonGreedyStates = data[p++];
    for (int i = 0; i < numNonGreedyStates; i++) {
        int stateNumber = data[p++];
    }
    int numPrecedenceStates = data[p++];
    for (int i = 0; i < numPrecedenceStates; i++) {
        int stateNumber = data[p++];
    }
    // finish
    int nrules = data[p++];
    for (int i = 0; i < nrules; i++) {
        int s = data[p++];
        if (atn.grammarType == ATNType.LEXER) {
            int arg1 = data[p++];
            buf.append(""rule "").append(i).append("":"").append(s).append("" "").append(arg1).append('\n');
        } else {
            buf.append(""rule "").append(i).append("":"").append(s).append('\n');
        }
    }
    int nmodes = data[p++];
    for (int i = 0; i < nmodes; i++) {
        int s = data[p++];
        buf.append(""mode "").append(i).append("":"").append(s).append('\n');
    }
    int numBMPSets = data[p++];
    p = appendSets(buf, data, p, numBMPSets);
    int nedges = data[p++];
    for (int i = 0; i < nedges; i++) {
        int src = data[p];
        int trg = data[p + 1];
        int ttype = data[p + 2];
        int arg1 = data[p + 3];
        int arg2 = data[p + 4];
        int arg3 = data[p + 5];
        buf.append(src).append(""->"").append(trg).append("" "").append(Transition.serializationNames.get(ttype)).append("" "").append(arg1).append("","").append(arg2).append("","").append(arg3).append(""\n"");
        p += 6;
    }
    int ndecisions = data[p++];
    for (int i = 0; i < ndecisions; i++) {
        int s = data[p++];
        buf.append(i).append("":"").append(s).append(""\n"");
    }
    if (atn.grammarType == ATNType.LEXER) {
        // this code is meant to model the form of ATNDeserializer.deserialize,
        // since both need to be updated together whenever a change is made to
        // the serialization format. The ""dead"" code is only used in debugging
        // and testing scenarios, so the form you see here was kept for
        // improved maintainability.
        int lexerActionCount = data[p++];
        for (int i = 0; i < lexerActionCount; i++) {
            LexerActionType actionType = LexerActionType.values()[data[p++]];
            int data1 = data[p++];
            int data2 = data[p++];
        }
    }
    return buf.toString();
}","/**
 * For testing really; gives a human readable version of the ATN
 */
","// this code is meant to model the form of ATNDeserializer.deserialize,
[[SEP]]// since both need to be updated together whenever a change is made to
[[SEP]]// the serialization format. The ""dead"" code is only used in debugging
[[SEP]]// and testing scenarios, so the form you see here was kept for
[[SEP]]// improved maintainability.
[[SEP]]// skip grammarType
[[SEP]]// ignore bad type of states
[[SEP]]// start
[[SEP]]// finish
[[SEP]]// this code is meant to model the form of ATNDeserializer.deserialize,
[[SEP]]// since both need to be updated together whenever a change is made to
[[SEP]]// the serialization format. The ""dead"" code is only used in debugging
[[SEP]]// and testing scenarios, so the form you see here was kept for
[[SEP]]// improved maintainability.
","/** * For testing really; gives a human readable version of the ATN */[[SEP]]// skip grammarType[[SEP]]// ignore bad type of states[[SEP]]// this code is meant to model the form of ATNDeserializer.deserialize,// since both need to be updated together whenever a change is made to// the serialization format. The ""dead"" code is only used in debugging// and testing scenarios, so the form you see here was kept for// improved maintainability.// start[[SEP]]// finish[[SEP]]// this code is meant to model the form of ATNDeserializer.deserialize,// since both need to be updated together whenever a change is made to// the serialization format. The ""dead"" code is only used in debugging// and testing scenarios, so the form you see here was kept for// improved maintainability.",37,137,[0],0,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]",0,"[0, 0, 0, 0, 0, 0]",0,0,0,0,decode(int[]),org.antlr.v4.test.tool.ATNDescriber,decode/1[int[]],False,37,4,29,28,1,18,11,82,1,42,1,11,1,2,8,9,0,0,24,16,47,7,2,0,0,0,72,1,0,True
675,..\projects\antlr4-4.11.0\tool-testsuite\test\org\antlr\v4\test\tool\ATNDescriber.java,org.antlr.v4.test.tool.ATNDescriber,String getTokenName(int),"public String getTokenName(int t) {
    if (t == -1)
        return ""EOF"";
    if (atn.grammarType == ATNType.LEXER && t >= Character.MIN_VALUE && t <= Character.MAX_VALUE) {
        switch(t) {
            case '\n':
                return ""'\\n'"";
            case '\r':
                return ""'\\r'"";
            case '\t':
                return ""'\\t'"";
            case '\b':
                return ""'\\b'"";
            case '\f':
                return ""'\\f'"";
            case '\\':
                return ""'\\\\'"";
            case '\'':
                return ""'\\''"";
            default:
                if (Character.UnicodeBlock.of((char) t) == Character.UnicodeBlock.BASIC_LATIN && !Character.isISOControl((char) t)) {
                    return '\'' + Character.toString((char) t) + '\'';
                }
                // turn on the bit above max ""\uFFFF"" value so that we pad with zeros
                // then only take last 4 digits
                String hex = Integer.toHexString(t | 0x10000).toUpperCase().substring(1, 5);
                String unicodeStr = ""'\\u"" + hex + ""'"";
                return unicodeStr;
        }
    }
    if (tokenNames != null && t >= 0 && t < tokenNames.size()) {
        return tokenNames.get(t);
    }
    return String.valueOf(t);
}", ,"// turn on the bit above max ""\uFFFF"" value so that we pad with zeros
[[SEP]]// then only take last 4 digits
","// turn on the bit above max ""\uFFFF"" value so that we pad with zeros// then only take last 4 digits",162,201,[0],0,"[0, 0]",0,[0],0,0,0,0,getTokenName(int),org.antlr.v4.test.tool.ATNDescriber,getTokenName/1[int],False,162,0,1,1,0,17,9,32,12,2,1,9,0,0,0,4,0,0,10,5,2,2,3,0,0,0,11,1,0,False
676,..\projects\antlr4-4.11.0\tool-testsuite\test\org\antlr\v4\test\tool\JavaUnicodeInputStream.java,org.antlr.v4.test.tool.JavaUnicodeInputStream,void consume(),"@Override
public void consume() {
    if (la1 != '\\') {
        source.consume();
        la1 = source.LA(1);
        range = Math.max(range, source.index());
        slashCount = 0;
        return;
    }
    // make sure the next character has been processed
    this.LA(1);
    if (escapeListIndex >= escapeIndexes.size() || escapeIndexes.get(escapeListIndex) != index()) {
        source.consume();
        slashCount++;
    } else {
        int indirectionLevel = escapeIndirectionLevels.get(escapeListIndex);
        for (int i = 0; i < 6 + indirectionLevel; i++) {
            source.consume();
        }
        escapeListIndex++;
        slashCount = 0;
    }
    la1 = source.LA(1);
    assert range >= index();
}", ,"// make sure the next character has been processed
",// make sure the next character has been processed,59,88,[0],0,[0],0,[0],0,0,0,0,consume(),org.antlr.v4.test.tool.JavaUnicodeInputStream,consume/0,False,60,1,2,0,2,6,8,24,1,2,0,8,2,3,1,2,0,0,0,7,7,1,2,0,0,0,13,1,0,False
677,..\projects\antlr4-4.11.0\tool-testsuite\test\org\antlr\v4\test\tool\TestASTStructure.java,org.antlr.v4.test.tool.TestASTStructure,"Object execParser(String, String, int)","public Object execParser(String ruleName, String input, int scriptLine) throws Exception {
    ANTLRStringStream is = new ANTLRStringStream(input);
    Class<? extends TokenSource> lexerClass = Class.forName(lexerClassName).asSubclass(TokenSource.class);
    Constructor<? extends TokenSource> lexConstructor = lexerClass.getConstructor(CharStream.class);
    TokenSource lexer = lexConstructor.newInstance(is);
    is.setLine(scriptLine);
    CommonTokenStream tokens = new CommonTokenStream(lexer);
    Class<? extends Parser> parserClass = Class.forName(parserClassName).asSubclass(Parser.class);
    Constructor<? extends Parser> parConstructor = parserClass.getConstructor(TokenStream.class);
    Parser parser = parConstructor.newInstance(tokens);
    // set up customized tree adaptor if necessary
    if (adaptorClassName != null) {
        Method m = parserClass.getMethod(""setTreeAdaptor"", TreeAdaptor.class);
        Class<? extends TreeAdaptor> adaptorClass = Class.forName(adaptorClassName).asSubclass(TreeAdaptor.class);
        m.invoke(parser, adaptorClass.newInstance());
    }
    Method ruleMethod = parserClass.getMethod(ruleName);
    // INVOKE RULE
    return ruleMethod.invoke(parser);
}", ,"// set up customized tree adaptor if necessary
[[SEP]]// INVOKE RULE
",// set up customized tree adaptor if necessary[[SEP]]// INVOKE RULE,30,59,[0],0,"[0, 0]",0,"[0, 0]",0,0,0,0,"execParser(String, String, int)",org.antlr.v4.test.tool.TestASTStructure,"execParser/3[java.lang.String,java.lang.String,int]",False,35,7,41,41,0,2,10,18,1,11,3,10,0,0,0,1,0,0,1,0,11,0,1,0,0,0,33,1,0,False
678,..\projects\antlr4-4.11.0\tool-testsuite\test\org\antlr\v4\test\tool\TestASTStructure.java,org.antlr.v4.test.tool.TestASTStructure,void test_grammarSpec1(),"@Test
public void test_grammarSpec1() throws Exception {
    // gunit test on line 15
    RuleReturnScope rstruct = (RuleReturnScope) execParser(""grammarSpec"", ""parser grammar P; a : A;"", 15);
    Object actual = ((Tree) rstruct.getTree()).toStringTree();
    Object expecting = ""(PARSER_GRAMMAR P (RULES (RULE a (BLOCK (ALT A)))))"";
    assertEquals(expecting, actual, ""testing rule grammarSpec"");
}", ,"// gunit test on line 15
",// gunit test on line 15,61,67,[0],0,[0],0,[0],0,0,0,0,test_grammarSpec1(),org.antlr.v4.test.tool.TestASTStructure,test_grammarSpec1/0,False,61,4,1,0,1,1,4,6,0,3,0,4,1,1,0,0,0,1,4,1,3,0,0,0,0,0,33,1,0,False
679,..\projects\antlr4-4.11.0\tool-testsuite\test\org\antlr\v4\test\tool\TestASTStructure.java,org.antlr.v4.test.tool.TestASTStructure,void test_grammarSpec2(),"@Test
public void test_grammarSpec2() throws Exception {
    // gunit test on line 18
    RuleReturnScope rstruct = (RuleReturnScope) execParser(""grammarSpec"", ""\n    parser grammar P;\n    tokens { A, B }\n    @header {foo}\n    a : A;\n    "", 18);
    Object actual = ((Tree) rstruct.getTree()).toStringTree();
    Object expecting = ""(PARSER_GRAMMAR P (tokens { A B) (@ header {foo}) (RULES (RULE a (BLOCK (ALT A)))))"";
    assertEquals(expecting, actual, ""testing rule grammarSpec"");
}", ,"// gunit test on line 18
",// gunit test on line 18,69,75,[0],0,[0],0,[0],0,0,0,0,test_grammarSpec2(),org.antlr.v4.test.tool.TestASTStructure,test_grammarSpec2/0,False,69,4,1,0,1,1,4,6,0,3,0,4,1,1,0,0,0,1,4,1,3,0,0,0,0,0,37,1,0,False
680,..\projects\antlr4-4.11.0\tool-testsuite\test\org\antlr\v4\test\tool\TestASTStructure.java,org.antlr.v4.test.tool.TestASTStructure,void test_grammarSpec3(),"@Test
public void test_grammarSpec3() throws Exception {
    // gunit test on line 30
    RuleReturnScope rstruct = (RuleReturnScope) execParser(""grammarSpec"", ""\n    parser grammar P;\n    @header {foo}\n    tokens { A,B }\n    a : A;\n    "", 30);
    Object actual = ((Tree) rstruct.getTree()).toStringTree();
    Object expecting = ""(PARSER_GRAMMAR P (@ header {foo}) (tokens { A B) (RULES (RULE a (BLOCK (ALT A)))))"";
    assertEquals(expecting, actual, ""testing rule grammarSpec"");
}", ,"// gunit test on line 30
",// gunit test on line 30,77,83,[0],0,[0],0,[0],0,0,0,0,test_grammarSpec3(),org.antlr.v4.test.tool.TestASTStructure,test_grammarSpec3/0,False,77,4,1,0,1,1,4,6,0,3,0,4,1,1,0,0,0,1,4,1,3,0,0,0,0,0,37,1,0,False
681,..\projects\antlr4-4.11.0\tool-testsuite\test\org\antlr\v4\test\tool\TestASTStructure.java,org.antlr.v4.test.tool.TestASTStructure,void test_grammarSpec4(),"@Test
public void test_grammarSpec4() throws Exception {
    // gunit test on line 42
    RuleReturnScope rstruct = (RuleReturnScope) execParser(""grammarSpec"", ""\n    parser grammar P;\n    import A=B, C;\n    a : A;\n    "", 42);
    Object actual = ((Tree) rstruct.getTree()).toStringTree();
    Object expecting = ""(PARSER_GRAMMAR P (import (= A B) C) (RULES (RULE a (BLOCK (ALT A)))))"";
    assertEquals(expecting, actual, ""testing rule grammarSpec"");
}", ,"// gunit test on line 42
",// gunit test on line 42,85,91,[0],0,[0],0,[0],0,0,0,0,test_grammarSpec4(),org.antlr.v4.test.tool.TestASTStructure,test_grammarSpec4/0,False,85,4,1,0,1,1,4,6,0,3,0,4,1,1,0,0,0,1,4,1,3,0,0,0,0,0,34,1,0,False
682,..\projects\antlr4-4.11.0\tool-testsuite\test\org\antlr\v4\test\tool\TestASTStructure.java,org.antlr.v4.test.tool.TestASTStructure,void test_delegateGrammars1(),"@Test
public void test_delegateGrammars1() throws Exception {
    // gunit test on line 53
    RuleReturnScope rstruct = (RuleReturnScope) execParser(""delegateGrammars"", ""import A;"", 53);
    Object actual = ((Tree) rstruct.getTree()).toStringTree();
    Object expecting = ""(import A)"";
    assertEquals(expecting, actual, ""testing rule delegateGrammars"");
}", ,"// gunit test on line 53
",// gunit test on line 53,91,97,[0],0,[0],0,[0],0,0,0,0,test_delegateGrammars1(),org.antlr.v4.test.tool.TestASTStructure,test_delegateGrammars1/0,False,91,4,1,0,1,1,4,6,0,3,0,4,1,1,0,0,0,1,4,1,3,0,0,0,0,0,18,1,0,False
683,..\projects\antlr4-4.11.0\tool-testsuite\test\org\antlr\v4\test\tool\TestASTStructure.java,org.antlr.v4.test.tool.TestASTStructure,void test_rule1(),"@Test
public void test_rule1() throws Exception {
    // gunit test on line 56
    RuleReturnScope rstruct = (RuleReturnScope) execParser(""rule"", ""a : A<X,Y=a.b.c>;"", 56);
    Object actual = ((Tree) rstruct.getTree()).toStringTree();
    Object expecting = ""(RULE a (BLOCK (ALT (A (ELEMENT_OPTIONS X (= Y a.b.c))))))"";
    assertEquals(expecting, actual, ""testing rule rule"");
}", ,"// gunit test on line 56
",// gunit test on line 56,97,103,[0],0,[0],0,[0],0,0,0,0,test_rule1(),org.antlr.v4.test.tool.TestASTStructure,test_rule1/0,False,97,4,1,0,1,1,4,6,0,3,0,4,1,1,0,0,0,1,4,1,3,0,0,0,0,0,35,1,0,False
684,..\projects\antlr4-4.11.0\tool-testsuite\test\org\antlr\v4\test\tool\TestASTStructure.java,org.antlr.v4.test.tool.TestASTStructure,void test_rule2(),"@Test
public void test_rule2() throws Exception {
    // gunit test on line 58
    RuleReturnScope rstruct = (RuleReturnScope) execParser(""rule"", ""A : B+;"", 58);
    Object actual = ((Tree) rstruct.getTree()).toStringTree();
    Object expecting = ""(RULE A (BLOCK (ALT (+ (BLOCK (ALT B))))))"";
    assertEquals(expecting, actual, ""testing rule rule"");
}", ,"// gunit test on line 58
",// gunit test on line 58,105,111,[0],0,[0],0,[0],0,0,0,0,test_rule2(),org.antlr.v4.test.tool.TestASTStructure,test_rule2/0,False,105,4,1,0,1,1,4,6,0,3,0,4,1,1,0,0,0,1,4,1,3,0,0,0,0,0,26,1,0,False
685,..\projects\antlr4-4.11.0\tool-testsuite\test\org\antlr\v4\test\tool\TestASTStructure.java,org.antlr.v4.test.tool.TestASTStructure,void test_rule3(),"@Test
public void test_rule3() throws Exception {
    // gunit test on line 60
    RuleReturnScope rstruct = (RuleReturnScope) execParser(""rule"", ""\n    a[int i] returns [int y]\n    @init {blort}\n      : ID ;\n    "", 60);
    Object actual = ((Tree) rstruct.getTree()).toStringTree();
    Object expecting = ""(RULE a int i (returns int y) (@ init {blort}) (BLOCK (ALT ID)))"";
    assertEquals(expecting, actual, ""testing rule rule"");
}", ,"// gunit test on line 60
",// gunit test on line 60,113,119,[0],0,[0],0,[0],0,0,0,0,test_rule3(),org.antlr.v4.test.tool.TestASTStructure,test_rule3/0,False,113,4,1,0,1,1,4,6,0,3,0,4,1,1,0,0,0,1,4,1,3,0,0,0,0,0,34,1,0,False
686,..\projects\antlr4-4.11.0\tool-testsuite\test\org\antlr\v4\test\tool\TestASTStructure.java,org.antlr.v4.test.tool.TestASTStructure,void test_rule4(),"@Test
public void test_rule4() throws Exception {
    // gunit test on line 75
    RuleReturnScope rstruct = (RuleReturnScope) execParser(""rule"", ""\n    a[int i] returns [int y]\n    @init {blort}\n    options {backtrack=true;}\n      : ID;\n    "", 75);
    Object actual = ((Tree) rstruct.getTree()).toStringTree();
    Object expecting = ""(RULE a int i (returns int y) (@ init {blort}) (OPTIONS (= backtrack true)) (BLOCK (ALT ID)))"";
    assertEquals(expecting, actual, ""testing rule rule"");
}", ,"// gunit test on line 75
",// gunit test on line 75,121,127,[0],0,[0],0,[0],0,0,0,0,test_rule4(),org.antlr.v4.test.tool.TestASTStructure,test_rule4/0,False,121,4,1,0,1,1,4,6,0,3,0,4,1,1,0,0,0,1,4,1,3,0,0,0,0,0,40,1,0,False
687,..\projects\antlr4-4.11.0\tool-testsuite\test\org\antlr\v4\test\tool\TestASTStructure.java,org.antlr.v4.test.tool.TestASTStructure,void test_rule5(),"@Test
public void test_rule5() throws Exception {
    // gunit test on line 88
    RuleReturnScope rstruct = (RuleReturnScope) execParser(""rule"", ""\n    a : ID ;\n      catch[A b] {foo}\n      finally {bar}\n    "", 88);
    Object actual = ((Tree) rstruct.getTree()).toStringTree();
    Object expecting = ""(RULE a (BLOCK (ALT ID)) (catch A b {foo}) (finally {bar}))"";
    assertEquals(expecting, actual, ""testing rule rule"");
}", ,"// gunit test on line 88
",// gunit test on line 88,129,135,[0],0,[0],0,[0],0,0,0,0,test_rule5(),org.antlr.v4.test.tool.TestASTStructure,test_rule5/0,False,129,4,1,0,1,1,4,6,0,3,0,4,1,1,0,0,0,1,4,1,3,0,0,0,0,0,32,1,0,False
688,..\projects\antlr4-4.11.0\tool-testsuite\test\org\antlr\v4\test\tool\TestASTStructure.java,org.antlr.v4.test.tool.TestASTStructure,void test_rule6(),"@Test
public void test_rule6() throws Exception {
    // gunit test on line 97
    RuleReturnScope rstruct = (RuleReturnScope) execParser(""rule"", ""\n    a : ID ;\n      catch[A a] {foo}\n      catch[B b] {fu}\n      finally {bar}\n    "", 97);
    Object actual = ((Tree) rstruct.getTree()).toStringTree();
    Object expecting = ""(RULE a (BLOCK (ALT ID)) (catch A a {foo}) (catch B b {fu}) (finally {bar}))"";
    assertEquals(expecting, actual, ""testing rule rule"");
}", ,"// gunit test on line 97
",// gunit test on line 97,137,143,[0],0,[0],0,[0],0,0,0,0,test_rule6(),org.antlr.v4.test.tool.TestASTStructure,test_rule6/0,False,137,4,1,0,1,1,4,6,0,3,0,4,1,1,0,0,0,1,4,1,3,0,0,0,0,0,33,1,0,False
689,..\projects\antlr4-4.11.0\tool-testsuite\test\org\antlr\v4\test\tool\TestASTStructure.java,org.antlr.v4.test.tool.TestASTStructure,void test_rule7(),"@Test
public void test_rule7() throws Exception {
    // gunit test on line 107
    RuleReturnScope rstruct = (RuleReturnScope) execParser(""rule"", ""\n\ta[int i]\n\tlocals [int a, float b]\n\t\t:\tA\n\t\t;\n\t"", 107);
    Object actual = ((Tree) rstruct.getTree()).toStringTree();
    Object expecting = ""(RULE a int i (locals int a, float b) (BLOCK (ALT A)))"";
    assertEquals(expecting, actual, ""testing rule rule"");
}", ,"// gunit test on line 107
",// gunit test on line 107,145,151,[0],0,[0],0,[0],0,0,0,0,test_rule7(),org.antlr.v4.test.tool.TestASTStructure,test_rule7/0,False,145,4,1,0,1,1,4,6,0,3,0,4,1,1,0,0,0,1,4,1,3,0,0,0,0,0,30,1,0,False
690,..\projects\antlr4-4.11.0\tool-testsuite\test\org\antlr\v4\test\tool\TestASTStructure.java,org.antlr.v4.test.tool.TestASTStructure,void test_rule8(),"@Test
public void test_rule8() throws Exception {
    // gunit test on line 115
    RuleReturnScope rstruct = (RuleReturnScope) execParser(""rule"", ""\n\ta[int i] throws a.b.c\n\t\t:\tA\n\t\t;\n\t"", 115);
    Object actual = ((Tree) rstruct.getTree()).toStringTree();
    Object expecting = ""(RULE a int i (throws a.b.c) (BLOCK (ALT A)))"";
    assertEquals(expecting, actual, ""testing rule rule"");
}", ,"// gunit test on line 115
",// gunit test on line 115,153,159,[0],0,[0],0,[0],0,0,0,0,test_rule8(),org.antlr.v4.test.tool.TestASTStructure,test_rule8/0,False,153,4,1,0,1,1,4,6,0,3,0,4,1,1,0,0,0,1,4,1,3,0,0,0,0,0,28,1,0,False
691,..\projects\antlr4-4.11.0\tool-testsuite\test\org\antlr\v4\test\tool\TestASTStructure.java,org.antlr.v4.test.tool.TestASTStructure,void test_ebnf1(),"@Test
public void test_ebnf1() throws Exception {
    // gunit test on line 123
    RuleReturnScope rstruct = (RuleReturnScope) execParser(""ebnf"", ""(A|B)"", 123);
    Object actual = ((Tree) rstruct.getTree()).toStringTree();
    Object expecting = ""(BLOCK (ALT A) (ALT B))"";
    assertEquals(expecting, actual, ""testing rule ebnf"");
}", ,"// gunit test on line 123
",// gunit test on line 123,159,165,[0],0,[0],0,[0],0,0,0,0,test_ebnf1(),org.antlr.v4.test.tool.TestASTStructure,test_ebnf1/0,False,159,4,1,0,1,1,4,6,0,3,0,4,1,1,0,0,0,1,4,1,3,0,0,0,0,0,23,1,0,False
692,..\projects\antlr4-4.11.0\tool-testsuite\test\org\antlr\v4\test\tool\TestASTStructure.java,org.antlr.v4.test.tool.TestASTStructure,void test_ebnf2(),"@Test
public void test_ebnf2() throws Exception {
    // gunit test on line 124
    RuleReturnScope rstruct = (RuleReturnScope) execParser(""ebnf"", ""(A|B)?"", 124);
    Object actual = ((Tree) rstruct.getTree()).toStringTree();
    Object expecting = ""(? (BLOCK (ALT A) (ALT B)))"";
    assertEquals(expecting, actual, ""testing rule ebnf"");
}", ,"// gunit test on line 124
",// gunit test on line 124,167,173,[0],0,[0],0,[0],0,0,0,0,test_ebnf2(),org.antlr.v4.test.tool.TestASTStructure,test_ebnf2/0,False,167,4,1,0,1,1,4,6,0,3,0,4,1,1,0,0,0,1,4,1,3,0,0,0,0,0,23,1,0,False
693,..\projects\antlr4-4.11.0\tool-testsuite\test\org\antlr\v4\test\tool\TestASTStructure.java,org.antlr.v4.test.tool.TestASTStructure,void test_ebnf3(),"@Test
public void test_ebnf3() throws Exception {
    // gunit test on line 125
    RuleReturnScope rstruct = (RuleReturnScope) execParser(""ebnf"", ""(A|B)*"", 125);
    Object actual = ((Tree) rstruct.getTree()).toStringTree();
    Object expecting = ""(* (BLOCK (ALT A) (ALT B)))"";
    assertEquals(expecting, actual, ""testing rule ebnf"");
}", ,"// gunit test on line 125
",// gunit test on line 125,175,181,[0],0,[0],0,[0],0,0,0,0,test_ebnf3(),org.antlr.v4.test.tool.TestASTStructure,test_ebnf3/0,False,175,4,1,0,1,1,4,6,0,3,0,4,1,1,0,0,0,1,4,1,3,0,0,0,0,0,23,1,0,False
694,..\projects\antlr4-4.11.0\tool-testsuite\test\org\antlr\v4\test\tool\TestASTStructure.java,org.antlr.v4.test.tool.TestASTStructure,void test_ebnf4(),"@Test
public void test_ebnf4() throws Exception {
    // gunit test on line 126
    RuleReturnScope rstruct = (RuleReturnScope) execParser(""ebnf"", ""(A|B)+"", 126);
    Object actual = ((Tree) rstruct.getTree()).toStringTree();
    Object expecting = ""(+ (BLOCK (ALT A) (ALT B)))"";
    assertEquals(expecting, actual, ""testing rule ebnf"");
}", ,"// gunit test on line 126
",// gunit test on line 126,183,189,[0],0,[0],0,[0],0,0,0,0,test_ebnf4(),org.antlr.v4.test.tool.TestASTStructure,test_ebnf4/0,False,183,4,1,0,1,1,4,6,0,3,0,4,1,1,0,0,0,1,4,1,3,0,0,0,0,0,23,1,0,False
695,..\projects\antlr4-4.11.0\tool-testsuite\test\org\antlr\v4\test\tool\TestASTStructure.java,org.antlr.v4.test.tool.TestASTStructure,void test_element1(),"@Test
public void test_element1() throws Exception {
    // gunit test on line 129
    RuleReturnScope rstruct = (RuleReturnScope) execParser(""element"", ""~A"", 129);
    Object actual = ((Tree) rstruct.getTree()).toStringTree();
    Object expecting = ""(~ (SET A))"";
    assertEquals(expecting, actual, ""testing rule element"");
}", ,"// gunit test on line 129
",// gunit test on line 129,189,195,[0],0,[0],0,[0],0,0,0,0,test_element1(),org.antlr.v4.test.tool.TestASTStructure,test_element1/0,False,189,4,1,0,1,1,4,6,0,3,0,4,1,1,0,0,0,1,4,1,3,0,0,0,0,0,20,1,0,False
696,..\projects\antlr4-4.11.0\tool-testsuite\test\org\antlr\v4\test\tool\TestASTStructure.java,org.antlr.v4.test.tool.TestASTStructure,void test_element2(),"@Test
public void test_element2() throws Exception {
    // gunit test on line 130
    RuleReturnScope rstruct = (RuleReturnScope) execParser(""element"", ""b+"", 130);
    Object actual = ((Tree) rstruct.getTree()).toStringTree();
    Object expecting = ""(+ (BLOCK (ALT b)))"";
    assertEquals(expecting, actual, ""testing rule element"");
}", ,"// gunit test on line 130
",// gunit test on line 130,197,203,[0],0,[0],0,[0],0,0,0,0,test_element2(),org.antlr.v4.test.tool.TestASTStructure,test_element2/0,False,197,4,1,0,1,1,4,6,0,3,0,4,1,1,0,0,0,1,4,1,3,0,0,0,0,0,24,1,0,False
697,..\projects\antlr4-4.11.0\tool-testsuite\test\org\antlr\v4\test\tool\TestASTStructure.java,org.antlr.v4.test.tool.TestASTStructure,void test_element3(),"@Test
public void test_element3() throws Exception {
    // gunit test on line 131
    RuleReturnScope rstruct = (RuleReturnScope) execParser(""element"", ""(b)+"", 131);
    Object actual = ((Tree) rstruct.getTree()).toStringTree();
    Object expecting = ""(+ (BLOCK (ALT b)))"";
    assertEquals(expecting, actual, ""testing rule element"");
}", ,"// gunit test on line 131
",// gunit test on line 131,205,211,[0],0,[0],0,[0],0,0,0,0,test_element3(),org.antlr.v4.test.tool.TestASTStructure,test_element3/0,False,205,4,1,0,1,1,4,6,0,3,0,4,1,1,0,0,0,1,4,1,3,0,0,0,0,0,24,1,0,False
698,..\projects\antlr4-4.11.0\tool-testsuite\test\org\antlr\v4\test\tool\TestASTStructure.java,org.antlr.v4.test.tool.TestASTStructure,void test_element4(),"@Test
public void test_element4() throws Exception {
    // gunit test on line 132
    RuleReturnScope rstruct = (RuleReturnScope) execParser(""element"", ""b?"", 132);
    Object actual = ((Tree) rstruct.getTree()).toStringTree();
    Object expecting = ""(? (BLOCK (ALT b)))"";
    assertEquals(expecting, actual, ""testing rule element"");
}", ,"// gunit test on line 132
",// gunit test on line 132,213,219,[0],0,[0],0,[0],0,0,0,0,test_element4(),org.antlr.v4.test.tool.TestASTStructure,test_element4/0,False,213,4,1,0,1,1,4,6,0,3,0,4,1,1,0,0,0,1,4,1,3,0,0,0,0,0,24,1,0,False
699,..\projects\antlr4-4.11.0\tool-testsuite\test\org\antlr\v4\test\tool\TestASTStructure.java,org.antlr.v4.test.tool.TestASTStructure,void test_element5(),"@Test
public void test_element5() throws Exception {
    // gunit test on line 133
    RuleReturnScope rstruct = (RuleReturnScope) execParser(""element"", ""(b)?"", 133);
    Object actual = ((Tree) rstruct.getTree()).toStringTree();
    Object expecting = ""(? (BLOCK (ALT b)))"";
    assertEquals(expecting, actual, ""testing rule element"");
}", ,"// gunit test on line 133
",// gunit test on line 133,221,227,[0],0,[0],0,[0],0,0,0,0,test_element5(),org.antlr.v4.test.tool.TestASTStructure,test_element5/0,False,221,4,1,0,1,1,4,6,0,3,0,4,1,1,0,0,0,1,4,1,3,0,0,0,0,0,24,1,0,False
700,..\projects\antlr4-4.11.0\tool-testsuite\test\org\antlr\v4\test\tool\TestASTStructure.java,org.antlr.v4.test.tool.TestASTStructure,void test_element6(),"@Test
public void test_element6() throws Exception {
    // gunit test on line 134
    RuleReturnScope rstruct = (RuleReturnScope) execParser(""element"", ""(b)*"", 134);
    Object actual = ((Tree) rstruct.getTree()).toStringTree();
    Object expecting = ""(* (BLOCK (ALT b)))"";
    assertEquals(expecting, actual, ""testing rule element"");
}", ,"// gunit test on line 134
",// gunit test on line 134,229,235,[0],0,[0],0,[0],0,0,0,0,test_element6(),org.antlr.v4.test.tool.TestASTStructure,test_element6/0,False,229,4,1,0,1,1,4,6,0,3,0,4,1,1,0,0,0,1,4,1,3,0,0,0,0,0,24,1,0,False
701,..\projects\antlr4-4.11.0\tool-testsuite\test\org\antlr\v4\test\tool\TestASTStructure.java,org.antlr.v4.test.tool.TestASTStructure,void test_element7(),"@Test
public void test_element7() throws Exception {
    // gunit test on line 135
    RuleReturnScope rstruct = (RuleReturnScope) execParser(""element"", ""b*"", 135);
    Object actual = ((Tree) rstruct.getTree()).toStringTree();
    Object expecting = ""(* (BLOCK (ALT b)))"";
    assertEquals(expecting, actual, ""testing rule element"");
}", ,"// gunit test on line 135
",// gunit test on line 135,237,243,[0],0,[0],0,[0],0,0,0,0,test_element7(),org.antlr.v4.test.tool.TestASTStructure,test_element7/0,False,237,4,1,0,1,1,4,6,0,3,0,4,1,1,0,0,0,1,4,1,3,0,0,0,0,0,24,1,0,False
702,..\projects\antlr4-4.11.0\tool-testsuite\test\org\antlr\v4\test\tool\TestASTStructure.java,org.antlr.v4.test.tool.TestASTStructure,void test_element8(),"@Test
public void test_element8() throws Exception {
    // gunit test on line 136
    RuleReturnScope rstruct = (RuleReturnScope) execParser(""element"", ""'while'*"", 136);
    Object actual = ((Tree) rstruct.getTree()).toStringTree();
    Object expecting = ""(* (BLOCK (ALT 'while')))"";
    assertEquals(expecting, actual, ""testing rule element"");
}", ,"// gunit test on line 136
",// gunit test on line 136,245,251,[0],0,[0],0,[0],0,0,0,0,test_element8(),org.antlr.v4.test.tool.TestASTStructure,test_element8/0,False,245,4,1,0,1,1,4,6,0,3,0,4,1,1,0,0,0,1,4,1,3,0,0,0,0,0,23,1,0,False
703,..\projects\antlr4-4.11.0\tool-testsuite\test\org\antlr\v4\test\tool\TestASTStructure.java,org.antlr.v4.test.tool.TestASTStructure,void test_element9(),"@Test
public void test_element9() throws Exception {
    // gunit test on line 137
    RuleReturnScope rstruct = (RuleReturnScope) execParser(""element"", ""'a'+"", 137);
    Object actual = ((Tree) rstruct.getTree()).toStringTree();
    Object expecting = ""(+ (BLOCK (ALT 'a')))"";
    assertEquals(expecting, actual, ""testing rule element"");
}", ,"// gunit test on line 137
",// gunit test on line 137,253,259,[0],0,[0],0,[0],0,0,0,0,test_element9(),org.antlr.v4.test.tool.TestASTStructure,test_element9/0,False,253,4,1,0,1,1,4,6,0,3,0,4,1,1,0,0,0,1,4,1,3,0,0,0,0,0,23,1,0,False
704,..\projects\antlr4-4.11.0\tool-testsuite\test\org\antlr\v4\test\tool\TestASTStructure.java,org.antlr.v4.test.tool.TestASTStructure,void test_element10(),"@Test
public void test_element10() throws Exception {
    // gunit test on line 138
    RuleReturnScope rstruct = (RuleReturnScope) execParser(""element"", ""a[3]"", 138);
    Object actual = ((Tree) rstruct.getTree()).toStringTree();
    Object expecting = ""(a 3)"";
    assertEquals(expecting, actual, ""testing rule element"");
}", ,"// gunit test on line 138
",// gunit test on line 138,261,267,[0],0,[0],0,[0],0,0,0,0,test_element10(),org.antlr.v4.test.tool.TestASTStructure,test_element10/0,False,261,4,1,0,1,1,4,6,0,3,0,4,1,1,0,0,0,1,4,1,3,0,0,0,0,0,17,1,0,False
705,..\projects\antlr4-4.11.0\tool-testsuite\test\org\antlr\v4\test\tool\TestASTStructure.java,org.antlr.v4.test.tool.TestASTStructure,void test_element11(),"@Test
public void test_element11() throws Exception {
    // gunit test on line 139
    RuleReturnScope rstruct = (RuleReturnScope) execParser(""element"", ""'a'..'z'+"", 139);
    Object actual = ((Tree) rstruct.getTree()).toStringTree();
    Object expecting = ""(+ (BLOCK (ALT (.. 'a' 'z'))))"";
    assertEquals(expecting, actual, ""testing rule element"");
}", ,"// gunit test on line 139
",// gunit test on line 139,269,275,[0],0,[0],0,[0],0,0,0,0,test_element11(),org.antlr.v4.test.tool.TestASTStructure,test_element11/0,False,269,4,1,0,1,1,4,6,0,3,0,4,1,1,0,0,0,1,4,1,3,0,0,0,0,0,23,1,0,False
706,..\projects\antlr4-4.11.0\tool-testsuite\test\org\antlr\v4\test\tool\TestASTStructure.java,org.antlr.v4.test.tool.TestASTStructure,void test_element12(),"@Test
public void test_element12() throws Exception {
    // gunit test on line 140
    RuleReturnScope rstruct = (RuleReturnScope) execParser(""element"", ""x=ID"", 140);
    Object actual = ((Tree) rstruct.getTree()).toStringTree();
    Object expecting = ""(= x ID)"";
    assertEquals(expecting, actual, ""testing rule element"");
}", ,"// gunit test on line 140
",// gunit test on line 140,277,283,[0],0,[0],0,[0],0,0,0,0,test_element12(),org.antlr.v4.test.tool.TestASTStructure,test_element12/0,False,277,4,1,0,1,1,4,6,0,3,0,4,1,1,0,0,0,1,4,1,3,0,0,0,0,0,19,1,0,False
707,..\projects\antlr4-4.11.0\tool-testsuite\test\org\antlr\v4\test\tool\TestASTStructure.java,org.antlr.v4.test.tool.TestASTStructure,void test_element13(),"@Test
public void test_element13() throws Exception {
    // gunit test on line 141
    RuleReturnScope rstruct = (RuleReturnScope) execParser(""element"", ""x=ID?"", 141);
    Object actual = ((Tree) rstruct.getTree()).toStringTree();
    Object expecting = ""(? (BLOCK (ALT (= x ID))))"";
    assertEquals(expecting, actual, ""testing rule element"");
}", ,"// gunit test on line 141
",// gunit test on line 141,285,291,[0],0,[0],0,[0],0,0,0,0,test_element13(),org.antlr.v4.test.tool.TestASTStructure,test_element13/0,False,285,4,1,0,1,1,4,6,0,3,0,4,1,1,0,0,0,1,4,1,3,0,0,0,0,0,26,1,0,False
708,..\projects\antlr4-4.11.0\tool-testsuite\test\org\antlr\v4\test\tool\TestASTStructure.java,org.antlr.v4.test.tool.TestASTStructure,void test_element14(),"@Test
public void test_element14() throws Exception {
    // gunit test on line 142
    RuleReturnScope rstruct = (RuleReturnScope) execParser(""element"", ""x=ID*"", 142);
    Object actual = ((Tree) rstruct.getTree()).toStringTree();
    Object expecting = ""(* (BLOCK (ALT (= x ID))))"";
    assertEquals(expecting, actual, ""testing rule element"");
}", ,"// gunit test on line 142
",// gunit test on line 142,293,299,[0],0,[0],0,[0],0,0,0,0,test_element14(),org.antlr.v4.test.tool.TestASTStructure,test_element14/0,False,293,4,1,0,1,1,4,6,0,3,0,4,1,1,0,0,0,1,4,1,3,0,0,0,0,0,26,1,0,False
709,..\projects\antlr4-4.11.0\tool-testsuite\test\org\antlr\v4\test\tool\TestASTStructure.java,org.antlr.v4.test.tool.TestASTStructure,void test_element15(),"@Test
public void test_element15() throws Exception {
    // gunit test on line 143
    RuleReturnScope rstruct = (RuleReturnScope) execParser(""element"", ""x=b"", 143);
    Object actual = ((Tree) rstruct.getTree()).toStringTree();
    Object expecting = ""(= x b)"";
    assertEquals(expecting, actual, ""testing rule element"");
}", ,"// gunit test on line 143
",// gunit test on line 143,301,307,[0],0,[0],0,[0],0,0,0,0,test_element15(),org.antlr.v4.test.tool.TestASTStructure,test_element15/0,False,301,4,1,0,1,1,4,6,0,3,0,4,1,1,0,0,0,1,4,1,3,0,0,0,0,0,18,1,0,False
710,..\projects\antlr4-4.11.0\tool-testsuite\test\org\antlr\v4\test\tool\TestASTStructure.java,org.antlr.v4.test.tool.TestASTStructure,void test_element16(),"@Test
public void test_element16() throws Exception {
    // gunit test on line 144
    RuleReturnScope rstruct = (RuleReturnScope) execParser(""element"", ""x=(A|B)"", 144);
    Object actual = ((Tree) rstruct.getTree()).toStringTree();
    Object expecting = ""(= x (BLOCK (ALT A) (ALT B)))"";
    assertEquals(expecting, actual, ""testing rule element"");
}", ,"// gunit test on line 144
",// gunit test on line 144,309,315,[0],0,[0],0,[0],0,0,0,0,test_element16(),org.antlr.v4.test.tool.TestASTStructure,test_element16/0,False,309,4,1,0,1,1,4,6,0,3,0,4,1,1,0,0,0,1,4,1,3,0,0,0,0,0,24,1,0,False
711,..\projects\antlr4-4.11.0\tool-testsuite\test\org\antlr\v4\test\tool\TestASTStructure.java,org.antlr.v4.test.tool.TestASTStructure,void test_element17(),"@Test
public void test_element17() throws Exception {
    // gunit test on line 145
    RuleReturnScope rstruct = (RuleReturnScope) execParser(""element"", ""x=~(A|B)"", 145);
    Object actual = ((Tree) rstruct.getTree()).toStringTree();
    Object expecting = ""(= x (~ (SET A B)))"";
    assertEquals(expecting, actual, ""testing rule element"");
}", ,"// gunit test on line 145
",// gunit test on line 145,317,323,[0],0,[0],0,[0],0,0,0,0,test_element17(),org.antlr.v4.test.tool.TestASTStructure,test_element17/0,False,317,4,1,0,1,1,4,6,0,3,0,4,1,1,0,0,0,1,4,1,3,0,0,0,0,0,22,1,0,False
712,..\projects\antlr4-4.11.0\tool-testsuite\test\org\antlr\v4\test\tool\TestASTStructure.java,org.antlr.v4.test.tool.TestASTStructure,void test_element18(),"@Test
public void test_element18() throws Exception {
    // gunit test on line 146
    RuleReturnScope rstruct = (RuleReturnScope) execParser(""element"", ""x+=~(A|B)"", 146);
    Object actual = ((Tree) rstruct.getTree()).toStringTree();
    Object expecting = ""(+= x (~ (SET A B)))"";
    assertEquals(expecting, actual, ""testing rule element"");
}", ,"// gunit test on line 146
",// gunit test on line 146,325,331,[0],0,[0],0,[0],0,0,0,0,test_element18(),org.antlr.v4.test.tool.TestASTStructure,test_element18/0,False,325,4,1,0,1,1,4,6,0,3,0,4,1,1,0,0,0,1,4,1,3,0,0,0,0,0,22,1,0,False
713,..\projects\antlr4-4.11.0\tool-testsuite\test\org\antlr\v4\test\tool\TestASTStructure.java,org.antlr.v4.test.tool.TestASTStructure,void test_element19(),"@Test
public void test_element19() throws Exception {
    // gunit test on line 147
    RuleReturnScope rstruct = (RuleReturnScope) execParser(""element"", ""x+=~(A|B)+"", 147);
    Object actual = ((Tree) rstruct.getTree()).toStringTree();
    Object expecting = ""(+ (BLOCK (ALT (+= x (~ (SET A B))))))"";
    assertEquals(expecting, actual, ""testing rule element"");
}", ,"// gunit test on line 147
",// gunit test on line 147,333,339,[0],0,[0],0,[0],0,0,0,0,test_element19(),org.antlr.v4.test.tool.TestASTStructure,test_element19/0,False,333,4,1,0,1,1,4,6,0,3,0,4,1,1,0,0,0,1,4,1,3,0,0,0,0,0,26,1,0,False
714,..\projects\antlr4-4.11.0\tool-testsuite\test\org\antlr\v4\test\tool\TestASTStructure.java,org.antlr.v4.test.tool.TestASTStructure,void test_element20(),"@Test
public void test_element20() throws Exception {
    // gunit test on line 148
    RuleReturnScope rstruct = (RuleReturnScope) execParser(""element"", ""x=b+"", 148);
    Object actual = ((Tree) rstruct.getTree()).toStringTree();
    Object expecting = ""(+ (BLOCK (ALT (= x b))))"";
    assertEquals(expecting, actual, ""testing rule element"");
}", ,"// gunit test on line 148
",// gunit test on line 148,341,347,[0],0,[0],0,[0],0,0,0,0,test_element20(),org.antlr.v4.test.tool.TestASTStructure,test_element20/0,False,341,4,1,0,1,1,4,6,0,3,0,4,1,1,0,0,0,1,4,1,3,0,0,0,0,0,25,1,0,False
715,..\projects\antlr4-4.11.0\tool-testsuite\test\org\antlr\v4\test\tool\TestASTStructure.java,org.antlr.v4.test.tool.TestASTStructure,void test_element21(),"@Test
public void test_element21() throws Exception {
    // gunit test on line 149
    RuleReturnScope rstruct = (RuleReturnScope) execParser(""element"", ""x+=ID*"", 149);
    Object actual = ((Tree) rstruct.getTree()).toStringTree();
    Object expecting = ""(* (BLOCK (ALT (+= x ID))))"";
    assertEquals(expecting, actual, ""testing rule element"");
}", ,"// gunit test on line 149
",// gunit test on line 149,349,355,[0],0,[0],0,[0],0,0,0,0,test_element21(),org.antlr.v4.test.tool.TestASTStructure,test_element21/0,False,349,4,1,0,1,1,4,6,0,3,0,4,1,1,0,0,0,1,4,1,3,0,0,0,0,0,26,1,0,False
716,..\projects\antlr4-4.11.0\tool-testsuite\test\org\antlr\v4\test\tool\TestASTStructure.java,org.antlr.v4.test.tool.TestASTStructure,void test_element22(),"@Test
public void test_element22() throws Exception {
    // gunit test on line 150
    RuleReturnScope rstruct = (RuleReturnScope) execParser(""element"", ""x+='int'*"", 150);
    Object actual = ((Tree) rstruct.getTree()).toStringTree();
    Object expecting = ""(* (BLOCK (ALT (+= x 'int'))))"";
    assertEquals(expecting, actual, ""testing rule element"");
}", ,"// gunit test on line 150
",// gunit test on line 150,357,363,[0],0,[0],0,[0],0,0,0,0,test_element22(),org.antlr.v4.test.tool.TestASTStructure,test_element22/0,False,357,4,1,0,1,1,4,6,0,3,0,4,1,1,0,0,0,1,4,1,3,0,0,0,0,0,24,1,0,False
717,..\projects\antlr4-4.11.0\tool-testsuite\test\org\antlr\v4\test\tool\TestASTStructure.java,org.antlr.v4.test.tool.TestASTStructure,void test_element23(),"@Test
public void test_element23() throws Exception {
    // gunit test on line 151
    RuleReturnScope rstruct = (RuleReturnScope) execParser(""element"", ""x+=b+"", 151);
    Object actual = ((Tree) rstruct.getTree()).toStringTree();
    Object expecting = ""(+ (BLOCK (ALT (+= x b))))"";
    assertEquals(expecting, actual, ""testing rule element"");
}", ,"// gunit test on line 151
",// gunit test on line 151,365,371,[0],0,[0],0,[0],0,0,0,0,test_element23(),org.antlr.v4.test.tool.TestASTStructure,test_element23/0,False,365,4,1,0,1,1,4,6,0,3,0,4,1,1,0,0,0,1,4,1,3,0,0,0,0,0,25,1,0,False
718,..\projects\antlr4-4.11.0\tool-testsuite\test\org\antlr\v4\test\tool\TestASTStructure.java,org.antlr.v4.test.tool.TestASTStructure,void test_element24(),"@Test
public void test_element24() throws Exception {
    // gunit test on line 152
    RuleReturnScope rstruct = (RuleReturnScope) execParser(""element"", ""({blort} 'x')*"", 152);
    Object actual = ((Tree) rstruct.getTree()).toStringTree();
    Object expecting = ""(* (BLOCK (ALT {blort} 'x')))"";
    assertEquals(expecting, actual, ""testing rule element"");
}", ,"// gunit test on line 152
",// gunit test on line 152,373,379,[0],0,[0],0,[0],0,0,0,0,test_element24(),org.antlr.v4.test.tool.TestASTStructure,test_element24/0,False,373,4,1,0,1,1,4,6,0,3,0,4,1,1,0,0,0,1,4,1,3,0,0,0,0,0,24,1,0,False
719,..\projects\antlr4-4.11.0\tool-testsuite\test\org\antlr\v4\test\tool\TestATNConstruction.java,org.antlr.v4.test.tool.TestATNConstruction,void testCharSetUnicodePropertyEscape(),"@Test
public void testCharSetUnicodePropertyEscape() throws Exception {
    // The Gothic script is long dead and unlikely to change (which would
    // cause this test to fail)
    LexerGrammar g = new LexerGrammar(""lexer grammar P;\n"" + ""A : [\\p{Gothic}] ;"");
    String expecting = ""s0->RuleStart_A_1\n"" + ""RuleStart_A_1->s3\n"" + ""s3-{66352..66378}->s4\n"" + ""s4->RuleStop_A_2\n"";
    checkTokensRule(g, null, expecting);
}", ,"// The Gothic script is long dead and unlikely to change (which would
[[SEP]]// cause this test to fail)
",// The Gothic script is long dead and unlikely to change (which would// cause this test to fail),183,196,[0],0,"[0, 0]",0,[0],0,0,0,0,testCharSetUnicodePropertyEscape(),org.antlr.v4.test.tool.TestATNConstruction,testCharSetUnicodePropertyEscape/0,False,183,3,2,0,2,1,1,5,0,2,0,1,1,1,0,0,0,0,6,0,2,2,0,0,0,0,17,1,0,False
720,..\projects\antlr4-4.11.0\tool-testsuite\test\org\antlr\v4\test\tool\TestATNConstruction.java,org.antlr.v4.test.tool.TestATNConstruction,void testCharSetUnicodeMultiplePropertyEscape(),"@Test
public void testCharSetUnicodeMultiplePropertyEscape() throws Exception {
    // Ditto the Mahajani script. Not going to change soon. I hope.
    LexerGrammar g = new LexerGrammar(""lexer grammar P;\n"" + ""A : [\\p{Gothic}\\p{Mahajani}] ;"");
    String expecting = ""s0->RuleStart_A_1\n"" + ""RuleStart_A_1->s3\n"" + ""s3-{66352..66378, 69968..70006}->s4\n"" + ""s4->RuleStop_A_2\n"";
    checkTokensRule(g, null, expecting);
}", ,"// Ditto the Mahajani script. Not going to change soon. I hope.
",// Ditto the Mahajani script. Not going to change soon. I hope.,209,221,[0],0,[0],0,[0],0,0,0,0,testCharSetUnicodeMultiplePropertyEscape(),org.antlr.v4.test.tool.TestATNConstruction,testCharSetUnicodeMultiplePropertyEscape/0,False,209,3,2,0,2,1,1,5,0,2,0,1,1,1,0,0,0,0,6,0,2,2,0,0,0,0,19,1,0,False
721,..\projects\antlr4-4.11.0\tool-testsuite\test\org\antlr\v4\test\tool\TestATNConstruction.java,org.antlr.v4.test.tool.TestATNConstruction,void testAplusSingleAltHasPlusASTPointingAtLoopBackState(),"@Test
public void testAplusSingleAltHasPlusASTPointingAtLoopBackState() throws Exception {
    Grammar g = new Grammar(""parser grammar P;\n"" + // (RULE a (BLOCK (ALT (+ (BLOCK (ALT A))))))
    ""s : a B ;\n"" + ""a : A+;"");
    String expecting = ""RuleStart_a_2->PlusBlockStart_8\n"" + ""PlusBlockStart_8->s7\n"" + ""s7-A->BlockEnd_9\n"" + ""BlockEnd_9->PlusLoopBack_10\n"" + ""PlusLoopBack_10->PlusBlockStart_8\n"" + ""PlusLoopBack_10->s11\n"" + ""s11->RuleStop_a_3\n"" + ""RuleStop_a_3->s5\n"";
    RuntimeTestUtils.checkRuleATN(g, ""a"", expecting);
    // Get all AST -> ATNState relationships. Make sure loopback is covered when no loop entry decision
    List<GrammarAST> ruleNodes = g.ast.getNodesWithType(ANTLRParser.RULE);
    RuleAST a = (RuleAST) ruleNodes.get(1);
    List<GrammarAST> nodesInRule = a.getNodesWithType(null);
    Map<GrammarAST, ATNState> covered = new LinkedHashMap<GrammarAST, ATNState>();
    for (GrammarAST node : nodesInRule) {
        if (node.atnState != null) {
            covered.put(node, node.atnState);
        }
    }
    assertEquals(""{RULE=2, BLOCK=8, +=10, BLOCK=8, A=7}"", covered.toString());
}", ,"// (RULE a (BLOCK (ALT (+ (BLOCK (ALT A))))))
[[SEP]]// Get all AST -> ATNState relationships. Make sure loopback is covered when no loop entry decision
",// (RULE a (BLOCK (ALT (+ (BLOCK (ALT A))))))[[SEP]]// Get all AST -> ATNState relationships. Make sure loopback is covered when no loop entry decision,395,421,[0],0,"[0, 0]",0,"[0, 0]",0,0,0,0,testAplusSingleAltHasPlusASTPointingAtLoopBackState(),org.antlr.v4.test.tool.TestATNConstruction,testAplusSingleAltHasPlusASTPointingAtLoopBackState/0,False,395,5,2,0,2,3,6,15,0,6,0,6,0,0,1,1,0,0,13,1,6,2,2,0,0,0,39,1,0,False
722,..\projects\antlr4-4.11.0\tool-testsuite\test\org\antlr\v4\test\tool\TestATNConstruction.java,org.antlr.v4.test.tool.TestATNConstruction,void testForRepeatedTransitionsToStopState(),"/**
 *  Test for https://github.com/antlr/antlr4/issues/1369
 *   Repeated edges:
 *
 * 	 RuleStop_e_3->BlockEnd_26
 * 	 RuleStop_e_3->BlockEnd_26
 * 	 RuleStop_e_3->BlockEnd_26
 *
 *  @throws Exception
 */
@Test
public void testForRepeatedTransitionsToStopState() throws Exception {
    String gstr = ""grammar T;\n"" + ""\t s : e EOF;\n"" + ""\t e :<assoc=right> e '*' e\n"" + ""\t   |<assoc=right> e '+' e\n"" + ""\t   |<assoc=right> e '?' e ':' e\n"" + ""\t   |<assoc=right> e '=' e\n"" + ""\t   | ID\n"" + ""\t   ;\n"" + ""\t ID : 'a'..'z'+ ;\n"" + ""\t WS : (' '|'\\n') -> skip ;"";
    Grammar g = new Grammar(gstr);
    String expecting = ""RuleStart_e_2->s7\n"" + ""s7-action_1:-1->s8\n"" + ""s8-ID->s9\n"" + ""s9->StarLoopEntry_27\n"" + ""StarLoopEntry_27->StarBlockStart_25\n"" + ""StarLoopEntry_27->s28\n"" + ""StarBlockStart_25->s10\n"" + ""StarBlockStart_25->s13\n"" + ""StarBlockStart_25->s16\n"" + ""StarBlockStart_25->s22\n"" + ""s28->RuleStop_e_3\n"" + ""s10-5 >= _p->s11\n"" + ""s13-4 >= _p->s14\n"" + ""s16-3 >= _p->s17\n"" + ""s22-2 >= _p->s23\n"" + ""RuleStop_e_3->s5\n"" + ""RuleStop_e_3->BlockEnd_26\n"" + ""RuleStop_e_3->s19\n"" + ""RuleStop_e_3->s21\n"" + ""s11-'*'->s12\n"" + ""s14-'+'->s15\n"" + ""s17-'?'->s18\n"" + ""s23-'='->s24\n"" + ""s12-e->RuleStart_e_2\n"" + ""s15-e->RuleStart_e_2\n"" + ""s18-e->RuleStart_e_2\n"" + ""s24-e->RuleStart_e_2\n"" + ""BlockEnd_26->StarLoopBack_29\n"" + ""s19-':'->s20\n"" + ""StarLoopBack_29->StarLoopEntry_27\n"" + ""s20-e->RuleStart_e_2\n"" + ""s21->BlockEnd_26\n"";
    RuntimeTestUtils.checkRuleATN(g, ""e"", expecting);
}","/**
 *  Test for https://github.com/antlr/antlr4/issues/1369
 *   Repeated edges:
 *
 * 	 RuleStop_e_3->BlockEnd_26
 * 	 RuleStop_e_3->BlockEnd_26
 * 	 RuleStop_e_3->BlockEnd_26
 *
 *  @throws Exception
 */
", ,/** *  Test for https://github.com/antlr/antlr4/issues/1369 *   Repeated edges: * * 	 RuleStop_e_3->BlockEnd_26 * 	 RuleStop_e_3->BlockEnd_26 * 	 RuleStop_e_3->BlockEnd_26 * *  @throws Exception */,588,635,[0],0,[0],0,[0],0,0,0,0,testForRepeatedTransitionsToStopState(),org.antlr.v4.test.tool.TestATNConstruction,testForRepeatedTransitionsToStopState/0,False,588,2,1,0,1,1,1,6,0,3,0,1,0,0,0,0,0,0,43,0,3,2,0,0,0,0,34,1,0,True
723,..\projects\antlr4-4.11.0\tool-testsuite\test\org\antlr\v4\test\tool\TestATNConstruction.java,org.antlr.v4.test.tool.TestATNConstruction,"void checkTokensRule(LexerGrammar, String, String)","void checkTokensRule(LexerGrammar g, String modeName, String expecting) {
    // if ( g.ast!=null && !g.ast.hasErrors ) {
    // System.out.println(g.ast.toStringTree());
    // Tool antlr = new Tool();
    // SemanticPipeline sem = new SemanticPipeline(g);
    // sem.process();
    // if ( g.getImportedGrammars()!=null ) { // process imported grammars (if any)
    // for (Grammar imp : g.getImportedGrammars()) {
    // antlr.processNonCombinedGrammar(imp);
    // }
    // }
    // }
    if (modeName == null)
        modeName = ""DEFAULT_MODE"";
    if (g.modes.get(modeName) == null) {
        System.err.println(""no such mode "" + modeName);
        return;
    }
    ParserATNFactory f = new LexerATNFactory(g);
    ATN nfa = f.createATN();
    ATNState startState = nfa.modeNameToStartState.get(modeName);
    ATNPrinter serializer = new ATNPrinter(g, startState);
    String result = serializer.asString();
    // System.out.print(result);
    assertEquals(expecting, result);
}", ,"// if ( g.ast!=null && !g.ast.hasErrors ) {
[[SEP]]// System.out.println(g.ast.toStringTree());
[[SEP]]// Tool antlr = new Tool();
[[SEP]]// SemanticPipeline sem = new SemanticPipeline(g);
[[SEP]]// sem.process();
[[SEP]]// if ( g.getImportedGrammars()!=null ) { // process imported grammars (if any)
[[SEP]]// for (Grammar imp : g.getImportedGrammars()) {
[[SEP]]// antlr.processNonCombinedGrammar(imp);
[[SEP]]// }
[[SEP]]// }
[[SEP]]// }
[[SEP]]// System.out.print(result);
",// if ( g.ast!=null && !g.ast.hasErrors ) {// System.out.println(g.ast.toStringTree());// Tool antlr = new Tool();// SemanticPipeline sem = new SemanticPipeline(g);// sem.process();// if ( g.getImportedGrammars()!=null ) { // process imported grammars (if any)// for (Grammar imp : g.getImportedGrammars()) {// antlr.processNonCombinedGrammar(imp);// }// }// }[[SEP]]// System.out.print(result);,825,849,[0],0,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]",0,"[0, 0]",0,0,0,0,"checkTokensRule(LexerGrammar, String, String)",org.antlr.v4.test.tool.TestATNConstruction,"checkTokensRule/3[org.antlr.v4.tool.LexerGrammar,java.lang.String,java.lang.String]",False,825,6,15,15,0,3,5,13,1,5,3,5,0,0,0,2,0,0,2,0,6,1,1,0,0,0,25,0,0,False
724,..\projects\antlr4-4.11.0\tool-testsuite\test\org\antlr\v4\test\tool\TestATNInterpreter.java,org.antlr.v4.test.tool.TestATNInterpreter,void testAmbigAltChooseFirst(),"@Test
public void testAmbigAltChooseFirst() throws Exception {
    LexerGrammar lg = new LexerGrammar(""lexer grammar L;\n"" + ""A : 'a' ;\n"" + ""B : 'b' ;\n"" + ""C : 'c' ;\n"" + ""D : 'd' ;\n"");
    Grammar g = new Grammar(""parser grammar T;\n"" + // first alt
    ""a : A B | A B ;"");
    checkMatchedAlt(lg, g, ""ab"", 1);
    checkMatchedAlt(lg, g, ""abc"", 1);
}", ,"// first alt
",// first alt,207,219,[0],0,[0],0,[0],0,0,0,0,testAmbigAltChooseFirst(),org.antlr.v4.test.tool.TestATNInterpreter,testAmbigAltChooseFirst/0,False,207,4,3,0,3,1,1,6,0,2,0,1,1,1,0,0,0,0,9,2,2,2,0,0,0,0,17,1,0,False
725,..\projects\antlr4-4.11.0\tool-testsuite\test\org\antlr\v4\test\tool\TestATNInterpreter.java,org.antlr.v4.test.tool.TestATNInterpreter,void testAmbigAltChooseFirstWithFollowingToken(),"@Test
public void testAmbigAltChooseFirstWithFollowingToken() throws Exception {
    LexerGrammar lg = new LexerGrammar(""lexer grammar L;\n"" + ""A : 'a' ;\n"" + ""B : 'b' ;\n"" + ""C : 'c' ;\n"" + ""D : 'd' ;\n"");
    Grammar g = new Grammar(""parser grammar T;\n"" + // first alt
    ""a : (A B | A B) C ;"");
    checkMatchedAlt(lg, g, ""abc"", 1);
    checkMatchedAlt(lg, g, ""abcd"", 1);
}", ,"// first alt
",// first alt,221,233,[0],0,[0],0,[0],0,0,0,0,testAmbigAltChooseFirstWithFollowingToken(),org.antlr.v4.test.tool.TestATNInterpreter,testAmbigAltChooseFirstWithFollowingToken/0,False,221,4,3,0,3,1,1,6,0,2,0,1,1,1,0,0,0,0,9,2,2,2,0,0,0,0,21,1,0,False
726,..\projects\antlr4-4.11.0\tool-testsuite\test\org\antlr\v4\test\tool\TestATNInterpreter.java,org.antlr.v4.test.tool.TestATNInterpreter,"void checkMatchedAlt(LexerGrammar, Grammar, String, int)","public void checkMatchedAlt(LexerGrammar lg, final Grammar g, String inputString, int expected) {
    ATN lexatn = createATN(lg, true);
    LexerATNSimulator lexInterp = new LexerATNSimulator(lexatn, new DFA[] { new DFA(lexatn.modeToStartState.get(Lexer.DEFAULT_MODE)) }, null);
    IntegerList types = getTokenTypesViaATN(inputString, lexInterp);
    // System.out.println(types);
    g.importVocab(lg);
    ParserATNFactory f = new ParserATNFactory(g);
    ATN atn = f.createATN();
    TokenStream input = new MockIntTokenStream(types);
    // System.out.println(""input=""+input.types);
    ParserInterpreterForTesting interp = new ParserInterpreterForTesting(g, input);
    ATNState startState = atn.ruleToStartState[g.getRule(""a"").index];
    if (startState.transition(0).target instanceof BlockStartState) {
        startState = startState.transition(0).target;
    }
    DOTGenerator dot = new DOTGenerator(g);
    // System.out.println(dot.getDOT(atn.ruleToStartState[g.getRule(""a"").index]));
    Rule r = g.getRule(""e"");
    // if ( r!=null ) System.out.println(dot.getDOT(atn.ruleToStartState[r.index]));
    int result = interp.matchATN(input, startState);
    assertEquals(expected, result);
}", ,"// System.out.println(types);
[[SEP]]// if ( r!=null ) System.out.println(dot.getDOT(atn.ruleToStartState[r.index]));
[[SEP]]// System.out.println(""input=""+input.types);
[[SEP]]// System.out.println(dot.getDOT(atn.ruleToStartState[g.getRule(""a"").index]));
","// System.out.println(types);[[SEP]]// System.out.println(""input=""+input.types);[[SEP]]// System.out.println(dot.getDOT(atn.ruleToStartState[g.getRule(""a"").index]));[[SEP]]// if ( r!=null ) System.out.println(dot.getDOT(atn.ruleToStartState[r.index]));",359,388,[0],0,"[0, 0, 0, 0]",0,"[0, 0, 0, 0]",0,0,0,0,"checkMatchedAlt(LexerGrammar, Grammar, String, int)",org.antlr.v4.test.tool.TestATNInterpreter,"checkMatchedAlt/4[org.antlr.v4.tool.LexerGrammar,org.antlr.v4.tool.Grammar,java.lang.String,int]",False,362,15,26,18,8,2,9,18,0,11,4,9,0,0,0,0,0,0,2,2,12,0,1,0,0,0,49,1,0,False
727,..\projects\antlr4-4.11.0\tool-testsuite\test\org\antlr\v4\test\tool\TestATNLexerInterpreter.java,org.antlr.v4.test.tool.TestATNLexerInterpreter,void testShortLongRule(),"@Test
public void testShortLongRule() throws Exception {
    LexerGrammar lg = new LexerGrammar(""lexer grammar L;\n"" + ""A : 'xy'\n"" + // this alt is preferred since there are no non-greedy configs
    ""  | 'xyz'\n"" + ""  ;\n"" + ""Z : 'z'\n"" + ""  ;\n"");
    checkLexerMatches(lg, ""xy"", ""A, EOF"");
    checkLexerMatches(lg, ""xyz"", ""A, EOF"");
}", ,"// this alt is preferred since there are no non-greedy configs
",// this alt is preferred since there are no non-greedy configs,49,59,[0],0,[0],0,[0],0,0,0,0,testShortLongRule(),org.antlr.v4.test.tool.TestATNLexerInterpreter,testShortLongRule/0,False,49,3,2,0,2,1,1,5,0,1,0,1,1,2,0,0,0,0,10,0,1,1,0,0,0,0,12,1,0,False
728,..\projects\antlr4-4.11.0\tool-testsuite\test\org\antlr\v4\test\tool\TestATNLexerInterpreter.java,org.antlr.v4.test.tool.TestATNLexerInterpreter,void testShortLongRule2(),"@Test
public void testShortLongRule2() throws Exception {
    LexerGrammar lg = new LexerGrammar(""lexer grammar L;\n"" + // make sure nongreedy mech cut off doesn't kill this alt
    ""A : 'xyz'\n"" + ""  | 'xy'\n"" + ""  ;\n"");
    checkLexerMatches(lg, ""xy"", ""A, EOF"");
    checkLexerMatches(lg, ""xyz"", ""A, EOF"");
}", ,"// make sure nongreedy mech cut off doesn't kill this alt
",// make sure nongreedy mech cut off doesn't kill this alt,61,69,[0],0,[0],0,[0],0,0,0,0,testShortLongRule2(),org.antlr.v4.test.tool.TestATNLexerInterpreter,testShortLongRule2/0,False,61,3,2,0,2,1,1,5,0,1,0,1,1,2,0,0,0,0,8,0,1,1,0,0,0,0,12,1,0,False
729,..\projects\antlr4-4.11.0\tool-testsuite\test\org\antlr\v4\test\tool\TestATNLexerInterpreter.java,org.antlr.v4.test.tool.TestATNLexerInterpreter,void testWildOnEndFirstAlt(),"@Test
public void testWildOnEndFirstAlt() throws Exception {
    LexerGrammar lg = new LexerGrammar(""lexer grammar L;\n"" + // should pursue '.' since xyz hits stop first, before 2nd alt
    ""A : 'xy' .\n"" + ""  | 'xy'\n"" + ""  ;\n"" + ""Z : 'z'\n"" + ""  ;\n"");
    checkLexerMatches(lg, ""xy"", ""A, EOF"");
    checkLexerMatches(lg, ""xyz"", ""A, EOF"");
}", ,"// should pursue '.' since xyz hits stop first, before 2nd alt
","// should pursue '.' since xyz hits stop first, before 2nd alt",71,81,[0],0,[0],0,[0],0,0,0,0,testWildOnEndFirstAlt(),org.antlr.v4.test.tool.TestATNLexerInterpreter,testWildOnEndFirstAlt/0,False,71,3,2,0,2,1,1,5,0,1,0,1,1,2,0,0,0,0,10,0,1,1,0,0,0,0,14,1,0,False
730,..\projects\antlr4-4.11.0\tool-testsuite\test\org\antlr\v4\test\tool\TestATNLexerInterpreter.java,org.antlr.v4.test.tool.TestATNLexerInterpreter,void testWildOnEndLastAlt(),"@Test
public void testWildOnEndLastAlt() throws Exception {
    LexerGrammar lg = new LexerGrammar(""lexer grammar L;\n"" + ""A : 'xy'\n"" + // this alt is preferred since there are no non-greedy configs
    ""  | 'xy' .\n"" + ""  ;\n"" + ""Z : 'z'\n"" + ""  ;\n"");
    checkLexerMatches(lg, ""xy"", ""A, EOF"");
    checkLexerMatches(lg, ""xyz"", ""A, EOF"");
}", ,"// this alt is preferred since there are no non-greedy configs
",// this alt is preferred since there are no non-greedy configs,83,93,[0],0,[0],0,[0],0,0,0,0,testWildOnEndLastAlt(),org.antlr.v4.test.tool.TestATNLexerInterpreter,testWildOnEndLastAlt/0,False,83,3,2,0,2,1,1,5,0,1,0,1,1,2,0,0,0,0,10,0,1,1,0,0,0,0,14,1,0,False
731,..\projects\antlr4-4.11.0\tool-testsuite\test\org\antlr\v4\test\tool\TestATNLexerInterpreter.java,org.antlr.v4.test.tool.TestATNLexerInterpreter,void testLexerKeywordIDAmbiguity(),"@Test
public void testLexerKeywordIDAmbiguity() throws Exception {
    LexerGrammar lg = new LexerGrammar(""lexer grammar L;\n"" + ""KEND : 'end' ;\n"" + ""ID : 'a'..'z'+ ;\n"" + ""WS : (' '|'\\n')+ ;"");
    String expecting = ""ID, EOF"";
    // checkLexerMatches(lg, ""e"", expecting);
    expecting = ""KEND, EOF"";
    checkLexerMatches(lg, ""end"", expecting);
    expecting = ""ID, EOF"";
    checkLexerMatches(lg, ""ending"", expecting);
    expecting = ""ID, WS, KEND, WS, ID, EOF"";
    checkLexerMatches(lg, ""a end bcd"", expecting);
}", ,"// checkLexerMatches(lg, ""e"", expecting);
","// checkLexerMatches(lg, ""e"", expecting);",209,223,[0],0,[0],0,[0],0,0,0,0,testLexerKeywordIDAmbiguity(),org.antlr.v4.test.tool.TestATNLexerInterpreter,testLexerKeywordIDAmbiguity/0,False,209,3,2,0,2,1,1,10,0,2,0,1,1,2,0,0,0,0,11,0,5,1,0,0,0,0,15,1,0,False
732,..\projects\antlr4-4.11.0\tool-testsuite\test\org\antlr\v4\test\tool\TestATNLexerInterpreter.java,org.antlr.v4.test.tool.TestATNLexerInterpreter,void testLexerGreedyOptionalShouldWorkAsWeExpect(),"// does not fail since ('*/')? can't match and have rule succeed
@Test
public void testLexerGreedyOptionalShouldWorkAsWeExpect() throws Exception {
    LexerGrammar lg = new LexerGrammar(""lexer grammar L;\n"" + ""CMT : '/*' ('*/')? '*/' ;\n"");
    String expecting = ""CMT, EOF"";
    checkLexerMatches(lg, ""/**/"", expecting);
}","// does not fail since ('*/')? can't match and have rule succeed
", ,// does not fail since ('*/')? can't match and have rule succeed[[SEP]]/*' ('*/[[SEP]]/**/,299,305,[0],0,[0],0,"[0, 0, 0]",0,0,0,0,testLexerGreedyOptionalShouldWorkAsWeExpect(),org.antlr.v4.test.tool.TestATNLexerInterpreter,testLexerGreedyOptionalShouldWorkAsWeExpect/0,False,299,3,2,0,2,1,1,5,0,2,0,1,1,2,0,0,0,0,4,0,2,1,0,0,0,0,17,1,0,False
733,..\projects\antlr4-4.11.0\tool-testsuite\test\org\antlr\v4\test\tool\TestATNLexerInterpreter.java,org.antlr.v4.test.tool.TestATNLexerInterpreter,void testEOFInSetAtEndOfLineComment(),"/**
 * only positive sets like (EOF|'\n') can match EOF and not in wildcard or ~foo sets
 *  EOF matches but does not advance cursor.
 */
@Test
public void testEOFInSetAtEndOfLineComment() throws Exception {
    LexerGrammar lg = new LexerGrammar(""lexer grammar L;\n"" + ""CMT : '//' .* (EOF|'\\n') ;\n"");
    String expecting = ""CMT, EOF"";
    checkLexerMatches(lg, ""//"", expecting);
}","/**
 * only positive sets like (EOF|'\n') can match EOF and not in wildcard or ~foo sets
 *  EOF matches but does not advance cursor.
 */
", ,"/** * only positive sets like (EOF|'\n') can match EOF and not in wildcard or ~foo sets *  EOF matches but does not advance cursor. */[[SEP]]//' .* (EOF|'\\n') ;\n"");[[SEP]]//"", expecting);",344,350,[0],0,[0],0,"[0, 0, 0]",0,0,0,0,testEOFInSetAtEndOfLineComment(),org.antlr.v4.test.tool.TestATNLexerInterpreter,testEOFInSetAtEndOfLineComment/0,False,344,3,2,0,2,1,1,5,0,2,0,1,1,2,0,0,0,0,4,0,2,1,0,0,0,0,35,1,0,True
734,..\projects\antlr4-4.11.0\tool-testsuite\test\org\antlr\v4\test\tool\TestATNLexerInterpreter.java,org.antlr.v4.test.tool.TestATNLexerInterpreter,void testEOFSuffixInSecondRule(),"@Test
public void testEOFSuffixInSecondRule() throws Exception {
    LexerGrammar lg = new LexerGrammar(""lexer grammar L;\n"" + // shorter than 'a' EOF, despite EOF being 0 width
    ""A : 'a' ;\n"" + ""B : 'a' EOF ;\n"");
    String expecting = ""B, EOF"";
    checkLexerMatches(lg, ""a"", expecting);
}", ,"// shorter than 'a' EOF, despite EOF being 0 width
","// shorter than 'a' EOF, despite EOF being 0 width",352,359,[0],0,[0],0,[0],0,0,0,0,testEOFSuffixInSecondRule(),org.antlr.v4.test.tool.TestATNLexerInterpreter,testEOFSuffixInSecondRule/0,False,352,3,2,0,2,1,1,5,0,2,0,1,1,2,0,0,0,0,5,0,2,1,0,0,0,0,17,1,0,False
735,..\projects\antlr4-4.11.0\tool-testsuite\test\org\antlr\v4\test\tool\TestATNLexerInterpreter.java,org.antlr.v4.test.tool.TestATNLexerInterpreter,void testLexerCaseInsensitive(),"@Test
public void testLexerCaseInsensitive() throws Exception {
    LexerGrammar lg = new LexerGrammar(""lexer grammar L;\n"" + ""\n"" + ""options { caseInsensitive = true; }\n"" + ""\n"" + ""WS:             [ \\t\\r\\n] -> skip;\n"" + ""\n"" + ""SIMPLE_TOKEN:           'and';\n"" + ""TOKEN_WITH_SPACES:      'as' 'd' 'f';\n"" + ""TOKEN_WITH_DIGITS:      'INT64';\n"" + ""TOKEN_WITH_UNDERSCORE:  'TOKEN_WITH_UNDERSCORE';\n"" + ""BOOL:                   'true' | 'FALSE';\n"" + ""SPECIAL:                '==';\n"" + // [a-zA-Z0-9]
    ""SET:                    [a-z0-9]+;\n"" + ""RANGE:                  ('а'..'я')+;"");
    String inputString = ""and AND aND\n"" + ""asdf ASDF\n"" + ""int64\n"" + ""token_WITH_underscore\n"" + ""TRUE FALSE\n"" + ""==\n"" + ""A0bcDE93\n"" + ""АБВабв\n"";
    String expecting = Utils.join(new String[] { ""SIMPLE_TOKEN"", ""SIMPLE_TOKEN"", ""SIMPLE_TOKEN"", ""TOKEN_WITH_SPACES"", ""TOKEN_WITH_SPACES"", ""TOKEN_WITH_DIGITS"", ""TOKEN_WITH_UNDERSCORE"", ""BOOL"", ""BOOL"", ""SPECIAL"", ""SET"", ""RANGE"", ""EOF"" }, "", WS, "");
    checkLexerMatches(lg, inputString, expecting);
}", ,"// [a-zA-Z0-9]
",// [a-zA-Z0-9],379,421,[0],0,[0],0,[0],0,0,0,0,testLexerCaseInsensitive(),org.antlr.v4.test.tool.TestATNLexerInterpreter,testLexerCaseInsensitive/0,False,379,3,2,0,2,1,2,6,0,3,0,2,1,2,0,0,0,0,36,0,3,2,0,0,0,0,21,1,0,False
736,..\projects\antlr4-4.11.0\tool-testsuite\test\org\antlr\v4\test\tool\TestATNLexerInterpreter.java,org.antlr.v4.test.tool.TestATNLexerInterpreter,void testLexerCaseInsensitiveLiteralWithNegation(),"@Test
public void testLexerCaseInsensitiveLiteralWithNegation() {
    String grammar = ""lexer grammar L;\n"" + ""options { caseInsensitive = true; }\n"" + // ~('f' | 'F)
    ""LITERAL_WITH_NOT:   ~'f';\n"";
    ExecutedState executedState = execLexer(""L.g4"", grammar, ""L"", ""F"");
    assertEquals(""line 1:0 token recognition error at: 'F'\n"", executedState.errors);
}", ,"// ~('f' | 'F)
",// ~('f' | 'F),423,431,[0],0,[0],0,[0],0,0,0,0,testLexerCaseInsensitiveLiteralWithNegation(),org.antlr.v4.test.tool.TestATNLexerInterpreter,testLexerCaseInsensitiveLiteralWithNegation/0,False,423,3,1,0,1,1,2,5,0,2,0,2,0,0,0,0,0,0,7,0,2,1,0,0,0,0,20,1,0,False
737,..\projects\antlr4-4.11.0\tool-testsuite\test\org\antlr\v4\test\tool\TestATNLexerInterpreter.java,org.antlr.v4.test.tool.TestATNLexerInterpreter,void testLexerCaseInsensitiveSetWithNegation(),"@Test
public void testLexerCaseInsensitiveSetWithNegation() {
    String grammar = ""lexer grammar L;\n"" + ""options { caseInsensitive = true; }\n"" + // ~[a-cA-C]
    ""SET_WITH_NOT: ~[a-c];\n"";
    ExecutedState executedState = execLexer(""L.g4"", grammar, ""L"", ""B"");
    assertEquals(""line 1:0 token recognition error at: 'B'\n"", executedState.errors);
}", ,"// ~[a-cA-C]
",// ~[a-cA-C],433,441,[0],0,[0],0,[0],0,0,0,0,testLexerCaseInsensitiveSetWithNegation(),org.antlr.v4.test.tool.TestATNLexerInterpreter,testLexerCaseInsensitiveSetWithNegation/0,False,433,3,1,0,1,1,2,5,0,2,0,2,0,0,0,0,0,0,7,0,2,1,0,0,0,0,20,1,0,False
738,..\projects\antlr4-4.11.0\tool-testsuite\test\org\antlr\v4\test\tool\TestATNLexerInterpreter.java,org.antlr.v4.test.tool.TestATNLexerInterpreter,void testLexerCaseInsensitiveWithDifferentCultures(),"@Test
public void testLexerCaseInsensitiveWithDifferentCultures() throws Exception {
    // From http://www.periodni.com/unicode_utf-8_encoding.html
    LexerGrammar lg = new LexerGrammar(""lexer grammar L;\n"" + ""options { caseInsensitive = true; }\n"" + ""ENGLISH_TOKEN:   [a-z]+;\n"" + ""GERMAN_TOKEN:    [äéöüß]+;\n"" + ""FRENCH_TOKEN:    [àâæ-ëîïôœùûüÿ]+;\n"" + ""CROATIAN_TOKEN:  [ćčđšž]+;\n"" + ""ITALIAN_TOKEN:   [àèéìòù]+;\n"" + ""SPANISH_TOKEN:   [áéíñóúü¡¿]+;\n"" + ""GREEK_TOKEN:     [α-ω]+;\n"" + ""RUSSIAN_TOKEN:   [а-я]+;\n"" + ""WS:              [ ]+ -> skip;"");
    String inputString = ""abcXYZ äéöüßÄÉÖÜß àâæçÙÛÜŸ ćčđĐŠŽ àèéÌÒÙ áéÚÜ¡¿ αβγΧΨΩ абвЭЮЯ "";
    String expecting = Utils.join(new String[] { ""ENGLISH_TOKEN"", ""GERMAN_TOKEN"", ""FRENCH_TOKEN"", ""CROATIAN_TOKEN"", ""ITALIAN_TOKEN"", ""SPANISH_TOKEN"", ""GREEK_TOKEN"", ""RUSSIAN_TOKEN"", ""EOF"" }, "", WS, "");
    checkLexerMatches(lg, inputString, expecting);
}", ,"// From http://www.periodni.com/unicode_utf-8_encoding.html
",// From http://www.periodni.com/unicode_utf-8_encoding.html,459,490,[0],0,[0],0,[0],0,0,0,0,testLexerCaseInsensitiveWithDifferentCultures(),org.antlr.v4.test.tool.TestATNLexerInterpreter,testLexerCaseInsensitiveWithDifferentCultures/0,False,459,3,2,0,2,1,2,6,0,3,0,2,1,2,0,0,0,0,22,0,3,1,0,0,0,0,20,1,0,False
739,..\projects\antlr4-4.11.0\tool-testsuite\test\org\antlr\v4\test\tool\TestATNLexerInterpreter.java,org.antlr.v4.test.tool.TestATNLexerInterpreter,void testNotImpliedCharactersWithEnabledCaseInsensitiveOption(),"@Test
public void testNotImpliedCharactersWithEnabledCaseInsensitiveOption() throws Exception {
    LexerGrammar lg = new LexerGrammar(""lexer grammar L;\n"" + ""options { caseInsensitive = true; }\n"" + ""TOKEN: ('A'..'z')+;\n"");
    // No range transformation because of mixed character case in range borders
    String inputString = ""ABCDEFGHIJKLMNOPQRSTUVWXYZ[\\]^_`abcdefghijklmnopqrstuvwxyz"";
    checkLexerMatches(lg, inputString, ""TOKEN, EOF"");
}", ,"// No range transformation because of mixed character case in range borders
",// No range transformation because of mixed character case in range borders,492,502,[0],0,[0],0,[0],0,0,0,0,testNotImpliedCharactersWithEnabledCaseInsensitiveOption(),org.antlr.v4.test.tool.TestATNLexerInterpreter,testNotImpliedCharactersWithEnabledCaseInsensitiveOption/0,False,492,3,2,0,2,1,1,5,0,2,0,1,1,2,0,0,0,0,5,0,2,1,0,0,0,0,21,1,0,False
740,..\projects\antlr4-4.11.0\tool-testsuite\test\org\antlr\v4\test\tool\TestATNLexerInterpreter.java,org.antlr.v4.test.tool.TestATNLexerInterpreter,"void checkLexerMatches(LexerGrammar, String, String)","private void checkLexerMatches(LexerGrammar lg, String inputString, String expecting) {
    ATN atn = createATN(lg, true);
    CharStream input = CharStreams.fromString(inputString);
    ATNState startState = atn.modeNameToStartState.get(""DEFAULT_MODE"");
    DOTGenerator dot = new DOTGenerator(lg);
    // System.out.println(dot.getDOT(startState, true));
    List<String> tokenTypes = getTokenTypes(lg, atn, input);
    String result = Utils.join(tokenTypes.iterator(), "", "");
    // System.out.println(tokenTypes);
    assertEquals(expecting, result);
}", ,"// System.out.println(dot.getDOT(startState, true));
[[SEP]]// System.out.println(tokenTypes);
","// System.out.println(dot.getDOT(startState, true));[[SEP]]// System.out.println(tokenTypes);",524,536,[0],0,"[0, 0]",0,"[0, 0]",0,0,0,0,"checkLexerMatches(LexerGrammar, String, String)",org.antlr.v4.test.tool.TestATNLexerInterpreter,"checkLexerMatches/3[org.antlr.v4.tool.LexerGrammar,java.lang.String,java.lang.String]",False,524,7,45,42,3,1,7,9,0,6,3,7,1,1,0,0,0,0,2,0,6,0,0,0,0,0,28,2,0,False
741,..\projects\antlr4-4.11.0\tool-testsuite\test\org\antlr\v4\test\tool\TestATNParserPrediction.java,org.antlr.v4.test.tool.TestATNParserPrediction,void testAorB(),"@Test
public void testAorB() throws Exception {
    LexerGrammar lg = new LexerGrammar(""lexer grammar L;\n"" + ""A : 'a' ;\n"" + ""B : 'b' ;\n"" + ""C : 'c' ;\n"");
    Grammar g = new Grammar(""parser grammar T;\n"" + ""a : A{;} | B ;"");
    int decision = 0;
    checkPredictedAlt(lg, g, decision, ""a"", 1);
    checkPredictedAlt(lg, g, decision, ""b"", 2);
    // After matching these inputs for decision, what is DFA after each prediction?
    String[] inputs = { ""a"", ""b"", ""a"" };
    String[] dfa = { ""s0-'a'->:s1=>1\n"", ""s0-'a'->:s1=>1\n"" + ""s0-'b'->:s2=>2\n"", // don't change after it works
    ""s0-'a'->:s1=>1\n"" + ""s0-'b'->:s2=>2\n"" };
    checkDFAConstruction(lg, g, decision, inputs, dfa);
}", ,"// After matching these inputs for decision, what is DFA after each prediction?
[[SEP]]// don't change after it works
","// After matching these inputs for decision, what is DFA after each prediction?[[SEP]]// don't change after it works",38,67,[0],0,"[0, 0]",0,"[0, 0]",0,0,1,0,testAorB(),org.antlr.v4.test.tool.TestATNParserPrediction,testAorB/0,False,38,4,4,0,4,1,2,10,0,5,0,2,2,1,0,0,0,0,16,3,5,4,0,0,0,0,21,1,0,False
742,..\projects\antlr4-4.11.0\tool-testsuite\test\org\antlr\v4\test\tool\TestATNParserPrediction.java,org.antlr.v4.test.tool.TestATNParserPrediction,void testEmptyInput(),"@Test
public void testEmptyInput() throws Exception {
    LexerGrammar lg = new LexerGrammar(""lexer grammar L;\n"" + ""A : 'a' ;\n"" + ""B : 'b' ;\n"" + ""C : 'c' ;\n"");
    Grammar g = new Grammar(""parser grammar T;\n"" + ""a : A | ;"");
    int decision = 0;
    checkPredictedAlt(lg, g, decision, ""a"", 1);
    checkPredictedAlt(lg, g, decision, """", 2);
    // After matching these inputs for decision, what is DFA after each prediction?
    String[] inputs = { ""a"", """" };
    String[] dfa = { ""s0-'a'->:s1=>1\n"", ""s0-EOF->:s2=>2\n"" + ""s0-'a'->:s1=>1\n"" };
    checkDFAConstruction(lg, g, decision, inputs, dfa);
}", ,"// After matching these inputs for decision, what is DFA after each prediction?
","// After matching these inputs for decision, what is DFA after each prediction?",69,94,[0],0,[0],0,[0],0,0,1,0,testEmptyInput(),org.antlr.v4.test.tool.TestATNParserPrediction,testEmptyInput/0,False,69,4,4,0,4,1,2,10,0,5,0,2,2,1,0,0,0,0,13,3,5,3,0,0,0,0,23,1,0,False
743,..\projects\antlr4-4.11.0\tool-testsuite\test\org\antlr\v4\test\tool\TestATNParserPrediction.java,org.antlr.v4.test.tool.TestATNParserPrediction,void testRuleRefxory(),"@Test
public void testRuleRefxory() throws Exception {
    LexerGrammar lg = new LexerGrammar(""lexer grammar L;\n"" + ""A : 'a' ;\n"" + ""B : 'b' ;\n"" + ""C : 'c' ;\n"");
    Grammar g = new Grammar(""parser grammar T;\n"" + ""a : x | y ;\n"" + ""x : A ;\n"" + ""y : B ;\n"");
    int decision = 0;
    checkPredictedAlt(lg, g, decision, ""a"", 1);
    checkPredictedAlt(lg, g, decision, ""b"", 2);
    // After matching these inputs for decision, what is DFA after each prediction?
    String[] inputs = { ""a"", ""b"", ""a"" };
    String[] dfa = { ""s0-'a'->:s1=>1\n"", ""s0-'a'->:s1=>1\n"" + ""s0-'b'->:s2=>2\n"", // don't change after it works
    ""s0-'a'->:s1=>1\n"" + ""s0-'b'->:s2=>2\n"" };
    checkDFAConstruction(lg, g, decision, inputs, dfa);
}", ,"// After matching these inputs for decision, what is DFA after each prediction?
[[SEP]]// don't change after it works
","// After matching these inputs for decision, what is DFA after each prediction?[[SEP]]// don't change after it works",129,160,[0],0,"[0, 0]",0,"[0, 0]",0,0,1,0,testRuleRefxory(),org.antlr.v4.test.tool.TestATNParserPrediction,testRuleRefxory/0,False,129,4,4,0,4,1,2,10,0,5,0,2,2,1,0,0,0,0,18,3,5,4,0,0,0,0,24,1,0,False
744,..\projects\antlr4-4.11.0\tool-testsuite\test\org\antlr\v4\test\tool\TestATNParserPrediction.java,org.antlr.v4.test.tool.TestATNParserPrediction,void testOptionalRuleChasesGlobalFollow(),"@Test
public void testOptionalRuleChasesGlobalFollow() throws Exception {
    LexerGrammar lg = new LexerGrammar(""lexer grammar L;\n"" + ""A : 'a' ;\n"" + ""B : 'b' ;\n"" + ""C : 'c' ;\n"");
    Grammar g = new Grammar(""parser grammar T;\n"" + ""tokens {A,B,C}\n"" + ""a : x B ;\n"" + ""b : x C ;\n"" + ""x : A | ;\n"");
    int decision = 0;
    checkPredictedAlt(lg, g, decision, ""a"", 1);
    checkPredictedAlt(lg, g, decision, ""b"", 2);
    checkPredictedAlt(lg, g, decision, ""c"", 2);
    // After matching these inputs for decision, what is DFA after each prediction?
    String[] inputs = { ""a"", ""b"", ""c"", ""c"" };
    String[] dfa = { ""s0-'a'->:s1=>1\n"", ""s0-'a'->:s1=>1\n"" + ""s0-'b'->:s2=>2\n"", ""s0-'a'->:s1=>1\n"" + ""s0-'b'->:s2=>2\n"" + ""s0-'c'->:s3=>2\n"", ""s0-'a'->:s1=>1\n"" + ""s0-'b'->:s2=>2\n"" + ""s0-'c'->:s3=>2\n"" };
    checkDFAConstruction(lg, g, decision, inputs, dfa);
}", ,"// After matching these inputs for decision, what is DFA after each prediction?
","// After matching these inputs for decision, what is DFA after each prediction?",162,201,[0],0,[0],0,[0],0,0,1,0,testOptionalRuleChasesGlobalFollow(),org.antlr.v4.test.tool.TestATNParserPrediction,testOptionalRuleChasesGlobalFollow/0,False,162,4,4,0,4,1,2,11,0,5,0,2,2,1,0,0,0,0,25,4,5,5,0,0,0,0,27,1,0,False
745,..\projects\antlr4-4.11.0\tool-testsuite\test\org\antlr\v4\test\tool\TestATNParserPrediction.java,org.antlr.v4.test.tool.TestATNParserPrediction,void testLL1Ambig(),"@Test
public void testLL1Ambig() throws Exception {
    LexerGrammar lg = new LexerGrammar(""lexer grammar L;\n"" + ""A : 'a' ;\n"" + ""B : 'b' ;\n"" + ""C : 'c' ;\n"");
    Grammar g = new Grammar(""parser grammar T;\n"" + ""a : A | A | A B ;"");
    int decision = 0;
    checkPredictedAlt(lg, g, decision, ""a"", 1);
    checkPredictedAlt(lg, g, decision, ""ab"", 3);
    // After matching these inputs for decision, what is DFA after each prediction?
    String[] inputs = { ""a"", ""ab"", ""ab"" };
    String[] dfa = { ""s0-'a'->s1\n"" + ""s1-EOF->:s2^=>1\n"", ""s0-'a'->s1\n"" + ""s1-EOF->:s2^=>1\n"" + ""s1-'b'->:s3=>3\n"", ""s0-'a'->s1\n"" + ""s1-EOF->:s2^=>1\n"" + ""s1-'b'->:s3=>3\n"" };
    checkDFAConstruction(lg, g, decision, inputs, dfa);
}", ,"// After matching these inputs for decision, what is DFA after each prediction?
","// After matching these inputs for decision, what is DFA after each prediction?",203,235,[0],0,[0],0,[0],0,0,1,0,testLL1Ambig(),org.antlr.v4.test.tool.TestATNParserPrediction,testLL1Ambig/0,False,203,4,4,0,4,1,2,10,0,5,0,2,2,1,0,0,0,0,19,3,5,5,0,0,0,0,24,1,0,False
746,..\projects\antlr4-4.11.0\tool-testsuite\test\org\antlr\v4\test\tool\TestATNParserPrediction.java,org.antlr.v4.test.tool.TestATNParserPrediction,void testLL2Ambig(),"@Test
public void testLL2Ambig() throws Exception {
    LexerGrammar lg = new LexerGrammar(""lexer grammar L;\n"" + ""A : 'a' ;\n"" + ""B : 'b' ;\n"" + ""C : 'c' ;\n"");
    Grammar g = new Grammar(""parser grammar T;\n"" + ""a : A B | A B | A B C ;"");
    int decision = 0;
    checkPredictedAlt(lg, g, decision, ""ab"", 1);
    checkPredictedAlt(lg, g, decision, ""abc"", 3);
    // After matching these inputs for decision, what is DFA after each prediction?
    String[] inputs = { ""ab"", ""abc"", ""ab"" };
    String[] dfa = { ""s0-'a'->s1\n"" + ""s1-'b'->s2\n"" + ""s2-EOF->:s3^=>1\n"", ""s0-'a'->s1\n"" + ""s1-'b'->s2\n"" + ""s2-EOF->:s3^=>1\n"" + ""s2-'c'->:s4=>3\n"", ""s0-'a'->s1\n"" + ""s1-'b'->s2\n"" + ""s2-EOF->:s3^=>1\n"" + ""s2-'c'->:s4=>3\n"" };
    checkDFAConstruction(lg, g, decision, inputs, dfa);
}", ,"// After matching these inputs for decision, what is DFA after each prediction?
","// After matching these inputs for decision, what is DFA after each prediction?",237,272,[0],0,[0],0,[0],0,0,1,0,testLL2Ambig(),org.antlr.v4.test.tool.TestATNParserPrediction,testLL2Ambig/0,False,237,4,4,0,4,1,2,10,0,5,0,2,2,1,0,0,0,0,22,3,5,5,0,0,0,0,25,1,0,False
747,..\projects\antlr4-4.11.0\tool-testsuite\test\org\antlr\v4\test\tool\TestATNParserPrediction.java,org.antlr.v4.test.tool.TestATNParserPrediction,void testRecursiveLeftPrefix(),"@Test
public void testRecursiveLeftPrefix() throws Exception {
    LexerGrammar lg = new LexerGrammar(""lexer grammar L;\n"" + ""A : 'a' ;\n"" + ""B : 'b' ;\n"" + ""C : 'c' ;\n"" + ""LP : '(' ;\n"" + ""RP : ')' ;\n"" + ""INT : '0'..'9'+ ;\n"");
    Grammar g = new Grammar(""parser grammar T;\n"" + ""tokens {A,B,C,LP,RP,INT}\n"" + ""a : e B | e C ;\n"" + ""e : LP e RP\n"" + ""  | INT\n"" + ""  ;"");
    int decision = 0;
    checkPredictedAlt(lg, g, decision, ""34b"", 1);
    checkPredictedAlt(lg, g, decision, ""34c"", 2);
    checkPredictedAlt(lg, g, decision, ""((34))b"", 1);
    checkPredictedAlt(lg, g, decision, ""((34))c"", 2);
    // After matching these inputs for decision, what is DFA after each prediction?
    String[] inputs = { ""34b"", ""34c"", ""((34))b"", ""((34))c"" };
    String[] dfa = { ""s0-INT->s1\n"" + ""s1-'b'->:s2=>1\n"", ""s0-INT->s1\n"" + ""s1-'b'->:s2=>1\n"" + ""s1-'c'->:s3=>2\n"", ""s0-'('->s4\n"" + ""s0-INT->s1\n"" + ""s1-'b'->:s2=>1\n"" + ""s1-'c'->:s3=>2\n"" + ""s4-'('->s5\n"" + ""s5-INT->s6\n"" + ""s6-')'->s7\n"" + ""s7-')'->s1\n"", ""s0-'('->s4\n"" + ""s0-INT->s1\n"" + ""s1-'b'->:s2=>1\n"" + ""s1-'c'->:s3=>2\n"" + ""s4-'('->s5\n"" + ""s5-INT->s6\n"" + ""s6-')'->s7\n"" + ""s7-')'->s1\n"" };
    checkDFAConstruction(lg, g, decision, inputs, dfa);
}", ,"// After matching these inputs for decision, what is DFA after each prediction?
","// After matching these inputs for decision, what is DFA after each prediction?",274,331,[0],0,[0],0,[0],0,0,1,0,testRecursiveLeftPrefix(),org.antlr.v4.test.tool.TestATNParserPrediction,testRecursiveLeftPrefix/0,False,274,4,4,0,4,1,2,12,0,5,0,2,2,1,0,0,0,0,42,5,5,6,0,0,0,0,28,1,0,False
748,..\projects\antlr4-4.11.0\tool-testsuite\test\org\antlr\v4\test\tool\TestATNParserPrediction.java,org.antlr.v4.test.tool.TestATNParserPrediction,void testRecursiveLeftPrefixWithAorABIssue(),"@Test
public void testRecursiveLeftPrefixWithAorABIssue() throws Exception {
    LexerGrammar lg = new LexerGrammar(""lexer grammar L;\n"" + ""A : 'a' ;\n"" + ""B : 'b' ;\n"" + ""C : 'c' ;\n"" + ""LP : '(' ;\n"" + ""RP : ')' ;\n"" + ""INT : '0'..'9'+ ;\n"");
    Grammar g = new Grammar(""parser grammar T;\n"" + ""tokens {A,B,C,LP,RP,INT}\n"" + ""a : e A | e A B ;\n"" + ""e : LP e RP\n"" + ""  | INT\n"" + ""  ;"");
    int decision = 0;
    checkPredictedAlt(lg, g, decision, ""34a"", 1);
    // PEG would miss this one!
    checkPredictedAlt(lg, g, decision, ""34ab"", 2);
    checkPredictedAlt(lg, g, decision, ""((34))a"", 1);
    checkPredictedAlt(lg, g, decision, ""((34))ab"", 2);
    // After matching these inputs for decision, what is DFA after each prediction?
    String[] inputs = { ""34a"", ""34ab"", ""((34))a"", ""((34))ab"" };
    String[] dfa = { ""s0-INT->s1\n"" + ""s1-'a'->s2\n"" + ""s2-EOF->:s3=>1\n"", ""s0-INT->s1\n"" + ""s1-'a'->s2\n"" + ""s2-EOF->:s3=>1\n"" + ""s2-'b'->:s4=>2\n"", ""s0-'('->s5\n"" + ""s0-INT->s1\n"" + ""s1-'a'->s2\n"" + ""s2-EOF->:s3=>1\n"" + ""s2-'b'->:s4=>2\n"" + ""s5-'('->s6\n"" + ""s6-INT->s7\n"" + ""s7-')'->s8\n"" + ""s8-')'->s1\n"", ""s0-'('->s5\n"" + ""s0-INT->s1\n"" + ""s1-'a'->s2\n"" + ""s2-EOF->:s3=>1\n"" + ""s2-'b'->:s4=>2\n"" + ""s5-'('->s6\n"" + ""s6-INT->s7\n"" + ""s7-')'->s8\n"" + ""s8-')'->s1\n"" };
    checkDFAConstruction(lg, g, decision, inputs, dfa);
}", ,"// PEG would miss this one!
[[SEP]]// After matching these inputs for decision, what is DFA after each prediction?
","// PEG would miss this one![[SEP]]// After matching these inputs for decision, what is DFA after each prediction?",333,394,[0],0,"[0, 0]",0,"[0, 0]",0,0,1,0,testRecursiveLeftPrefixWithAorABIssue(),org.antlr.v4.test.tool.TestATNParserPrediction,testRecursiveLeftPrefixWithAorABIssue/0,False,333,4,4,0,4,1,2,12,0,5,0,2,2,1,0,0,0,0,46,5,5,6,0,0,0,0,32,1,0,False
749,..\projects\antlr4-4.11.0\tool-testsuite\test\org\antlr\v4\test\tool\TestATNParserPrediction.java,org.antlr.v4.test.tool.TestATNParserPrediction,void testContinuePrediction(),"@Test
public void testContinuePrediction() throws Exception {
    // Sam found prev def of ambiguity was too restrictive.
    // E.g., (13, 1, []), (13, 2, []), (12, 2, []) should not
    // be declared ambig since (12, 2, []) can take us to
    // unambig state maybe. keep going.
    LexerGrammar lg = new LexerGrammar(""lexer grammar L;\n"" + // one char
    ""ID : 'a'..'z' ;\n"" + ""SEMI : ';' ;\n"" + ""INT : '0'..'9'+ ;\n"");
    Grammar g = new Grammar(""parser grammar T;\n"" + ""tokens {ID,SEMI,INT}\n"" + ""a : (ID | ID ID?) SEMI ;"");
    int decision = 1;
    checkPredictedAlt(lg, g, decision, ""a;"", 1);
    checkPredictedAlt(lg, g, decision, ""ab;"", 2);
}", ,"// Sam found prev def of ambiguity was too restrictive.
[[SEP]]// E.g., (13, 1, []), (13, 2, []), (12, 2, []) should not
[[SEP]]// be declared ambig since (12, 2, []) can take us to
[[SEP]]// unambig state maybe. keep going.
[[SEP]]// one char
","// Sam found prev def of ambiguity was too restrictive.// E.g., (13, 1, []), (13, 2, []), (12, 2, []) should not// be declared ambig since (12, 2, []) can take us to// unambig state maybe. keep going.[[SEP]]// one char",396,414,[0],0,"[0, 0, 0, 0, 0]",0,"[0, 0]",0,0,0,0,testContinuePrediction(),org.antlr.v4.test.tool.TestATNParserPrediction,testContinuePrediction/0,False,396,4,3,0,3,1,1,7,0,3,0,1,1,1,0,0,0,0,9,3,3,2,0,0,0,0,20,1,0,False
750,..\projects\antlr4-4.11.0\tool-testsuite\test\org\antlr\v4\test\tool\TestATNParserPrediction.java,org.antlr.v4.test.tool.TestATNParserPrediction,void testContinuePrediction2(),"@Test
public void testContinuePrediction2() throws Exception {
    // ID is ambig for first two alts, but ID SEMI lets us move forward with alt 3
    LexerGrammar lg = new LexerGrammar(""lexer grammar L;\n"" + // one char
    ""ID : 'a'..'z' ;\n"" + ""SEMI : ';' ;\n"" + ""INT : '0'..'9'+ ;\n"");
    Grammar g = new Grammar(""parser grammar T;\n"" + ""tokens {ID,SEMI,INT}\n"" + ""a : ID | ID | ID SEMI ;\n"");
    int decision = 0;
    checkPredictedAlt(lg, g, decision, ""a"", 1);
    checkPredictedAlt(lg, g, decision, ""a;"", 3);
}", ,"// ID is ambig for first two alts, but ID SEMI lets us move forward with alt 3
[[SEP]]// one char
","// ID is ambig for first two alts, but ID SEMI lets us move forward with alt 3[[SEP]]// one char",416,431,[0],0,"[0, 0]",0,"[0, 0]",0,0,0,0,testContinuePrediction2(),org.antlr.v4.test.tool.TestATNParserPrediction,testContinuePrediction2/0,False,416,4,3,0,3,1,1,7,0,3,0,1,1,1,0,0,0,0,9,3,3,2,0,0,0,0,20,1,0,False
751,..\projects\antlr4-4.11.0\tool-testsuite\test\org\antlr\v4\test\tool\TestATNParserPrediction.java,org.antlr.v4.test.tool.TestATNParserPrediction,void testAltsForLRRuleComputation3(),"@Test
public void testAltsForLRRuleComputation3() throws Exception {
    Grammar g = new Grammar(""grammar T;\n"" + // should have no effect
    ""random : 'blort';\n"" + ""e : '--' e\n"" + ""  | e '*' e\n"" + ""  | e '+' e\n"" + ""  | e '--'\n"" + ""  | ID\n"" + ""  ;\n"" + ""ID : [a-z]+ ;\n"" + ""INT : [0-9]+ ;\n"" + ""WS : [ \\r\\t\\n]+ ;"");
    Rule e = g.getRule(""e"");
    assertTrue(e instanceof LeftRecursiveRule);
    LeftRecursiveRule lr = (LeftRecursiveRule) e;
    assertEquals(""[0, 1, 5]"", Arrays.toString(lr.getPrimaryAlts()));
    assertEquals(""[0, 2, 3, 4]"", Arrays.toString(lr.getRecursiveOpAlts()));
}", ,"// should have no effect
",// should have no effect,468,486,[0],0,[0],0,[0],0,0,0,0,testAltsForLRRuleComputation3(),org.antlr.v4.test.tool.TestATNParserPrediction,testAltsForLRRuleComputation3/0,False,468,4,4,0,4,1,6,8,0,3,0,6,0,0,0,0,0,0,14,0,3,1,0,0,0,0,18,1,0,False
752,..\projects\antlr4-4.11.0\tool-testsuite\test\org\antlr\v4\test\tool\TestATNParserPrediction.java,org.antlr.v4.test.tool.TestATNParserPrediction,"void checkPredictedAlt(LexerGrammar, Grammar, int, String, int)","/**
 * first check that the ATN predicts right alt.
 *  Then check adaptive prediction.
 */
public void checkPredictedAlt(LexerGrammar lg, Grammar g, int decision, String inputString, int expectedAlt) {
    ATN lexatn = createATN(lg, true);
    LexerATNSimulator lexInterp = new LexerATNSimulator(lexatn, new DFA[] { new DFA(lexatn.modeToStartState.get(Lexer.DEFAULT_MODE)) }, new PredictionContextCache());
    IntegerList types = getTokenTypesViaATN(inputString, lexInterp);
    // System.out.println(types);
    semanticProcess(lg);
    g.importVocab(lg);
    semanticProcess(g);
    ParserATNFactory f = new ParserATNFactory(g);
    ATN atn = f.createATN();
    DOTGenerator dot = new DOTGenerator(g);
    Rule r = g.getRule(""a"");
    // if ( r!=null) System.out.println(dot.getDOT(atn.ruleToStartState[r.index]));
    r = g.getRule(""b"");
    // if ( r!=null) System.out.println(dot.getDOT(atn.ruleToStartState[r.index]));
    r = g.getRule(""e"");
    // if ( r!=null) System.out.println(dot.getDOT(atn.ruleToStartState[r.index]));
    r = g.getRule(""ifstat"");
    // if ( r!=null) System.out.println(dot.getDOT(atn.ruleToStartState[r.index]));
    r = g.getRule(""block"");
    // if ( r!=null) System.out.println(dot.getDOT(atn.ruleToStartState[r.index]));
    // Check ATN prediction
    // ParserATNSimulator interp = new ParserATNSimulator(atn);
    TokenStream input = new MockIntTokenStream(types);
    ParserInterpreterForTesting interp = new ParserInterpreterForTesting(g, input);
    int alt = interp.adaptivePredict(input, decision, ParserRuleContext.EMPTY);
    assertEquals(expectedAlt, alt);
    // Check adaptive prediction
    input.seek(0);
    alt = interp.adaptivePredict(input, decision, null);
    assertEquals(expectedAlt, alt);
    // run 2x; first time creates DFA in atn
    input.seek(0);
    alt = interp.adaptivePredict(input, decision, null);
    assertEquals(expectedAlt, alt);
}","/**
 * first check that the ATN predicts right alt.
 *  Then check adaptive prediction.
 */
","// System.out.println(types);
[[SEP]]// if ( r!=null) System.out.println(dot.getDOT(atn.ruleToStartState[r.index]));
[[SEP]]// Check ATN prediction
[[SEP]]// if ( r!=null) System.out.println(dot.getDOT(atn.ruleToStartState[r.index]));
[[SEP]]// if ( r!=null) System.out.println(dot.getDOT(atn.ruleToStartState[r.index]));
[[SEP]]// if ( r!=null) System.out.println(dot.getDOT(atn.ruleToStartState[r.index]));
[[SEP]]// if ( r!=null) System.out.println(dot.getDOT(atn.ruleToStartState[r.index]));
[[SEP]]// ParserATNSimulator interp = new ParserATNSimulator(atn);
[[SEP]]// Check adaptive prediction
[[SEP]]// run 2x; first time creates DFA in atn
",/** * first check that the ATN predicts right alt. *  Then check adaptive prediction. */[[SEP]]// System.out.println(types);[[SEP]]// if ( r!=null) System.out.println(dot.getDOT(atn.ruleToStartState[r.index]));[[SEP]]// if ( r!=null) System.out.println(dot.getDOT(atn.ruleToStartState[r.index]));[[SEP]]// if ( r!=null) System.out.println(dot.getDOT(atn.ruleToStartState[r.index]));[[SEP]]// if ( r!=null) System.out.println(dot.getDOT(atn.ruleToStartState[r.index]));[[SEP]]// if ( r!=null) System.out.println(dot.getDOT(atn.ruleToStartState[r.index]));// Check ATN prediction// ParserATNSimulator interp = new ParserATNSimulator(atn);[[SEP]]// Check adaptive prediction[[SEP]]// run 2x; first time creates DFA in atn,491,536,[0],0,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]",0,"[0, 0, 0, 0, 0, 0, 0, 0, 0]",0,0,0,0,"checkPredictedAlt(LexerGrammar, Grammar, int, String, int)",org.antlr.v4.test.tool.TestATNParserPrediction,"checkPredictedAlt/5[org.antlr.v4.tool.LexerGrammar,org.antlr.v4.tool.Grammar,int,java.lang.String,int]",False,493,14,20,11,9,1,10,26,0,10,5,10,0,0,0,0,0,0,5,2,16,0,0,0,0,0,57,1,0,True
753,..\projects\antlr4-4.11.0\tool-testsuite\test\org\antlr\v4\test\tool\TestATNParserPrediction.java,org.antlr.v4.test.tool.TestATNParserPrediction,"void checkDFAConstruction(LexerGrammar, Grammar, int, String[], String[])","public void checkDFAConstruction(LexerGrammar lg, Grammar g, int decision, String[] inputString, String[] dfaString) {
    // Tool.internalOption_ShowATNConfigsInDFA = true;
    ATN lexatn = createATN(lg, true);
    LexerATNSimulator lexInterp = new LexerATNSimulator(lexatn, new DFA[] { new DFA(lexatn.getDecisionState(Lexer.DEFAULT_MODE)) }, new PredictionContextCache());
    semanticProcess(lg);
    g.importVocab(lg);
    semanticProcess(g);
    ParserInterpreterForTesting interp = new ParserInterpreterForTesting(g, null);
    for (int i = 0; i < inputString.length; i++) {
        // Check DFA
        IntegerList types = getTokenTypesViaATN(inputString[i], lexInterp);
        // System.out.println(types);
        TokenStream input = new MockIntTokenStream(types);
        try {
            interp.adaptivePredict(input, decision, ParserRuleContext.EMPTY);
        } catch (NoViableAltException nvae) {
            nvae.printStackTrace(System.err);
        }
        DFA dfa = interp.parser.decisionToDFA[decision];
        assertEquals(dfaString[i], dfa.toString(g.getVocabulary()));
    }
}", ,"// Tool.internalOption_ShowATNConfigsInDFA = true;
[[SEP]]// Check DFA
[[SEP]]// System.out.println(types);
",// Tool.internalOption_ShowATNConfigsInDFA = true;[[SEP]]// Check DFA[[SEP]]// System.out.println(types);,538,565,[0],0,"[0, 0, 0]",0,"[0, 0, 0]",0,0,0,0,"checkDFAConstruction(LexerGrammar, Grammar, int, String[], String[])",org.antlr.v4.test.tool.TestATNParserPrediction,"checkDFAConstruction/5[org.antlr.v4.tool.LexerGrammar,org.antlr.v4.tool.Grammar,int,java.lang.String[],java.lang.String[]]",False,540,11,17,9,8,3,10,20,0,7,5,10,0,0,1,0,1,0,0,1,7,0,2,0,0,0,47,1,0,False
754,..\projects\antlr4-4.11.0\tool-testsuite\test\org\antlr\v4\test\tool\TestActionTranslation.java,org.antlr.v4.test.tool.TestActionTranslation,void testUnescaped$InAction(),"/**
 * Regression test for ""in antlr v4 lexer, $ translation issue in action"".
 * https://github.com/antlr/antlr4/issues/176
 */
@Test
public void testUnescaped$InAction() throws Exception {
    String action = ""\\$string$"";
    String expected = ""$string$"";
    testActions(attributeTemplate, ""members"", action, expected);
    testActions(attributeTemplate, ""init"", action, expected);
    testActions(attributeTemplate, ""inline"", action, expected);
    testActions(attributeTemplate, ""finally"", action, expected);
    testActions(attributeTemplate, ""inline2"", action, expected);
}","/**
 * Regression test for ""in antlr v4 lexer, $ translation issue in action"".
 * https://github.com/antlr/antlr4/issues/176
 */
", ,"/** * Regression test for ""in antlr v4 lexer, $ translation issue in action"". * https://github.com/antlr/antlr4/issues/176 */",71,79,[0],0,[0],0,[0],0,0,0,0,testUnescaped$InAction(),org.antlr.v4.test.tool.TestActionTranslation,testUnescaped$InAction/0,False,71,2,1,0,1,1,1,9,0,2,0,1,1,1,0,0,0,0,7,0,2,0,0,0,0,0,13,1,0,True
755,..\projects\antlr4-4.11.0\tool-testsuite\test\org\antlr\v4\test\tool\TestActionTranslation.java,org.antlr.v4.test.tool.TestActionTranslation,void testEscapedSlash(),"@Test
public void testEscapedSlash() throws Exception {
    // x = '\n'; -> x = '\n';
    String action = ""x = '\\n';"";
    String expected = ""x = '\\n';"";
    testActions(attributeTemplate, ""members"", action, expected);
    testActions(attributeTemplate, ""init"", action, expected);
    testActions(attributeTemplate, ""inline"", action, expected);
    testActions(attributeTemplate, ""finally"", action, expected);
    testActions(attributeTemplate, ""inline2"", action, expected);
}", ,"// x = '\n'; -> x = '\n';
",// x = '\n'; -> x = '\n';,81,89,[0],0,[0],0,[0],0,0,0,0,testEscapedSlash(),org.antlr.v4.test.tool.TestActionTranslation,testEscapedSlash/0,False,81,2,1,0,1,1,1,9,0,2,0,1,1,1,0,0,0,0,7,0,2,0,0,0,0,0,7,1,0,False
756,..\projects\antlr4-4.11.0\tool-testsuite\test\org\antlr\v4\test\tool\TestActionTranslation.java,org.antlr.v4.test.tool.TestActionTranslation,void testUnknownAttr(),"/**
 * Added in response to https://github.com/antlr/antlr4/issues/1211
 */
@Test
public void testUnknownAttr() throws Exception {
    String action = ""$qqq.text"";
    // was causing an exception
    String expected = """";
    testActions(attributeTemplate, ""inline"", action, expected);
}","/**
 * Added in response to https://github.com/antlr/antlr4/issues/1211
 */
","// was causing an exception
",/** * Added in response to https://github.com/antlr/antlr4/issues/1211 */[[SEP]]// was causing an exception,161,165,[0],0,[0],0,"[0, 0]",0,0,0,0,testUnknownAttr(),org.antlr.v4.test.tool.TestActionTranslation,testUnknownAttr/0,False,161,2,1,0,1,1,1,5,0,2,0,1,1,1,0,0,0,0,3,0,2,0,0,0,0,0,14,1,0,True
757,..\projects\antlr4-4.11.0\tool-testsuite\test\org\antlr\v4\test\tool\TestActionTranslation.java,org.antlr.v4.test.tool.TestActionTranslation,void testRuleRefsRecursive(),"/**
 * Regression test for issue #1295
 * $e.v yields incorrect value 0 in ""e returns [int v] : '1' {$v = 1;} | '(' e ')' {$v = $e.v;} ;""
 * https://github.com/antlr/antlr4/issues/1295
 */
@Test
public void testRuleRefsRecursive() throws Exception {
    String recursiveTemplate = ""recursiveTemplate(inline) ::= <<\n"" + ""parser grammar A;\n"" + ""e returns [int v]\n"" + ""    :   INT {$v = $INT.int;}\n"" + ""    |   '(' e ')' {\n"" + ""		 #inline#<inline>#end-inline#\n"" + ""		 }\n"" + ""    ;\n"" + "">>"";
    String leftRecursiveTemplate = ""recursiveTemplate(inline) ::= <<\n"" + ""parser grammar A;\n"" + ""e returns [int v]\n"" + ""    :   a=e op=('*'|'/') b=e  {$v = eval($a.v, $op.type, $b.v);}\n"" + ""    |   INT {$v = $INT.int;}\n"" + ""    |   '(' e ')' {\n"" + ""		 #inline#<inline>#end-inline#\n"" + ""		 }\n"" + ""    ;\n"" + "">>"";
    // ref to value returned from recursive call to rule
    String action = ""$v = $e.v;"";
    String expected = ""((EContext)_localctx).v =  ((EContext)_localctx).e.v;"";
    testActions(recursiveTemplate, ""inline"", action, expected);
    testActions(leftRecursiveTemplate, ""inline"", action, expected);
    // ref to predefined attribute obtained from recursive call to rule
    action = ""$v = $e.text.length();"";
    expected = ""((EContext)_localctx).v =  (((EContext)_localctx).e!=null?_input.getText(((EContext)_localctx).e.start,((EContext)_localctx).e.stop):null).length();"";
    testActions(recursiveTemplate, ""inline"", action, expected);
    testActions(leftRecursiveTemplate, ""inline"", action, expected);
}","/**
 * Regression test for issue #1295
 * $e.v yields incorrect value 0 in ""e returns [int v] : '1' {$v = 1;} | '(' e ')' {$v = $e.v;} ;""
 * https://github.com/antlr/antlr4/issues/1295
 */
","// ref to value returned from recursive call to rule
[[SEP]]// ref to predefined attribute obtained from recursive call to rule
","/** * Regression test for issue #1295 * $e.v yields incorrect value 0 in ""e returns [int v] : '1' {$v = 1;} | '(' e ')' {$v = $e.v;} ;"" * https://github.com/antlr/antlr4/issues/1295 */[[SEP]]// ref to value returned from recursive call to rule[[SEP]]// ref to predefined attribute obtained from recursive call to rule",172,204,[0],0,"[0, 0]",0,"[0, 0, 0]",0,0,0,0,testRuleRefsRecursive(),org.antlr.v4.test.tool.TestActionTranslation,testRuleRefsRecursive/0,False,172,2,1,0,1,1,1,12,0,4,0,1,1,1,0,0,0,0,27,0,6,2,0,0,0,0,35,1,0,True
758,..\projects\antlr4-4.11.0\tool-testsuite\test\org\antlr\v4\test\tool\TestActionTranslation.java,org.antlr.v4.test.tool.TestActionTranslation,void testRefToTextAttributeForCurrentRule(),"@Test
public void testRefToTextAttributeForCurrentRule() throws Exception {
    String action = ""$ctx.text; $text"";
    // this is the expected translation for all cases
    String expected = ""_localctx.text; _input.getText(_localctx.start, _input.LT(-1))"";
    testActions(attributeTemplate, ""init"", action, expected);
    testActions(attributeTemplate, ""inline"", action, expected);
    testActions(attributeTemplate, ""finally"", action, expected);
}", ,"// this is the expected translation for all cases
",// this is the expected translation for all cases,206,216,[0],0,[0],0,[0],0,0,0,0,testRefToTextAttributeForCurrentRule(),org.antlr.v4.test.tool.TestActionTranslation,testRefToTextAttributeForCurrentRule/0,False,206,2,1,0,1,1,1,7,0,2,0,1,1,1,0,0,0,0,5,0,2,0,0,0,0,0,12,1,0,False
759,..\projects\antlr4-4.11.0\tool-testsuite\test\org\antlr\v4\test\tool\TestActionTranslation.java,org.antlr.v4.test.tool.TestActionTranslation,"void testActions(String, String, String, String)","private static void testActions(String templates, String actionName, String action, String expected) throws org.antlr.runtime.RecognitionException {
    int lp = templates.indexOf('(');
    String name = templates.substring(0, lp);
    STGroup group = new STGroupString(templates);
    ST st = group.getInstanceOf(name);
    st.add(actionName, action);
    String grammar = st.render();
    ErrorQueue equeue = new ErrorQueue();
    Grammar g = new Grammar(grammar, equeue);
    if (g.ast != null && !g.ast.hasErrors) {
        SemanticPipeline sem = new SemanticPipeline(g);
        sem.process();
        ATNFactory factory = new ParserATNFactory(g);
        if (g.isLexer())
            factory = new LexerATNFactory((LexerGrammar) g);
        g.atn = factory.createATN();
        AnalysisPipeline anal = new AnalysisPipeline(g);
        anal.process();
        CodeGenerator gen = CodeGenerator.create(g);
        ST outputFileST = gen.generateParser(false);
        String output = outputFileST.render();
        // System.out.println(output);
        String b = ""#"" + actionName + ""#"";
        int start = output.indexOf(b);
        String e = ""#end-"" + actionName + ""#"";
        int end = output.indexOf(e);
        String snippet = output.substring(start + b.length(), end);
        assertEquals(expected, snippet);
    }
    if (equeue.size() > 0) {
        // System.err.println(equeue.toString());
    }
}", ,"// System.out.println(output);
[[SEP]]// System.err.println(equeue.toString());
",// System.out.println(output);[[SEP]]// System.err.println(equeue.toString());,226,260,[0],0,"[0, 0]",0,"[0, 0]",0,0,0,0,"testActions(String, String, String, String)",org.antlr.v4.test.tool.TestActionTranslation,"testActions/4[java.lang.String,java.lang.String,java.lang.String,java.lang.String]",False,226,12,21,17,4,5,15,30,0,18,4,15,0,0,0,1,0,0,4,2,20,3,2,0,0,0,45,10,0,False
760,..\projects\antlr4-4.11.0\tool-testsuite\test\org\antlr\v4\test\tool\TestAmbigParseTrees.java,org.antlr.v4.test.tool.TestAmbigParseTrees,void testAmbigAltDipsIntoOuterContextToRoot(),"@Test
public void testAmbigAltDipsIntoOuterContextToRoot() throws Exception {
    LexerGrammar lg = new LexerGrammar(""lexer grammar L;\n"" + ""SELF : 'self' ;\n"" + ""ID : [a-z]+ ;\n"" + ""DOT : '.' ;\n"");
    Grammar g = new Grammar(""parser grammar T;\n"" + ""e : p (DOT ID)* ;\n"" + ""p : SELF"" + ""  | SELF DOT ID"" + ""  ;"", lg);
    String startRule = ""e"";
    String input = ""self.x"";
    String expectedAmbigAlts = ""{1, 2}"";
    // decision in p
    int decision = 1;
    String expectedOverallTree = ""(e:1 (p:1 self) . x)"";
    String[] expectedParseTrees = { ""(e:1 (p:1 self) . x)"", ""(p:2 self . x)"" };
    testAmbiguousTrees(lg, g, startRule, input, decision, expectedAmbigAlts, expectedOverallTree, expectedParseTrees);
}", ,"// decision in p
",// decision in p,109,134,[0],0,[0],0,[0],0,0,0,0,testAmbigAltDipsIntoOuterContextToRoot(),org.antlr.v4.test.tool.TestAmbigParseTrees,testAmbigAltDipsIntoOuterContextToRoot/0,False,109,4,3,0,3,1,1,11,0,8,0,1,1,1,0,0,0,0,15,1,8,2,0,0,0,0,37,1,0,False
761,..\projects\antlr4-4.11.0\tool-testsuite\test\org\antlr\v4\test\tool\TestAmbigParseTrees.java,org.antlr.v4.test.tool.TestAmbigParseTrees,void testAmbigAltDipsIntoOuterContextBelowRoot(),"@Test
public void testAmbigAltDipsIntoOuterContextBelowRoot() throws Exception {
    LexerGrammar lg = new LexerGrammar(""lexer grammar L;\n"" + ""SELF : 'self' ;\n"" + ""ID : [a-z]+ ;\n"" + ""DOT : '.' ;\n"");
    Grammar g = new Grammar(""parser grammar T;\n"" + ""s : e ;\n"" + ""e : p (DOT ID)* ;\n"" + ""p : SELF"" + ""  | SELF DOT ID"" + ""  ;"", lg);
    String startRule = ""s"";
    String input = ""self.x"";
    String expectedAmbigAlts = ""{1, 2}"";
    // decision in p
    int decision = 1;
    String expectedOverallTree = ""(s:1 (e:1 (p:1 self) . x))"";
    String[] expectedParseTrees = { // shouldn't include s
    ""(e:1 (p:1 self) . x)"", // shouldn't include e
    ""(p:2 self . x)"" };
    testAmbiguousTrees(lg, g, startRule, input, decision, expectedAmbigAlts, expectedOverallTree, expectedParseTrees);
}", ,"// decision in p
[[SEP]]// shouldn't include s
[[SEP]]// shouldn't include e
",// decision in p[[SEP]]// shouldn't include s[[SEP]]// shouldn't include e,136,162,[0],0,"[0, 0, 0]",0,"[0, 0, 0]",0,0,0,0,testAmbigAltDipsIntoOuterContextBelowRoot(),org.antlr.v4.test.tool.TestAmbigParseTrees,testAmbigAltDipsIntoOuterContextBelowRoot/0,False,136,4,3,0,3,1,1,11,0,8,0,1,1,1,0,0,0,0,16,1,8,2,0,0,0,0,38,1,0,False
762,..\projects\antlr4-4.11.0\tool-testsuite\test\org\antlr\v4\test\tool\TestAmbigParseTrees.java,org.antlr.v4.test.tool.TestAmbigParseTrees,void testAmbigAltInLeftRecursiveBelowStartRule(),"@Test
public void testAmbigAltInLeftRecursiveBelowStartRule() throws Exception {
    LexerGrammar lg = new LexerGrammar(""lexer grammar L;\n"" + ""SELF : 'self' ;\n"" + ""ID : [a-z]+ ;\n"" + ""DOT : '.' ;\n"");
    Grammar g = new Grammar(""parser grammar T;\n"" + ""s : e ;\n"" + ""e : p | e DOT ID ;\n"" + ""p : SELF"" + ""  | SELF DOT ID"" + ""  ;"", lg);
    String startRule = ""s"";
    String input = ""self.x"";
    String expectedAmbigAlts = ""{1, 2}"";
    // decision in p
    int decision = 1;
    String expectedOverallTree = ""(s:1 (e:2 (e:1 (p:1 self)) . x))"";
    String[] expectedParseTrees = { ""(e:2 (e:1 (p:1 self)) . x)"", ""(p:2 self . x)"" };
    testAmbiguousTrees(lg, g, startRule, input, decision, expectedAmbigAlts, expectedOverallTree, expectedParseTrees);
}", ,"// decision in p
",// decision in p,164,190,[0],0,[0],0,[0],0,0,0,0,testAmbigAltInLeftRecursiveBelowStartRule(),org.antlr.v4.test.tool.TestAmbigParseTrees,testAmbigAltInLeftRecursiveBelowStartRule/0,False,164,4,3,0,3,1,1,11,0,8,0,1,1,1,0,0,0,0,16,1,8,2,0,0,0,0,37,1,0,False
763,..\projects\antlr4-4.11.0\tool-testsuite\test\org\antlr\v4\test\tool\TestAmbigParseTrees.java,org.antlr.v4.test.tool.TestAmbigParseTrees,void testAmbigAltInLeftRecursiveStartRule(),"@Test
public void testAmbigAltInLeftRecursiveStartRule() throws Exception {
    LexerGrammar lg = new LexerGrammar(""lexer grammar L;\n"" + ""SELF : 'self' ;\n"" + ""ID : [a-z]+ ;\n"" + ""DOT : '.' ;\n"");
    Grammar g = new Grammar(""parser grammar T;\n"" + ""e : p | e DOT ID ;\n"" + ""p : SELF"" + ""  | SELF DOT ID"" + ""  ;"", lg);
    String startRule = ""e"";
    String input = ""self.x"";
    String expectedAmbigAlts = ""{1, 2}"";
    // decision in p
    int decision = 1;
    String expectedOverallTree = ""(e:2 (e:1 (p:1 self)) . x)"";
    String[] expectedParseTrees = { ""(e:2 (e:1 (p:1 self)) . x)"", // shows just enough for self.x
    ""(p:2 self . x)"" };
    testAmbiguousTrees(lg, g, startRule, input, decision, expectedAmbigAlts, expectedOverallTree, expectedParseTrees);
}", ,"// decision in p
[[SEP]]// shows just enough for self.x
",// decision in p[[SEP]]// shows just enough for self.x,192,217,[0],0,"[0, 0]",0,"[0, 0]",0,0,0,0,testAmbigAltInLeftRecursiveStartRule(),org.antlr.v4.test.tool.TestAmbigParseTrees,testAmbigAltInLeftRecursiveStartRule/0,False,192,4,3,0,3,1,1,11,0,8,0,1,1,1,0,0,0,0,15,1,8,2,0,0,0,0,36,1,0,False
764,..\projects\antlr4-4.11.0\tool-testsuite\test\org\antlr\v4\test\tool\TestAmbigParseTrees.java,org.antlr.v4.test.tool.TestAmbigParseTrees,"void testAmbiguousTrees(LexerGrammar, Grammar, String, String, int, String, String, String[])","public void testAmbiguousTrees(LexerGrammar lg, Grammar g, String startRule, String input, int decision, String expectedAmbigAlts, String overallTree, String[] expectedParseTrees) {
    InterpreterTreeTextProvider nodeTextProvider = new InterpreterTreeTextProvider(g.getRuleNames());
    LexerInterpreter lexEngine = lg.createLexerInterpreter(new ANTLRInputStream(input));
    CommonTokenStream tokens = new CommonTokenStream(lexEngine);
    final GrammarParserInterpreter parser = g.createGrammarParserInterpreter(tokens);
    parser.setProfile(true);
    parser.getInterpreter().setPredictionMode(PredictionMode.LL_EXACT_AMBIG_DETECTION);
    // PARSE
    int ruleIndex = g.rules.get(startRule).index;
    ParserRuleContext parseTree = parser.parse(ruleIndex);
    assertEquals(overallTree, Trees.toStringTree(parseTree, nodeTextProvider));
    System.out.println();
    DecisionInfo[] decisionInfo = parser.getParseInfo().getDecisionInfo();
    List<AmbiguityInfo> ambiguities = decisionInfo[decision].ambiguities;
    assertEquals(1, ambiguities.size());
    AmbiguityInfo ambiguityInfo = ambiguities.get(0);
    List<ParserRuleContext> ambiguousParseTrees = GrammarParserInterpreter.getAllPossibleParseTrees(g, parser, tokens, decision, ambiguityInfo.ambigAlts, ambiguityInfo.startIndex, ambiguityInfo.stopIndex, ruleIndex);
    assertEquals(expectedAmbigAlts, ambiguityInfo.ambigAlts.toString());
    assertEquals(ambiguityInfo.ambigAlts.cardinality(), ambiguousParseTrees.size());
    for (int i = 0; i < ambiguousParseTrees.size(); i++) {
        ParserRuleContext t = ambiguousParseTrees.get(i);
        assertEquals(expectedParseTrees[i], Trees.toStringTree(t, nodeTextProvider));
    }
}", ,"// PARSE
",// PARSE,219,260,[0],0,[0],0,[0],0,0,0,0,"testAmbiguousTrees(LexerGrammar, Grammar, String, String, int, String, String, String[])",org.antlr.v4.test.tool.TestAmbigParseTrees,"testAmbiguousTrees/8[org.antlr.v4.tool.LexerGrammar,org.antlr.v4.tool.Grammar,java.lang.String,java.lang.String,int,java.lang.String,java.lang.String,java.lang.String[]]",False,224,10,11,6,5,2,17,23,0,12,8,17,0,0,1,0,0,0,0,3,12,0,1,0,0,0,44,1,0,False
765,..\projects\antlr4-4.11.0\tool-testsuite\test\org\antlr\v4\test\tool\TestAttributeChecks.java,org.antlr.v4.test.tool.TestAttributeChecks,"void testActions(String, String[], String)","private static void testActions(String location, String[] pairs, String template) {
    for (int i = 0; i < pairs.length; i += 2) {
        String action = pairs[i];
        String expected = pairs[i + 1];
        STGroup g = new STGroup('<', '>');
        // hush warnings
        g.setListener(new ErrorBuffer());
        ST st = new ST(g, template);
        st.add(location, action);
        String grammar = st.render();
        testErrors(new String[] { grammar, expected }, false);
    }
}", ,"// hush warnings
",// hush warnings,243,254,[0],0,[0],0,[0],0,0,0,0,"testActions(String, String[], String)",org.antlr.v4.test.tool.TestAttributeChecks,"testActions/3[java.lang.String,java.lang.String[],java.lang.String]",False,243,4,10,9,1,2,4,12,0,6,3,4,0,0,1,0,0,0,0,3,7,1,1,0,0,0,15,10,0,False
766,..\projects\antlr4-4.11.0\tool-testsuite\test\org\antlr\v4\test\tool\TestBasicSemanticErrors.java,org.antlr.v4.test.tool.TestBasicSemanticErrors,void testIllegalNonSetLabel(),"/**
 * Regression test for #25 ""Don't allow labels on not token set subrules"".
 * https://github.com/antlr/antlr4/issues/25
 */
@Test
public void testIllegalNonSetLabel() throws Exception {
    String grammar = ""grammar T;\n"" + ""ss : op=('=' | '+=' | expr) EOF;\n"" + ""expr : '=' '=';\n"" + """";
    String expected = ""error("" + ErrorType.LABEL_BLOCK_NOT_A_SET.code + ""): T.g4:2:5: label op assigned to a block which is not a set\n"";
    testErrors(new String[] { grammar, expected }, false);
}","/**
 * Regression test for #25 ""Don't allow labels on not token set subrules"".
 * https://github.com/antlr/antlr4/issues/25
 */
", ,"/** * Regression test for #25 ""Don't allow labels on not token set subrules"". * https://github.com/antlr/antlr4/issues/25 */",54,66,[0],0,[0],0,[0],0,0,0,0,testIllegalNonSetLabel(),org.antlr.v4.test.tool.TestBasicSemanticErrors,testIllegalNonSetLabel/0,False,55,2,1,0,1,1,1,5,0,2,0,1,0,0,0,0,0,0,6,0,2,2,0,0,0,0,32,1,0,True
767,..\projects\antlr4-4.11.0\tool-testsuite\test\org\antlr\v4\test\tool\TestBufferedTokenStream.java,org.antlr.v4.test.tool.TestBufferedTokenStream,void testFirstToken(),"@Test
public void testFirstToken() throws Exception {
    LexerGrammar g = new LexerGrammar(""lexer grammar t;\n"" + ""ID : 'a'..'z'+;\n"" + ""INT : '0'..'9'+;\n"" + ""SEMI : ';';\n"" + ""ASSIGN : '=';\n"" + ""PLUS : '+';\n"" + ""MULT : '*';\n"" + ""WS : ' '+;\n"");
    // Tokens: 012345678901234567
    // Input:  x = 3 * 0 + 2 * 0;
    CharStream input = new ANTLRInputStream(""x = 3 * 0 + 2 * 0;"");
    LexerInterpreter lexEngine = g.createLexerInterpreter(input);
    TokenStream tokens = createTokenStream(lexEngine);
    String result = tokens.LT(1).getText();
    String expecting = ""x"";
    assertEquals(expecting, result);
}", ,"// Tokens: 012345678901234567
[[SEP]]// Input:  x = 3 * 0 + 2 * 0;
",// Tokens: 012345678901234567// Input:  x = 3 * 0 + 2 * 0;,26,45,[0],0,"[0, 0]",0,[0],0,0,0,0,testFirstToken(),org.antlr.v4.test.tool.TestBufferedTokenStream,testFirstToken/0,False,26,8,3,0,3,1,5,9,0,6,0,5,1,1,0,0,0,0,10,1,6,1,0,0,0,0,27,1,0,False
768,..\projects\antlr4-4.11.0\tool-testsuite\test\org\antlr\v4\test\tool\TestBufferedTokenStream.java,org.antlr.v4.test.tool.TestBufferedTokenStream,void test2ndToken(),"@Test
public void test2ndToken() throws Exception {
    LexerGrammar g = new LexerGrammar(""lexer grammar t;\n"" + ""ID : 'a'..'z'+;\n"" + ""INT : '0'..'9'+;\n"" + ""SEMI : ';';\n"" + ""ASSIGN : '=';\n"" + ""PLUS : '+';\n"" + ""MULT : '*';\n"" + ""WS : ' '+;\n"");
    // Tokens: 012345678901234567
    // Input:  x = 3 * 0 + 2 * 0;
    CharStream input = new ANTLRInputStream(""x = 3 * 0 + 2 * 0;"");
    LexerInterpreter lexEngine = g.createLexerInterpreter(input);
    TokenStream tokens = createTokenStream(lexEngine);
    String result = tokens.LT(2).getText();
    String expecting = "" "";
    assertEquals(expecting, result);
}", ,"// Tokens: 012345678901234567
[[SEP]]// Input:  x = 3 * 0 + 2 * 0;
",// Tokens: 012345678901234567// Input:  x = 3 * 0 + 2 * 0;,47,66,[0],0,"[0, 0]",0,[0],0,0,0,0,test2ndToken(),org.antlr.v4.test.tool.TestBufferedTokenStream,test2ndToken/0,False,47,8,3,0,3,1,5,9,0,6,0,5,1,1,0,0,0,0,10,1,6,1,0,0,0,0,26,1,0,False
769,..\projects\antlr4-4.11.0\tool-testsuite\test\org\antlr\v4\test\tool\TestBufferedTokenStream.java,org.antlr.v4.test.tool.TestBufferedTokenStream,void testCompleteBuffer(),"@Test
public void testCompleteBuffer() throws Exception {
    LexerGrammar g = new LexerGrammar(""lexer grammar t;\n"" + ""ID : 'a'..'z'+;\n"" + ""INT : '0'..'9'+;\n"" + ""SEMI : ';';\n"" + ""ASSIGN : '=';\n"" + ""PLUS : '+';\n"" + ""MULT : '*';\n"" + ""WS : ' '+;\n"");
    // Tokens: 012345678901234567
    // Input:  x = 3 * 0 + 2 * 0;
    CharStream input = new ANTLRInputStream(""x = 3 * 0 + 2 * 0;"");
    LexerInterpreter lexEngine = g.createLexerInterpreter(input);
    TokenStream tokens = createTokenStream(lexEngine);
    int i = 1;
    Token t = tokens.LT(i);
    while (t.getType() != Token.EOF) {
        i++;
        t = tokens.LT(i);
    }
    // push it past end
    tokens.LT(i++);
    tokens.LT(i++);
    String result = tokens.getText();
    String expecting = ""x = 3 * 0 + 2 * 0;"";
    assertEquals(expecting, result);
}", ,"// Tokens: 012345678901234567
[[SEP]]// Input:  x = 3 * 0 + 2 * 0;
[[SEP]]// push it past end
",// Tokens: 012345678901234567// Input:  x = 3 * 0 + 2 * 0;[[SEP]]// push it past end,68,96,[0],0,"[0, 0, 0]",0,"[0, 0]",0,0,0,0,testCompleteBuffer(),org.antlr.v4.test.tool.TestBufferedTokenStream,testCompleteBuffer/0,False,68,9,3,0,3,2,6,17,0,8,0,6,1,1,1,1,0,0,10,1,9,1,1,0,0,0,29,1,0,False
770,..\projects\antlr4-4.11.0\tool-testsuite\test\org\antlr\v4\test\tool\TestBufferedTokenStream.java,org.antlr.v4.test.tool.TestBufferedTokenStream,void testCompleteBufferAfterConsuming(),"@Test
public void testCompleteBufferAfterConsuming() throws Exception {
    LexerGrammar g = new LexerGrammar(""lexer grammar t;\n"" + ""ID : 'a'..'z'+;\n"" + ""INT : '0'..'9'+;\n"" + ""SEMI : ';';\n"" + ""ASSIGN : '=';\n"" + ""PLUS : '+';\n"" + ""MULT : '*';\n"" + ""WS : ' '+;\n"");
    // Tokens: 012345678901234567
    // Input:  x = 3 * 0 + 2 * 0;
    CharStream input = new ANTLRInputStream(""x = 3 * 0 + 2 * 0;"");
    LexerInterpreter lexEngine = g.createLexerInterpreter(input);
    TokenStream tokens = createTokenStream(lexEngine);
    Token t = tokens.LT(1);
    while (t.getType() != Token.EOF) {
        tokens.consume();
        t = tokens.LT(1);
    }
    String result = tokens.getText();
    String expecting = ""x = 3 * 0 + 2 * 0;"";
    assertEquals(expecting, result);
}", ,"// Tokens: 012345678901234567
[[SEP]]// Input:  x = 3 * 0 + 2 * 0;
",// Tokens: 012345678901234567// Input:  x = 3 * 0 + 2 * 0;,98,123,[0],0,"[0, 0]",0,[0],0,0,0,0,testCompleteBufferAfterConsuming(),org.antlr.v4.test.tool.TestBufferedTokenStream,testCompleteBufferAfterConsuming/0,False,98,9,3,0,3,2,7,14,0,7,0,7,1,1,1,1,0,0,10,2,8,1,1,0,0,0,30,1,0,False
771,..\projects\antlr4-4.11.0\tool-testsuite\test\org\antlr\v4\test\tool\TestBufferedTokenStream.java,org.antlr.v4.test.tool.TestBufferedTokenStream,void testLookback(),"@Test
public void testLookback() throws Exception {
    LexerGrammar g = new LexerGrammar(""lexer grammar t;\n"" + ""ID : 'a'..'z'+;\n"" + ""INT : '0'..'9'+;\n"" + ""SEMI : ';';\n"" + ""ASSIGN : '=';\n"" + ""PLUS : '+';\n"" + ""MULT : '*';\n"" + ""WS : ' '+;\n"");
    // Tokens: 012345678901234567
    // Input:  x = 3 * 0 + 2 * 0;
    CharStream input = new ANTLRInputStream(""x = 3 * 0 + 2 * 0;"");
    LexerInterpreter lexEngine = g.createLexerInterpreter(input);
    TokenStream tokens = createTokenStream(lexEngine);
    // get x into buffer
    tokens.consume();
    Token t = tokens.LT(-1);
    assertEquals(""x"", t.getText());
    tokens.consume();
    // consume '='
    tokens.consume();
    t = tokens.LT(-3);
    assertEquals(""x"", t.getText());
    t = tokens.LT(-2);
    assertEquals("" "", t.getText());
    t = tokens.LT(-1);
    assertEquals(""="", t.getText());
}", ,"// Tokens: 012345678901234567
[[SEP]]// Input:  x = 3 * 0 + 2 * 0;
[[SEP]]// get x into buffer
[[SEP]]// consume '='
",// Tokens: 012345678901234567// Input:  x = 3 * 0 + 2 * 0;[[SEP]]// get x into buffer[[SEP]]// consume '=',125,153,[0],0,"[0, 0, 0, 0]",0,"[0, 0, 0]",0,0,0,0,testLookback(),org.antlr.v4.test.tool.TestBufferedTokenStream,testLookback/0,False,125,9,3,0,3,1,6,17,0,5,0,6,1,1,0,0,0,0,13,4,8,1,0,0,0,0,25,1,0,False
772,..\projects\antlr4-4.11.0\tool-testsuite\test\org\antlr\v4\test\tool\TestCodeGeneration.java,org.antlr.v4.test.tool.TestCodeGeneration,void testArgDecl(),"@Test
public void testArgDecl() throws Exception {
    // should use template not string
    /*ErrorQueue equeue = */
    new ErrorQueue();
    String g = ""grammar T;\n"" + ""a[int xyz] : 'a' ;\n"";
    List<String> evals = getEvalInfoForString(g, ""int xyz"");
    System.out.println(evals);
    for (int i = 0; i < evals.size(); i++) {
        String eval = evals.get(i);
        assertFalse(eval.startsWith(""<pojo:""), ""eval should not be POJO: "" + eval);
    }
}", ,"// should use template not string
[[SEP]]/*ErrorQueue equeue = */
",// should use template not string[[SEP]]/*ErrorQueue equeue = */,36,47,[0],0,"[0, 0]",0,"[0, 0]",0,0,0,0,testArgDecl(),org.antlr.v4.test.tool.TestCodeGeneration,testArgDecl/0,False,36,3,1,0,1,2,6,10,0,4,0,6,1,1,1,0,0,0,5,1,4,2,1,0,0,0,21,1,0,False
773,..\projects\antlr4-4.11.0\tool-testsuite\test\org\antlr\v4\test\tool\TestCodeGeneration.java,org.antlr.v4.test.tool.TestCodeGeneration,"List<String> getEvalInfoForString(String, String)","public List<String> getEvalInfoForString(String grammarString, String pattern) throws RecognitionException {
    ErrorQueue equeue = new ErrorQueue();
    Grammar g = new Grammar(grammarString);
    List<String> evals = new ArrayList<String>();
    if (g.ast != null && !g.ast.hasErrors) {
        SemanticPipeline sem = new SemanticPipeline(g);
        sem.process();
        ATNFactory factory = new ParserATNFactory(g);
        if (g.isLexer())
            factory = new LexerATNFactory((LexerGrammar) g);
        g.atn = factory.createATN();
        CodeGenerator gen = CodeGenerator.create(g);
        ST outputFileST = gen.generateParser();
        // STViz viz = outputFileST.inspect();
        // try {
        // viz.waitForClose();
        // }
        // catch (Exception e) {
        // e.printStackTrace();
        // }
        boolean debug = false;
        DebugInterpreter interp = new DebugInterpreter(outputFileST.groupThatCreatedThisInstance, outputFileST.impl.nativeGroup.errMgr, debug);
        InstanceScope scope = new InstanceScope(null, outputFileST);
        StringWriter sw = new StringWriter();
        AutoIndentWriter out = new AutoIndentWriter(sw);
        interp.exec(out, scope);
        for (String e : interp.evals) {
            if (e.contains(pattern)) {
                evals.add(e);
            }
        }
    }
    if (equeue.size() > 0) {
        System.err.println(equeue.toString());
    }
    return evals;
}", ,"// STViz viz = outputFileST.inspect();
[[SEP]]// try {
[[SEP]]// viz.waitForClose();
[[SEP]]// }
[[SEP]]// catch (Exception e) {
[[SEP]]// e.printStackTrace();
[[SEP]]// }
",// STViz viz = outputFileST.inspect();// try {// viz.waitForClose();// }// catch (Exception e) {// e.printStackTrace();// },114,157,[0],0,"[0, 0, 0, 0, 0, 0, 0]",0,[0],0,0,0,0,"getEvalInfoForString(String, String)",org.antlr.v4.test.tool.TestCodeGeneration,"getEvalInfoForString/2[java.lang.String,java.lang.String]",False,114,12,8,3,5,7,11,29,1,12,2,11,0,0,1,1,0,0,0,1,14,0,3,0,0,0,46,1,0,False
774,..\projects\antlr4-4.11.0\tool-testsuite\test\org\antlr\v4\test\tool\TestCommonTokenStream.java,org.antlr.v4.test.tool.TestCommonTokenStream,void testOffChannel(),"@Test
public void testOffChannel() throws Exception {
    // simulate input "" x =34  ;\n""
    TokenSource // simulate input "" x =34  ;\n""
    lexer = new TokenSource() {

        int i = 0;

        @SuppressWarnings(""serial"")
        WritableToken[] tokens = { new CommonToken(1, "" "") {

            {
                channel = Lexer.HIDDEN;
            }
        }, new CommonToken(1, ""x""), new CommonToken(1, "" "") {

            {
                channel = Lexer.HIDDEN;
            }
        }, new CommonToken(1, ""=""), new CommonToken(1, ""34""), new CommonToken(1, "" "") {

            {
                channel = Lexer.HIDDEN;
            }
        }, new CommonToken(1, "" "") {

            {
                channel = Lexer.HIDDEN;
            }
        }, new CommonToken(1, "";""), new CommonToken(1, ""\n"") {

            {
                channel = Lexer.HIDDEN;
            }
        }, new CommonToken(Token.EOF, """") };

        @Override
        public Token nextToken() {
            return tokens[i++];
        }

        @Override
        public String getSourceName() {
            return ""test"";
        }

        @Override
        public int getCharPositionInLine() {
            return 0;
        }

        @Override
        public int getLine() {
            return 0;
        }

        @Override
        public CharStream getInputStream() {
            return null;
        }

        @Override
        public void setTokenFactory(TokenFactory<?> factory) {
        }

        @Override
        public TokenFactory<?> getTokenFactory() {
            return null;
        }
    };
    CommonTokenStream tokens = new CommonTokenStream(lexer);
    // must skip first off channel token
    assertEquals(""x"", tokens.LT(1).getText());
    tokens.consume();
    assertEquals(""="", tokens.LT(1).getText());
    assertEquals(""x"", tokens.LT(-1).getText());
    tokens.consume();
    assertEquals(""34"", tokens.LT(1).getText());
    assertEquals(""="", tokens.LT(-1).getText());
    tokens.consume();
    assertEquals("";"", tokens.LT(1).getText());
    assertEquals(""34"", tokens.LT(-1).getText());
    tokens.consume();
    assertEquals(Token.EOF, tokens.LA(1));
    assertEquals("";"", tokens.LT(-1).getText());
    assertEquals(""34"", tokens.LT(-2).getText());
    assertEquals(""="", tokens.LT(-3).getText());
    assertEquals(""x"", tokens.LT(-4).getText());
}", ,"// simulate input "" x =34  ;\n""
[[SEP]]// simulate input "" x =34  ;\n""
[[SEP]]// must skip first off channel token
","// simulate input "" x =34  ;\n""[[SEP]]// simulate input "" x =34  ;\n""[[SEP]]// must skip first off channel token",30,98,[0],0,"[0, 0, 0]",0,"[0, 0, 0]",0,0,0,0,testOffChannel(),org.antlr.v4.test.tool.TestCommonTokenStream,testOffChannel/0,False,30,3,0,0,0,1,5,69,0,2,0,5,0,0,0,0,0,0,11,12,2,0,0,1,0,0,26,1,0,False
775,..\projects\antlr4-4.11.0\tool-testsuite\test\org\antlr\v4\test\tool\TestCommonTokenStream.java,org.antlr.v4.test.tool.TestCommonTokenStream,void testFetchOffChannel(),"@Test
public void testFetchOffChannel() throws Exception {
    // simulate input "" x =34  ; \n""
    TokenSource // simulate input "" x =34  ; \n""
    lexer = // token indexes   01234 56789
    new TokenSource() {

        int i = 0;

        @SuppressWarnings(""serial"")
        WritableToken[] tokens = { // 0
        new CommonToken(1, "" "") {

            {
                channel = Lexer.HIDDEN;
            }
        }, // 1
        new CommonToken(1, ""x""), // 2
        new CommonToken(1, "" "") {

            {
                channel = Lexer.HIDDEN;
            }
        }, // 3
        new CommonToken(1, ""=""), // 4
        new CommonToken(1, ""34""), // 5
        new CommonToken(1, "" "") {

            {
                channel = Lexer.HIDDEN;
            }
        }, // 6
        new CommonToken(1, "" "") {

            {
                channel = Lexer.HIDDEN;
            }
        }, // 7
        new CommonToken(1, "";""), // 8
        new CommonToken(1, "" "") {

            {
                channel = Lexer.HIDDEN;
            }
        }, // 9
        new CommonToken(1, ""\n"") {

            {
                channel = Lexer.HIDDEN;
            }
        }, // 10
        new CommonToken(Token.EOF, """") };

        @Override
        public Token nextToken() {
            return tokens[i++];
        }

        @Override
        public String getSourceName() {
            return ""test"";
        }

        @Override
        public int getCharPositionInLine() {
            return 0;
        }

        @Override
        public int getLine() {
            return 0;
        }

        @Override
        public CharStream getInputStream() {
            return null;
        }

        @Override
        public void setTokenFactory(TokenFactory<?> factory) {
        }

        @Override
        public TokenFactory<?> getTokenFactory() {
            return null;
        }
    };
    CommonTokenStream tokens = new CommonTokenStream(lexer);
    tokens.fill();
    assertEquals(null, tokens.getHiddenTokensToLeft(0));
    assertEquals(null, tokens.getHiddenTokensToRight(0));
    assertEquals(""[[@0,0:0=' ',<1>,channel=1,0:-1]]"", tokens.getHiddenTokensToLeft(1).toString());
    assertEquals(""[[@2,0:0=' ',<1>,channel=1,0:-1]]"", tokens.getHiddenTokensToRight(1).toString());
    assertEquals(null, tokens.getHiddenTokensToLeft(2));
    assertEquals(null, tokens.getHiddenTokensToRight(2));
    assertEquals(""[[@2,0:0=' ',<1>,channel=1,0:-1]]"", tokens.getHiddenTokensToLeft(3).toString());
    assertEquals(null, tokens.getHiddenTokensToRight(3));
    assertEquals(null, tokens.getHiddenTokensToLeft(4));
    assertEquals(""[[@5,0:0=' ',<1>,channel=1,0:-1], [@6,0:0=' ',<1>,channel=1,0:-1]]"", tokens.getHiddenTokensToRight(4).toString());
    assertEquals(null, tokens.getHiddenTokensToLeft(5));
    assertEquals(""[[@6,0:0=' ',<1>,channel=1,0:-1]]"", tokens.getHiddenTokensToRight(5).toString());
    assertEquals(""[[@5,0:0=' ',<1>,channel=1,0:-1]]"", tokens.getHiddenTokensToLeft(6).toString());
    assertEquals(null, tokens.getHiddenTokensToRight(6));
    assertEquals(""[[@5,0:0=' ',<1>,channel=1,0:-1], [@6,0:0=' ',<1>,channel=1,0:-1]]"", tokens.getHiddenTokensToLeft(7).toString());
    assertEquals(""[[@8,0:0=' ',<1>,channel=1,0:-1], [@9,0:0='\\n',<1>,channel=1,0:-1]]"", tokens.getHiddenTokensToRight(7).toString());
    assertEquals(null, tokens.getHiddenTokensToLeft(8));
    assertEquals(""[[@9,0:0='\\n',<1>,channel=1,0:-1]]"", tokens.getHiddenTokensToRight(8).toString());
    assertEquals(""[[@8,0:0=' ',<1>,channel=1,0:-1]]"", tokens.getHiddenTokensToLeft(9).toString());
    assertEquals(null, tokens.getHiddenTokensToRight(9));
}", ,"// simulate input "" x =34  ; \n""
[[SEP]]// simulate input "" x =34  ; \n""
[[SEP]]// token indexes   01234 56789
[[SEP]]// 0
[[SEP]]// 1
[[SEP]]// 2
[[SEP]]// 3
[[SEP]]// 4
[[SEP]]// 5
[[SEP]]// 6
[[SEP]]// 7
[[SEP]]// 8
[[SEP]]// 9
[[SEP]]// 10
","// simulate input "" x =34  ; \n""[[SEP]]// simulate input "" x =34  ; \n""[[SEP]]// token indexes   01234 56789[[SEP]]// 0[[SEP]]// 1[[SEP]]// 2[[SEP]]// 3[[SEP]]// 4[[SEP]]// 5[[SEP]]// 6[[SEP]]// 7[[SEP]]// 8[[SEP]]// 9[[SEP]]// 10",100,189,[0],0,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]",0,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]",0,0,0,0,testFetchOffChannel(),org.antlr.v4.test.tool.TestCommonTokenStream,testFetchOffChannel/0,False,100,3,0,0,0,1,5,79,0,2,0,5,0,0,0,0,0,0,10,20,2,0,0,1,0,0,27,1,0,False
776,..\projects\antlr4-4.11.0\tool-testsuite\test\org\antlr\v4\test\tool\TestCompositeGrammars.java,org.antlr.v4.test.tool.TestCompositeGrammars,void testImportFileLocationInSubdir(Path),"@Test
public void testImportFileLocationInSubdir(@TempDir Path tempDir) {
    String tempDirPath = tempDir.toString();
    String slave = ""parser grammar S;\n"" + ""a : B {System.out.println(\""S.a\"");} ;\n"";
    FileUtils.mkdir(tempDirPath);
    String subdir = tempDirPath + PathSeparator + ""sub"";
    FileUtils.mkdir(subdir);
    writeFile(subdir, ""S.g4"", slave);
    String master = ""grammar M;\n"" + ""import S;\n"" + ""s : a ;\n"" + // defines B from inherited token space
    ""B : 'b' ;"" + ""WS : (' '|'\\n') -> skip ;\n"";
    writeFile(tempDirPath, ""M.g4"", master);
    ErrorQueue equeue = Generator.antlrOnString(tempDirPath, ""Java"", ""M.g4"", false, ""-lib"", subdir);
    assertEquals(0, equeue.size());
}", ,"// defines B from inherited token space
",// defines B from inherited token space,35,53,[0],0,[0],0,[0],0,0,0,0,testImportFileLocationInSubdir(Path),org.antlr.v4.test.tool.TestCompositeGrammars,testImportFileLocationInSubdir/1[java.nio.file.Path],False,35,3,0,0,0,1,6,12,0,5,1,6,0,0,0,0,0,0,13,1,5,3,0,0,0,0,25,1,0,False
777,..\projects\antlr4-4.11.0\tool-testsuite\test\org\antlr\v4\test\tool\TestCompositeGrammars.java,org.antlr.v4.test.tool.TestCompositeGrammars,void testImportSelfLoop(Path),"// Test for https://github.com/antlr/antlr4/issues/1317
@Test
public void testImportSelfLoop(@TempDir Path tempDir) {
    String tempDirPath = tempDir.toString();
    FileUtils.mkdir(tempDirPath);
    String master = ""grammar M;\n"" + ""import M;\n"" + ""s : 'a' ;\n"";
    writeFile(tempDirPath, ""M.g4"", master);
    ErrorQueue equeue = Generator.antlrOnString(tempDirPath, ""Java"", ""M.g4"", false, ""-lib"", tempDirPath);
    assertEquals(0, equeue.size());
}","// Test for https://github.com/antlr/antlr4/issues/1317
", ,// Test for https://github.com/antlr/antlr4/issues/1317,56,66,[0],0,[0],0,[0],0,0,0,0,testImportSelfLoop(Path),org.antlr.v4.test.tool.TestCompositeGrammars,testImportSelfLoop/1[java.nio.file.Path],False,56,3,0,0,0,1,6,8,0,3,1,6,0,0,0,0,0,0,7,1,3,1,0,0,0,0,16,1,0,False
778,..\projects\antlr4-4.11.0\tool-testsuite\test\org\antlr\v4\test\tool\TestCompositeGrammars.java,org.antlr.v4.test.tool.TestCompositeGrammars,void testImportFileNotSearchedForInOutputDir(Path),"@Test
public void testImportFileNotSearchedForInOutputDir(@TempDir Path tempDir) {
    String tempDirPath = tempDir.toString();
    String slave = ""parser grammar S;\n"" + ""a : B {System.out.println(\""S.a\"");} ;\n"";
    FileUtils.mkdir(tempDirPath);
    String outdir = tempDirPath + ""/out"";
    FileUtils.mkdir(outdir);
    writeFile(outdir, ""S.g4"", slave);
    String master = ""grammar M;\n"" + ""import S;\n"" + ""s : a ;\n"" + // defines B from inherited token space
    ""B : 'b' ;"" + ""WS : (' '|'\\n') -> skip ;\n"";
    writeFile(tempDirPath, ""M.g4"", master);
    ErrorQueue equeue = Generator.antlrOnString(tempDirPath, ""Java"", ""M.g4"", false, ""-o"", outdir);
    assertEquals(ErrorType.CANNOT_FIND_IMPORTED_GRAMMAR, equeue.errors.get(0).getErrorType());
}", ,"// defines B from inherited token space
",// defines B from inherited token space,316,334,[0],0,[0],0,[0],0,0,0,0,testImportFileNotSearchedForInOutputDir(Path),org.antlr.v4.test.tool.TestCompositeGrammars,testImportFileNotSearchedForInOutputDir/1[java.nio.file.Path],False,316,3,0,0,0,1,7,12,0,5,1,7,0,0,0,0,0,0,13,1,5,3,0,0,0,0,26,1,0,False
779,..\projects\antlr4-4.11.0\tool-testsuite\test\org\antlr\v4\test\tool\TestCompositeGrammars.java,org.antlr.v4.test.tool.TestCompositeGrammars,void testOutputDirShouldNotEffectImports(Path),"@Test
public void testOutputDirShouldNotEffectImports(@TempDir Path tempDir) {
    String tempDirPath = tempDir.toString();
    String slave = ""parser grammar S;\n"" + ""a : B {System.out.println(\""S.a\"");} ;\n"";
    FileUtils.mkdir(tempDirPath);
    String subdir = tempDirPath + ""/sub"";
    FileUtils.mkdir(subdir);
    writeFile(subdir, ""S.g4"", slave);
    String master = ""grammar M;\n"" + ""import S;\n"" + ""s : a ;\n"" + // defines B from inherited token space
    ""B : 'b' ;"" + ""WS : (' '|'\\n') -> skip ;\n"";
    writeFile(tempDirPath, ""M.g4"", master);
    String outdir = tempDirPath + ""/out"";
    FileUtils.mkdir(outdir);
    ErrorQueue equeue = Generator.antlrOnString(tempDirPath, ""Java"", ""M.g4"", false, ""-o"", outdir, ""-lib"", subdir);
    assertEquals(0, equeue.size());
}", ,"// defines B from inherited token space
",// defines B from inherited token space,336,356,[0],0,[0],0,[0],0,0,0,0,testOutputDirShouldNotEffectImports(Path),org.antlr.v4.test.tool.TestCompositeGrammars,testOutputDirShouldNotEffectImports/1[java.nio.file.Path],False,336,3,0,0,0,1,6,14,0,6,1,6,0,0,0,0,0,0,15,1,6,4,0,0,0,0,26,1,0,False
780,..\projects\antlr4-4.11.0\tool-testsuite\test\org\antlr\v4\test\tool\TestCompositeGrammars.java,org.antlr.v4.test.tool.TestCompositeGrammars,void testTokensFileInOutputDirAndImportFileInSubdir(Path),"@Test
public void testTokensFileInOutputDirAndImportFileInSubdir(@TempDir Path tempDir) {
    String tempDirPath = tempDir.toString();
    String slave = ""parser grammar S;\n"" + ""a : B {System.out.println(\""S.a\"");} ;\n"";
    FileUtils.mkdir(tempDirPath);
    String subdir = tempDirPath + ""/sub"";
    FileUtils.mkdir(subdir);
    writeFile(subdir, ""S.g4"", slave);
    String parser = ""parser grammar MParser;\n"" + ""import S;\n"" + ""options {tokenVocab=MLexer;}\n"" + ""s : a ;\n"";
    writeFile(tempDirPath, ""MParser.g4"", parser);
    String lexer = ""lexer grammar MLexer;\n"" + // defines B from inherited token space
    ""B : 'b' ;"" + ""WS : (' '|'\\n') -> skip ;\n"";
    writeFile(tempDirPath, ""MLexer.g4"", lexer);
    String outdir = tempDirPath + ""/out"";
    FileUtils.mkdir(outdir);
    ErrorQueue equeue = Generator.antlrOnString(tempDirPath, ""Java"", ""MLexer.g4"", false, ""-o"", outdir);
    assertEquals(0, equeue.size());
    equeue = Generator.antlrOnString(tempDirPath, ""Java"", ""MParser.g4"", false, ""-o"", outdir, ""-lib"", subdir);
    assertEquals(0, equeue.size());
}", ,"// defines B from inherited token space
",// defines B from inherited token space,358,384,[0],0,[0],0,[0],0,0,0,0,testTokensFileInOutputDirAndImportFileInSubdir(Path),org.antlr.v4.test.tool.TestCompositeGrammars,testTokensFileInOutputDirAndImportFileInSubdir/1[java.nio.file.Path],False,358,3,0,0,0,1,6,18,0,7,1,6,0,0,0,0,0,0,21,2,8,5,0,0,0,0,32,1,0,False
781,..\projects\antlr4-4.11.0\tool-testsuite\test\org\antlr\v4\test\tool\TestCompositeGrammars.java,org.antlr.v4.test.tool.TestCompositeGrammars,void testSyntaxErrorsInImportsNotThrownOut(Path),"@Test
public void testSyntaxErrorsInImportsNotThrownOut(@TempDir Path tempDir) throws RecognitionException {
    String tempDirPath = tempDir.toString();
    ErrorQueue equeue = new ErrorQueue();
    String slave = ""parser grammar S;\n"" + ""options {toke\n"";
    FileUtils.mkdir(tempDirPath);
    writeFile(tempDirPath, ""S.g4"", slave);
    String master = ""grammar M;\n"" + ""import S;\n"" + ""s : x ;\n"" + ""WS : (' '|'\\n') -> skip ;\n"";
    writeFile(tempDirPath, ""M.g4"", master);
    /*Grammar g =*/
    new Grammar(tempDirPath + ""/M.g4"", master, equeue);
    assertEquals(ErrorType.SYNTAX_ERROR, equeue.errors.get(0).getErrorType());
}", ,"/*Grammar g =*/
",/*Grammar g =*/,415,433,[0],0,[0],0,[0],0,0,0,0,testSyntaxErrorsInImportsNotThrownOut(Path),org.antlr.v4.test.tool.TestCompositeGrammars,testSyntaxErrorsInImportsNotThrownOut/1[java.nio.file.Path],False,415,4,1,0,1,1,6,11,0,4,1,6,0,0,0,0,0,0,9,1,4,3,0,0,0,0,28,1,0,False
782,..\projects\antlr4-4.11.0\tool-testsuite\test\org\antlr\v4\test\tool\TestCompositeGrammars.java,org.antlr.v4.test.tool.TestCompositeGrammars,void test3LevelImport(Path),"// Make sure that M can import S that imports T.
@Test
public void test3LevelImport(@TempDir Path tempDir) throws RecognitionException {
    String tempDirPath = tempDir.toString();
    ErrorQueue equeue = new ErrorQueue();
    String slave = ""parser grammar T;\n"" + ""a : T ;\n"";
    FileUtils.mkdir(tempDirPath);
    writeFile(tempDirPath, ""T.g4"", slave);
    String slave2 = ""parser grammar S;\n"" + ""import T;\n"" + ""a : S ;\n"";
    FileUtils.mkdir(tempDirPath);
    writeFile(tempDirPath, ""S.g4"", slave2);
    String master = ""grammar M;\n"" + ""import S;\n"" + ""a : M ;\n"";
    writeFile(tempDirPath, ""M.g4"", master);
    Grammar g = new Grammar(tempDirPath + ""/M.g4"", master, equeue);
    // S and T aren't imported; overridden
    String expectedTokenIDToTypeMap = ""{EOF=-1, M=1}"";
    String expectedStringLiteralToTypeMap = ""{}"";
    String expectedTypeToTokenList = ""[M]"";
    assertEquals(expectedTokenIDToTypeMap, g.tokenNameToTypeMap.toString());
    assertEquals(expectedStringLiteralToTypeMap, g.stringLiteralToTypeMap.toString());
    assertEquals(expectedTypeToTokenList, realElements(g.typeToTokenList).toString());
    assertEquals(0, equeue.errors.size(), ""unexpected errors: "" + equeue);
    assertTrue(compile(""M.g4"", master, ""MParser"", ""a"", tempDir));
}","// Make sure that M can import S that imports T.
","// S and T aren't imported; overridden
",// Make sure that M can import S that imports T.[[SEP]]// S and T aren't imported; overridden,436,470,[0],0,[0],0,"[0, 0]",0,0,0,0,test3LevelImport(Path),org.antlr.v4.test.tool.TestCompositeGrammars,test3LevelImport/1[java.nio.file.Path],False,436,6,3,0,3,1,9,21,0,9,1,9,1,1,0,0,0,0,19,1,9,5,0,0,0,0,39,1,0,False
783,..\projects\antlr4-4.11.0\tool-testsuite\test\org\antlr\v4\test\tool\TestCompositeGrammars.java,org.antlr.v4.test.tool.TestCompositeGrammars,void testRulesVisibleThroughMultilevelImport(Path),"@Test
public void testRulesVisibleThroughMultilevelImport(@TempDir Path tempDir) throws RecognitionException {
    String tempDirPath = tempDir.toString();
    ErrorQueue equeue = new ErrorQueue();
    String slave = ""parser grammar T;\n"" + ""x : T ;\n"";
    FileUtils.mkdir(tempDirPath);
    writeFile(tempDirPath, ""T.g4"", slave);
    String slave2 = // A, B, C token type order
    ""parser grammar S;\n"" + ""import T;\n"" + ""a : S ;\n"";
    FileUtils.mkdir(tempDirPath);
    writeFile(tempDirPath, ""S.g4"", slave2);
    String master = ""grammar M;\n"" + ""import S;\n"" + // x MUST BE VISIBLE TO M
    ""a : M x ;\n"";
    writeFile(tempDirPath, ""M.g4"", master);
    Grammar g = new Grammar(tempDirPath + ""/M.g4"", master, equeue);
    String expectedTokenIDToTypeMap = ""{EOF=-1, M=1, T=2}"";
    String expectedStringLiteralToTypeMap = ""{}"";
    String expectedTypeToTokenList = ""[M, T]"";
    assertEquals(expectedTokenIDToTypeMap, g.tokenNameToTypeMap.toString());
    assertEquals(expectedStringLiteralToTypeMap, g.stringLiteralToTypeMap.toString());
    assertEquals(expectedTypeToTokenList, realElements(g.typeToTokenList).toString());
    assertEquals(0, equeue.errors.size(), ""unexpected errors: "" + equeue);
}", ,"// A, B, C token type order
[[SEP]]// x MUST BE VISIBLE TO M
","// A, B, C token type order[[SEP]]// x MUST BE VISIBLE TO M",531,564,[0],0,"[0, 0]",0,"[0, 0]",0,0,0,0,testRulesVisibleThroughMultilevelImport(Path),org.antlr.v4.test.tool.TestCompositeGrammars,testRulesVisibleThroughMultilevelImport/1[java.nio.file.Path],False,531,5,2,0,2,1,7,20,0,9,1,7,0,0,0,0,0,0,16,1,9,5,0,0,0,0,41,1,0,False
784,..\projects\antlr4-4.11.0\tool-testsuite\test\org\antlr\v4\test\tool\TestCompositeGrammars.java,org.antlr.v4.test.tool.TestCompositeGrammars,void testNestedComposite(Path),"@Test
public void testNestedComposite(@TempDir Path tempDir) throws RecognitionException {
    String tempDirPath = tempDir.toString();
    // Wasn't compiling. http://www.antlr.org/jira/browse/ANTLR-438
    ErrorQueue equeue = new ErrorQueue();
    String gstr = ""lexer grammar L;\n"" + ""T1: '1';\n"" + ""T2: '2';\n"" + ""T3: '3';\n"" + ""T4: '4';\n"";
    FileUtils.mkdir(tempDirPath);
    writeFile(tempDirPath, ""L.g4"", gstr);
    gstr = ""parser grammar G1;\n"" + ""s: a | b;\n"" + ""a: T1;\n"" + ""b: T2;\n"";
    FileUtils.mkdir(tempDirPath);
    writeFile(tempDirPath, ""G1.g4"", gstr);
    gstr = ""parser grammar G2;\n"" + ""import G1;\n"" + ""a: T3;\n"";
    FileUtils.mkdir(tempDirPath);
    writeFile(tempDirPath, ""G2.g4"", gstr);
    String G3str = ""grammar G3;\n"" + ""import G2;\n"" + ""b: T4;\n"";
    FileUtils.mkdir(tempDirPath);
    writeFile(tempDirPath, ""G3.g4"", G3str);
    Grammar g = new Grammar(tempDirPath + ""/G3.g4"", G3str, equeue);
    String expectedTokenIDToTypeMap = ""{EOF=-1, T4=1, T3=2}"";
    String expectedStringLiteralToTypeMap = ""{}"";
    String expectedTypeToTokenList = ""[T4, T3]"";
    assertEquals(expectedTokenIDToTypeMap, g.tokenNameToTypeMap.toString());
    assertEquals(expectedStringLiteralToTypeMap, g.stringLiteralToTypeMap.toString());
    assertEquals(expectedTypeToTokenList, realElements(g.typeToTokenList).toString());
    assertEquals(0, equeue.errors.size(), ""unexpected errors: "" + equeue);
    assertTrue(compile(""G3.g4"", G3str, ""G3Parser"", ""b"", tempDir));
}", ,"// Wasn't compiling. http://www.antlr.org/jira/browse/ANTLR-438
",// Wasn't compiling. http://www.antlr.org/jira/browse/ANTLR-438,566,614,[0],0,[0],0,[0],0,0,0,0,testNestedComposite(Path),org.antlr.v4.test.tool.TestCompositeGrammars,testNestedComposite/1[java.nio.file.Path],False,566,6,3,0,3,1,9,25,0,8,1,9,1,1,0,0,0,0,27,1,10,6,0,0,0,0,45,1,0,False
785,..\projects\antlr4-4.11.0\tool-testsuite\test\org\antlr\v4\test\tool\TestCompositeGrammars.java,org.antlr.v4.test.tool.TestCompositeGrammars,void testHeadersPropogatedCorrectlyToImportedGrammars(Path),"@Test
public void testHeadersPropogatedCorrectlyToImportedGrammars(@TempDir Path tempDir) {
    String tempDirPath = tempDir.toString();
    String slave = ""parser grammar S;\n"" + ""a : B {System.out.print(\""S.a\"");} ;\n"";
    FileUtils.mkdir(tempDirPath);
    writeFile(tempDirPath, ""S.g4"", slave);
    String master = ""grammar M;\n"" + ""import S;\n"" + ""@header{package mypackage;}\n"" + ""s : a ;\n"" + // defines B from inherited token space
    ""B : 'b' ;"" + ""WS : (' '|'\\n') -> skip ;\n"";
    ErrorQueue equeue = Generator.antlrOnString(tempDirPath, ""Java"", ""M.g4"", master, false);
    // should be ok
    int expecting = 0;
    assertEquals(expecting, equeue.errors.size());
}", ,"// defines B from inherited token space
[[SEP]]// should be ok
",// defines B from inherited token space[[SEP]]// should be ok,616,633,[0],0,"[0, 0]",0,"[0, 0]",0,0,0,0,testHeadersPropogatedCorrectlyToImportedGrammars(Path),org.antlr.v4.test.tool.TestCompositeGrammars,testHeadersPropogatedCorrectlyToImportedGrammars/1[java.nio.file.Path],False,616,3,0,0,0,1,6,10,0,5,1,6,0,0,0,0,0,0,11,1,5,2,0,0,0,0,27,1,0,False
786,..\projects\antlr4-4.11.0\tool-testsuite\test\org\antlr\v4\test\tool\TestCompositeGrammars.java,org.antlr.v4.test.tool.TestCompositeGrammars,void testImportLargeGrammar(Path),"/**
 * This is a regression test for antlr/antlr4#670 ""exception when importing
 * grammar"".  I think this one always worked but I found that a different
 * Java grammar caused an error and so I made the testImportLeftRecursiveGrammar() test below.
 * https://github.com/antlr/antlr4/issues/670
 */
// TODO: migrate to test framework
@Test
public void testImportLargeGrammar(@TempDir Path tempDir) throws IOException {
    String tempDirPath = tempDir.toString();
    String slave = load(""Java.g4"");
    String master = ""grammar NewJava;\n"" + ""import Java;\n"";
    FileUtils.mkdir(tempDirPath);
    writeFile(tempDirPath, ""Java.g4"", slave);
    ExecutedState executedState = execParser(""NewJava.g4"", master, ""NewJavaParser"", ""NewJavaLexer"", ""compilationUnit"", ""package Foo;"", debug, tempDir);
    assertEquals("""", executedState.output);
    assertEquals("""", executedState.errors);
}","// TODO: migrate to test framework
", ,"/** * This is a regression test for antlr/antlr4#670 ""exception when importing * grammar"".  I think this one always worked but I found that a different * Java grammar caused an error and so I made the testImportLeftRecursiveGrammar() test below. * https://github.com/antlr/antlr4/issues/670 */[[SEP]]// TODO: migrate to test framework",642,657,[1],1,[0],0,"[0, 1]",1,1,1,1,testImportLargeGrammar(Path),org.antlr.v4.test.tool.TestCompositeGrammars,testImportLargeGrammar/1[java.nio.file.Path],False,643,4,2,0,2,1,6,10,0,4,1,6,0,0,0,0,0,0,11,0,4,1,0,0,0,0,52,1,0,True
787,..\projects\antlr4-4.11.0\tool-testsuite\test\org\antlr\v4\test\tool\TestCompositeGrammars.java,org.antlr.v4.test.tool.TestCompositeGrammars,void testImportLeftRecursiveGrammar(Path),"/**
 * This is a regression test for antlr/antlr4#670 ""exception when importing
 * grammar"".
 * https://github.com/antlr/antlr4/issues/670
 */
// TODO: migrate to test framework
@Test
public void testImportLeftRecursiveGrammar(@TempDir Path tempDir) {
    String tempDirPath = tempDir.toString();
    String slave = ""grammar Java;\n"" + ""e : '(' e ')'\n"" + ""  | e '=' e\n"" + ""  | ID\n"" + ""  ;\n"" + ""ID : [a-z]+ ;\n"";
    String master = ""grammar T;\n"" + ""import Java;\n"" + ""s : e ;\n"";
    FileUtils.mkdir(tempDirPath);
    writeFile(tempDirPath, ""Java.g4"", slave);
    ExecutedState executedState = execParser(""T.g4"", master, ""TParser"", ""TLexer"", ""s"", ""a=b"", debug, tempDir);
    assertEquals("""", executedState.output);
    assertEquals("""", executedState.errors);
}","// TODO: migrate to test framework
", ,"/** * This is a regression test for antlr/antlr4#670 ""exception when importing * grammar"". * https://github.com/antlr/antlr4/issues/670 */[[SEP]]// TODO: migrate to test framework",665,687,[1],1,[0],0,"[0, 1]",1,1,1,1,testImportLeftRecursiveGrammar(Path),org.antlr.v4.test.tool.TestCompositeGrammars,testImportLeftRecursiveGrammar/1[java.nio.file.Path],False,666,4,1,0,1,1,5,10,0,4,1,5,0,0,0,0,0,0,17,0,4,2,0,0,0,0,31,1,0,True
788,..\projects\antlr4-4.11.0\tool-testsuite\test\org\antlr\v4\test\tool\TestCompositeGrammars.java,org.antlr.v4.test.tool.TestCompositeGrammars,void testCircularGrammarInclusion(Path),"// ISSUE: https://github.com/antlr/antlr4/issues/2296
@Test
public void testCircularGrammarInclusion(@TempDir Path tempDir) {
    String tempDirPath = tempDir.toString();
    String g1 = ""grammar G1;\n"" + ""import  G2;\n"" + ""r : 'R1';"";
    String g2 = ""grammar G2;\n"" + ""import  G1;\n"" + ""r : 'R2';"";
    FileUtils.mkdir(tempDirPath);
    writeFile(tempDirPath, ""G1.g4"", g1);
    ExecutedState executedState = execParser(""G2.g4"", g2, ""G2Parser"", ""G2Lexer"", ""r"", ""R2"", debug, tempDir);
    assertEquals("""", executedState.errors);
}","// ISSUE: https://github.com/antlr/antlr4/issues/2296
", ,// ISSUE: https://github.com/antlr/antlr4/issues/2296,690,707,[0],0,[0],0,[0],0,0,0,0,testCircularGrammarInclusion(Path),org.antlr.v4.test.tool.TestCompositeGrammars,testCircularGrammarInclusion/1[java.nio.file.Path],False,691,4,1,0,1,1,5,9,0,4,1,5,0,0,0,0,0,0,13,0,4,2,0,0,0,0,20,1,0,False
789,..\projects\antlr4-4.11.0\tool-testsuite\test\org\antlr\v4\test\tool\TestErrorSets.java,org.antlr.v4.test.tool.TestErrorSets,void testNotCharSetWithRuleRef(),"@Test
public void testNotCharSetWithRuleRef() throws Exception {
    // might be a useful feature to add someday
    String[] pair = new String[] { ""grammar T;\n"" + ""a : A {System.out.println($A.text);} ;\n"" + ""A : ~('a'|B) ;\n"" + ""B : 'b' ;\n"", ""error("" + ErrorType.UNSUPPORTED_REFERENCE_IN_LEXER_SET.code + ""): T.g4:3:10: rule reference B is not currently supported in a set\n"" };
    testErrors(pair, true);
}", ,"// might be a useful feature to add someday
",// might be a useful feature to add someday,17,27,[0],0,[0],0,[0],0,0,0,0,testNotCharSetWithRuleRef(),org.antlr.v4.test.tool.TestErrorSets,testNotCharSetWithRuleRef/0,False,17,2,1,0,1,1,1,4,0,1,0,1,0,0,0,0,0,0,6,0,1,2,0,0,0,0,21,1,0,False
790,..\projects\antlr4-4.11.0\tool-testsuite\test\org\antlr\v4\test\tool\TestErrorSets.java,org.antlr.v4.test.tool.TestErrorSets,void testNotCharSetWithString(),"@Test
public void testNotCharSetWithString() throws Exception {
    // might be a useful feature to add someday
    String[] pair = new String[] { ""grammar T;\n"" + ""a : A {System.out.println($A.text);} ;\n"" + ""A : ~('a'|'aa') ;\n"" + ""B : 'b' ;\n"", ""error("" + ErrorType.INVALID_LITERAL_IN_LEXER_SET.code + ""): T.g4:3:10: multi-character literals are not allowed in lexer sets: 'aa'\n"" };
    testErrors(pair, true);
}", ,"// might be a useful feature to add someday
",// might be a useful feature to add someday,29,39,[0],0,[0],0,[0],0,0,0,0,testNotCharSetWithString(),org.antlr.v4.test.tool.TestErrorSets,testNotCharSetWithString/0,False,29,2,1,0,1,1,1,4,0,1,0,1,0,0,0,0,0,0,6,0,1,2,0,0,0,0,19,1,0,False
791,..\projects\antlr4-4.11.0\tool-testsuite\test\org\antlr\v4\test\tool\TestGrammarParserInterpreter.java,org.antlr.v4.test.tool.TestGrammarParserInterpreter,void testAltsWithLabels(),"@Test
public void testAltsWithLabels() throws Exception {
    LexerGrammar lg = new LexerGrammar(lexerText);
    Grammar g = new Grammar(""parser grammar T;\n"" + ""s : ID  # foo\n"" + ""  | INT # bar\n"" + ""  ;\n"", lg);
    // it won't show the labels here because my simple node text provider above just shows the alternative
    testInterp(lg, g, ""s"", ""a"", ""(s:1 a)"");
    testInterp(lg, g, ""s"", ""3"", ""(s:2 3)"");
}", ,"// it won't show the labels here because my simple node text provider above just shows the alternative
",// it won't show the labels here because my simple node text provider above just shows the alternative,58,70,[0],0,[0],0,[0],0,0,0,0,testAltsWithLabels(),org.antlr.v4.test.tool.TestGrammarParserInterpreter,testAltsWithLabels/0,False,59,4,3,0,3,1,1,6,0,2,0,1,1,1,0,0,0,0,10,0,2,1,0,0,0,0,18,1,0,False
792,..\projects\antlr4-4.11.0\tool-testsuite\test\org\antlr\v4\test\tool\TestGrammarParserInterpreter.java,org.antlr.v4.test.tool.TestGrammarParserInterpreter,"InterpreterRuleContext testInterp(LexerGrammar, Grammar, String, String, String)","InterpreterRuleContext testInterp(LexerGrammar lg, Grammar g, String startRule, String input, String expectedParseTree) {
    LexerInterpreter lexEngine = lg.createLexerInterpreter(new ANTLRInputStream(input));
    CommonTokenStream tokens = new CommonTokenStream(lexEngine);
    GrammarParserInterpreter parser = g.createGrammarParserInterpreter(tokens);
    ParseTree t = parser.parse(g.rules.get(startRule).index);
    InterpreterTreeTextProvider nodeTextProvider = new InterpreterTreeTextProvider(g.getRuleNames());
    String treeStr = Trees.toStringTree(t, nodeTextProvider);
    // System.out.println(""parse tree: ""+treeStr);
    assertEquals(expectedParseTree, treeStr);
    return (InterpreterRuleContext) t;
}", ,"// System.out.println(""parse tree: ""+treeStr);
","// System.out.println(""parse tree: ""+treeStr);",104,117,[0],0,[0],0,[0],0,0,0,0,"testInterp(LexerGrammar, Grammar, String, String, String)",org.antlr.v4.test.tool.TestGrammarParserInterpreter,"testInterp/5[org.antlr.v4.tool.LexerGrammar,org.antlr.v4.tool.Grammar,java.lang.String,java.lang.String,java.lang.String]",False,107,9,9,5,4,1,7,10,1,6,5,7,0,0,0,0,0,0,0,0,6,0,0,0,0,0,34,0,0,False
793,..\projects\antlr4-4.11.0\tool-testsuite\test\org\antlr\v4\test\tool\TestGraphNodes.java,org.antlr.v4.test.tool.TestGraphNodes,void test_$_$(),"@Test
public void test_$_$() {
    PredictionContext r = PredictionContext.merge(EmptyPredictionContext.Instance, EmptyPredictionContext.Instance, rootIsWildcard(), null);
    // System.out.println(toDOTString(r, rootIsWildcard()));
    String expecting = ""digraph G {\n"" + ""rankdir=LR;\n"" + ""  s0[label=\""*\""];\n"" + ""}\n"";
    assertEquals(expecting, toDOTString(r, rootIsWildcard()));
}", ,"// System.out.println(toDOTString(r, rootIsWildcard()));
","// System.out.println(toDOTString(r, rootIsWildcard()));",27,37,[0],0,[0],0,[0],0,0,0,0,test_$_$(),org.antlr.v4.test.tool.TestGraphNodes,test_$_$/0,False,27,3,2,0,2,1,4,5,0,2,0,4,2,1,0,0,0,0,4,0,2,1,0,0,0,0,9,1,0,False
794,..\projects\antlr4-4.11.0\tool-testsuite\test\org\antlr\v4\test\tool\TestGraphNodes.java,org.antlr.v4.test.tool.TestGraphNodes,void test_$_$_fullctx(),"@Test
public void test_$_$_fullctx() {
    PredictionContext r = PredictionContext.merge(EmptyPredictionContext.Instance, EmptyPredictionContext.Instance, fullCtx(), null);
    // System.out.println(toDOTString(r, fullCtx()));
    String expecting = ""digraph G {\n"" + ""rankdir=LR;\n"" + ""  s0[label=\""$\""];\n"" + ""}\n"";
    assertEquals(expecting, toDOTString(r, fullCtx()));
}", ,"// System.out.println(toDOTString(r, fullCtx()));
","// System.out.println(toDOTString(r, fullCtx()));",39,49,[0],0,[0],0,[0],0,0,0,0,test_$_$_fullctx(),org.antlr.v4.test.tool.TestGraphNodes,test_$_$_fullctx/0,False,39,3,2,0,2,1,4,5,0,2,0,4,2,1,0,0,0,0,4,0,2,1,0,0,0,0,9,1,0,False
795,..\projects\antlr4-4.11.0\tool-testsuite\test\org\antlr\v4\test\tool\TestGraphNodes.java,org.antlr.v4.test.tool.TestGraphNodes,void test_x_$(),"@Test
public void test_x_$() {
    PredictionContext r = PredictionContext.merge(x(), EmptyPredictionContext.Instance, rootIsWildcard(), null);
    // System.out.println(toDOTString(r, rootIsWildcard()));
    String expecting = ""digraph G {\n"" + ""rankdir=LR;\n"" + ""  s0[label=\""*\""];\n"" + ""}\n"";
    assertEquals(expecting, toDOTString(r, rootIsWildcard()));
}", ,"// System.out.println(toDOTString(r, rootIsWildcard()));
","// System.out.println(toDOTString(r, rootIsWildcard()));",51,60,[0],0,[0],0,[0],0,0,0,0,test_x_$(),org.antlr.v4.test.tool.TestGraphNodes,test_x_$/0,False,51,3,3,0,3,1,5,5,0,2,0,5,3,2,0,0,0,0,4,0,2,1,0,0,0,0,10,1,0,False
796,..\projects\antlr4-4.11.0\tool-testsuite\test\org\antlr\v4\test\tool\TestGraphNodes.java,org.antlr.v4.test.tool.TestGraphNodes,void test_x_$_fullctx(),"@Test
public void test_x_$_fullctx() {
    PredictionContext r = PredictionContext.merge(x(), EmptyPredictionContext.Instance, fullCtx(), null);
    // System.out.println(toDOTString(r, fullCtx()));
    String expecting = ""digraph G {\n"" + ""rankdir=LR;\n"" + ""  s0[shape=record, label=\""<p0>|<p1>$\""];\n"" + ""  s1[label=\""$\""];\n"" + ""  s0:p0->s1[label=\""9\""];\n"" + ""}\n"";
    assertEquals(expecting, toDOTString(r, fullCtx()));
}", ,"// System.out.println(toDOTString(r, fullCtx()));
","// System.out.println(toDOTString(r, fullCtx()));",62,73,[0],0,[0],0,[0],0,0,0,0,test_x_$_fullctx(),org.antlr.v4.test.tool.TestGraphNodes,test_x_$_fullctx/0,False,62,3,3,0,3,1,5,5,0,2,0,5,3,2,0,0,0,0,6,0,2,1,0,0,0,0,11,1,0,False
797,..\projects\antlr4-4.11.0\tool-testsuite\test\org\antlr\v4\test\tool\TestGraphNodes.java,org.antlr.v4.test.tool.TestGraphNodes,void test_$_x(),"@Test
public void test_$_x() {
    PredictionContext r = PredictionContext.merge(EmptyPredictionContext.Instance, x(), rootIsWildcard(), null);
    // System.out.println(toDOTString(r, rootIsWildcard()));
    String expecting = ""digraph G {\n"" + ""rankdir=LR;\n"" + ""  s0[label=\""*\""];\n"" + ""}\n"";
    assertEquals(expecting, toDOTString(r, rootIsWildcard()));
}", ,"// System.out.println(toDOTString(r, rootIsWildcard()));
","// System.out.println(toDOTString(r, rootIsWildcard()));",75,84,[0],0,[0],0,[0],0,0,0,0,test_$_x(),org.antlr.v4.test.tool.TestGraphNodes,test_$_x/0,False,75,3,3,0,3,1,5,5,0,2,0,5,3,2,0,0,0,0,4,0,2,1,0,0,0,0,9,1,0,False
798,..\projects\antlr4-4.11.0\tool-testsuite\test\org\antlr\v4\test\tool\TestGraphNodes.java,org.antlr.v4.test.tool.TestGraphNodes,void test_$_x_fullctx(),"@Test
public void test_$_x_fullctx() {
    PredictionContext r = PredictionContext.merge(EmptyPredictionContext.Instance, x(), fullCtx(), null);
    // System.out.println(toDOTString(r, fullCtx()));
    String expecting = ""digraph G {\n"" + ""rankdir=LR;\n"" + ""  s0[shape=record, label=\""<p0>|<p1>$\""];\n"" + ""  s1[label=\""$\""];\n"" + ""  s0:p0->s1[label=\""9\""];\n"" + ""}\n"";
    assertEquals(expecting, toDOTString(r, fullCtx()));
}", ,"// System.out.println(toDOTString(r, fullCtx()));
","// System.out.println(toDOTString(r, fullCtx()));",86,97,[0],0,[0],0,[0],0,0,0,0,test_$_x_fullctx(),org.antlr.v4.test.tool.TestGraphNodes,test_$_x_fullctx/0,False,86,3,3,0,3,1,5,5,0,2,0,5,3,2,0,0,0,0,6,0,2,1,0,0,0,0,10,1,0,False
799,..\projects\antlr4-4.11.0\tool-testsuite\test\org\antlr\v4\test\tool\TestGraphNodes.java,org.antlr.v4.test.tool.TestGraphNodes,void test_a_a(),"@Test
public void test_a_a() {
    PredictionContext r = PredictionContext.merge(a(), a(), rootIsWildcard(), null);
    // System.out.println(toDOTString(r, rootIsWildcard()));
    String expecting = ""digraph G {\n"" + ""rankdir=LR;\n"" + ""  s0[label=\""0\""];\n"" + ""  s1[label=\""*\""];\n"" + ""  s0->s1[label=\""1\""];\n"" + ""}\n"";
    assertEquals(expecting, toDOTString(r, rootIsWildcard()));
}", ,"// System.out.println(toDOTString(r, rootIsWildcard()));
","// System.out.println(toDOTString(r, rootIsWildcard()));",99,110,[0],0,[0],0,[0],0,0,0,0,test_a_a(),org.antlr.v4.test.tool.TestGraphNodes,test_a_a/0,False,99,3,3,0,3,1,5,5,0,2,0,5,3,2,0,0,0,0,6,0,2,1,0,0,0,0,12,1,0,False
800,..\projects\antlr4-4.11.0\tool-testsuite\test\org\antlr\v4\test\tool\TestGraphNodes.java,org.antlr.v4.test.tool.TestGraphNodes,void test_a$_ax(),"@Test
public void test_a$_ax() {
    PredictionContext a1 = a();
    PredictionContext x = x();
    PredictionContext a2 = createSingleton(x, 1);
    PredictionContext r = PredictionContext.merge(a1, a2, rootIsWildcard(), null);
    // System.out.println(toDOTString(r, rootIsWildcard()));
    String expecting = ""digraph G {\n"" + ""rankdir=LR;\n"" + ""  s0[label=\""0\""];\n"" + ""  s1[label=\""*\""];\n"" + ""  s0->s1[label=\""1\""];\n"" + ""}\n"";
    assertEquals(expecting, toDOTString(r, rootIsWildcard()));
}", ,"// System.out.println(toDOTString(r, rootIsWildcard()));
","// System.out.println(toDOTString(r, rootIsWildcard()));",112,126,[0],0,[0],0,[0],0,0,0,0,test_a$_ax(),org.antlr.v4.test.tool.TestGraphNodes,test_a$_ax/0,False,112,3,5,0,5,1,7,8,0,5,0,7,5,3,0,0,0,0,6,1,5,1,0,0,0,0,16,1,0,False
801,..\projects\antlr4-4.11.0\tool-testsuite\test\org\antlr\v4\test\tool\TestGraphNodes.java,org.antlr.v4.test.tool.TestGraphNodes,void test_a$_ax_fullctx(),"@Test
public void test_a$_ax_fullctx() {
    PredictionContext a1 = a();
    PredictionContext x = x();
    PredictionContext a2 = createSingleton(x, 1);
    PredictionContext r = PredictionContext.merge(a1, a2, fullCtx(), null);
    // System.out.println(toDOTString(r, fullCtx()));
    String expecting = ""digraph G {\n"" + ""rankdir=LR;\n"" + ""  s0[label=\""0\""];\n"" + ""  s1[shape=record, label=\""<p0>|<p1>$\""];\n"" + ""  s2[label=\""$\""];\n"" + ""  s0->s1[label=\""1\""];\n"" + ""  s1:p0->s2[label=\""9\""];\n"" + ""}\n"";
    assertEquals(expecting, toDOTString(r, fullCtx()));
}", ,"// System.out.println(toDOTString(r, fullCtx()));
","// System.out.println(toDOTString(r, fullCtx()));",128,144,[0],0,[0],0,[0],0,0,0,0,test_a$_ax_fullctx(),org.antlr.v4.test.tool.TestGraphNodes,test_a$_ax_fullctx/0,False,128,3,5,0,5,1,7,8,0,5,0,7,5,3,0,0,0,0,8,1,5,1,0,0,0,0,17,1,0,False
802,..\projects\antlr4-4.11.0\tool-testsuite\test\org\antlr\v4\test\tool\TestGraphNodes.java,org.antlr.v4.test.tool.TestGraphNodes,void test_ax$_a$(),"@Test
public void test_ax$_a$() {
    PredictionContext x = x();
    PredictionContext a1 = createSingleton(x, 1);
    PredictionContext a2 = a();
    PredictionContext r = PredictionContext.merge(a1, a2, rootIsWildcard(), null);
    // System.out.println(toDOTString(r, rootIsWildcard()));
    String expecting = ""digraph G {\n"" + ""rankdir=LR;\n"" + ""  s0[label=\""0\""];\n"" + ""  s1[label=\""*\""];\n"" + ""  s0->s1[label=\""1\""];\n"" + ""}\n"";
    assertEquals(expecting, toDOTString(r, rootIsWildcard()));
}", ,"// System.out.println(toDOTString(r, rootIsWildcard()));
","// System.out.println(toDOTString(r, rootIsWildcard()));",146,160,[0],0,[0],0,[0],0,0,0,0,test_ax$_a$(),org.antlr.v4.test.tool.TestGraphNodes,test_ax$_a$/0,False,146,3,5,0,5,1,7,8,0,5,0,7,5,3,0,0,0,0,6,1,5,1,0,0,0,0,16,1,0,False
803,..\projects\antlr4-4.11.0\tool-testsuite\test\org\antlr\v4\test\tool\TestGraphNodes.java,org.antlr.v4.test.tool.TestGraphNodes,void test_aa$_a$_$_fullCtx(),"@Test
public void test_aa$_a$_$_fullCtx() {
    PredictionContext empty = EmptyPredictionContext.Instance;
    PredictionContext child1 = createSingleton(empty, 8);
    PredictionContext right = PredictionContext.merge(empty, child1, false, null);
    PredictionContext left = createSingleton(right, 8);
    PredictionContext merged = PredictionContext.merge(left, right, false, null);
    String actual = toDOTString(merged, false);
    // System.out.println(actual);
    String expecting = ""digraph G {\n"" + ""rankdir=LR;\n"" + ""  s0[shape=record, label=\""<p0>|<p1>$\""];\n"" + ""  s1[shape=record, label=\""<p0>|<p1>$\""];\n"" + ""  s2[label=\""$\""];\n"" + ""  s0:p0->s1[label=\""8\""];\n"" + ""  s1:p0->s2[label=\""8\""];\n"" + ""}\n"";
    assertEquals(expecting, actual);
}", ,"// System.out.println(actual);
",// System.out.println(actual);,162,180,[0],0,[0],0,[0],0,0,0,0,test_aa$_a$_$_fullCtx(),org.antlr.v4.test.tool.TestGraphNodes,test_aa$_a$_$_fullCtx/0,False,162,3,2,0,2,1,4,10,0,7,0,4,2,1,0,0,0,0,8,2,7,1,0,0,0,0,22,1,0,False
804,..\projects\antlr4-4.11.0\tool-testsuite\test\org\antlr\v4\test\tool\TestGraphNodes.java,org.antlr.v4.test.tool.TestGraphNodes,void test_ax$_a$_fullctx(),"@Test
public void test_ax$_a$_fullctx() {
    PredictionContext x = x();
    PredictionContext a1 = createSingleton(x, 1);
    PredictionContext a2 = a();
    PredictionContext r = PredictionContext.merge(a1, a2, fullCtx(), null);
    // System.out.println(toDOTString(r, fullCtx()));
    String expecting = ""digraph G {\n"" + ""rankdir=LR;\n"" + ""  s0[label=\""0\""];\n"" + ""  s1[shape=record, label=\""<p0>|<p1>$\""];\n"" + ""  s2[label=\""$\""];\n"" + ""  s0->s1[label=\""1\""];\n"" + ""  s1:p0->s2[label=\""9\""];\n"" + ""}\n"";
    assertEquals(expecting, toDOTString(r, fullCtx()));
}", ,"// System.out.println(toDOTString(r, fullCtx()));
","// System.out.println(toDOTString(r, fullCtx()));",182,198,[0],0,[0],0,[0],0,0,0,0,test_ax$_a$_fullctx(),org.antlr.v4.test.tool.TestGraphNodes,test_ax$_a$_fullctx/0,False,182,3,5,0,5,1,7,8,0,5,0,7,5,3,0,0,0,0,8,1,5,1,0,0,0,0,17,1,0,False
805,..\projects\antlr4-4.11.0\tool-testsuite\test\org\antlr\v4\test\tool\TestGraphNodes.java,org.antlr.v4.test.tool.TestGraphNodes,void test_a_b(),"@Test
public void test_a_b() {
    PredictionContext r = PredictionContext.merge(a(), b(), rootIsWildcard(), null);
    // System.out.println(toDOTString(r, rootIsWildcard()));
    String expecting = ""digraph G {\n"" + ""rankdir=LR;\n"" + ""  s0[shape=record, label=\""<p0>|<p1>\""];\n"" + ""  s1[label=\""*\""];\n"" + ""  s0:p0->s1[label=\""1\""];\n"" + ""  s0:p1->s1[label=\""2\""];\n"" + ""}\n"";
    assertEquals(expecting, toDOTString(r, rootIsWildcard()));
}", ,"// System.out.println(toDOTString(r, rootIsWildcard()));
","// System.out.println(toDOTString(r, rootIsWildcard()));",200,212,[0],0,[0],0,[0],0,0,0,0,test_a_b(),org.antlr.v4.test.tool.TestGraphNodes,test_a_b/0,False,200,3,4,0,4,1,6,5,0,2,0,6,4,3,0,0,0,0,7,0,2,1,0,0,0,0,13,1,0,False
806,..\projects\antlr4-4.11.0\tool-testsuite\test\org\antlr\v4\test\tool\TestGraphNodes.java,org.antlr.v4.test.tool.TestGraphNodes,void test_ax_ax_same(),"@Test
public void test_ax_ax_same() {
    PredictionContext x = x();
    PredictionContext a1 = createSingleton(x, 1);
    PredictionContext a2 = createSingleton(x, 1);
    PredictionContext r = PredictionContext.merge(a1, a2, rootIsWildcard(), null);
    // System.out.println(toDOTString(r, rootIsWildcard()));
    String expecting = ""digraph G {\n"" + ""rankdir=LR;\n"" + ""  s0[label=\""0\""];\n"" + ""  s1[label=\""1\""];\n"" + ""  s2[label=\""*\""];\n"" + ""  s0->s1[label=\""1\""];\n"" + ""  s1->s2[label=\""9\""];\n"" + ""}\n"";
    assertEquals(expecting, toDOTString(r, rootIsWildcard()));
}", ,"// System.out.println(toDOTString(r, rootIsWildcard()));
","// System.out.println(toDOTString(r, rootIsWildcard()));",214,230,[0],0,[0],0,[0],0,0,0,0,test_ax_ax_same(),org.antlr.v4.test.tool.TestGraphNodes,test_ax_ax_same/0,False,214,3,4,0,4,1,6,8,0,5,0,6,4,2,0,0,0,0,8,2,5,1,0,0,0,0,19,1,0,False
807,..\projects\antlr4-4.11.0\tool-testsuite\test\org\antlr\v4\test\tool\TestGraphNodes.java,org.antlr.v4.test.tool.TestGraphNodes,void test_ax_ax(),"@Test
public void test_ax_ax() {
    PredictionContext x1 = x();
    PredictionContext x2 = x();
    PredictionContext a1 = createSingleton(x1, 1);
    PredictionContext a2 = createSingleton(x2, 1);
    PredictionContext r = PredictionContext.merge(a1, a2, rootIsWildcard(), null);
    // System.out.println(toDOTString(r, rootIsWildcard()));
    String expecting = ""digraph G {\n"" + ""rankdir=LR;\n"" + ""  s0[label=\""0\""];\n"" + ""  s1[label=\""1\""];\n"" + ""  s2[label=\""*\""];\n"" + ""  s0->s1[label=\""1\""];\n"" + ""  s1->s2[label=\""9\""];\n"" + ""}\n"";
    assertEquals(expecting, toDOTString(r, rootIsWildcard()));
}", ,"// System.out.println(toDOTString(r, rootIsWildcard()));
","// System.out.println(toDOTString(r, rootIsWildcard()));",232,249,[0],0,[0],0,[0],0,0,0,0,test_ax_ax(),org.antlr.v4.test.tool.TestGraphNodes,test_ax_ax/0,False,232,3,4,0,4,1,6,9,0,6,0,6,4,2,0,0,0,0,8,2,6,1,0,0,0,0,20,1,0,False
808,..\projects\antlr4-4.11.0\tool-testsuite\test\org\antlr\v4\test\tool\TestGraphNodes.java,org.antlr.v4.test.tool.TestGraphNodes,void test_abx_abx(),"@Test
public void test_abx_abx() {
    PredictionContext x1 = x();
    PredictionContext x2 = x();
    PredictionContext b1 = createSingleton(x1, 2);
    PredictionContext b2 = createSingleton(x2, 2);
    PredictionContext a1 = createSingleton(b1, 1);
    PredictionContext a2 = createSingleton(b2, 1);
    PredictionContext r = PredictionContext.merge(a1, a2, rootIsWildcard(), null);
    // System.out.println(toDOTString(r, rootIsWildcard()));
    String expecting = ""digraph G {\n"" + ""rankdir=LR;\n"" + ""  s0[label=\""0\""];\n"" + ""  s1[label=\""1\""];\n"" + ""  s2[label=\""2\""];\n"" + ""  s3[label=\""*\""];\n"" + ""  s0->s1[label=\""1\""];\n"" + ""  s1->s2[label=\""2\""];\n"" + ""  s2->s3[label=\""9\""];\n"" + ""}\n"";
    assertEquals(expecting, toDOTString(r, rootIsWildcard()));
}", ,"// System.out.println(toDOTString(r, rootIsWildcard()));
","// System.out.println(toDOTString(r, rootIsWildcard()));",251,272,[0],0,[0],0,[0],0,0,0,0,test_abx_abx(),org.antlr.v4.test.tool.TestGraphNodes,test_abx_abx/0,False,251,3,4,0,4,1,6,11,0,8,0,6,4,2,0,0,0,0,10,4,8,1,0,0,0,0,23,1,0,False
809,..\projects\antlr4-4.11.0\tool-testsuite\test\org\antlr\v4\test\tool\TestGraphNodes.java,org.antlr.v4.test.tool.TestGraphNodes,void test_abx_acx(),"@Test
public void test_abx_acx() {
    PredictionContext x1 = x();
    PredictionContext x2 = x();
    PredictionContext b = createSingleton(x1, 2);
    PredictionContext c = createSingleton(x2, 3);
    PredictionContext a1 = createSingleton(b, 1);
    PredictionContext a2 = createSingleton(c, 1);
    PredictionContext r = PredictionContext.merge(a1, a2, rootIsWildcard(), null);
    // System.out.println(toDOTString(r, rootIsWildcard()));
    String expecting = ""digraph G {\n"" + ""rankdir=LR;\n"" + ""  s0[label=\""0\""];\n"" + ""  s1[shape=record, label=\""<p0>|<p1>\""];\n"" + ""  s2[label=\""2\""];\n"" + ""  s3[label=\""*\""];\n"" + ""  s0->s1[label=\""1\""];\n"" + ""  s1:p0->s2[label=\""2\""];\n"" + ""  s1:p1->s2[label=\""3\""];\n"" + ""  s2->s3[label=\""9\""];\n"" + ""}\n"";
    assertEquals(expecting, toDOTString(r, rootIsWildcard()));
}", ,"// System.out.println(toDOTString(r, rootIsWildcard()));
","// System.out.println(toDOTString(r, rootIsWildcard()));",274,296,[0],0,[0],0,[0],0,0,0,0,test_abx_acx(),org.antlr.v4.test.tool.TestGraphNodes,test_abx_acx/0,False,274,3,4,0,4,1,6,11,0,8,0,6,4,2,0,0,0,0,11,4,8,1,0,0,0,0,24,1,0,False
810,..\projects\antlr4-4.11.0\tool-testsuite\test\org\antlr\v4\test\tool\TestGraphNodes.java,org.antlr.v4.test.tool.TestGraphNodes,void test_ax_bx_same(),"@Test
public void test_ax_bx_same() {
    PredictionContext x = x();
    PredictionContext a = createSingleton(x, 1);
    PredictionContext b = createSingleton(x, 2);
    PredictionContext r = PredictionContext.merge(a, b, rootIsWildcard(), null);
    // System.out.println(toDOTString(r, rootIsWildcard()));
    String expecting = ""digraph G {\n"" + ""rankdir=LR;\n"" + ""  s0[shape=record, label=\""<p0>|<p1>\""];\n"" + ""  s1[label=\""1\""];\n"" + ""  s2[label=\""*\""];\n"" + ""  s0:p0->s1[label=\""1\""];\n"" + ""  s0:p1->s1[label=\""2\""];\n"" + ""  s1->s2[label=\""9\""];\n"" + ""}\n"";
    assertEquals(expecting, toDOTString(r, rootIsWildcard()));
}", ,"// System.out.println(toDOTString(r, rootIsWildcard()));
","// System.out.println(toDOTString(r, rootIsWildcard()));",298,315,[0],0,[0],0,[0],0,0,0,0,test_ax_bx_same(),org.antlr.v4.test.tool.TestGraphNodes,test_ax_bx_same/0,False,298,3,4,0,4,1,6,8,0,5,0,6,4,2,0,0,0,0,9,2,5,1,0,0,0,0,20,1,0,False
811,..\projects\antlr4-4.11.0\tool-testsuite\test\org\antlr\v4\test\tool\TestGraphNodes.java,org.antlr.v4.test.tool.TestGraphNodes,void test_ax_bx(),"@Test
public void test_ax_bx() {
    PredictionContext x1 = x();
    PredictionContext x2 = x();
    PredictionContext a = createSingleton(x1, 1);
    PredictionContext b = createSingleton(x2, 2);
    PredictionContext r = PredictionContext.merge(a, b, rootIsWildcard(), null);
    // System.out.println(toDOTString(r, rootIsWildcard()));
    String expecting = ""digraph G {\n"" + ""rankdir=LR;\n"" + ""  s0[shape=record, label=\""<p0>|<p1>\""];\n"" + ""  s1[label=\""1\""];\n"" + ""  s2[label=\""*\""];\n"" + ""  s0:p0->s1[label=\""1\""];\n"" + ""  s0:p1->s1[label=\""2\""];\n"" + ""  s1->s2[label=\""9\""];\n"" + ""}\n"";
    assertEquals(expecting, toDOTString(r, rootIsWildcard()));
}", ,"// System.out.println(toDOTString(r, rootIsWildcard()));
","// System.out.println(toDOTString(r, rootIsWildcard()));",317,335,[0],0,[0],0,[0],0,0,0,0,test_ax_bx(),org.antlr.v4.test.tool.TestGraphNodes,test_ax_bx/0,False,317,3,4,0,4,1,6,9,0,6,0,6,4,2,0,0,0,0,9,2,6,1,0,0,0,0,21,1,0,False
812,..\projects\antlr4-4.11.0\tool-testsuite\test\org\antlr\v4\test\tool\TestGraphNodes.java,org.antlr.v4.test.tool.TestGraphNodes,void test_ax_by(),"@Test
public void test_ax_by() {
    PredictionContext a = createSingleton(x(), 1);
    PredictionContext b = createSingleton(y(), 2);
    PredictionContext r = PredictionContext.merge(a, b, rootIsWildcard(), null);
    // System.out.println(toDOTString(r, rootIsWildcard()));
    String expecting = ""digraph G {\n"" + ""rankdir=LR;\n"" + ""  s0[shape=record, label=\""<p0>|<p1>\""];\n"" + ""  s2[label=\""2\""];\n"" + ""  s3[label=\""*\""];\n"" + ""  s1[label=\""1\""];\n"" + ""  s0:p0->s1[label=\""1\""];\n"" + ""  s0:p1->s2[label=\""2\""];\n"" + ""  s2->s3[label=\""10\""];\n"" + ""  s1->s3[label=\""9\""];\n"" + ""}\n"";
    assertEquals(expecting, toDOTString(r, rootIsWildcard()));
}", ,"// System.out.println(toDOTString(r, rootIsWildcard()));
","// System.out.println(toDOTString(r, rootIsWildcard()));",337,355,[0],0,[0],0,[0],0,0,0,0,test_ax_by(),org.antlr.v4.test.tool.TestGraphNodes,test_ax_by/0,False,337,3,5,0,5,1,7,7,0,4,0,7,5,3,0,0,0,0,11,2,4,1,0,0,0,0,21,1,0,False
813,..\projects\antlr4-4.11.0\tool-testsuite\test\org\antlr\v4\test\tool\TestGraphNodes.java,org.antlr.v4.test.tool.TestGraphNodes,void test_a$_bx(),"@Test
public void test_a$_bx() {
    PredictionContext x2 = x();
    PredictionContext a = a();
    PredictionContext b = createSingleton(x2, 2);
    PredictionContext r = PredictionContext.merge(a, b, rootIsWildcard(), null);
    // System.out.println(toDOTString(r, rootIsWildcard()));
    String expecting = ""digraph G {\n"" + ""rankdir=LR;\n"" + ""  s0[shape=record, label=\""<p0>|<p1>\""];\n"" + ""  s2[label=\""2\""];\n"" + ""  s1[label=\""*\""];\n"" + ""  s0:p0->s1[label=\""1\""];\n"" + ""  s0:p1->s2[label=\""2\""];\n"" + ""  s2->s1[label=\""9\""];\n"" + ""}\n"";
    assertEquals(expecting, toDOTString(r, rootIsWildcard()));
}", ,"// System.out.println(toDOTString(r, rootIsWildcard()));
","// System.out.println(toDOTString(r, rootIsWildcard()));",357,374,[0],0,[0],0,[0],0,0,0,0,test_a$_bx(),org.antlr.v4.test.tool.TestGraphNodes,test_a$_bx/0,False,357,3,5,0,5,1,7,8,0,5,0,7,5,3,0,0,0,0,9,1,5,1,0,0,0,0,17,1,0,False
814,..\projects\antlr4-4.11.0\tool-testsuite\test\org\antlr\v4\test\tool\TestGraphNodes.java,org.antlr.v4.test.tool.TestGraphNodes,void test_a$_bx_fullctx(),"@Test
public void test_a$_bx_fullctx() {
    PredictionContext x2 = x();
    PredictionContext a = a();
    PredictionContext b = createSingleton(x2, 2);
    PredictionContext r = PredictionContext.merge(a, b, fullCtx(), null);
    // System.out.println(toDOTString(r, fullCtx()));
    String expecting = ""digraph G {\n"" + ""rankdir=LR;\n"" + ""  s0[shape=record, label=\""<p0>|<p1>\""];\n"" + ""  s2[label=\""2\""];\n"" + ""  s1[label=\""$\""];\n"" + ""  s0:p0->s1[label=\""1\""];\n"" + ""  s0:p1->s2[label=\""2\""];\n"" + ""  s2->s1[label=\""9\""];\n"" + ""}\n"";
    assertEquals(expecting, toDOTString(r, fullCtx()));
}", ,"// System.out.println(toDOTString(r, fullCtx()));
","// System.out.println(toDOTString(r, fullCtx()));",376,393,[0],0,[0],0,[0],0,0,0,0,test_a$_bx_fullctx(),org.antlr.v4.test.tool.TestGraphNodes,test_a$_bx_fullctx/0,False,376,3,5,0,5,1,7,8,0,5,0,7,5,3,0,0,0,0,9,1,5,1,0,0,0,0,17,1,0,False
815,..\projects\antlr4-4.11.0\tool-testsuite\test\org\antlr\v4\test\tool\TestGraphNodes.java,org.antlr.v4.test.tool.TestGraphNodes,void test_aex_bfx(),"@Disabled(""Known inefficiency but deferring resolving the issue for now"")
@Test
public void test_aex_bfx() {
    // TJP: this is inefficient as it leaves the top x nodes unmerged.
    PredictionContext x1 = x();
    PredictionContext x2 = x();
    PredictionContext e = createSingleton(x1, 5);
    PredictionContext f = createSingleton(x2, 6);
    PredictionContext a = createSingleton(e, 1);
    PredictionContext b = createSingleton(f, 2);
    PredictionContext r = PredictionContext.merge(a, b, rootIsWildcard(), null);
    // System.out.println(toDOTString(r, rootIsWildcard()));
    String expecting = ""digraph G {\n"" + ""rankdir=LR;\n"" + ""  s0[shape=record, label=\""<p0>|<p1>\""];\n"" + ""  s2[label=\""2\""];\n"" + ""  s3[label=\""3\""];\n"" + ""  s4[label=\""*\""];\n"" + ""  s1[label=\""1\""];\n"" + ""  s0:p0->s1[label=\""1\""];\n"" + ""  s0:p1->s2[label=\""2\""];\n"" + ""  s2->s3[label=\""6\""];\n"" + ""  s3->s4[label=\""9\""];\n"" + ""  s1->s3[label=\""5\""];\n"" + ""}\n"";
    assertEquals(expecting, toDOTString(r, rootIsWildcard()));
}", ,"// TJP: this is inefficient as it leaves the top x nodes unmerged.
[[SEP]]// System.out.println(toDOTString(r, rootIsWildcard()));
","// TJP: this is inefficient as it leaves the top x nodes unmerged.[[SEP]]// System.out.println(toDOTString(r, rootIsWildcard()));",395,421,[0],0,"[0, 0]",0,"[0, 0]",0,0,0,0,test_aex_bfx(),org.antlr.v4.test.tool.TestGraphNodes,test_aex_bfx/0,False,396,4,4,0,4,1,6,11,0,8,0,6,4,2,0,0,0,0,14,4,8,1,0,0,0,0,31,1,0,False
816,..\projects\antlr4-4.11.0\tool-testsuite\test\org\antlr\v4\test\tool\TestGraphNodes.java,org.antlr.v4.test.tool.TestGraphNodes,void test_A$_A$_fullctx(),"// Array merges
@Test
public void test_A$_A$_fullctx() {
    ArrayPredictionContext A1 = array(EmptyPredictionContext.Instance);
    ArrayPredictionContext A2 = array(EmptyPredictionContext.Instance);
    PredictionContext r = PredictionContext.merge(A1, A2, fullCtx(), null);
    // System.out.println(toDOTString(r, fullCtx()));
    String expecting = ""digraph G {\n"" + ""rankdir=LR;\n"" + ""  s0[label=\""$\""];\n"" + ""}\n"";
    assertEquals(expecting, toDOTString(r, fullCtx()));
}", ,"// System.out.println(toDOTString(r, fullCtx()));
","// Array merges[[SEP]]// System.out.println(toDOTString(r, fullCtx()));",425,436,[0],0,[0],0,"[0, 0]",0,0,0,0,test_A$_A$_fullctx(),org.antlr.v4.test.tool.TestGraphNodes,test_A$_A$_fullctx/0,False,425,4,3,0,3,1,5,7,0,4,0,5,3,1,0,0,0,0,4,0,4,1,0,0,0,0,13,1,0,False
817,..\projects\antlr4-4.11.0\tool-testsuite\test\org\antlr\v4\test\tool\TestGraphNodes.java,org.antlr.v4.test.tool.TestGraphNodes,void test_Aab_Ac(),"@Test
public void test_Aab_Ac() {
    // a,b + c
    SingletonPredictionContext a = a();
    SingletonPredictionContext b = b();
    SingletonPredictionContext c = c();
    ArrayPredictionContext A1 = array(a, b);
    ArrayPredictionContext A2 = array(c);
    PredictionContext r = PredictionContext.merge(A1, A2, rootIsWildcard(), null);
    // System.out.println(toDOTString(r, rootIsWildcard()));
    String expecting = ""digraph G {\n"" + ""rankdir=LR;\n"" + ""  s0[shape=record, label=\""<p0>|<p1>|<p2>\""];\n"" + ""  s1[label=\""*\""];\n"" + ""  s0:p0->s1[label=\""1\""];\n"" + ""  s0:p1->s1[label=\""2\""];\n"" + ""  s0:p2->s1[label=\""3\""];\n"" + ""}\n"";
    assertEquals(expecting, toDOTString(r, rootIsWildcard()));
}", ,"// a,b + c
[[SEP]]// System.out.println(toDOTString(r, rootIsWildcard()));
","// a,b + c[[SEP]]// System.out.println(toDOTString(r, rootIsWildcard()));",438,456,[0],0,"[0, 0]",0,"[0, 0]",0,0,0,0,test_Aab_Ac(),org.antlr.v4.test.tool.TestGraphNodes,test_Aab_Ac/0,False,438,5,6,0,6,1,8,10,0,7,0,8,6,4,0,0,0,0,8,0,7,1,0,0,0,0,22,1,0,False
818,..\projects\antlr4-4.11.0\tool-testsuite\test\org\antlr\v4\test\tool\TestGraphNodes.java,org.antlr.v4.test.tool.TestGraphNodes,void test_Aa_Aa(),"@Test
public void test_Aa_Aa() {
    SingletonPredictionContext a1 = a();
    SingletonPredictionContext a2 = a();
    ArrayPredictionContext A1 = array(a1);
    ArrayPredictionContext A2 = array(a2);
    PredictionContext r = PredictionContext.merge(A1, A2, rootIsWildcard(), null);
    // System.out.println(toDOTString(r, rootIsWildcard()));
    String expecting = ""digraph G {\n"" + ""rankdir=LR;\n"" + ""  s0[label=\""0\""];\n"" + ""  s1[label=\""*\""];\n"" + ""  s0->s1[label=\""1\""];\n"" + ""}\n"";
    assertEquals(expecting, toDOTString(r, rootIsWildcard()));
}", ,"// System.out.println(toDOTString(r, rootIsWildcard()));
","// System.out.println(toDOTString(r, rootIsWildcard()));",458,473,[0],0,[0],0,[0],0,0,0,0,test_Aa_Aa(),org.antlr.v4.test.tool.TestGraphNodes,test_Aa_Aa/0,False,458,5,4,0,4,1,6,9,0,6,0,6,4,2,0,0,0,0,6,0,6,1,0,0,0,0,21,1,0,False
819,..\projects\antlr4-4.11.0\tool-testsuite\test\org\antlr\v4\test\tool\TestGraphNodes.java,org.antlr.v4.test.tool.TestGraphNodes,void test_Aa_Abc(),"@Test
public void test_Aa_Abc() {
    // a + b,c
    SingletonPredictionContext a = a();
    SingletonPredictionContext b = b();
    SingletonPredictionContext c = c();
    ArrayPredictionContext A1 = array(a);
    ArrayPredictionContext A2 = array(b, c);
    PredictionContext r = PredictionContext.merge(A1, A2, rootIsWildcard(), null);
    // System.out.println(toDOTString(r, rootIsWildcard()));
    String expecting = ""digraph G {\n"" + ""rankdir=LR;\n"" + ""  s0[shape=record, label=\""<p0>|<p1>|<p2>\""];\n"" + ""  s1[label=\""*\""];\n"" + ""  s0:p0->s1[label=\""1\""];\n"" + ""  s0:p1->s1[label=\""2\""];\n"" + ""  s0:p2->s1[label=\""3\""];\n"" + ""}\n"";
    assertEquals(expecting, toDOTString(r, rootIsWildcard()));
}", ,"// a + b,c
[[SEP]]// System.out.println(toDOTString(r, rootIsWildcard()));
","// a + b,c[[SEP]]// System.out.println(toDOTString(r, rootIsWildcard()));",475,493,[0],0,"[0, 0]",0,"[0, 0]",0,0,0,0,test_Aa_Abc(),org.antlr.v4.test.tool.TestGraphNodes,test_Aa_Abc/0,False,475,5,6,0,6,1,8,10,0,7,0,8,6,4,0,0,0,0,8,0,7,1,0,0,0,0,22,1,0,False
820,..\projects\antlr4-4.11.0\tool-testsuite\test\org\antlr\v4\test\tool\TestGraphNodes.java,org.antlr.v4.test.tool.TestGraphNodes,void test_Aac_Ab(),"@Test
public void test_Aac_Ab() {
    // a,c + b
    SingletonPredictionContext a = a();
    SingletonPredictionContext b = b();
    SingletonPredictionContext c = c();
    ArrayPredictionContext A1 = array(a, c);
    ArrayPredictionContext A2 = array(b);
    PredictionContext r = PredictionContext.merge(A1, A2, rootIsWildcard(), null);
    // System.out.println(toDOTString(r, rootIsWildcard()));
    String expecting = ""digraph G {\n"" + ""rankdir=LR;\n"" + ""  s0[shape=record, label=\""<p0>|<p1>|<p2>\""];\n"" + ""  s1[label=\""*\""];\n"" + ""  s0:p0->s1[label=\""1\""];\n"" + ""  s0:p1->s1[label=\""2\""];\n"" + ""  s0:p2->s1[label=\""3\""];\n"" + ""}\n"";
    assertEquals(expecting, toDOTString(r, rootIsWildcard()));
}", ,"// a,c + b
[[SEP]]// System.out.println(toDOTString(r, rootIsWildcard()));
","// a,c + b[[SEP]]// System.out.println(toDOTString(r, rootIsWildcard()));",495,513,[0],0,"[0, 0]",0,"[0, 0]",0,0,0,0,test_Aac_Ab(),org.antlr.v4.test.tool.TestGraphNodes,test_Aac_Ab/0,False,495,5,6,0,6,1,8,10,0,7,0,8,6,4,0,0,0,0,8,0,7,1,0,0,0,0,22,1,0,False
821,..\projects\antlr4-4.11.0\tool-testsuite\test\org\antlr\v4\test\tool\TestGraphNodes.java,org.antlr.v4.test.tool.TestGraphNodes,void test_Aab_Aa(),"@Test
public void test_Aab_Aa() {
    // a,b + a
    ArrayPredictionContext A1 = array(a(), b());
    ArrayPredictionContext A2 = array(a());
    PredictionContext r = PredictionContext.merge(A1, A2, rootIsWildcard(), null);
    // System.out.println(toDOTString(r, rootIsWildcard()));
    String expecting = ""digraph G {\n"" + ""rankdir=LR;\n"" + ""  s0[shape=record, label=\""<p0>|<p1>\""];\n"" + ""  s1[label=\""*\""];\n"" + ""  s0:p0->s1[label=\""1\""];\n"" + ""  s0:p1->s1[label=\""2\""];\n"" + ""}\n"";
    assertEquals(expecting, toDOTString(r, rootIsWildcard()));
}", ,"// a,b + a
[[SEP]]// System.out.println(toDOTString(r, rootIsWildcard()));
","// a,b + a[[SEP]]// System.out.println(toDOTString(r, rootIsWildcard()));",515,529,[0],0,"[0, 0]",0,"[0, 0]",0,0,0,0,test_Aab_Aa(),org.antlr.v4.test.tool.TestGraphNodes,test_Aab_Aa/0,False,515,4,5,0,5,1,7,7,0,4,0,7,5,3,0,0,0,0,7,0,4,1,0,0,0,0,19,1,0,False
822,..\projects\antlr4-4.11.0\tool-testsuite\test\org\antlr\v4\test\tool\TestGraphNodes.java,org.antlr.v4.test.tool.TestGraphNodes,void test_Aab_Ab(),"@Test
public void test_Aab_Ab() {
    // a,b + b
    ArrayPredictionContext A1 = array(a(), b());
    ArrayPredictionContext A2 = array(b());
    PredictionContext r = PredictionContext.merge(A1, A2, rootIsWildcard(), null);
    // System.out.println(toDOTString(r, rootIsWildcard()));
    String expecting = ""digraph G {\n"" + ""rankdir=LR;\n"" + ""  s0[shape=record, label=\""<p0>|<p1>\""];\n"" + ""  s1[label=\""*\""];\n"" + ""  s0:p0->s1[label=\""1\""];\n"" + ""  s0:p1->s1[label=\""2\""];\n"" + ""}\n"";
    assertEquals(expecting, toDOTString(r, rootIsWildcard()));
}", ,"// a,b + b
[[SEP]]// System.out.println(toDOTString(r, rootIsWildcard()));
","// a,b + b[[SEP]]// System.out.println(toDOTString(r, rootIsWildcard()));",531,545,[0],0,"[0, 0]",0,"[0, 0]",0,0,0,0,test_Aab_Ab(),org.antlr.v4.test.tool.TestGraphNodes,test_Aab_Ab/0,False,531,4,5,0,5,1,7,7,0,4,0,7,5,3,0,0,0,0,7,0,4,1,0,0,0,0,20,1,0,False
823,..\projects\antlr4-4.11.0\tool-testsuite\test\org\antlr\v4\test\tool\TestGraphNodes.java,org.antlr.v4.test.tool.TestGraphNodes,void test_Aax_Aby(),"@Test
public void test_Aax_Aby() {
    // ax + by but in arrays
    SingletonPredictionContext a = createSingleton(x(), 1);
    SingletonPredictionContext b = createSingleton(y(), 2);
    ArrayPredictionContext A1 = array(a);
    ArrayPredictionContext A2 = array(b);
    PredictionContext r = PredictionContext.merge(A1, A2, rootIsWildcard(), null);
    // System.out.println(toDOTString(r, rootIsWildcard()));
    String expecting = ""digraph G {\n"" + ""rankdir=LR;\n"" + ""  s0[shape=record, label=\""<p0>|<p1>\""];\n"" + ""  s2[label=\""2\""];\n"" + ""  s3[label=\""*\""];\n"" + ""  s1[label=\""1\""];\n"" + ""  s0:p0->s1[label=\""1\""];\n"" + ""  s0:p1->s2[label=\""2\""];\n"" + ""  s2->s3[label=\""10\""];\n"" + ""  s1->s3[label=\""9\""];\n"" + ""}\n"";
    assertEquals(expecting, toDOTString(r, rootIsWildcard()));
}", ,"// ax + by but in arrays
[[SEP]]// System.out.println(toDOTString(r, rootIsWildcard()));
","// ax + by but in arrays[[SEP]]// System.out.println(toDOTString(r, rootIsWildcard()));",547,567,[0],0,"[0, 0]",0,"[0, 0]",0,0,0,0,test_Aax_Aby(),org.antlr.v4.test.tool.TestGraphNodes,test_Aax_Aby/0,False,547,5,6,0,6,1,8,9,0,6,0,8,6,3,0,0,0,0,11,2,6,1,0,0,0,0,26,1,0,False
824,..\projects\antlr4-4.11.0\tool-testsuite\test\org\antlr\v4\test\tool\TestGraphNodes.java,org.antlr.v4.test.tool.TestGraphNodes,void test_Aax_Aay(),"@Test
public void test_Aax_Aay() {
    // ax + ay -> merged singleton a, array parent
    SingletonPredictionContext a1 = createSingleton(x(), 1);
    SingletonPredictionContext a2 = createSingleton(y(), 1);
    ArrayPredictionContext A1 = array(a1);
    ArrayPredictionContext A2 = array(a2);
    PredictionContext r = PredictionContext.merge(A1, A2, rootIsWildcard(), null);
    // System.out.println(toDOTString(r, rootIsWildcard()));
    String expecting = ""digraph G {\n"" + ""rankdir=LR;\n"" + ""  s0[label=\""0\""];\n"" + ""  s1[shape=record, label=\""<p0>|<p1>\""];\n"" + ""  s2[label=\""*\""];\n"" + ""  s0->s1[label=\""1\""];\n"" + ""  s1:p0->s2[label=\""9\""];\n"" + ""  s1:p1->s2[label=\""10\""];\n"" + ""}\n"";
    assertEquals(expecting, toDOTString(r, rootIsWildcard()));
}", ,"// ax + ay -> merged singleton a, array parent
[[SEP]]// System.out.println(toDOTString(r, rootIsWildcard()));
","// ax + ay -> merged singleton a, array parent[[SEP]]// System.out.println(toDOTString(r, rootIsWildcard()));",569,587,[0],0,"[0, 0]",0,"[0, 0]",0,0,0,0,test_Aax_Aay(),org.antlr.v4.test.tool.TestGraphNodes,test_Aax_Aay/0,False,569,5,6,0,6,1,8,9,0,6,0,8,6,3,0,0,0,0,9,2,6,1,0,0,0,0,25,1,0,False
825,..\projects\antlr4-4.11.0\tool-testsuite\test\org\antlr\v4\test\tool\TestGraphNodes.java,org.antlr.v4.test.tool.TestGraphNodes,void test_Aaxc_Aayd(),"@Test
public void test_Aaxc_Aayd() {
    // ax,c + ay,d -> merged a, array parent
    SingletonPredictionContext a1 = createSingleton(x(), 1);
    SingletonPredictionContext a2 = createSingleton(y(), 1);
    ArrayPredictionContext A1 = array(a1, c());
    ArrayPredictionContext A2 = array(a2, d());
    PredictionContext r = PredictionContext.merge(A1, A2, rootIsWildcard(), null);
    // System.out.println(toDOTString(r, rootIsWildcard()));
    String expecting = ""digraph G {\n"" + ""rankdir=LR;\n"" + ""  s0[shape=record, label=\""<p0>|<p1>|<p2>\""];\n"" + ""  s2[label=\""*\""];\n"" + ""  s1[shape=record, label=\""<p0>|<p1>\""];\n"" + ""  s0:p0->s1[label=\""1\""];\n"" + ""  s0:p1->s2[label=\""3\""];\n"" + ""  s0:p2->s2[label=\""4\""];\n"" + ""  s1:p0->s2[label=\""9\""];\n"" + ""  s1:p1->s2[label=\""10\""];\n"" + ""}\n"";
    assertEquals(expecting, toDOTString(r, rootIsWildcard()));
}", ,"// ax,c + ay,d -> merged a, array parent
[[SEP]]// System.out.println(toDOTString(r, rootIsWildcard()));
","// ax,c + ay,d -> merged a, array parent[[SEP]]// System.out.println(toDOTString(r, rootIsWildcard()));",589,609,[0],0,"[0, 0]",0,"[0, 0]",0,0,0,0,test_Aaxc_Aayd(),org.antlr.v4.test.tool.TestGraphNodes,test_Aaxc_Aayd/0,False,589,5,8,0,8,1,10,9,0,6,0,10,8,5,0,0,0,0,11,2,6,1,0,0,0,0,24,1,0,False
826,..\projects\antlr4-4.11.0\tool-testsuite\test\org\antlr\v4\test\tool\TestGraphNodes.java,org.antlr.v4.test.tool.TestGraphNodes,void test_Aaubv_Acwdx(),"@Test
public void test_Aaubv_Acwdx() {
    // au,bv + cw,dx -> [a,b,c,d]->[u,v,w,x]
    SingletonPredictionContext a = createSingleton(u(), 1);
    SingletonPredictionContext b = createSingleton(v(), 2);
    SingletonPredictionContext c = createSingleton(w(), 3);
    SingletonPredictionContext d = createSingleton(x(), 4);
    ArrayPredictionContext A1 = array(a, b);
    ArrayPredictionContext A2 = array(c, d);
    PredictionContext r = PredictionContext.merge(A1, A2, rootIsWildcard(), null);
    // System.out.println(toDOTString(r, rootIsWildcard()));
    String expecting = ""digraph G {\n"" + ""rankdir=LR;\n"" + ""  s0[shape=record, label=\""<p0>|<p1>|<p2>|<p3>\""];\n"" + ""  s4[label=\""4\""];\n"" + ""  s5[label=\""*\""];\n"" + ""  s3[label=\""3\""];\n"" + ""  s2[label=\""2\""];\n"" + ""  s1[label=\""1\""];\n"" + ""  s0:p0->s1[label=\""1\""];\n"" + ""  s0:p1->s2[label=\""2\""];\n"" + ""  s0:p2->s3[label=\""3\""];\n"" + ""  s0:p3->s4[label=\""4\""];\n"" + ""  s4->s5[label=\""9\""];\n"" + ""  s3->s5[label=\""8\""];\n"" + ""  s2->s5[label=\""7\""];\n"" + ""  s1->s5[label=\""6\""];\n"" + ""}\n"";
    assertEquals(expecting, toDOTString(r, rootIsWildcard()));
}", ,"// au,bv + cw,dx -> [a,b,c,d]->[u,v,w,x]
[[SEP]]// System.out.println(toDOTString(r, rootIsWildcard()));
","// au,bv + cw,dx -> [a,b,c,d]->[u,v,w,x][[SEP]]// System.out.println(toDOTString(r, rootIsWildcard()));",611,639,[0],0,"[0, 0]",0,"[0, 0]",0,0,0,0,test_Aaubv_Acwdx(),org.antlr.v4.test.tool.TestGraphNodes,test_Aaubv_Acwdx/0,False,611,5,8,0,8,1,10,11,0,8,0,10,8,5,0,0,0,0,17,4,8,1,0,0,0,0,32,1,0,False
827,..\projects\antlr4-4.11.0\tool-testsuite\test\org\antlr\v4\test\tool\TestGraphNodes.java,org.antlr.v4.test.tool.TestGraphNodes,void test_Aaubv_Abvdx(),"@Test
public void test_Aaubv_Abvdx() {
    // au,bv + bv,dx -> [a,b,d]->[u,v,x]
    SingletonPredictionContext a = createSingleton(u(), 1);
    SingletonPredictionContext b1 = createSingleton(v(), 2);
    SingletonPredictionContext b2 = createSingleton(v(), 2);
    SingletonPredictionContext d = createSingleton(x(), 4);
    ArrayPredictionContext A1 = array(a, b1);
    ArrayPredictionContext A2 = array(b2, d);
    PredictionContext r = PredictionContext.merge(A1, A2, rootIsWildcard(), null);
    // System.out.println(toDOTString(r, rootIsWildcard()));
    String expecting = ""digraph G {\n"" + ""rankdir=LR;\n"" + ""  s0[shape=record, label=\""<p0>|<p1>|<p2>\""];\n"" + ""  s3[label=\""3\""];\n"" + ""  s4[label=\""*\""];\n"" + ""  s2[label=\""2\""];\n"" + ""  s1[label=\""1\""];\n"" + ""  s0:p0->s1[label=\""1\""];\n"" + ""  s0:p1->s2[label=\""2\""];\n"" + ""  s0:p2->s3[label=\""4\""];\n"" + ""  s3->s4[label=\""9\""];\n"" + ""  s2->s4[label=\""7\""];\n"" + ""  s1->s4[label=\""6\""];\n"" + ""}\n"";
    assertEquals(expecting, toDOTString(r, rootIsWildcard()));
}", ,"// au,bv + bv,dx -> [a,b,d]->[u,v,x]
[[SEP]]// System.out.println(toDOTString(r, rootIsWildcard()));
","// au,bv + bv,dx -> [a,b,d]->[u,v,x][[SEP]]// System.out.println(toDOTString(r, rootIsWildcard()));",641,666,[0],0,"[0, 0]",0,"[0, 0]",0,0,0,0,test_Aaubv_Abvdx(),org.antlr.v4.test.tool.TestGraphNodes,test_Aaubv_Abvdx/0,False,641,5,7,0,7,1,9,11,0,8,0,9,7,4,0,0,0,0,14,4,8,1,0,0,0,0,30,1,0,False
828,..\projects\antlr4-4.11.0\tool-testsuite\test\org\antlr\v4\test\tool\TestGraphNodes.java,org.antlr.v4.test.tool.TestGraphNodes,void test_Aaubv_Abwdx(),"@Test
public void test_Aaubv_Abwdx() {
    // au,bv + bw,dx -> [a,b,d]->[u,[v,w],x]
    SingletonPredictionContext a = createSingleton(u(), 1);
    SingletonPredictionContext b1 = createSingleton(v(), 2);
    SingletonPredictionContext b2 = createSingleton(w(), 2);
    SingletonPredictionContext d = createSingleton(x(), 4);
    ArrayPredictionContext A1 = array(a, b1);
    ArrayPredictionContext A2 = array(b2, d);
    PredictionContext r = PredictionContext.merge(A1, A2, rootIsWildcard(), null);
    // System.out.println(toDOTString(r, rootIsWildcard()));
    String expecting = ""digraph G {\n"" + ""rankdir=LR;\n"" + ""  s0[shape=record, label=\""<p0>|<p1>|<p2>\""];\n"" + ""  s3[label=\""3\""];\n"" + ""  s4[label=\""*\""];\n"" + ""  s2[shape=record, label=\""<p0>|<p1>\""];\n"" + ""  s1[label=\""1\""];\n"" + ""  s0:p0->s1[label=\""1\""];\n"" + ""  s0:p1->s2[label=\""2\""];\n"" + ""  s0:p2->s3[label=\""4\""];\n"" + ""  s3->s4[label=\""9\""];\n"" + ""  s2:p0->s4[label=\""7\""];\n"" + ""  s2:p1->s4[label=\""8\""];\n"" + ""  s1->s4[label=\""6\""];\n"" + ""}\n"";
    assertEquals(expecting, toDOTString(r, rootIsWildcard()));
}", ,"// au,bv + bw,dx -> [a,b,d]->[u,[v,w],x]
[[SEP]]// System.out.println(toDOTString(r, rootIsWildcard()));
","// au,bv + bw,dx -> [a,b,d]->[u,[v,w],x][[SEP]]// System.out.println(toDOTString(r, rootIsWildcard()));",668,694,[0],0,"[0, 0]",0,"[0, 0]",0,0,0,0,test_Aaubv_Abwdx(),org.antlr.v4.test.tool.TestGraphNodes,test_Aaubv_Abwdx/0,False,668,5,8,0,8,1,10,11,0,8,0,10,8,5,0,0,0,0,15,4,8,1,0,0,0,0,30,1,0,False
829,..\projects\antlr4-4.11.0\tool-testsuite\test\org\antlr\v4\test\tool\TestGraphNodes.java,org.antlr.v4.test.tool.TestGraphNodes,void test_Aaubv_Abvdu(),"@Test
public void test_Aaubv_Abvdu() {
    // au,bv + bv,du -> [a,b,d]->[u,v,u]; u,v shared
    SingletonPredictionContext a = createSingleton(u(), 1);
    SingletonPredictionContext b1 = createSingleton(v(), 2);
    SingletonPredictionContext b2 = createSingleton(v(), 2);
    SingletonPredictionContext d = createSingleton(u(), 4);
    ArrayPredictionContext A1 = array(a, b1);
    ArrayPredictionContext A2 = array(b2, d);
    PredictionContext r = PredictionContext.merge(A1, A2, rootIsWildcard(), null);
    // System.out.println(toDOTString(r, rootIsWildcard()));
    String expecting = ""digraph G {\n"" + ""rankdir=LR;\n"" + ""  s0[shape=record, label=\""<p0>|<p1>|<p2>\""];\n"" + ""  s2[label=\""2\""];\n"" + ""  s3[label=\""*\""];\n"" + ""  s1[label=\""1\""];\n"" + ""  s0:p0->s1[label=\""1\""];\n"" + ""  s0:p1->s2[label=\""2\""];\n"" + ""  s0:p2->s1[label=\""4\""];\n"" + ""  s2->s3[label=\""7\""];\n"" + ""  s1->s3[label=\""6\""];\n"" + ""}\n"";
    assertEquals(expecting, toDOTString(r, rootIsWildcard()));
}", ,"// au,bv + bv,du -> [a,b,d]->[u,v,u]; u,v shared
[[SEP]]// System.out.println(toDOTString(r, rootIsWildcard()));
","// au,bv + bv,du -> [a,b,d]->[u,v,u]; u,v shared[[SEP]]// System.out.println(toDOTString(r, rootIsWildcard()));",696,719,[0],0,"[0, 0]",0,"[0, 0]",0,0,0,0,test_Aaubv_Abvdu(),org.antlr.v4.test.tool.TestGraphNodes,test_Aaubv_Abvdu/0,False,696,5,6,0,6,1,8,11,0,8,0,8,6,3,0,0,0,0,12,4,8,1,0,0,0,0,28,1,0,False
830,..\projects\antlr4-4.11.0\tool-testsuite\test\org\antlr\v4\test\tool\TestGraphNodes.java,org.antlr.v4.test.tool.TestGraphNodes,void test_Aaubu_Acudu(),"@Test
public void test_Aaubu_Acudu() {
    // au,bu + cu,du -> [a,b,c,d]->[u,u,u,u]
    SingletonPredictionContext a = createSingleton(u(), 1);
    SingletonPredictionContext b = createSingleton(u(), 2);
    SingletonPredictionContext c = createSingleton(u(), 3);
    SingletonPredictionContext d = createSingleton(u(), 4);
    ArrayPredictionContext A1 = array(a, b);
    ArrayPredictionContext A2 = array(c, d);
    PredictionContext r = PredictionContext.merge(A1, A2, rootIsWildcard(), null);
    // System.out.println(toDOTString(r, rootIsWildcard()));
    String expecting = ""digraph G {\n"" + ""rankdir=LR;\n"" + ""  s0[shape=record, label=\""<p0>|<p1>|<p2>|<p3>\""];\n"" + ""  s1[label=\""1\""];\n"" + ""  s2[label=\""*\""];\n"" + ""  s0:p0->s1[label=\""1\""];\n"" + ""  s0:p1->s1[label=\""2\""];\n"" + ""  s0:p2->s1[label=\""3\""];\n"" + ""  s0:p3->s1[label=\""4\""];\n"" + ""  s1->s2[label=\""6\""];\n"" + ""}\n"";
    assertEquals(expecting, toDOTString(r, rootIsWildcard()));
}", ,"// au,bu + cu,du -> [a,b,c,d]->[u,u,u,u]
[[SEP]]// System.out.println(toDOTString(r, rootIsWildcard()));
","// au,bu + cu,du -> [a,b,c,d]->[u,u,u,u][[SEP]]// System.out.println(toDOTString(r, rootIsWildcard()));",721,743,[0],0,"[0, 0]",0,"[0, 0]",0,0,0,0,test_Aaubu_Acudu(),org.antlr.v4.test.tool.TestGraphNodes,test_Aaubu_Acudu/0,False,721,5,5,0,5,1,7,11,0,8,0,7,5,2,0,0,0,0,11,4,8,1,0,0,0,0,26,1,0,False
831,..\projects\antlr4-4.11.0\tool-testsuite\test\org\antlr\v4\test\tool\TestIntervalSet.java,org.antlr.v4.test.tool.TestIntervalSet,void testNotSetFragmentedVocabulary(),"@Test
public void testNotSetFragmentedVocabulary() throws Exception {
    IntervalSet vocabulary = IntervalSet.of(1, 255);
    vocabulary.add(1000, 2000);
    vocabulary.add(9999);
    IntervalSet s = IntervalSet.of(50, 60);
    s.add(3);
    s.add(250, 300);
    // this is outside range of vocab and should be ignored
    s.add(10000);
    String expecting = ""{1..2, 4..49, 61..249, 1000..2000, 9999}"";
    String result = (s.complement(vocabulary)).toString();
    assertEquals(expecting, result);
}", ,"// this is outside range of vocab and should be ignored
",// this is outside range of vocab and should be ignored,119,130,[0],0,[0],0,[0],0,0,0,0,testNotSetFragmentedVocabulary(),org.antlr.v4.test.tool.TestIntervalSet,testNotSetFragmentedVocabulary/0,False,119,2,0,0,0,1,5,12,0,4,0,5,0,0,0,0,0,1,1,11,4,0,0,0,0,0,13,1,0,False
832,..\projects\antlr4-4.11.0\tool-testsuite\test\org\antlr\v4\test\tool\TestIntervalSet.java,org.antlr.v4.test.tool.TestIntervalSet,void testSubtractOfRangeSpanningMultipleRanges(),"@Test
public void testSubtractOfRangeSpanningMultipleRanges() throws Exception {
    IntervalSet s = IntervalSet.of(10, 20);
    s.add(30, 40);
    // s has 3 ranges now: 10..20, 30..40, 50..60
    s.add(50, 60);
    // covers one and touches 2nd range
    IntervalSet s2 = IntervalSet.of(5, 55);
    String expecting = ""{56..60}"";
    String result = (s.subtract(s2)).toString();
    assertEquals(expecting, result);
    // touches both
    IntervalSet s3 = IntervalSet.of(15, 55);
    expecting = ""{10..14, 56..60}"";
    result = (s.subtract(s3)).toString();
    assertEquals(expecting, result);
}", ,"// s has 3 ranges now: 10..20, 30..40, 50..60
[[SEP]]// covers one and touches 2nd range
[[SEP]]// touches both
","// s has 3 ranges now: 10..20, 30..40, 50..60[[SEP]]// covers one and touches 2nd range[[SEP]]// touches both",183,196,[0],0,"[0, 0, 0]",0,"[0, 0, 0]",0,0,0,0,testSubtractOfRangeSpanningMultipleRanges(),org.antlr.v4.test.tool.TestIntervalSet,testSubtractOfRangeSpanningMultipleRanges/0,False,183,2,0,0,0,1,5,13,0,5,0,5,0,0,0,0,0,2,2,10,7,0,0,0,0,0,17,1,0,False
833,..\projects\antlr4-4.11.0\tool-testsuite\test\org\antlr\v4\test\tool\TestIntervalSet.java,org.antlr.v4.test.tool.TestIntervalSet,void testSubtractOfWackyRange(),"/**
 *  The following was broken:
 * 	 	{0..113, 115..65534}-{0..115, 117..65534}=116..65534
 */
@Test
public void testSubtractOfWackyRange() throws Exception {
    IntervalSet s = IntervalSet.of(0, 113);
    s.add(115, 200);
    IntervalSet s2 = IntervalSet.of(0, 115);
    s2.add(117, 200);
    String expecting = ""116"";
    String result = (s.subtract(s2)).toString();
    assertEquals(expecting, result);
}","/**
 *  The following was broken:
 * 	 	{0..113, 115..65534}-{0..115, 117..65534}=116..65534
 */
", ,"/** *  The following was broken: * 	 	{0..113, 115..65534}-{0..115, 117..65534}=116..65534 */",201,209,[0],0,[0],0,[0],0,0,0,0,testSubtractOfWackyRange(),org.antlr.v4.test.tool.TestIntervalSet,testSubtractOfWackyRange/0,False,201,2,0,0,0,1,5,9,0,4,0,5,0,0,0,0,0,1,1,8,4,0,0,0,0,0,17,1,0,True
834,..\projects\antlr4-4.11.0\tool-testsuite\test\org\antlr\v4\test\tool\TestIntervalSet.java,org.antlr.v4.test.tool.TestIntervalSet,void testSingleElementMinusDisjointSet(),"@Test
public void testSingleElementMinusDisjointSet() throws Exception {
    IntervalSet s = IntervalSet.of(15, 15);
    IntervalSet s2 = IntervalSet.of(1, 5);
    s2.add(10, 20);
    // 15 - {1..5, 10..20} = {}
    String expecting = ""{}"";
    String result = s.subtract(s2).toString();
    assertEquals(expecting, result);
}", ,"// 15 - {1..5, 10..20} = {}
","// 15 - {1..5, 10..20} = {}",234,241,[0],0,[0],0,[0],0,0,0,0,testSingleElementMinusDisjointSet(),org.antlr.v4.test.tool.TestIntervalSet,testSingleElementMinusDisjointSet/0,False,234,2,0,0,0,1,5,8,0,4,0,5,0,0,0,0,0,0,1,6,4,0,0,0,0,0,14,1,0,False
835,..\projects\antlr4-4.11.0\tool-testsuite\test\org\antlr\v4\test\tool\TestIntervalSet.java,org.antlr.v4.test.tool.TestIntervalSet,void testIntersectionWithTwoContainedElements(),"// {2,15,18} & 10..20
@Test
public void testIntersectionWithTwoContainedElements() throws Exception {
    IntervalSet s = IntervalSet.of(10, 20);
    IntervalSet s2 = IntervalSet.of(2, 2);
    s2.add(15);
    s2.add(18);
    String expecting = ""{15, 18}"";
    String result = (s.and(s2)).toString();
    assertEquals(expecting, result);
}","// {2,15,18} & 10..20
", ,"// {2,15,18} & 10..20",256,264,[0],0,[0],0,[0],0,0,0,0,testIntersectionWithTwoContainedElements(),org.antlr.v4.test.tool.TestIntervalSet,testIntersectionWithTwoContainedElements/0,False,256,2,0,0,0,1,5,9,0,4,0,5,0,0,0,0,0,1,1,6,4,0,0,0,0,0,15,1,0,False
836,..\projects\antlr4-4.11.0\tool-testsuite\test\org\antlr\v4\test\tool\TestIntervalSet.java,org.antlr.v4.test.tool.TestIntervalSet,void testMergeOfRangesAndSingleValues(),"@Test
public void testMergeOfRangesAndSingleValues() throws Exception {
    // {0..41, 42, 43..65534}
    IntervalSet s = IntervalSet.of(0, 41);
    s.add(42);
    s.add(43, 65534);
    String expecting = ""{0..65534}"";
    String result = s.toString();
    assertEquals(expecting, result);
}", ,"// {0..41, 42, 43..65534}
","// {0..41, 42, 43..65534}",301,309,[0],0,[0],0,[0],0,0,0,0,testMergeOfRangesAndSingleValues(),org.antlr.v4.test.tool.TestIntervalSet,testMergeOfRangesAndSingleValues/0,False,301,2,0,0,0,1,4,8,0,3,0,4,0,0,0,0,0,0,1,5,3,0,0,0,0,0,15,1,0,False
837,..\projects\antlr4-4.11.0\tool-testsuite\test\org\antlr\v4\test\tool\TestIntervalSet.java,org.antlr.v4.test.tool.TestIntervalSet,void testMergeWhereAdditionMergesTwoExistingIntervals(),"@Test
public void testMergeWhereAdditionMergesTwoExistingIntervals() throws Exception {
    // 42, 10, {0..9, 11..41, 43..65534}
    IntervalSet s = IntervalSet.of(42);
    s.add(10);
    s.add(0, 9);
    s.add(43, 65534);
    s.add(11, 41);
    String expecting = ""{0..65534}"";
    String result = s.toString();
    assertEquals(expecting, result);
}", ,"// 42, 10, {0..9, 11..41, 43..65534}
","// 42, 10, {0..9, 11..41, 43..65534}",320,330,[0],0,[0],0,[0],0,0,0,0,testMergeWhereAdditionMergesTwoExistingIntervals(),org.antlr.v4.test.tool.TestIntervalSet,testMergeWhereAdditionMergesTwoExistingIntervals/0,False,320,2,0,0,0,1,4,10,0,3,0,4,0,0,0,0,0,0,1,8,3,0,0,0,0,0,16,1,0,False
838,..\projects\antlr4-4.11.0\tool-testsuite\test\org\antlr\v4\test\tool\TestIntervalSet.java,org.antlr.v4.test.tool.TestIntervalSet,void testMergeWhereAdditionMergesThreeExistingIntervals(),"/**
 * This case is responsible for antlr/antlr4#153.
 * https://github.com/antlr/antlr4/issues/153
 */
@Test
public void testMergeWhereAdditionMergesThreeExistingIntervals() throws Exception {
    IntervalSet s = new IntervalSet();
    s.add(0);
    s.add(3);
    s.add(5);
    s.add(0, 7);
    String expecting = ""{0..7}"";
    String result = s.toString();
    assertEquals(expecting, result);
}","/**
 * This case is responsible for antlr/antlr4#153.
 * https://github.com/antlr/antlr4/issues/153
 */
", ,/** * This case is responsible for antlr/antlr4#153. * https://github.com/antlr/antlr4/issues/153 */,336,345,[0],0,[0],0,[0],0,0,0,0,testMergeWhereAdditionMergesThreeExistingIntervals(),org.antlr.v4.test.tool.TestIntervalSet,testMergeWhereAdditionMergesThreeExistingIntervals/0,False,336,2,0,0,0,1,3,10,0,3,0,3,0,0,0,0,0,0,1,5,3,0,0,0,0,0,22,1,0,True
839,..\projects\antlr4-4.11.0\tool-testsuite\test\org\antlr\v4\test\tool\TestIntervalSet.java,org.antlr.v4.test.tool.TestIntervalSet,void testMergeWithDoubleOverlap(),"@Test
public void testMergeWithDoubleOverlap() throws Exception {
    IntervalSet s = IntervalSet.of(1, 10);
    s.add(20, 30);
    // overlaps two!
    s.add(5, 25);
    String expecting = ""{1..30}"";
    String result = s.toString();
    assertEquals(expecting, result);
}", ,"// overlaps two!
",// overlaps two!,347,354,[0],0,[0],0,[0],0,0,0,0,testMergeWithDoubleOverlap(),org.antlr.v4.test.tool.TestIntervalSet,testMergeWithDoubleOverlap/0,False,347,2,0,0,0,1,4,8,0,3,0,4,0,0,0,0,0,0,1,6,3,0,0,0,0,0,13,1,0,False
840,..\projects\antlr4-4.11.0\tool-testsuite\test\org\antlr\v4\test\tool\TestIntervalSet.java,org.antlr.v4.test.tool.TestIntervalSet,void testNotRIntersectionNotT(),"/**
 *  The following was broken:
 * 	    {'\u0000'..'s', 'u'..'\uFFFE'} & {'\u0000'..'q', 's'..'\uFFFE'}=
 * 	    {'\u0000'..'q', 's'}!!!! broken...
 * 	 	'q' is 113 ascii
 * 	 	'u' is 117
 */
@Test
public void testNotRIntersectionNotT() throws Exception {
    IntervalSet s = IntervalSet.of(0, 's');
    s.add('u', 200);
    IntervalSet s2 = IntervalSet.of(0, 'q');
    s2.add('s', 200);
    String expecting = ""{0..113, 115, 117..200}"";
    String result = (s.and(s2)).toString();
    assertEquals(expecting, result);
}","/**
 *  The following was broken:
 * 	    {'\u0000'..'s', 'u'..'\uFFFE'} & {'\u0000'..'q', 's'..'\uFFFE'}=
 * 	    {'\u0000'..'q', 's'}!!!! broken...
 * 	 	'q' is 113 ascii
 * 	 	'u' is 117
 */
", ,"/** *  The following was broken: * 	    {'\u0000'..'s', 'u'..'\uFFFE'} & {'\u0000'..'q', 's'..'\uFFFE'}= * 	    {'\u0000'..'q', 's'}!!!! broken... * 	 	'q' is 113 ascii * 	 	'u' is 117 */",380,388,[0],0,[0],0,[0],0,0,0,0,testNotRIntersectionNotT(),org.antlr.v4.test.tool.TestIntervalSet,testNotRIntersectionNotT/0,False,380,2,0,0,0,1,5,9,0,4,0,5,0,0,0,0,0,1,1,4,4,0,0,0,0,0,19,1,0,True
841,..\projects\antlr4-4.11.0\tool-testsuite\test\org\antlr\v4\test\tool\TestLeftRecursionToolIssues.java,org.antlr.v4.test.tool.TestLeftRecursionToolIssues,void testLeftRecursiveRuleRefWithArg(),"/**
 * Reproduces https://github.com/antlr/antlr4/issues/855
 */
@Test
public void testLeftRecursiveRuleRefWithArg() throws Exception {
    String grammar = ""grammar T;\n"" + ""statement\n"" + ""locals[Scope scope]\n"" + ""    : expressionA[$scope] ';'\n"" + ""    ;\n"" + ""expressionA[Scope scope]\n"" + ""    : atom[$scope]\n"" + ""    | expressionA[$scope] '[' expressionA[$scope] ']'\n"" + ""    ;\n"" + ""atom[Scope scope]\n"" + ""    : 'dummy'\n"" + ""    ;\n"";
    String expected = ""error("" + ErrorType.NONCONFORMING_LR_RULE.code + ""): T.g4:6:0: rule expressionA is left recursive but doesn't conform to a pattern ANTLR can handle\n"";
    testErrors(new String[] { grammar, expected }, false);
}","/**
 * Reproduces https://github.com/antlr/antlr4/issues/855
 */
", ,/** * Reproduces https://github.com/antlr/antlr4/issues/855 */,46,63,[0],0,[0],0,[0],0,0,0,0,testLeftRecursiveRuleRefWithArg(),org.antlr.v4.test.tool.TestLeftRecursionToolIssues,testLeftRecursiveRuleRefWithArg/0,False,46,2,1,0,1,1,1,5,0,2,0,1,0,0,0,0,0,0,14,0,2,2,0,0,0,0,31,1,0,True
842,..\projects\antlr4-4.11.0\tool-testsuite\test\org\antlr\v4\test\tool\TestLeftRecursionToolIssues.java,org.antlr.v4.test.tool.TestLeftRecursionToolIssues,void testLeftRecursiveRuleRefWithArg2(),"/**
 * Reproduces https://github.com/antlr/antlr4/issues/855
 */
@Test
public void testLeftRecursiveRuleRefWithArg2() throws Exception {
    String grammar = ""grammar T;\n"" + ""a[int i] : 'x'\n"" + ""  | a[3] 'y'\n"" + ""  ;"";
    String expected = ""error("" + ErrorType.NONCONFORMING_LR_RULE.code + ""): T.g4:2:0: rule a is left recursive but doesn't conform to a pattern ANTLR can handle\n"";
    testErrors(new String[] { grammar, expected }, false);
}","/**
 * Reproduces https://github.com/antlr/antlr4/issues/855
 */
", ,/** * Reproduces https://github.com/antlr/antlr4/issues/855 */,66,75,[0],0,[0],0,[0],0,0,0,0,testLeftRecursiveRuleRefWithArg2(),org.antlr.v4.test.tool.TestLeftRecursionToolIssues,testLeftRecursiveRuleRefWithArg2/0,False,66,2,1,0,1,1,1,5,0,2,0,1,0,0,0,0,0,0,6,0,2,2,0,0,0,0,30,1,0,True
843,..\projects\antlr4-4.11.0\tool-testsuite\test\org\antlr\v4\test\tool\TestLeftRecursionToolIssues.java,org.antlr.v4.test.tool.TestLeftRecursionToolIssues,void testLeftRecursiveRuleRefWithArg3(),"/**
 * Reproduces https://github.com/antlr/antlr4/issues/855
 */
@Test
public void testLeftRecursiveRuleRefWithArg3() throws Exception {
    String grammar = ""grammar T;\n"" + ""a : 'x'\n"" + ""  | a[3] 'y'\n"" + ""  ;"";
    String expected = ""error("" + ErrorType.NONCONFORMING_LR_RULE.code + ""): T.g4:2:0: rule a is left recursive but doesn't conform to a pattern ANTLR can handle\n"";
    testErrors(new String[] { grammar, expected }, false);
}","/**
 * Reproduces https://github.com/antlr/antlr4/issues/855
 */
", ,/** * Reproduces https://github.com/antlr/antlr4/issues/855 */,78,87,[0],0,[0],0,[0],0,0,0,0,testLeftRecursiveRuleRefWithArg3(),org.antlr.v4.test.tool.TestLeftRecursionToolIssues,testLeftRecursiveRuleRefWithArg3/0,False,78,2,1,0,1,1,1,5,0,2,0,1,0,0,0,0,0,0,6,0,2,2,0,0,0,0,30,1,0,True
844,..\projects\antlr4-4.11.0\tool-testsuite\test\org\antlr\v4\test\tool\TestLeftRecursionToolIssues.java,org.antlr.v4.test.tool.TestLeftRecursionToolIssues,void testIsolatedLeftRecursiveRuleRef(),"/**
 * Reproduces https://github.com/antlr/antlr4/issues/822
 */
@Test
public void testIsolatedLeftRecursiveRuleRef() throws Exception {
    String grammar = ""grammar T;\n"" + ""a : a | b ;\n"" + ""b : 'B' ;\n"";
    String expected = ""error("" + ErrorType.NONCONFORMING_LR_RULE.code + ""): T.g4:2:0: rule a is left recursive but doesn't conform to a pattern ANTLR can handle\n"";
    testErrors(new String[] { grammar, expected }, false);
}","/**
 * Reproduces https://github.com/antlr/antlr4/issues/822
 */
", ,/** * Reproduces https://github.com/antlr/antlr4/issues/822 */,90,98,[0],0,[0],0,[0],0,0,0,0,testIsolatedLeftRecursiveRuleRef(),org.antlr.v4.test.tool.TestLeftRecursionToolIssues,testIsolatedLeftRecursiveRuleRef/0,False,90,2,1,0,1,1,1,5,0,2,0,1,0,0,0,0,0,0,5,0,2,2,0,0,0,0,30,1,0,True
845,..\projects\antlr4-4.11.0\tool-testsuite\test\org\antlr\v4\test\tool\TestLeftRecursionToolIssues.java,org.antlr.v4.test.tool.TestLeftRecursionToolIssues,void testArgOnPrimaryRuleInLeftRecursiveRule(),"/**
 * Reproduces https://github.com/antlr/antlr4/issues/773
 */
@Test
public void testArgOnPrimaryRuleInLeftRecursiveRule() throws Exception {
    String grammar = ""grammar T;\n"" + ""val: dval[1]\n"" + ""   | val '*' val\n"" + ""   ;\n"" + ""dval[int  x]: '.';\n"";
    // dval[1] should not be error
    String expected = """";
    testErrors(new String[] { grammar, expected }, false);
}","/**
 * Reproduces https://github.com/antlr/antlr4/issues/773
 */
","// dval[1] should not be error
",/** * Reproduces https://github.com/antlr/antlr4/issues/773 */[[SEP]]// dval[1] should not be error,101,110,[0],0,[0],0,"[0, 0]",0,0,0,0,testArgOnPrimaryRuleInLeftRecursiveRule(),org.antlr.v4.test.tool.TestLeftRecursionToolIssues,testArgOnPrimaryRuleInLeftRecursiveRule/0,False,101,2,1,0,1,1,1,5,0,2,0,1,0,0,0,0,0,0,6,0,2,1,0,0,0,0,18,1,0,True
846,..\projects\antlr4-4.11.0\tool-testsuite\test\org\antlr\v4\test\tool\TestLexerActions.java,org.antlr.v4.test.tool.TestLexerActions,void testEvalMultipleActions(),"/**
 * This is a regressing test for antlr/antlr4#469 ""Not all internal lexer
 * rule actions are executed"".
 * https://github.com/antlr/antlr4/issues/469
 */
@Test
public void testEvalMultipleActions() throws Exception {
    String grammar = ""lexer grammar L;\n"" + ""\n"" + ""@lexer::members\n"" + ""{\n"" + ""class Marker\n"" + ""{\n"" + ""   Marker (Lexer lexer) { this.lexer = lexer; }\n"" + ""\n"" + ""   public String getText ()\n"" + ""   {\n"" + ""      return lexer._input.getText (new Interval (start_index, stop_index));\n"" + ""   }\n"" + ""\n"" + ""   public void start ()  { start_index = lexer._input.index (); outStream.println (\""Start:\"" + start_index);}\n"" + ""   public void stop () { stop_index = lexer._input.index (); outStream.println (\""Stop:\"" + stop_index);}\n"" + ""\n"" + ""   private int start_index = 0;\n"" + ""   private int stop_index = 0;\n"" + ""   private Lexer lexer;\n"" + ""}\n"" + ""\n"" + ""Marker m_name = new Marker (this);\n"" + ""}\n"" + ""\n"" + ""HELLO: 'hello' WS { m_name.start (); } NAME { m_name.stop (); } '\\n' { outStream.println (\""Hello: \"" + m_name.getText ()); };\n"" + ""NAME: ('a'..'z' | 'A'..'Z')+ ('\\n')?;\n"" + ""\n"" + ""fragment WS: [ \\r\\t\\n]+ ;\n"";
    ExecutedState executedState = execLexer(""L.g4"", grammar, ""L"", ""hello Steve\n"");
    String expecting = ""Start:6\n"" + ""Stop:11\n"" + ""Hello: Steve\n"" + ""\n"" + ""[@0,0:11='hello Steve\\n',<1>,1:0]\n"" + ""[@1,12:11='<EOF>',<-1>,2:0]\n"";
    assertEquals(expecting, executedState.output);
}","/**
 * This is a regressing test for antlr/antlr4#469 ""Not all internal lexer
 * rule actions are executed"".
 * https://github.com/antlr/antlr4/issues/469
 */
", ,"/** * This is a regressing test for antlr/antlr4#469 ""Not all internal lexer * rule actions are executed"". * https://github.com/antlr/antlr4/issues/469 */",53,92,[0],0,[0],0,[0],0,0,0,0,testEvalMultipleActions(),org.antlr.v4.test.tool.TestLexerActions,testEvalMultipleActions/0,False,53,3,1,0,1,1,2,6,0,3,0,2,0,0,0,0,0,0,37,0,3,2,0,0,0,0,43,1,0,True
847,..\projects\antlr4-4.11.0\tool-testsuite\test\org\antlr\v4\test\tool\TestLexerActions.java,org.antlr.v4.test.tool.TestLexerActions,void testLexerPushPopModeAction(),"@Test
public void testLexerPushPopModeAction() throws Exception {
    String grammar = ""lexer grammar L;\n"" + ""STRING_START : '\""' -> pushMode(STRING_MODE), more ;\n"" + ""WS : (' '|'\\n') -> skip ;\n"" + ""mode STRING_MODE;\n"" + // token type 2
    ""STRING : '\""' -> popMode ;\n"" + ""ANY : . -> more ;\n"";
    ExecutedState executedState = execLexer(""L.g4"", grammar, ""L"", ""\""abc\"" \""ab\"""");
    String expecting = ""[@0,0:4='\""abc\""',<2>,1:0]\n"" + ""[@1,6:9='\""ab\""',<2>,1:6]\n"" + ""[@2,10:9='<EOF>',<-1>,1:10]\n"";
    assertEquals(expecting, executedState.output);
}", ,"// token type 2
",// token type 2,220,234,[0],0,[0],0,[0],0,0,0,0,testLexerPushPopModeAction(),org.antlr.v4.test.tool.TestLexerActions,testLexerPushPopModeAction/0,False,220,3,1,0,1,1,2,6,0,3,0,2,0,0,0,0,0,0,12,0,3,2,0,0,0,0,31,1,0,False
848,..\projects\antlr4-4.11.0\tool-testsuite\test\org\antlr\v4\test\tool\TestLexerActions.java,org.antlr.v4.test.tool.TestLexerActions,void testLexerModeAction(),"@Test
public void testLexerModeAction() throws Exception {
    String grammar = ""lexer grammar L;\n"" + ""STRING_START : '\""' -> mode(STRING_MODE), more ;\n"" + ""WS : (' '|'\\n') -> skip ;\n"" + ""mode STRING_MODE;\n"" + // ttype 2 since '""' ambiguity
    ""STRING : '\""' -> mode(DEFAULT_MODE) ;\n"" + ""ANY : . -> more ;\n"";
    ExecutedState executedState = execLexer(""L.g4"", grammar, ""L"", ""\""abc\"" \""ab\"""");
    String expecting = ""[@0,0:4='\""abc\""',<2>,1:0]\n"" + ""[@1,6:9='\""ab\""',<2>,1:6]\n"" + ""[@2,10:9='<EOF>',<-1>,1:10]\n"";
    assertEquals(expecting, executedState.output);
}", ,"// ttype 2 since '""' ambiguity
","// ttype 2 since '""' ambiguity",236,250,[0],0,[0],0,[0],0,0,0,0,testLexerModeAction(),org.antlr.v4.test.tool.TestLexerActions,testLexerModeAction/0,False,236,3,1,0,1,1,2,6,0,3,0,2,0,0,0,0,0,0,12,0,3,2,0,0,0,0,31,1,0,False
849,..\projects\antlr4-4.11.0\tool-testsuite\test\org\antlr\v4\test\tool\TestLexerActions.java,org.antlr.v4.test.tool.TestLexerActions,void testFailingPredicateEvalIsNotCached(),"// ----- PREDICATES --------------------------------------------------------
/**
 * This is a regression test for antlr/antlr4#398 ""Lexer: literal matches
 * while negated char set fail to match""
 * https://github.com/antlr/antlr4/issues/398
 */
@Test
public void testFailingPredicateEvalIsNotCached() {
    String grammar = ""lexer grammar TestLexer;\n"" + ""\n"" + ""fragment WS: [ \\t]+;\n"" + ""fragment EOL: '\\r'? '\\n';\n"" + ""\n"" + ""LINE: WS? ~[\\r\\n]* EOL { !getText().trim().startsWith(\""Item:\"") }?;\n"" + ""ITEM: WS? 'Item:' -> pushMode(ITEM_HEADING_MODE);\n"" + ""\n"" + ""mode ITEM_HEADING_MODE;\n"" + ""\n"" + ""NAME: ~[\\r\\n]+;\n"" + ""SECTION_HEADING_END: EOL -> popMode;\n"";
    String input = ""A line here.\n"" + ""Item: name of item\n"" + ""Another line.\n"" + ""More line.\n"";
    ExecutedState executedState = execLexer(""TestLexer.g4"", grammar, ""TestLexer"", input);
    String expecting = ""[@0,0:12='A line here.\\n',<1>,1:0]\n"" + ""[@1,13:17='Item:',<2>,2:0]\n"" + ""[@2,18:30=' name of item',<3>,2:5]\n"" + ""[@3,31:31='\\n',<4>,2:18]\n"" + ""[@4,32:45='Another line.\\n',<1>,3:0]\n"" + ""[@5,46:56='More line.\\n',<1>,4:0]\n"" + ""[@6,57:56='<EOF>',<-1>,5:0]\n"";
    assertEquals(expecting, executedState.output);
}","/**
 * This is a regression test for antlr/antlr4#398 ""Lexer: literal matches
 * while negated char set fail to match""
 * https://github.com/antlr/antlr4/issues/398
 */
", ,"// ----- PREDICATES --------------------------------------------------------[[SEP]]/** * This is a regression test for antlr/antlr4#398 ""Lexer: literal matches * while negated char set fail to match"" * https://github.com/antlr/antlr4/issues/398 */",259,289,[0],0,[0],0,"[0, 0]",0,0,0,0,testFailingPredicateEvalIsNotCached(),org.antlr.v4.test.tool.TestLexerActions,testFailingPredicateEvalIsNotCached/0,False,260,3,1,0,1,1,2,7,0,4,0,2,0,0,0,0,0,0,25,0,4,3,0,0,0,0,51,1,0,True
850,..\projects\antlr4-4.11.0\tool-testsuite\test\org\antlr\v4\test\tool\TestLookaheadTrees.java,org.antlr.v4.test.tool.TestLookaheadTrees,void testAlts2(),"@Test
public void testAlts2() throws Exception {
    LexerGrammar lg = new LexerGrammar(lexerText);
    Grammar g = new Grammar(""parser grammar T;\n"" + ""s : e? SEMI EOF ;\n"" + ""e : ID\n"" + ""  | e BANG"" + ""  ;\n"", lg);
    String startRuleName = ""s"";
    // (...)* in e.
    int decision = 1;
    testLookaheadTrees(lg, g, ""a;"", startRuleName, decision, new String[] { // Decision for alt 1 is error as no ! char, but alt 2 (exit) is good.
    ""(e:2 (e:1 a) <error ;>)"", // root s:1 is included to show ';' node
    ""(s:1 (e:1 a) ; <EOF>)"" });
}", ,"// (...)* in e.
[[SEP]]// Decision for alt 1 is error as no ! char, but alt 2 (exit) is good.
[[SEP]]// root s:1 is included to show ';' node
","// (...)* in e.[[SEP]]// Decision for alt 1 is error as no ! char, but alt 2 (exit) is good.[[SEP]]// root s:1 is included to show ';' node",58,75,[0],0,"[0, 0, 0]",0,"[0, 0, 0]",0,0,0,0,testAlts2(),org.antlr.v4.test.tool.TestLookaheadTrees,testAlts2/0,False,59,4,3,0,3,1,1,7,0,4,0,1,1,1,0,0,0,0,9,1,4,1,0,0,0,0,25,1,0,False
851,..\projects\antlr4-4.11.0\tool-testsuite\test\org\antlr\v4\test\tool\TestLookaheadTrees.java,org.antlr.v4.test.tool.TestLookaheadTrees,void testCallLeftRecursiveRule(),"@Test
public void testCallLeftRecursiveRule() throws Exception {
    LexerGrammar lg = new LexerGrammar(lexerText);
    Grammar g = new Grammar(""parser grammar T;\n"" + ""s : a BANG EOF;\n"" + ""a : e SEMI \n"" + ""  | ID SEMI \n"" + ""  ;"" + ""e : e MULT e\n"" + ""  | e PLUS e\n"" + ""  | e DOT e\n"" + ""  | ID\n"" + ""  | INT\n"" + ""  ;\n"", lg);
    int decision = 0;
    testLookaheadTrees(lg, g, ""x;!"", ""s"", decision, new String[] { ""(a:1 (e:4 x) ;)"", // shouldn't include BANG, EOF
    ""(a:2 x ;)"" });
    // (...)* in e
    decision = 2;
    testLookaheadTrees(lg, g, ""x+1;!"", ""s"", decision, new String[] { ""(e:1 (e:4 x) <error +>)"", ""(e:2 (e:4 x) + (e:5 1))"", ""(e:3 (e:4 x) <error +>)"" });
}", ,"// shouldn't include BANG, EOF
[[SEP]]// (...)* in e
","// shouldn't include BANG, EOF[[SEP]]// (...)* in e",93,119,[0],0,"[0, 0]",0,"[0, 0]",0,0,0,0,testCallLeftRecursiveRule(),org.antlr.v4.test.tool.TestLookaheadTrees,testCallLeftRecursiveRule/0,False,94,4,3,0,3,1,1,8,0,3,0,1,1,1,0,0,0,0,20,2,4,1,0,0,0,0,34,1,0,False
852,..\projects\antlr4-4.11.0\tool-testsuite\test\org\antlr\v4\test\tool\TestParseTreeMatcher.java,org.antlr.v4.test.tool.TestParseTreeMatcher,void testIDNodeWithMultipleLabelMatches(),"@Test
public void testIDNodeWithMultipleLabelMatches() throws Exception {
    String grammar = ""grammar X7;\n"" + ""s : ID ID ID ';' ;\n"" + ""ID : [a-z]+ ;\n"" + ""WS : [ \\r\\n\\t]+ -> skip ;\n"";
    String input = ""x y z;"";
    String pattern = ""<a:ID> <b:ID> <a:ID>;"";
    ParseTreeMatch m = checkPatternMatch(grammar, ""s"", input, pattern, ""X7"");
    assertEquals(""{ID=[x, y, z], a=[x, z], b=[y]}"", m.getLabels().toString());
    // get first
    assertNotNull(m.get(""a""));
    assertNotNull(m.get(""b""));
    assertNotNull(m.get(""ID""));
    assertEquals(""z"", m.get(""a"").getText());
    assertEquals(""y"", m.get(""b"").getText());
    // get last
    assertEquals(""z"", m.get(""ID"").getText());
    assertEquals(""[x, z]"", m.getAll(""a"").toString());
    assertEquals(""[y]"", m.getAll(""b"").toString());
    // ordered
    assertEquals(""[x, y, z]"", m.getAll(""ID"").toString());
    // whitespace stripped by lexer
    assertEquals(""xyz;"", m.getTree().getText());
    assertNull(m.get(""undefined""));
    assertEquals(""[]"", m.getAll(""undefined"").toString());
}", ,"// get first
[[SEP]]// get last
[[SEP]]// ordered
[[SEP]]// whitespace stripped by lexer
",// get first[[SEP]]// get last[[SEP]]// ordered[[SEP]]// whitespace stripped by lexer,265,290,[0],0,"[0, 0, 0, 0]",0,"[0, 0, 0, 0]",0,0,0,0,testIDNodeWithMultipleLabelMatches(),org.antlr.v4.test.tool.TestParseTreeMatcher,testIDNodeWithMultipleLabelMatches/0,False,265,3,1,0,1,1,10,19,0,4,0,10,1,2,0,0,0,0,28,0,4,1,0,0,0,0,28,1,0,False
853,..\projects\antlr4-4.11.0\tool-testsuite\test\org\antlr\v4\test\tool\TestParseTreeMatcher.java,org.antlr.v4.test.tool.TestParseTreeMatcher,void testTokenTextMatch(),"@Test
public void testTokenTextMatch() throws Exception {
    String grammar = ""grammar X4;\n"" + ""s : ID '=' expr ';' ;\n"" + ""expr : ID | INT ;\n"" + ""ID : [a-z]+ ;\n"" + ""INT : [0-9]+ ;\n"" + ""WS : [ \\r\\n\\t]+ -> skip ;\n"";
    String input = ""x = 0;"";
    String pattern = ""<ID> = 1;"";
    // 0!=1
    boolean invertMatch = true;
    checkPatternMatch(grammar, ""s"", input, pattern, ""X4"", invertMatch);
    input = ""x = 0;"";
    pattern = ""<ID> = 0;"";
    invertMatch = false;
    checkPatternMatch(grammar, ""s"", input, pattern, ""X4"", invertMatch);
    input = ""x = 0;"";
    pattern = ""x = 0;"";
    invertMatch = false;
    checkPatternMatch(grammar, ""s"", input, pattern, ""X4"", invertMatch);
    input = ""x = 0;"";
    pattern = ""y = 0;"";
    invertMatch = true;
    checkPatternMatch(grammar, ""s"", input, pattern, ""X4"", invertMatch);
}", ,"// 0!=1
",// 0!=1,306,334,[0],0,[0],0,[0],0,0,0,0,testTokenTextMatch(),org.antlr.v4.test.tool.TestParseTreeMatcher,testTokenTextMatch/0,False,306,2,1,0,1,1,1,19,0,4,0,1,1,1,0,0,0,0,22,0,13,1,0,0,0,0,20,1,0,False
854,..\projects\antlr4-4.11.0\tool-testsuite\test\org\antlr\v4\test\tool\TestParseTreeMatcher.java,org.antlr.v4.test.tool.TestParseTreeMatcher,void testAssign(),"@Test
public void testAssign() throws Exception {
    String grammar = ""grammar X5;\n"" + ""s   : expr ';'\n"" + // ""    | 'return' expr ';'\n"" +
    ""    ;\n"" + ""expr: expr '.' ID\n"" + ""    | expr '*' expr\n"" + ""    | expr '=' expr\n"" + ""    | ID\n"" + ""    | INT\n"" + ""    ;\n"" + ""ID : [a-z]+ ;\n"" + ""INT : [0-9]+ ;\n"" + ""WS : [ \\r\\n\\t]+ -> skip ;\n"";
    String input = ""x = 99;"";
    String pattern = ""<ID> = <expr>;"";
    checkPatternMatch(grammar, ""s"", input, pattern, ""X5"");
}", ,"// ""    | 'return' expr ';'\n"" +
","// ""    | 'return' expr ';'\n"" +",336,355,[0],0,[0],0,[0],0,0,0,0,testAssign(),org.antlr.v4.test.tool.TestParseTreeMatcher,testAssign/0,False,336,2,1,0,1,1,1,6,0,3,0,1,1,2,0,0,0,0,16,0,3,1,0,0,0,0,12,1,0,False
855,..\projects\antlr4-4.11.0\tool-testsuite\test\org\antlr\v4\test\tool\TestParserExec.java,org.antlr.v4.test.tool.TestParserExec,void testStartRuleWithoutEOF(),"/**
 * This is a regression test for antlr/antlr4#118.
 * https://github.com/antlr/antlr4/issues/118
 */
@Disabled(""Performance impact of passing this test may not be worthwhile"")
// TODO: port to test framework (not ported because test currently fails)
@Test
public void testStartRuleWithoutEOF() {
    String grammar = ""grammar T;\n"" + ""s @after {dumpDFA();}\n"" + ""  : ID | ID INT ID ;\n"" + ""ID : 'a'..'z'+ ;\n"" + ""INT : '0'..'9'+ ;\n"" + ""WS : (' '|'\\t'|'\\n')+ -> skip ;\n"";
    ExecutedState executedState = execParser(""T.g4"", grammar, ""TParser"", ""TLexer"", ""s"", ""abc 34"", true);
    String expecting = ""Decision 0:\n"" + ""s0-ID->s1\n"" + ""s1-INT->s2\n"" + // Must point at accept state
    ""s2-EOF->:s3=>1\n"";
    assertEquals(expecting, executedState.output);
    assertEquals("""", executedState.errors);
}","/**
 * This is a regression test for antlr/antlr4#118.
 * https://github.com/antlr/antlr4/issues/118
 */
","// TODO: port to test framework (not ported because test currently fails)
[[SEP]]// Must point at accept state
",/** * This is a regression test for antlr/antlr4#118. * https://github.com/antlr/antlr4/issues/118 */[[SEP]]// TODO: port to test framework (not ported because test currently fails)[[SEP]]// Must point at accept state,55,74,[0],0,"[1, 0]",1,"[0, 1, 0]",1,1,1,1,testStartRuleWithoutEOF(),org.antlr.v4.test.tool.TestParserExec,testStartRuleWithoutEOF/0,False,57,4,1,0,1,1,2,7,0,3,0,2,0,0,0,0,0,0,17,0,3,2,0,0,0,0,36,1,0,True
856,..\projects\antlr4-4.11.0\tool-testsuite\test\org\antlr\v4\test\tool\TestParserExec.java,org.antlr.v4.test.tool.TestParserExec,void testFailedPredicateExceptionState(),"/**
 * This is a regression test for antlr/antlr4#588 ""ClassCastException during
 * semantic predicate handling"".
 * https://github.com/antlr/antlr4/issues/588
 */
// TODO: port to test framework (can we simplify the Psl grammar?)
@Test
public void testFailedPredicateExceptionState() throws Exception {
    String grammar = load(""Psl.g4"");
    ExecutedState executedState = execParser(""Psl.g4"", grammar, ""PslParser"", ""PslLexer"", ""floating_constant"", "" . 234"", false);
    assertEquals("""", executedState.output);
    assertEquals(""line 1:6 rule floating_constant DEC:A floating-point constant cannot have internal white space\n"", executedState.errors);
}","// TODO: port to test framework (can we simplify the Psl grammar?)
", ,"/** * This is a regression test for antlr/antlr4#588 ""ClassCastException during * semantic predicate handling"". * https://github.com/antlr/antlr4/issues/588 */[[SEP]]// TODO: port to test framework (can we simplify the Psl grammar?)",82,88,[1],1,[0],0,"[0, 1]",1,1,1,1,testFailedPredicateExceptionState(),org.antlr.v4.test.tool.TestParserExec,testFailedPredicateExceptionState/0,False,82,3,2,0,2,1,3,6,0,2,0,3,0,0,0,0,0,0,8,0,2,0,0,0,0,0,31,1,0,True
857,..\projects\antlr4-4.11.0\tool-testsuite\test\org\antlr\v4\test\tool\TestParserExec.java,org.antlr.v4.test.tool.TestParserExec,void testAlternateQuotes(Path),"/**
 * This is a regression test for antlr/antlr4#563 ""Inconsistent token
 * handling in ANTLR4"".
 * https://github.com/antlr/antlr4/issues/563
 */
// TODO: port to test framework (missing templates)
@Test
public void testAlternateQuotes(@TempDir Path tempDir) {
    String lexerGrammar = ""lexer grammar ModeTagsLexer;\n"" + ""\n"" + ""// Default mode rules (the SEA)\n"" + ""OPEN  : '«'     -> mode(ISLAND) ;       // switch to ISLAND mode\n"" + ""TEXT  : ~'«'+ ;                         // clump all text together\n"" + ""\n"" + ""mode ISLAND;\n"" + ""CLOSE : '»'     -> mode(DEFAULT_MODE) ; // back to SEA mode \n"" + ""SLASH : '/' ;\n"" + ""ID    : [a-zA-Z]+ ;                     // match/send ID in tag to parser\n"";
    String parserGrammar = ""parser grammar ModeTagsParser;\n"" + ""\n"" + ""options { tokenVocab=ModeTagsLexer; } // use tokens from ModeTagsLexer.g4\n"" + ""\n"" + ""file: (tag | TEXT)* ;\n"" + ""\n"" + ""tag : '«' ID '»'\n"" + ""    | '«' '/' ID '»'\n"" + ""    ;"";
    execLexer(""ModeTagsLexer.g4"", lexerGrammar, ""ModeTagsLexer"", """", tempDir, true);
    ExecutedState executedState = execParser(""ModeTagsParser.g4"", parserGrammar, ""ModeTagsParser"", ""ModeTagsLexer"", ""file"", """", false, tempDir);
    assertEquals("""", executedState.output);
    assertEquals("""", executedState.errors);
}","// TODO: port to test framework (missing templates)
", ,"/** * This is a regression test for antlr/antlr4#563 ""Inconsistent token * handling in ANTLR4"". * https://github.com/antlr/antlr4/issues/563 */[[SEP]]// TODO: port to test framework (missing templates)[[SEP]]// Default mode rules (the SEA)\n"" + ""OPEN  : '«'     -> mode(ISLAND) ;       // switch to ISLAND mode\n"" + ""TEXT  : ~'«'+ ;                         // clump all text together\n"" + ""\n"" + ""mode ISLAND;\n"" + ""CLOSE : '»'     -> mode(DEFAULT_MODE) ; // back to SEA mode \n"" + ""SLASH : '/' ;\n"" + ""ID    : [a-zA-Z]+ ;                     // match/send ID in tag to parser\n"";[[SEP]]// use tokens from ModeTagsLexer.g4\n"" + ""\n"" + ""file: (tag | TEXT)* ;\n"" + ""\n"" + ""tag : '«' ID '»'\n"" + ""    | '«' '/' ID '»'\n"" + ""    ;"";",96,127,[1],1,[0],0,"[0, 1, 0, 0]",1,1,1,1,testAlternateQuotes(Path),org.antlr.v4.test.tool.TestParserExec,testAlternateQuotes/1[java.nio.file.Path],False,96,4,2,0,2,1,3,8,0,3,1,3,0,0,0,0,0,0,29,0,3,2,0,0,0,0,61,1,0,True
858,..\projects\antlr4-4.11.0\tool-testsuite\test\org\antlr\v4\test\tool\TestParserExec.java,org.antlr.v4.test.tool.TestParserExec,void testAttributeValueInitialization(),"/**
 * This is a regression test for antlr/antlr4#672 ""Initialization failed in
 * locals"".
 * https://github.com/antlr/antlr4/issues/672
 */
// TODO: port to test framework (missing templates)
@Test
public void testAttributeValueInitialization() {
    String grammar = ""grammar Data; \n"" + ""\n"" + ""file : group+ EOF; \n"" + ""\n"" + ""group: INT sequence {outStream.println($sequence.values.size());} ; \n"" + ""\n"" + ""sequence returns [List<Integer> values = new ArrayList<Integer>()] \n"" + ""  locals[List<Integer> localValues = new ArrayList<Integer>()]\n"" + ""         : (INT {$localValues.add($INT.int);})* {$values.addAll($localValues);}\n"" + ""; \n"" + ""\n"" + ""INT : [0-9]+ ; // match integers \n"" + ""WS : [ \\t\\n\\r]+ -> skip ; // toss out all whitespace\n"";
    String input = ""2 9 10 3 1 2 3"";
    ExecutedState executedState = execParser(""Data.g4"", grammar, ""DataParser"", ""DataLexer"", ""file"", input, false);
    assertEquals(""6\n"", executedState.output);
    assertEquals("""", executedState.errors);
}","// TODO: port to test framework (missing templates)
", ,"/** * This is a regression test for antlr/antlr4#672 ""Initialization failed in * locals"". * https://github.com/antlr/antlr4/issues/672 */[[SEP]]// TODO: port to test framework (missing templates)[[SEP]]// match integers \n"" + ""WS : [ \\t\\n\\r]+ -> skip ; // toss out all whitespace\n"";",135,156,[1],1,[0],0,"[0, 1, 0]",1,1,1,1,testAttributeValueInitialization(),org.antlr.v4.test.tool.TestParserExec,testAttributeValueInitialization/0,False,135,3,1,0,1,1,2,7,0,3,0,2,0,0,0,0,0,0,20,0,3,1,0,0,0,0,41,1,0,True
859,..\projects\antlr4-4.11.0\tool-testsuite\test\org\antlr\v4\test\tool\TestParserInterpreter.java,org.antlr.v4.test.tool.TestParserInterpreter,void testEmptyRuleAfterEOFInChild(),"@Test
public void testEmptyRuleAfterEOFInChild() throws Exception {
    LexerGrammar lg = new LexerGrammar(""lexer grammar L;\n"" + ""A : 'a' ;\n"");
    Grammar g = new Grammar(""parser grammar T;\n"" + ""s : x y;\n"" + ""x : A EOF ;\n"" + ""y : ;"", lg);
    ParseTree t = testInterp(lg, g, ""s"", ""a"", ""(s (x a <EOF>) y)"");
    // s
    assertEquals(""0..1"", t.getSourceInterval().toString());
    // x
    assertEquals(""0..1"", t.getChild(0).getSourceInterval().toString());
    // unspecified		assertEquals(""1..0"", t.getChild(1).getSourceInterval().toString()); // y
}", ,"// unspecified		assertEquals(""1..0"", t.getChild(1).getSourceInterval().toString()); // y
[[SEP]]// s
[[SEP]]// x
","// s[[SEP]]// x[[SEP]]// unspecified		assertEquals(""1..0"", t.getChild(1).getSourceInterval().toString()); // y",76,91,[0],0,"[0, 0, 0]",0,"[0, 0, 0]",0,0,0,0,testEmptyRuleAfterEOFInChild(),org.antlr.v4.test.tool.TestParserInterpreter,testEmptyRuleAfterEOFInChild/0,False,76,5,3,0,3,1,5,7,0,3,0,5,1,1,0,0,0,0,11,1,3,2,0,0,0,0,28,1,0,False
860,..\projects\antlr4-4.11.0\tool-testsuite\test\org\antlr\v4\test\tool\TestParserInterpreter.java,org.antlr.v4.test.tool.TestParserInterpreter,void testEmptyRuleAfterJustEOFInChild(),"@Test
public void testEmptyRuleAfterJustEOFInChild() throws Exception {
    LexerGrammar lg = new LexerGrammar(""lexer grammar L;\n"" + ""A : 'a' ;\n"");
    Grammar g = new Grammar(""parser grammar T;\n"" + ""s : x y;\n"" + ""x : EOF ;\n"" + ""y : ;"", lg);
    ParseTree t = testInterp(lg, g, ""s"", """", ""(s (x <EOF>) y)"");
    // s
    assertEquals(""0..0"", t.getSourceInterval().toString());
    // x
    assertEquals(""0..0"", t.getChild(0).getSourceInterval().toString());
    // this next one is a weird special case where somebody tries to match beyond in the file
    // unspecified		assertEquals(""0..-1"", t.getChild(1).getSourceInterval().toString()); // y
}", ,"// this next one is a weird special case where somebody tries to match beyond in the file
[[SEP]]// unspecified		assertEquals(""0..-1"", t.getChild(1).getSourceInterval().toString()); // y
[[SEP]]// s
[[SEP]]// x
","// s[[SEP]]// x[[SEP]]// this next one is a weird special case where somebody tries to match beyond in the file// unspecified		assertEquals(""0..-1"", t.getChild(1).getSourceInterval().toString()); // y",93,109,[0],0,"[0, 0, 0, 0]",0,"[0, 0, 0]",0,0,0,0,testEmptyRuleAfterJustEOFInChild(),org.antlr.v4.test.tool.TestParserInterpreter,testEmptyRuleAfterJustEOFInChild/0,False,93,5,3,0,3,1,5,7,0,3,0,5,1,1,0,0,0,0,11,1,3,2,0,0,0,0,27,1,0,False
861,..\projects\antlr4-4.11.0\tool-testsuite\test\org\antlr\v4\test\tool\TestParserInterpreter.java,org.antlr.v4.test.tool.TestParserInterpreter,void testEmptyInput(),"@Test
public void testEmptyInput() throws Exception {
    LexerGrammar lg = new LexerGrammar(""lexer grammar L;\n"" + ""A : 'a' ;\n"");
    Grammar g = new Grammar(""parser grammar T;\n"" + ""s : x EOF ;\n"" + ""x : ;\n"", lg);
    ParseTree t = testInterp(lg, g, ""s"", """", ""(s x <EOF>)"");
    // s
    assertEquals(""0..0"", t.getSourceInterval().toString());
    // x
    assertEquals(""0..-1"", t.getChild(0).getSourceInterval().toString());
}", ,"// s
[[SEP]]// x
",// s[[SEP]]// x,111,124,[0],0,"[0, 0]",0,"[0, 0]",0,0,0,0,testEmptyInput(),org.antlr.v4.test.tool.TestParserInterpreter,testEmptyInput/0,False,111,5,3,0,3,1,5,7,0,3,0,5,1,1,0,0,0,0,10,1,3,2,0,0,0,0,22,1,0,False
862,..\projects\antlr4-4.11.0\tool-testsuite\test\org\antlr\v4\test\tool\TestParserInterpreter.java,org.antlr.v4.test.tool.TestParserInterpreter,void testEmptyInputWithCallsAfter(),"@Test
public void testEmptyInputWithCallsAfter() throws Exception {
    LexerGrammar lg = new LexerGrammar(""lexer grammar L;\n"" + ""A : 'a' ;\n"");
    Grammar g = new Grammar(""parser grammar T;\n"" + ""s : x y ;\n"" + ""x : EOF ;\n"" + ""y : z ;\n"" + ""z : ;"", lg);
    ParseTree t = testInterp(lg, g, ""s"", """", ""(s (x <EOF>) (y z))"");
    // s
    assertEquals(""0..0"", t.getSourceInterval().toString());
    // x
    assertEquals(""0..0"", t.getChild(0).getSourceInterval().toString());
    // unspecified		assertEquals(""0..-1"", t.getChild(1).getSourceInterval().toString()); // x
}", ,"// unspecified		assertEquals(""0..-1"", t.getChild(1).getSourceInterval().toString()); // x
[[SEP]]// s
[[SEP]]// x
","// s[[SEP]]// x[[SEP]]// unspecified		assertEquals(""0..-1"", t.getChild(1).getSourceInterval().toString()); // x",126,142,[0],0,"[0, 0, 0]",0,"[0, 0, 0]",0,0,0,0,testEmptyInputWithCallsAfter(),org.antlr.v4.test.tool.TestParserInterpreter,testEmptyInputWithCallsAfter/0,False,126,5,3,0,3,1,5,7,0,3,0,5,1,1,0,0,0,0,12,1,3,2,0,0,0,0,27,1,0,False
863,..\projects\antlr4-4.11.0\tool-testsuite\test\org\antlr\v4\test\tool\TestParserInterpreter.java,org.antlr.v4.test.tool.TestParserInterpreter,void testEmptyFirstRule(),"@Test
public void testEmptyFirstRule() throws Exception {
    LexerGrammar lg = new LexerGrammar(""lexer grammar L;\n"" + ""A : 'a' ;\n"");
    Grammar g = new Grammar(""parser grammar T;\n"" + ""s : x A ;\n"" + ""x : ;\n"", lg);
    ParseTree t = testInterp(lg, g, ""s"", ""a"", ""(s x a)"");
    // s
    assertEquals(""0..0"", t.getSourceInterval().toString());
    // This gets an empty interval because the stop token is null for x
    // x
    assertEquals(""0..-1"", t.getChild(0).getSourceInterval().toString());
}", ,"// This gets an empty interval because the stop token is null for x
[[SEP]]// s
[[SEP]]// x
",// s[[SEP]]// This gets an empty interval because the stop token is null for x// x,144,158,[0],0,"[0, 0, 0]",0,"[0, 0]",0,0,0,0,testEmptyFirstRule(),org.antlr.v4.test.tool.TestParserInterpreter,testEmptyFirstRule/0,False,144,5,3,0,3,1,5,7,0,3,0,5,1,1,0,0,0,0,10,1,3,2,0,0,0,0,22,1,0,False
864,..\projects\antlr4-4.11.0\tool-testsuite\test\org\antlr\v4\test\tool\TestParserInterpreter.java,org.antlr.v4.test.tool.TestParserInterpreter,void testLeftRecursiveStartRule(),"/**
 * This is a regression test for antlr/antlr4#461.
 * https://github.com/antlr/antlr4/issues/461
 */
@Test
public void testLeftRecursiveStartRule() throws Exception {
    LexerGrammar lg = new LexerGrammar(""lexer grammar L;\n"" + ""A : 'a' ;\n"" + ""B : 'b' ;\n"" + ""C : 'c' ;\n"" + ""PLUS : '+' ;\n"" + ""MULT : '*' ;\n"");
    Grammar g = new Grammar(""parser grammar T;\n"" + ""s : e ;\n"" + ""e : e MULT e\n"" + ""  | e PLUS e\n"" + ""  | A\n"" + ""  ;\n"", lg);
    testInterp(lg, g, ""e"", ""a"", ""(e a)"");
    testInterp(lg, g, ""e"", ""a+a"", ""(e (e a) + (e a))"");
    testInterp(lg, g, ""e"", ""a*a"", ""(e (e a) * (e a))"");
    testInterp(lg, g, ""e"", ""a+a+a"", ""(e (e (e a) + (e a)) + (e a))"");
    testInterp(lg, g, ""e"", ""a*a+a"", ""(e (e (e a) * (e a)) + (e a))"");
    testInterp(lg, g, ""e"", ""a+a*a"", ""(e (e a) + (e (e a) * (e a)))"");
}","/**
 * This is a regression test for antlr/antlr4#461.
 * https://github.com/antlr/antlr4/issues/461
 */
", ,/** * This is a regression test for antlr/antlr4#461. * https://github.com/antlr/antlr4/issues/461 */,301,324,[0],0,[0],0,[0],0,0,0,0,testLeftRecursiveStartRule(),org.antlr.v4.test.tool.TestParserInterpreter,testLeftRecursiveStartRule/0,False,301,4,3,0,3,1,1,10,0,2,0,1,1,1,0,0,0,0,30,0,2,2,0,0,0,0,26,1,0,True
865,..\projects\antlr4-4.11.0\tool-testsuite\test\org\antlr\v4\test\tool\TestParserProfiler.java,org.antlr.v4.test.tool.TestParserProfiler,void test3xLL2(),"@Test
public void test3xLL2() throws Exception {
    Grammar g = new Grammar(""parser grammar T;\n"" + ""s : ID ';'{}\n"" + ""  | ID '.'\n"" + ""  ;\n"", lg);
    // The '.' vs ';' causes another ATN transition
    DecisionInfo[] info = interpAndGetDecisionInfo(lg, g, ""s"", ""xyz;"", ""abc;"", ""z."");
    assertEquals(1, info.length);
    String expecting = ""{decision=0, contextSensitivities=0, errors=0, ambiguities=0, SLL_lookahead=6, "" + ""SLL_ATNTransitions=3, SLL_DFATransitions=3, LL_Fallback=0, LL_lookahead=0, LL_ATNTransitions=0}"";
    assertEquals(expecting, info[0].toString());
}", ,"// The '.' vs ';' causes another ATN transition
",// The '.' vs ';' causes another ATN transition,99,114,[0],0,[0],0,[0],0,0,0,0,test3xLL2(),org.antlr.v4.test.tool.TestParserProfiler,test3xLL2/0,False,99,4,2,0,2,1,3,7,0,3,0,3,1,1,0,0,0,0,10,2,3,2,0,0,0,0,32,1,0,False
866,..\projects\antlr4-4.11.0\tool-testsuite\test\org\antlr\v4\test\tool\TestParserProfiler.java,org.antlr.v4.test.tool.TestParserProfiler,void testDeepLookahead(),"@Disabled
@Test
public void testDeepLookahead() throws Exception {
    Grammar g = new Grammar(""parser grammar T;\n"" + ""s : e ';'\n"" + ""  | e '.' \n"" + ""  ;\n"" + // d=1 entry, d=2 bypass
    ""e : (ID|INT) ({true}? '+' e)*\n"" + ""  ;\n"", lg);
    // pred forces to
    // ambig and ('+' e)* tail recursion forces lookahead to fall out of e
    // any non-precedence predicates are always evaluated as true by the interpreter
    DecisionInfo[] info = interpAndGetDecisionInfo(lg, g, ""s"", ""a+b+c;"");
    // at ""+b"" it uses k=1 and enters loop then calls e for b...
    // e matches and d=2 uses ""+c;"" for k=3
    assertEquals(2, info.length);
    String expecting = ""[{decision=0, contextSensitivities=0, errors=0, ambiguities=0, SLL_lookahead=6, "" + ""SLL_ATNTransitions=6, SLL_DFATransitions=0, LL_Fallback=0, LL_lookahead=0, LL_ATNTransitions=0}, "" + ""{decision=1, contextSensitivities=0, errors=0, ambiguities=0, SLL_lookahead=4, "" + ""SLL_ATNTransitions=2, SLL_DFATransitions=2, LL_Fallback=0, LL_lookahead=0, LL_ATNTransitions=0}]"";
    assertEquals(expecting, Arrays.toString(info));
}", ,"// pred forces to
[[SEP]]// ambig and ('+' e)* tail recursion forces lookahead to fall out of e
[[SEP]]// at ""+b"" it uses k=1 and enters loop then calls e for b...
[[SEP]]// d=1 entry, d=2 bypass
[[SEP]]// any non-precedence predicates are always evaluated as true by the interpreter
[[SEP]]// e matches and d=2 uses ""+c;"" for k=3
","// d=1 entry, d=2 bypass[[SEP]]// pred forces to// ambig and ('+' e)* tail recursion forces lookahead to fall out of e// any non-precedence predicates are always evaluated as true by the interpreter[[SEP]]// at ""+b"" it uses k=1 and enters loop then calls e for b...// e matches and d=2 uses ""+c;"" for k=3",183,207,[0],0,"[0, 0, 0, 0, 0, 0]",0,"[0, 0, 0]",0,0,0,0,testDeepLookahead(),org.antlr.v4.test.tool.TestParserProfiler,testDeepLookahead/0,False,184,5,2,0,2,1,3,7,0,3,0,3,1,1,0,0,0,0,12,1,3,2,0,0,0,0,37,1,0,False
867,..\projects\antlr4-4.11.0\tool-testsuite\test\org\antlr\v4\test\tool\TestParserProfiler.java,org.antlr.v4.test.tool.TestParserProfiler,"DecisionInfo[] interpAndGetDecisionInfo(LexerGrammar, Grammar, String, String...)","public DecisionInfo[] interpAndGetDecisionInfo(LexerGrammar lg, Grammar g, String startRule, String... input) {
    LexerInterpreter lexEngine = lg.createLexerInterpreter(null);
    ParserInterpreter parser = g.createParserInterpreter(null);
    parser.setProfile(true);
    for (String s : input) {
        lexEngine.reset();
        parser.reset();
        lexEngine.setInputStream(new ANTLRInputStream(s));
        CommonTokenStream tokens = new CommonTokenStream(lexEngine);
        parser.setInputStream(tokens);
        Rule r = g.rules.get(startRule);
        if (r == null) {
            return parser.getParseInfo().getDecisionInfo();
        }
        ParserRuleContext t = parser.parse(r.index);
        // try {
        // Utils.waitForClose(t.inspect(parser).get());
        // }
        // catch (Exception e) {
        // e.printStackTrace();
        // }
        // 
        // System.out.println(t.toStringTree(parser));
    }
    return parser.getParseInfo().getDecisionInfo();
}", ,"// try {
[[SEP]]// Utils.waitForClose(t.inspect(parser).get());
[[SEP]]// }
[[SEP]]// catch (Exception e) {
[[SEP]]// e.printStackTrace();
[[SEP]]// }
[[SEP]]// 
[[SEP]]// System.out.println(t.toStringTree(parser));
",// try {// Utils.waitForClose(t.inspect(parser).get());// }// catch (Exception e) {// e.printStackTrace();// }//// System.out.println(t.toStringTree(parser));,239,268,[0],0,"[0, 0, 0, 0, 0, 0, 0, 0]",0,[0],0,0,0,0,"interpAndGetDecisionInfo(LexerGrammar, Grammar, String, String[])",org.antlr.v4.test.tool.TestParserProfiler,"interpAndGetDecisionInfo/4[org.antlr.v4.tool.LexerGrammar,org.antlr.v4.tool.Grammar,java.lang.String,java.lang.String[]]",False,242,9,11,9,2,3,9,18,2,5,4,9,0,0,1,1,0,0,0,0,5,0,2,0,0,0,31,1,0,False
868,..\projects\antlr4-4.11.0\tool-testsuite\test\org\antlr\v4\test\tool\TestPerformance.java,org.antlr.v4.test.tool.TestPerformance,void computeTransitionStatistics(),"/**
 * Compute and print ATN/DFA transition statistics.
 */
private void computeTransitionStatistics() {
    if (TRANSITION_RUNNING_AVERAGE) {
        for (int i = 0; i < PASSES; i++) {
            long[] data = computedTransitionsPerFile[i];
            for (int j = 0; j < data.length - 1; j++) {
                data[j + 1] += data[j];
            }
            data = totalTransitionsPerFile[i];
            for (int j = 0; j < data.length - 1; j++) {
                data[j + 1] += data[j];
            }
        }
    }
    long[] sumNum = new long[totalTransitionsPerFile[0].length];
    long[] sumDen = new long[totalTransitionsPerFile[0].length];
    double[] sumNormalized = new double[totalTransitionsPerFile[0].length];
    for (int i = 0; i < PASSES; i++) {
        long[] num = computedTransitionsPerFile[i];
        long[] den = totalTransitionsPerFile[i];
        for (int j = 0; j < den.length; j++) {
            sumNum[j] += num[j];
            sumDen[j] += den[j];
            if (den[j] > 0) {
                sumNormalized[j] += (double) num[j] / (double) den[j];
            }
        }
    }
    double[] weightedAverage = new double[totalTransitionsPerFile[0].length];
    double[] average = new double[totalTransitionsPerFile[0].length];
    for (int i = 0; i < average.length; i++) {
        if (sumDen[i] > 0) {
            weightedAverage[i] = (double) sumNum[i] / (double) sumDen[i];
        } else {
            weightedAverage[i] = 0;
        }
        average[i] = sumNormalized[i] / PASSES;
    }
    double[] low95 = new double[totalTransitionsPerFile[0].length];
    double[] high95 = new double[totalTransitionsPerFile[0].length];
    double[] low67 = new double[totalTransitionsPerFile[0].length];
    double[] high67 = new double[totalTransitionsPerFile[0].length];
    double[] stddev = new double[totalTransitionsPerFile[0].length];
    for (int i = 0; i < stddev.length; i++) {
        double[] points = new double[PASSES];
        for (int j = 0; j < PASSES; j++) {
            long totalTransitions = totalTransitionsPerFile[j][i];
            if (totalTransitions > 0) {
                points[j] = ((double) computedTransitionsPerFile[j][i] / (double) totalTransitionsPerFile[j][i]);
            } else {
                points[j] = 0;
            }
        }
        Arrays.sort(points);
        final double averageValue = TRANSITION_WEIGHTED_AVERAGE ? weightedAverage[i] : average[i];
        double value = 0;
        for (int j = 0; j < PASSES; j++) {
            double diff = points[j] - averageValue;
            value += diff * diff;
        }
        int ignoreCount95 = (int) Math.round(PASSES * (1 - 0.95) / 2.0);
        int ignoreCount67 = (int) Math.round(PASSES * (1 - 0.667) / 2.0);
        low95[i] = points[ignoreCount95];
        high95[i] = points[points.length - 1 - ignoreCount95];
        low67[i] = points[ignoreCount67];
        high67[i] = points[points.length - 1 - ignoreCount67];
        stddev[i] = Math.sqrt(value / PASSES);
    }
    System.out.format(""File\tAverage\tStd. Dev.\t95%% Low\t95%% High\t66.7%% Low\t66.7%% High%n"");
    for (int i = 0; i < stddev.length; i++) {
        final double averageValue = TRANSITION_WEIGHTED_AVERAGE ? weightedAverage[i] : average[i];
        System.out.format(""%d\t%e\t%e\t%e\t%e\t%e\t%e%n"", i + 1, averageValue, stddev[i], averageValue - low95[i], high95[i] - averageValue, averageValue - low67[i], high67[i] - averageValue);
    }
}","/**
 * Compute and print ATN/DFA transition statistics.
 */
", ,/** * Compute and print ATN/DFA transition statistics. */,518,601,[0],0,[0],0,[0],0,0,0,0,computeTransitionStatistics(),org.antlr.v4.test.tool.TestPerformance,computeTransitionStatistics/0,False,518,2,1,1,0,17,4,75,0,31,0,4,0,0,10,0,0,3,2,39,48,24,3,0,0,0,50,2,0,True
869,..\projects\antlr4-4.11.0\tool-testsuite\test\org\antlr\v4\test\tool\TestPerformance.java,org.antlr.v4.test.tool.TestPerformance,void computeTimingStatistics(),"/**
 * Compute and print timing statistics.
 */
private void computeTimingStatistics() {
    if (TIMING_CUMULATIVE) {
        for (int i = 0; i < PASSES; i++) {
            long[] data = timePerFile[i];
            for (int j = 0; j < data.length - 1; j++) {
                data[j + 1] += data[j];
            }
            int[] data2 = tokensPerFile[i];
            for (int j = 0; j < data2.length - 1; j++) {
                data2[j + 1] += data2[j];
            }
        }
    }
    final int fileCount = timePerFile[0].length;
    double[] sum = new double[fileCount];
    for (int i = 0; i < PASSES; i++) {
        long[] data = timePerFile[i];
        int[] tokenData = tokensPerFile[i];
        for (int j = 0; j < data.length; j++) {
            sum[j] += (double) data[j] / (double) tokenData[j];
        }
    }
    double[] average = new double[fileCount];
    for (int i = 0; i < average.length; i++) {
        average[i] = sum[i] / PASSES;
    }
    double[] low95 = new double[fileCount];
    double[] high95 = new double[fileCount];
    double[] low67 = new double[fileCount];
    double[] high67 = new double[fileCount];
    double[] stddev = new double[fileCount];
    for (int i = 0; i < stddev.length; i++) {
        double[] points = new double[PASSES];
        for (int j = 0; j < PASSES; j++) {
            points[j] = (double) timePerFile[j][i] / (double) tokensPerFile[j][i];
        }
        Arrays.sort(points);
        final double averageValue = average[i];
        double value = 0;
        for (int j = 0; j < PASSES; j++) {
            double diff = points[j] - averageValue;
            value += diff * diff;
        }
        int ignoreCount95 = (int) Math.round(PASSES * (1 - 0.95) / 2.0);
        int ignoreCount67 = (int) Math.round(PASSES * (1 - 0.667) / 2.0);
        low95[i] = points[ignoreCount95];
        high95[i] = points[points.length - 1 - ignoreCount95];
        low67[i] = points[ignoreCount67];
        high67[i] = points[points.length - 1 - ignoreCount67];
        stddev[i] = Math.sqrt(value / PASSES);
    }
    System.out.format(""File\tAverage\tStd. Dev.\t95%% Low\t95%% High\t66.7%% Low\t66.7%% High%n"");
    for (int i = 0; i < stddev.length; i++) {
        final double averageValue = average[i];
        System.out.format(""%d\t%e\t%e\t%e\t%e\t%e\t%e%n"", i + 1, averageValue, stddev[i], averageValue - low95[i], high95[i] - averageValue, averageValue - low67[i], high67[i] - averageValue);
    }
}","/**
 * Compute and print timing statistics.
 */
", ,/** * Compute and print timing statistics. */,606,670,[0],0,[0],0,[0],0,0,0,0,computeTimingStatistics(),org.antlr.v4.test.tool.TestPerformance,computeTimingStatistics/0,False,606,3,1,1,0,12,4,57,0,29,0,4,0,0,10,0,0,2,2,25,40,23,3,0,0,0,43,2,0,True
870,..\projects\antlr4-4.11.0\tool-testsuite\test\org\antlr\v4\test\tool\TestPerformance.java,org.antlr.v4.test.tool.TestPerformance,"void parse1(int, ParserFactory, Collection<InputDescriptor>, boolean)","/**
 *  This method is separate from {@link #parse2} so the first pass can be distinguished when analyzing
 *  profiler results.
 */
protected void parse1(int currentPass, ParserFactory factory, Collection<InputDescriptor> sources, boolean shuffleSources) throws InterruptedException {
    if (FILE_GRANULARITY) {
        System.gc();
    }
    parseSources(currentPass, factory, sources, shuffleSources);
}","/**
 *  This method is separate from {@link #parse2} so the first pass can be distinguished when analyzing
 *  profiler results.
 */
", ,/** *  This method is separate from {@link #parse2} so the first pass can be distinguished when analyzing *  profiler results. */,716,722,[0],0,[0],0,[0],0,0,0,0,"parse1(int, ParserFactory, Collection<InputDescriptor>, boolean)",org.antlr.v4.test.tool.TestPerformance,"parse1/4[int,org.antlr.v4.test.tool.TestPerformance.ParserFactory,java.util.Collection<org.antlr.v4.test.tool.TestPerformance.InputDescriptor>,boolean]",False,716,3,2,1,1,2,2,6,0,0,4,2,1,2,0,0,0,0,0,0,0,0,1,0,0,0,32,4,0,True
871,..\projects\antlr4-4.11.0\tool-testsuite\test\org\antlr\v4\test\tool\TestPerformance.java,org.antlr.v4.test.tool.TestPerformance,"void parse2(int, ParserFactory, Collection<InputDescriptor>, boolean)","/**
 *  This method is separate from {@link #parse1} so the first pass can be distinguished when analyzing
 *  profiler results.
 */
protected void parse2(int currentPass, ParserFactory factory, Collection<InputDescriptor> sources, boolean shuffleSources) throws InterruptedException {
    if (FILE_GRANULARITY) {
        System.gc();
    }
    parseSources(currentPass, factory, sources, shuffleSources);
}","/**
 *  This method is separate from {@link #parse1} so the first pass can be distinguished when analyzing
 *  profiler results.
 */
", ,/** *  This method is separate from {@link #parse1} so the first pass can be distinguished when analyzing *  profiler results. */,728,734,[0],0,[0],0,[0],0,0,0,0,"parse2(int, ParserFactory, Collection<InputDescriptor>, boolean)",org.antlr.v4.test.tool.TestPerformance,"parse2/4[int,org.antlr.v4.test.tool.TestPerformance.ParserFactory,java.util.Collection<org.antlr.v4.test.tool.TestPerformance.InputDescriptor>,boolean]",False,728,3,2,1,1,2,2,6,0,0,4,2,1,2,0,0,0,0,0,0,0,0,1,0,0,0,32,4,0,True
872,..\projects\antlr4-4.11.0\tool-testsuite\test\org\antlr\v4\test\tool\TestPerformance.java,org.antlr.v4.test.tool.TestPerformance,"void parseSources(int, ParserFactory, Collection<InputDescriptor>, boolean)","protected void parseSources(final int currentPass, final ParserFactory factory, Collection<InputDescriptor> sources, boolean shuffleSources) throws InterruptedException {
    if (shuffleSources) {
        List<InputDescriptor> sourcesList = new ArrayList<InputDescriptor>(sources);
        synchronized (RANDOM) {
            Collections.shuffle(sourcesList, RANDOM);
        }
        sources = sourcesList;
    }
    long startTime = System.nanoTime();
    tokenCount.set(currentPass, 0);
    int inputSize = 0;
    int inputCount = 0;
    Collection<Future<FileParseResult>> results = new ArrayList<Future<FileParseResult>>();
    ExecutorService executorService;
    if (FILE_GRANULARITY) {
        executorService = Executors.newFixedThreadPool(FILE_GRANULARITY ? NUMBER_OF_THREADS : 1, new NumberedThreadFactory());
    } else {
        executorService = Executors.newSingleThreadExecutor(new FixedThreadNumberFactory(((NumberedThread) Thread.currentThread()).getThreadNumber()));
    }
    for (InputDescriptor inputDescriptor : sources) {
        if (inputCount >= MAX_FILES_PER_PARSE_ITERATION) {
            break;
        }
        final CharStream input = inputDescriptor.getInputStream();
        input.seek(0);
        inputSize += input.size();
        inputCount++;
        Future<FileParseResult> futureChecksum = executorService.submit(new Callable<FileParseResult>() {

            @Override
            public FileParseResult call() {
                // this incurred a great deal of overhead and was causing significant variations in performance results.
                // System.out.format(""Parsing file %s\n"", input.getSourceName());
                try {
                    return factory.parseFile(input, currentPass, ((NumberedThread) Thread.currentThread()).getThreadNumber());
                } catch (IllegalStateException ex) {
                    ex.printStackTrace(System.err);
                } catch (Throwable t) {
                    t.printStackTrace(System.err);
                }
                return null;
            }
        });
        results.add(futureChecksum);
    }
    MurmurHashChecksum checksum = new MurmurHashChecksum();
    int currentIndex = -1;
    for (Future<FileParseResult> future : results) {
        currentIndex++;
        int fileChecksum = 0;
        try {
            FileParseResult fileResult = future.get();
            if (COMPUTE_TRANSITION_STATS) {
                totalTransitionsPerFile[currentPass][currentIndex] = sum(fileResult.parserTotalTransitions);
                computedTransitionsPerFile[currentPass][currentIndex] = sum(fileResult.parserComputedTransitions);
                if (DETAILED_DFA_STATE_STATS) {
                    decisionInvocationsPerFile[currentPass][currentIndex] = fileResult.decisionInvocations;
                    fullContextFallbackPerFile[currentPass][currentIndex] = fileResult.fullContextFallback;
                    nonSllPerFile[currentPass][currentIndex] = fileResult.nonSll;
                    totalTransitionsPerDecisionPerFile[currentPass][currentIndex] = fileResult.parserTotalTransitions;
                    computedTransitionsPerDecisionPerFile[currentPass][currentIndex] = fileResult.parserComputedTransitions;
                    fullContextTransitionsPerDecisionPerFile[currentPass][currentIndex] = fileResult.parserFullContextTransitions;
                }
            }
            if (COMPUTE_TIMING_STATS) {
                timePerFile[currentPass][currentIndex] = fileResult.endTime - fileResult.startTime;
                tokensPerFile[currentPass][currentIndex] = fileResult.tokenCount;
            }
            fileChecksum = fileResult.checksum;
        } catch (ExecutionException ex) {
            Logger.getLogger(TestPerformance.class.getName()).log(Level.SEVERE, null, ex);
        }
        if (COMPUTE_CHECKSUM) {
            updateChecksum(checksum, fileChecksum);
        }
    }
    executorService.shutdown();
    executorService.awaitTermination(Long.MAX_VALUE, TimeUnit.NANOSECONDS);
    System.out.format(""%d. Total parse time for %d files (%d KB, %d tokens%s): %.0fms%n"", currentPass + 1, inputCount, inputSize / 1024, tokenCount.get(currentPass), COMPUTE_CHECKSUM ? String.format("", checksum 0x%8X"", checksum.getValue()) : """", (double) (System.nanoTime() - startTime) / 1000000.0);
    if (sharedLexers.length > 0) {
        int index = FILE_GRANULARITY ? 0 : ((NumberedThread) Thread.currentThread()).getThreadNumber();
        Lexer lexer = sharedLexers[index];
        final LexerATNSimulator lexerInterpreter = lexer.getInterpreter();
        final DFA[] modeToDFA = lexerInterpreter.decisionToDFA;
        if (SHOW_DFA_STATE_STATS) {
            int states = 0;
            int configs = 0;
            Set<ATNConfig> uniqueConfigs = new HashSet<ATNConfig>();
            for (int i = 0; i < modeToDFA.length; i++) {
                DFA dfa = modeToDFA[i];
                if (dfa == null) {
                    continue;
                }
                states += dfa.states.size();
                for (DFAState state : dfa.states.values()) {
                    configs += state.configs.size();
                    uniqueConfigs.addAll(state.configs);
                }
            }
            System.out.format(""There are %d lexer DFAState instances, %d configs (%d unique).%n"", states, configs, uniqueConfigs.size());
            if (DETAILED_DFA_STATE_STATS) {
                System.out.format(""\tMode\tStates\tConfigs\tMode%n"");
                for (int i = 0; i < modeToDFA.length; i++) {
                    DFA dfa = modeToDFA[i];
                    if (dfa == null || dfa.states.isEmpty()) {
                        continue;
                    }
                    int modeConfigs = 0;
                    for (DFAState state : dfa.states.values()) {
                        modeConfigs += state.configs.size();
                    }
                    String modeName = lexer.getModeNames()[i];
                    System.out.format(""\t%d\t%d\t%d\t%s%n"", dfa.decision, dfa.states.size(), modeConfigs, modeName);
                }
            }
        }
    }
    if (RUN_PARSER && sharedParsers.length > 0) {
        int index = FILE_GRANULARITY ? 0 : ((NumberedThread) Thread.currentThread()).getThreadNumber();
        Parser parser = sharedParsers[index];
        // make sure the individual DFAState objects actually have unique ATNConfig arrays
        final ParserATNSimulator interpreter = parser.getInterpreter();
        final DFA[] decisionToDFA = interpreter.decisionToDFA;
        if (SHOW_DFA_STATE_STATS) {
            int states = 0;
            int configs = 0;
            Set<ATNConfig> uniqueConfigs = new HashSet<ATNConfig>();
            for (int i = 0; i < decisionToDFA.length; i++) {
                DFA dfa = decisionToDFA[i];
                if (dfa == null) {
                    continue;
                }
                states += dfa.states.size();
                for (DFAState state : dfa.states.values()) {
                    configs += state.configs.size();
                    uniqueConfigs.addAll(state.configs);
                }
            }
            System.out.format(""There are %d parser DFAState instances, %d configs (%d unique).%n"", states, configs, uniqueConfigs.size());
            if (DETAILED_DFA_STATE_STATS) {
                if (COMPUTE_TRANSITION_STATS) {
                    System.out.format(""\tDecision\tStates\tConfigs\tPredict (ALL)\tPredict (LL)\tNon-SLL\tTransitions\tTransitions (ATN)\tTransitions (LL)\tLA (SLL)\tLA (LL)\tRule%n"");
                } else {
                    System.out.format(""\tDecision\tStates\tConfigs\tRule%n"");
                }
                for (int i = 0; i < decisionToDFA.length; i++) {
                    DFA dfa = decisionToDFA[i];
                    if (dfa == null || dfa.states.isEmpty()) {
                        continue;
                    }
                    int decisionConfigs = 0;
                    for (DFAState state : dfa.states.values()) {
                        decisionConfigs += state.configs.size();
                    }
                    String ruleName = parser.getRuleNames()[parser.getATN().decisionToState.get(dfa.decision).ruleIndex];
                    long calls = 0;
                    long fullContextCalls = 0;
                    long nonSllCalls = 0;
                    long transitions = 0;
                    long computedTransitions = 0;
                    long fullContextTransitions = 0;
                    double lookahead = 0;
                    double fullContextLookahead = 0;
                    String formatString;
                    if (COMPUTE_TRANSITION_STATS) {
                        for (long[] data : decisionInvocationsPerFile[currentPass]) {
                            calls += data[i];
                        }
                        for (long[] data : fullContextFallbackPerFile[currentPass]) {
                            fullContextCalls += data[i];
                        }
                        for (long[] data : nonSllPerFile[currentPass]) {
                            nonSllCalls += data[i];
                        }
                        for (long[] data : totalTransitionsPerDecisionPerFile[currentPass]) {
                            transitions += data[i];
                        }
                        for (long[] data : computedTransitionsPerDecisionPerFile[currentPass]) {
                            computedTransitions += data[i];
                        }
                        for (long[] data : fullContextTransitionsPerDecisionPerFile[currentPass]) {
                            fullContextTransitions += data[i];
                        }
                        if (calls > 0) {
                            lookahead = (double) (transitions - fullContextTransitions) / (double) calls;
                        }
                        if (fullContextCalls > 0) {
                            fullContextLookahead = (double) fullContextTransitions / (double) fullContextCalls;
                        }
                        formatString = ""\t%1$d\t%2$d\t%3$d\t%4$d\t%5$d\t%6$d\t%7$d\t%8$d\t%9$d\t%10$f\t%11$f\t%12$s%n"";
                    } else {
                        calls = 0;
                        formatString = ""\t%1$d\t%2$d\t%3$d\t%12$s%n"";
                    }
                    System.out.format(formatString, dfa.decision, dfa.states.size(), decisionConfigs, calls, fullContextCalls, nonSllCalls, transitions, computedTransitions, fullContextTransitions, lookahead, fullContextLookahead, ruleName);
                }
            }
        }
        int localDfaCount = 0;
        int globalDfaCount = 0;
        int localConfigCount = 0;
        int globalConfigCount = 0;
        int[] contextsInDFAState = new int[0];
        for (int i = 0; i < decisionToDFA.length; i++) {
            DFA dfa = decisionToDFA[i];
            if (dfa == null) {
                continue;
            }
            if (SHOW_CONFIG_STATS) {
                for (DFAState state : dfa.states.keySet()) {
                    if (state.configs.size() >= contextsInDFAState.length) {
                        contextsInDFAState = Arrays.copyOf(contextsInDFAState, state.configs.size() + 1);
                    }
                    if (state.isAcceptState) {
                        boolean hasGlobal = false;
                        for (ATNConfig config : state.configs) {
                            if (config.reachesIntoOuterContext > 0) {
                                globalConfigCount++;
                                hasGlobal = true;
                            } else {
                                localConfigCount++;
                            }
                        }
                        if (hasGlobal) {
                            globalDfaCount++;
                        } else {
                            localDfaCount++;
                        }
                    }
                    contextsInDFAState[state.configs.size()]++;
                }
            }
        }
        if (SHOW_CONFIG_STATS && currentPass == 0) {
            System.out.format(""  DFA accept states: %d total, %d with only local context, %d with a global context%n"", localDfaCount + globalDfaCount, localDfaCount, globalDfaCount);
            System.out.format(""  Config stats: %d total, %d local, %d global%n"", localConfigCount + globalConfigCount, localConfigCount, globalConfigCount);
            if (SHOW_DFA_STATE_STATS) {
                for (int i = 0; i < contextsInDFAState.length; i++) {
                    if (contextsInDFAState[i] != 0) {
                        System.out.format(""  %d configs = %d%n"", i, contextsInDFAState[i]);
                    }
                }
            }
        }
    }
    if (COMPUTE_TIMING_STATS) {
        System.out.format(""File\tTokens\tTime%n"");
        for (int i = 0; i < timePerFile[currentPass].length; i++) {
            System.out.format(""%d\t%d\t%d%n"", i + 1, tokensPerFile[currentPass][i], timePerFile[currentPass][i]);
        }
    }
}", ,"// this incurred a great deal of overhead and was causing significant variations in performance results.
[[SEP]]// System.out.format(""Parsing file %s\n"", input.getSourceName());
[[SEP]]// make sure the individual DFAState objects actually have unique ATNConfig arrays
","// this incurred a great deal of overhead and was causing significant variations in performance results.// System.out.format(""Parsing file %s\n"", input.getSourceName());[[SEP]]// make sure the individual DFAState objects actually have unique ATNConfig arrays",766,1072,[0],0,"[0, 0, 0]",0,"[0, 0]",0,0,0,0,"parseSources(int, ParserFactory, Collection<InputDescriptor>, boolean)",org.antlr.v4.test.tool.TestPerformance,"parseSources/4[int,org.antlr.v4.test.tool.TestPerformance.ParserFactory,java.util.Collection<org.antlr.v4.test.tool.TestPerformance.InputDescriptor>,boolean]",False,766,16,11,2,9,62,34,256,0,57,4,34,2,1,21,7,1,5,16,48,89,12,7,1,0,0,123,4,0,False
873,..\projects\antlr4-4.11.0\tool-testsuite\test\org\antlr\v4\test\tool\TestPerformance.java,org.antlr.v4.test.tool.TestPerformance,"ParserFactory getParserFactory(JavaCompiledState, String, String)","protected ParserFactory getParserFactory(JavaCompiledState javaCompiledState, String listenerName, final String entryPoint) {
    try {
        ClassLoader loader = javaCompiledState.loader;
        final Class<? extends ParseTreeListener> listenerClass = loader.loadClass(listenerName).asSubclass(ParseTreeListener.class);
        final Constructor<? extends Lexer> lexerCtor = javaCompiledState.lexer.getConstructor(CharStream.class);
        final Constructor<? extends Parser> parserCtor = javaCompiledState.parser.getConstructor(TokenStream.class);
        // construct initial instances of the lexer and parser to deserialize their ATNs
        javaCompiledState.initializeLexerAndParser("""");
        return new ParserFactory() {

            @Override
            public FileParseResult parseFile(CharStream input, int currentPass, int thread) {
                final MurmurHashChecksum checksum = new MurmurHashChecksum();
                final long startTime = System.nanoTime();
                assert thread >= 0 && thread < NUMBER_OF_THREADS;
                try {
                    ParseTreeListener listener = sharedListeners[thread];
                    if (listener == null) {
                        listener = listenerClass.newInstance();
                        sharedListeners[thread] = listener;
                    }
                    Lexer lexer = sharedLexers[thread];
                    if (REUSE_LEXER && lexer != null) {
                        lexer.setInputStream(input);
                    } else {
                        Lexer previousLexer = lexer;
                        lexer = lexerCtor.newInstance(input);
                        DFA[] decisionToDFA = (FILE_GRANULARITY || previousLexer == null ? lexer : previousLexer).getInterpreter().decisionToDFA;
                        if (!REUSE_LEXER_DFA || (!FILE_GRANULARITY && previousLexer == null)) {
                            decisionToDFA = new DFA[decisionToDFA.length];
                        }
                        if (COMPUTE_TRANSITION_STATS) {
                            lexer.setInterpreter(new StatisticsLexerATNSimulator(lexer, lexer.getATN(), decisionToDFA, lexer.getInterpreter().getSharedContextCache()));
                        } else if (!REUSE_LEXER_DFA) {
                            lexer.setInterpreter(new LexerATNSimulator(lexer, lexer.getATN(), decisionToDFA, lexer.getInterpreter().getSharedContextCache()));
                        }
                        sharedLexers[thread] = lexer;
                    }
                    lexer.removeErrorListeners();
                    lexer.addErrorListener(DescriptiveErrorListener.INSTANCE);
                    if (lexer.getInterpreter().decisionToDFA[0] == null) {
                        ATN atn = lexer.getATN();
                        for (int i = 0; i < lexer.getInterpreter().decisionToDFA.length; i++) {
                            lexer.getInterpreter().decisionToDFA[i] = new DFA(atn.getDecisionState(i), i);
                        }
                    }
                    CommonTokenStream tokens = new CommonTokenStream(lexer);
                    tokens.fill();
                    tokenCount.addAndGet(currentPass, tokens.size());
                    if (COMPUTE_CHECKSUM) {
                        for (Token token : tokens.getTokens()) {
                            updateChecksum(checksum, token);
                        }
                    }
                    if (!RUN_PARSER) {
                        return new FileParseResult(input.getSourceName(), (int) checksum.getValue(), null, tokens.size(), startTime, lexer, null);
                    }
                    final long parseStartTime = System.nanoTime();
                    Parser parser = sharedParsers[thread];
                    if (REUSE_PARSER && parser != null) {
                        parser.setInputStream(tokens);
                    } else {
                        Parser previousParser = parser;
                        if (USE_PARSER_INTERPRETER) {
                            Parser referenceParser = parserCtor.newInstance(tokens);
                            parser = new ParserInterpreter(referenceParser.getGrammarFileName(), referenceParser.getVocabulary(), Arrays.asList(referenceParser.getRuleNames()), referenceParser.getATN(), tokens);
                        } else {
                            parser = parserCtor.newInstance(tokens);
                        }
                        DFA[] decisionToDFA = (FILE_GRANULARITY || previousParser == null ? parser : previousParser).getInterpreter().decisionToDFA;
                        if (!REUSE_PARSER_DFA || (!FILE_GRANULARITY && previousParser == null)) {
                            decisionToDFA = new DFA[decisionToDFA.length];
                        }
                        if (COMPUTE_TRANSITION_STATS) {
                            parser.setInterpreter(new StatisticsParserATNSimulator(parser, parser.getATN(), decisionToDFA, parser.getInterpreter().getSharedContextCache()));
                        } else if (!REUSE_PARSER_DFA) {
                            parser.setInterpreter(new ParserATNSimulator(parser, parser.getATN(), decisionToDFA, parser.getInterpreter().getSharedContextCache()));
                        }
                        sharedParsers[thread] = parser;
                    }
                    parser.removeParseListeners();
                    parser.removeErrorListeners();
                    if (!TWO_STAGE_PARSING) {
                        parser.addErrorListener(DescriptiveErrorListener.INSTANCE);
                        parser.addErrorListener(new SummarizingDiagnosticErrorListener());
                    }
                    if (parser.getInterpreter().decisionToDFA[0] == null) {
                        ATN atn = parser.getATN();
                        for (int i = 0; i < parser.getInterpreter().decisionToDFA.length; i++) {
                            parser.getInterpreter().decisionToDFA[i] = new DFA(atn.getDecisionState(i), i);
                        }
                    }
                    parser.getInterpreter().setPredictionMode(TWO_STAGE_PARSING ? PredictionMode.SLL : PREDICTION_MODE);
                    parser.setBuildParseTree(BUILD_PARSE_TREES);
                    if (!BUILD_PARSE_TREES && BLANK_LISTENER) {
                        parser.addParseListener(listener);
                    }
                    if (BAIL_ON_ERROR || TWO_STAGE_PARSING) {
                        parser.setErrorHandler(new BailErrorStrategy());
                    }
                    Method parseMethod = javaCompiledState.parser.getMethod(entryPoint);
                    Object parseResult;
                    try {
                        if (COMPUTE_CHECKSUM && !BUILD_PARSE_TREES) {
                            parser.addParseListener(new ChecksumParseTreeListener(checksum));
                        }
                        if (USE_PARSER_INTERPRETER) {
                            ParserInterpreter parserInterpreter = (ParserInterpreter) parser;
                            parseResult = parserInterpreter.parse(Collections.lastIndexOfSubList(Arrays.asList(parser.getRuleNames()), Collections.singletonList(entryPoint)));
                        } else {
                            parseResult = parseMethod.invoke(parser);
                        }
                    } catch (InvocationTargetException ex) {
                        if (!TWO_STAGE_PARSING) {
                            throw ex;
                        }
                        String sourceName = tokens.getSourceName();
                        sourceName = sourceName != null && !sourceName.isEmpty() ? sourceName + "": "" : """";
                        if (REPORT_SECOND_STAGE_RETRY) {
                            System.err.println(sourceName + ""Forced to retry with full context."");
                        }
                        if (!(ex.getCause() instanceof ParseCancellationException)) {
                            throw ex;
                        }
                        tokens.seek(0);
                        if (REUSE_PARSER && parser != null) {
                            parser.setInputStream(tokens);
                        } else {
                            Parser previousParser = parser;
                            if (USE_PARSER_INTERPRETER) {
                                Parser referenceParser = parserCtor.newInstance(tokens);
                                parser = new ParserInterpreter(referenceParser.getGrammarFileName(), referenceParser.getVocabulary(), Arrays.asList(referenceParser.getRuleNames()), referenceParser.getATN(), tokens);
                            } else {
                                parser = parserCtor.newInstance(tokens);
                            }
                            DFA[] decisionToDFA = previousParser.getInterpreter().decisionToDFA;
                            if (COMPUTE_TRANSITION_STATS) {
                                parser.setInterpreter(new StatisticsParserATNSimulator(parser, parser.getATN(), decisionToDFA, parser.getInterpreter().getSharedContextCache()));
                            } else if (!REUSE_PARSER_DFA) {
                                parser.setInterpreter(new ParserATNSimulator(parser, parser.getATN(), decisionToDFA, parser.getInterpreter().getSharedContextCache()));
                            }
                            sharedParsers[thread] = parser;
                        }
                        parser.removeParseListeners();
                        parser.removeErrorListeners();
                        parser.addErrorListener(DescriptiveErrorListener.INSTANCE);
                        parser.addErrorListener(new SummarizingDiagnosticErrorListener());
                        parser.getInterpreter().setPredictionMode(PredictionMode.LL);
                        parser.setBuildParseTree(BUILD_PARSE_TREES);
                        if (COMPUTE_CHECKSUM && !BUILD_PARSE_TREES) {
                            parser.addParseListener(new ChecksumParseTreeListener(checksum));
                        }
                        if (!BUILD_PARSE_TREES && BLANK_LISTENER) {
                            parser.addParseListener(listener);
                        }
                        if (BAIL_ON_ERROR) {
                            parser.setErrorHandler(new BailErrorStrategy());
                        }
                        parseResult = parseMethod.invoke(parser);
                    }
                    assertTrue(parseResult instanceof ParseTree);
                    if (COMPUTE_CHECKSUM && BUILD_PARSE_TREES) {
                        ParseTreeWalker.DEFAULT.walk(new ChecksumParseTreeListener(checksum), (ParseTree) parseResult);
                    }
                    if (BUILD_PARSE_TREES && BLANK_LISTENER) {
                        ParseTreeWalker.DEFAULT.walk(listener, (ParseTree) parseResult);
                    }
                    return new FileParseResult(input.getSourceName(), (int) checksum.getValue(), (ParseTree) parseResult, tokens.size(), TIME_PARSE_ONLY ? parseStartTime : startTime, lexer, parser);
                } catch (Exception e) {
                    if (!REPORT_SYNTAX_ERRORS && e instanceof ParseCancellationException) {
                        return new FileParseResult(""unknown"", (int) checksum.getValue(), null, 0, startTime, null, null);
                    }
                    e.printStackTrace(System.out);
                    throw new IllegalStateException(e);
                }
            }
        };
    } catch (Exception e) {
        e.printStackTrace(System.out);
        fail(e.getMessage());
        throw new IllegalStateException(e);
    }
}", ,"// construct initial instances of the lexer and parser to deserialize their ATNs
",// construct initial instances of the lexer and parser to deserialize their ATNs,1130,1350,[0],0,[0],0,[0],0,0,0,0,"getParserFactory(JavaCompiledState, String, String)",org.antlr.v4.test.tool.TestPerformance,"getParserFactory/3[org.antlr.v4.test.tool.JavaCompiledState,java.lang.String,java.lang.String]",False,1130,6,2,1,1,2,7,193,1,4,3,7,0,0,0,0,1,0,1,0,4,0,1,1,0,0,94,4,0,False
874,..\projects\antlr4-4.11.0\tool-testsuite\test\org\antlr\v4\test\tool\TestPerformance.java,org.antlr.v4.test.tool.TestPerformance.SummarizingDiagnosticErrorListener,"void reportAmbiguity(Parser, DFA, int, int, boolean, BitSet, ATNConfigSet)","@Override
public void reportAmbiguity(Parser recognizer, DFA dfa, int startIndex, int stopIndex, boolean exact, BitSet ambigAlts, ATNConfigSet configs) {
    if (COMPUTE_TRANSITION_STATS && DETAILED_DFA_STATE_STATS) {
        BitSet sllPredictions = getConflictingAlts(_sllConflict, _sllConfigs);
        int sllPrediction = sllPredictions.nextSetBit(0);
        BitSet llPredictions = getConflictingAlts(ambigAlts, configs);
        int llPrediction = llPredictions.cardinality() == 0 ? ATN.INVALID_ALT_NUMBER : llPredictions.nextSetBit(0);
        if (sllPrediction != llPrediction) {
            ((StatisticsParserATNSimulator) recognizer.getInterpreter()).nonSll[dfa.decision]++;
        }
    }
    if (!REPORT_AMBIGUITIES) {
        return;
    }
    // show the rule name along with the decision
    String format = ""reportAmbiguity d=%d (%s): ambigAlts=%s, input='%s'"";
    int decision = dfa.decision;
    String rule = recognizer.getRuleNames()[dfa.atnStartState.ruleIndex];
    String input = recognizer.getTokenStream().getText(Interval.of(startIndex, stopIndex));
    recognizer.notifyErrorListeners(String.format(format, decision, rule, ambigAlts, input));
}", ,"// show the rule name along with the decision
",// show the rule name along with the decision,1571,1593,[0],0,[0],0,[0],0,0,0,0,"reportAmbiguity(Parser, DFA, int, int, boolean, BitSet, ATNConfigSet)",org.antlr.v4.test.tool.TestPerformance$SummarizingDiagnosticErrorListener,"reportAmbiguity/7[org.antlr.v4.test.tool.Parser,org.antlr.v4.test.tool.DFA,int,int,boolean,java.util.BitSet,org.antlr.v4.test.tool.ATNConfigSet]",False,1572,4,0,0,0,6,10,19,1,8,7,10,0,0,0,2,0,1,1,3,8,0,2,0,0,0,39,1,0,False
875,..\projects\antlr4-4.11.0\tool-testsuite\test\org\antlr\v4\test\tool\TestPerformance.java,org.antlr.v4.test.tool.TestPerformance.SummarizingDiagnosticErrorListener,"void reportAttemptingFullContext(Parser, DFA, int, int, BitSet, ATNConfigSet)","@Override
public void reportAttemptingFullContext(Parser recognizer, DFA dfa, int startIndex, int stopIndex, BitSet conflictingAlts, ATNConfigSet configs) {
    _sllConflict = conflictingAlts;
    _sllConfigs = configs;
    if (!REPORT_FULL_CONTEXT) {
        return;
    }
    // show the rule name and viable configs along with the base info
    String format = ""reportAttemptingFullContext d=%d (%s), input='%s', viable=%s"";
    int decision = dfa.decision;
    String rule = recognizer.getRuleNames()[dfa.atnStartState.ruleIndex];
    String input = recognizer.getTokenStream().getText(Interval.of(startIndex, stopIndex));
    BitSet representedAlts = getConflictingAlts(conflictingAlts, configs);
    recognizer.notifyErrorListeners(String.format(format, decision, rule, input, representedAlts));
}", ,"// show the rule name and viable configs along with the base info
",// show the rule name and viable configs along with the base info,1595,1610,[0],0,[0],0,[0],0,0,0,0,"reportAttemptingFullContext(Parser, DFA, int, int, BitSet, ATNConfigSet)",org.antlr.v4.test.tool.TestPerformance$SummarizingDiagnosticErrorListener,"reportAttemptingFullContext/6[org.antlr.v4.test.tool.Parser,org.antlr.v4.test.tool.DFA,int,int,java.util.BitSet,org.antlr.v4.test.tool.ATNConfigSet]",False,1596,3,0,0,0,2,7,13,1,5,6,7,0,0,0,0,0,0,1,0,7,0,1,0,0,0,34,1,0,False
876,..\projects\antlr4-4.11.0\tool-testsuite\test\org\antlr\v4\test\tool\TestPerformance.java,org.antlr.v4.test.tool.TestPerformance.SummarizingDiagnosticErrorListener,"void reportContextSensitivity(Parser, DFA, int, int, int, ATNConfigSet)","@Override
public void reportContextSensitivity(Parser recognizer, DFA dfa, int startIndex, int stopIndex, int prediction, ATNConfigSet configs) {
    if (COMPUTE_TRANSITION_STATS && DETAILED_DFA_STATE_STATS) {
        BitSet sllPredictions = getConflictingAlts(_sllConflict, _sllConfigs);
        int sllPrediction = sllPredictions.nextSetBit(0);
        if (sllPrediction != prediction) {
            ((StatisticsParserATNSimulator) recognizer.getInterpreter()).nonSll[dfa.decision]++;
        }
    }
    if (!REPORT_CONTEXT_SENSITIVITY) {
        return;
    }
    // show the rule name and viable configs along with the base info
    String format = ""reportContextSensitivity d=%d (%s), input='%s', viable={%d}"";
    int decision = dfa.decision;
    String rule = recognizer.getRuleNames()[dfa.atnStartState.ruleIndex];
    String input = recognizer.getTokenStream().getText(Interval.of(startIndex, stopIndex));
    recognizer.notifyErrorListeners(String.format(format, decision, rule, input, prediction));
}", ,"// show the rule name and viable configs along with the base info
",// show the rule name and viable configs along with the base info,1612,1632,[0],0,[0],0,[0],0,0,0,0,"reportContextSensitivity(Parser, DFA, int, int, int, ATNConfigSet)",org.antlr.v4.test.tool.TestPerformance$SummarizingDiagnosticErrorListener,"reportContextSensitivity/6[org.antlr.v4.test.tool.Parser,org.antlr.v4.test.tool.DFA,int,int,int,org.antlr.v4.test.tool.ATNConfigSet]",False,1613,4,0,0,0,5,9,17,1,6,6,9,0,0,0,1,0,1,1,1,6,0,2,0,0,0,41,1,0,False
877,..\projects\antlr4-4.11.0\tool-testsuite\test\org\antlr\v4\test\tool\TestSymbolIssues.java,org.antlr.v4.test.tool.TestSymbolIssues,void testWrongIdForTypeChannelModeCommand(),"// https://github.com/antlr/antlr4/issues/1411
@Test
public void testWrongIdForTypeChannelModeCommand() throws Exception {
    String[] test = { ""lexer grammar L;\n"" + ""tokens { TOKEN1 }\n"" + ""channels { CHANNEL1 }\n"" + ""TOKEN: 'asdf' -> type(CHANNEL1), channel(MODE1), mode(TOKEN1);\n"" + ""mode MODE1;\n"" + ""MODE1_TOKEN: 'qwer';"", ""error("" + ErrorType.CONSTANT_VALUE_IS_NOT_A_RECOGNIZED_TOKEN_NAME.code + ""): L.g4:4:22: CHANNEL1 is not a recognized token name\n"" + ""error("" + ErrorType.CONSTANT_VALUE_IS_NOT_A_RECOGNIZED_CHANNEL_NAME.code + ""): L.g4:4:41: MODE1 is not a recognized channel name\n"" + ""error("" + ErrorType.CONSTANT_VALUE_IS_NOT_A_RECOGNIZED_MODE_NAME.code + ""): L.g4:4:54: TOKEN1 is not a recognized mode name\n"" };
    testErrors(test, false);
}","// https://github.com/antlr/antlr4/issues/1411
", ,// https://github.com/antlr/antlr4/issues/1411,205,220,[0],0,[0],0,[0],0,0,0,0,testWrongIdForTypeChannelModeCommand(),org.antlr.v4.test.tool.TestSymbolIssues,testWrongIdForTypeChannelModeCommand/0,False,205,2,1,0,1,1,1,4,0,1,0,1,0,0,0,0,0,0,12,0,1,2,0,0,0,0,33,1,0,False
878,..\projects\antlr4-4.11.0\tool-testsuite\test\org\antlr\v4\test\tool\TestSymbolIssues.java,org.antlr.v4.test.tool.TestSymbolIssues,void testDuplicatedCommands(),"// https://github.com/antlr/antlr4/issues/1388
@Test
public void testDuplicatedCommands() throws Exception {
    String[] test = { ""lexer grammar Lexer;\n"" + ""channels { CHANNEL1, CHANNEL2 }\n"" + ""tokens { TEST1, TEST2 }\n"" + ""TOKEN: 'a' -> mode(MODE1), mode(MODE2);\n"" + ""TOKEN1: 'b' -> pushMode(MODE1), mode(MODE2);\n"" + ""TOKEN2: 'c' -> pushMode(MODE1), pushMode(MODE2); // pushMode is not duplicate\n"" + ""TOKEN3: 'd' -> popMode, popMode;                 // popMode is not duplicate\n"" + ""mode MODE1;\n"" + ""MODE1_TOKEN: 'e';\n"" + ""mode MODE2;\n"" + ""MODE2_TOKEN: 'f';\n"" + ""MODE2_TOKEN1: 'g' -> type(TEST1), type(TEST2);\n"" + ""MODE2_TOKEN2: 'h' -> channel(CHANNEL1), channel(CHANNEL2), channel(DEFAULT_TOKEN_CHANNEL);"", ""warning("" + ErrorType.DUPLICATED_COMMAND.code + ""): Lexer.g4:4:27: duplicated command mode\n"" + ""warning("" + ErrorType.DUPLICATED_COMMAND.code + ""): Lexer.g4:12:34: duplicated command type\n"" + ""warning("" + ErrorType.DUPLICATED_COMMAND.code + ""): Lexer.g4:13:40: duplicated command channel\n"" + ""warning("" + ErrorType.DUPLICATED_COMMAND.code + ""): Lexer.g4:13:59: duplicated command channel\n"" };
    testErrors(test, false);
}","// https://github.com/antlr/antlr4/issues/1388
", ,"// https://github.com/antlr/antlr4/issues/1388[[SEP]]// pushMode is not duplicate\n"" + ""TOKEN3: 'd' -> popMode, popMode;                 // popMode is not duplicate\n"" + ""mode MODE1;\n"" + ""MODE1_TOKEN: 'e';\n"" + ""mode MODE2;\n"" + ""MODE2_TOKEN: 'f';\n"" + ""MODE2_TOKEN1: 'g' -> type(TEST1), type(TEST2);\n"" + ""MODE2_TOKEN2: 'h' -> channel(CHANNEL1), channel(CHANNEL2), channel(DEFAULT_TOKEN_CHANNEL);"", ""warning("" + ErrorType.DUPLICATED_COMMAND.code + ""): Lexer.g4:4:27: duplicated command mode\n"" + ""warning("" + ErrorType.DUPLICATED_COMMAND.code + ""): Lexer.g4:12:34: duplicated command type\n"" + ""warning("" + ErrorType.DUPLICATED_COMMAND.code + ""): Lexer.g4:13:40: duplicated command channel\n"" + ""warning("" + ErrorType.DUPLICATED_COMMAND.code + ""): Lexer.g4:13:59: duplicated command channel\n"" };",223,246,[0],0,[0],0,"[0, 0]",0,0,0,0,testDuplicatedCommands(),org.antlr.v4.test.tool.TestSymbolIssues,testDuplicatedCommands/0,False,223,2,1,0,1,1,1,4,0,1,0,1,0,0,0,0,0,0,21,0,1,2,0,0,0,0,38,1,0,False
879,..\projects\antlr4-4.11.0\tool-testsuite\test\org\antlr\v4\test\tool\TestSymbolIssues.java,org.antlr.v4.test.tool.TestSymbolIssues,void testIncompatibleCommands(),"// https://github.com/antlr/antlr4/issues/1388
@Test
public void testIncompatibleCommands() throws Exception {
    String[] test = { ""lexer grammar L;\n"" + ""channels { CHANNEL1 }\n"" + ""tokens { TYPE1 }\n"" + ""// Incompatible\n"" + ""T00: 'a00' -> skip, more;\n"" + ""T01: 'a01' -> skip, type(TYPE1);\n"" + ""T02: 'a02' -> skip, channel(CHANNEL1);\n"" + ""T03: 'a03' -> more, type(TYPE1);\n"" + ""T04: 'a04' -> more, channel(CHANNEL1);\n"" + ""T05: 'a05' -> more, skip;\n"" + ""T06: 'a06' -> type(TYPE1), skip;\n"" + ""T07: 'a07' -> type(TYPE1), more;\n"" + ""T08: 'a08' -> channel(CHANNEL1), skip;\n"" + ""T09: 'a09' -> channel(CHANNEL1), more;\n"" + ""// Allowed\n"" + ""T10: 'a10' -> type(TYPE1), channel(CHANNEL1);\n"" + ""T11: 'a11' -> channel(CHANNEL1), type(TYPE1);"", ""warning("" + ErrorType.INCOMPATIBLE_COMMANDS.code + ""): L.g4:5:20: incompatible commands skip and more\n"" + ""warning("" + ErrorType.INCOMPATIBLE_COMMANDS.code + ""): L.g4:6:20: incompatible commands skip and type\n"" + ""warning("" + ErrorType.INCOMPATIBLE_COMMANDS.code + ""): L.g4:7:20: incompatible commands skip and channel\n"" + ""warning("" + ErrorType.INCOMPATIBLE_COMMANDS.code + ""): L.g4:8:20: incompatible commands more and type\n"" + ""warning("" + ErrorType.INCOMPATIBLE_COMMANDS.code + ""): L.g4:9:20: incompatible commands more and channel\n"" + ""warning("" + ErrorType.INCOMPATIBLE_COMMANDS.code + ""): L.g4:10:20: incompatible commands more and skip\n"" + ""warning("" + ErrorType.INCOMPATIBLE_COMMANDS.code + ""): L.g4:11:27: incompatible commands type and skip\n"" + ""warning("" + ErrorType.INCOMPATIBLE_COMMANDS.code + ""): L.g4:12:27: incompatible commands type and more\n"" + ""warning("" + ErrorType.INCOMPATIBLE_COMMANDS.code + ""): L.g4:13:33: incompatible commands channel and skip\n"" + ""warning("" + ErrorType.INCOMPATIBLE_COMMANDS.code + ""): L.g4:14:33: incompatible commands channel and more\n"" };
    testErrors(test, false);
}","// https://github.com/antlr/antlr4/issues/1388
", ,"// https://github.com/antlr/antlr4/issues/1388[[SEP]]// Incompatible\n"" + ""T00: 'a00' -> skip, more;\n"" + ""T01: 'a01' -> skip, type(TYPE1);\n"" + ""T02: 'a02' -> skip, channel(CHANNEL1);\n"" + ""T03: 'a03' -> more, type(TYPE1);\n"" + ""T04: 'a04' -> more, channel(CHANNEL1);\n"" + ""T05: 'a05' -> more, skip;\n"" + ""T06: 'a06' -> type(TYPE1), skip;\n"" + ""T07: 'a07' -> type(TYPE1), more;\n"" + ""T08: 'a08' -> channel(CHANNEL1), skip;\n"" + ""T09: 'a09' -> channel(CHANNEL1), more;\n"" + ""// Allowed\n"" + ""T10: 'a10' -> type(TYPE1), channel(CHANNEL1);\n"" + ""T11: 'a11' -> channel(CHANNEL1), type(TYPE1);"", ""warning("" + ErrorType.INCOMPATIBLE_COMMANDS.code + ""): L.g4:5:20: incompatible commands skip and more\n"" + ""warning("" + ErrorType.INCOMPATIBLE_COMMANDS.code + ""): L.g4:6:20: incompatible commands skip and type\n"" + ""warning("" + ErrorType.INCOMPATIBLE_COMMANDS.code + ""): L.g4:7:20: incompatible commands skip and channel\n"" + ""warning("" + ErrorType.INCOMPATIBLE_COMMANDS.code + ""): L.g4:8:20: incompatible commands more and type\n"" + ""warning("" + ErrorType.INCOMPATIBLE_COMMANDS.code + ""): L.g4:9:20: incompatible commands more and channel\n"" + ""warning("" + ErrorType.INCOMPATIBLE_COMMANDS.code + ""): L.g4:10:20: incompatible commands more and skip\n"" + ""warning("" + ErrorType.INCOMPATIBLE_COMMANDS.code + ""): L.g4:11:27: incompatible commands type and skip\n"" + ""warning("" + ErrorType.INCOMPATIBLE_COMMANDS.code + ""): L.g4:12:27: incompatible commands type and more\n"" + ""warning("" + ErrorType.INCOMPATIBLE_COMMANDS.code + ""): L.g4:13:33: incompatible commands channel and skip\n"" + ""warning("" + ErrorType.INCOMPATIBLE_COMMANDS.code + ""): L.g4:14:33: incompatible commands channel and more\n"" };",249,282,[0],0,[0],0,"[0, 0]",0,0,0,0,testIncompatibleCommands(),org.antlr.v4.test.tool.TestSymbolIssues,testIncompatibleCommands/0,False,249,2,1,0,1,1,1,4,0,1,0,1,0,0,0,0,0,0,37,0,1,2,0,0,0,0,24,1,0,False
880,..\projects\antlr4-4.11.0\tool-testsuite\test\org\antlr\v4\test\tool\TestSymbolIssues.java,org.antlr.v4.test.tool.TestSymbolIssues,void testLabelsForTokensWithMixedTypes(),"// https://github.com/antlr/antlr4/issues/1409
@Test
public void testLabelsForTokensWithMixedTypes() {
    String[] test = { ""grammar L;\n"" + ""\n"" + ""rule1                                      // Correct (Alternatives)\n"" + ""    : t1=a  #aLabel\n"" + ""    | t1=b  #bLabel\n"" + ""    ;\n"" + ""rule2                         //Incorrect type casting in generated code (RULE_LABEL)\n"" + ""    : t2=a | t2=b\n"" + ""    ;\n"" + ""rule3\n"" + ""    : t3+=a+ b t3+=c+     //Incorrect type casting in generated code (RULE_LIST_LABEL)\n"" + ""    ;\n"" + ""rule4\n"" + ""    : a t4=A b t4=B c                  // Correct (TOKEN_LABEL)\n"" + ""    ;\n"" + ""rule5\n"" + ""    : a t5+=A b t5+=B c                // Correct (TOKEN_LIST_LABEL)\n"" + ""    ;\n"" + ""rule6                     // Correct (https://github.com/antlr/antlr4/issues/1543)\n"" + ""    : t6=a                          #t6_1_Label\n"" + ""    | t6=rule6 b (t61=c)? t62=rule6 #t6_2_Label\n"" + ""    | t6=A     a (t61=B)? t62=A     #t6_3_Label\n"" + ""    ;\n"" + ""rule7                     // Incorrect (https://github.com/antlr/antlr4/issues/1543)\n"" + ""    : a\n"" + ""    | t7=rule7 b (t71=c)? t72=rule7 \n"" + ""    | t7=A     a (t71=B)? t72=A     \n"" + ""    ;\n"" + ""rule8                     // Correct (https://github.com/antlr/antlr4/issues/1543)\n"" + ""    : a\n"" + ""    | t8=rule8 a t8=rule8\n"" + ""    | t8=rule8 b t8=rule8\n"" + ""    ;\n"" + ""a: A;\n"" + ""b: B;\n"" + ""c: C;\n"" + ""A: 'a';\n"" + ""B: 'b';\n"" + ""C: 'c';\n"", ""error("" + ErrorType.LABEL_TYPE_CONFLICT.code + ""): L.g4:8:13: label t2=b type mismatch with previous definition: t2=a\n"" + ""error("" + ErrorType.LABEL_TYPE_CONFLICT.code + ""): L.g4:11:15: label t3+=c type mismatch with previous definition: t3+=a\n"" + ""error("" + ErrorType.LABEL_TYPE_CONFLICT.code + ""): L.g4:24:0: label t7 type mismatch with previous definition: TOKEN_LABEL!=RULE_LABEL\n"" + ""error("" + ErrorType.LABEL_TYPE_CONFLICT.code + ""): L.g4:24:0: label t71 type mismatch with previous definition: RULE_LABEL!=TOKEN_LABEL\n"" + ""error("" + ErrorType.LABEL_TYPE_CONFLICT.code + ""): L.g4:24:0: label t72 type mismatch with previous definition: RULE_LABEL!=TOKEN_LABEL\n"" };
    testErrors(test, false);
}","// https://github.com/antlr/antlr4/issues/1409
", ,"// https://github.com/antlr/antlr4/issues/1409[[SEP]]// Correct (Alternatives)\n"" + ""    : t1=a  #aLabel\n"" + ""    | t1=b  #bLabel\n"" + ""    ;\n"" + ""rule2                         //Incorrect type casting in generated code (RULE_LABEL)\n"" + ""    : t2=a | t2=b\n"" + ""    ;\n"" + ""rule3\n"" + ""    : t3+=a+ b t3+=c+     //Incorrect type casting in generated code (RULE_LIST_LABEL)\n"" + ""    ;\n"" + ""rule4\n"" + ""    : a t4=A b t4=B c                  // Correct (TOKEN_LABEL)\n"" + ""    ;\n"" + ""rule5\n"" + ""    : a t5+=A b t5+=B c                // Correct (TOKEN_LIST_LABEL)\n"" + ""    ;\n"" + ""rule6                     // Correct (https://github.com/antlr/antlr4/issues/1543)\n"" + ""    : t6=a                          #t6_1_Label\n"" + ""    | t6=rule6 b (t61=c)? t62=rule6 #t6_2_Label\n"" + ""    | t6=A     a (t61=B)? t62=A     #t6_3_Label\n"" + ""    ;\n"" + ""rule7                     // Incorrect (https://github.com/antlr/antlr4/issues/1543)\n"" + ""    : a\n"" + ""    | t7=rule7 b (t71=c)? t72=rule7 \n"" + ""    | t7=A     a (t71=B)? t72=A     \n"" + ""    ;\n"" + ""rule8                     // Correct (https://github.com/antlr/antlr4/issues/1543)\n"" + ""    : a\n"" + ""    | t8=rule8 a t8=rule8\n"" + ""    | t8=rule8 b t8=rule8\n"" + ""    ;\n"" + ""a: A;\n"" + ""b: B;\n"" + ""c: C;\n"" + ""A: 'a';\n"" + ""B: 'b';\n"" + ""C: 'c';\n"", ""error("" + ErrorType.LABEL_TYPE_CONFLICT.code + ""): L.g4:8:13: label t2=b type mismatch with previous definition: t2=a\n"" + ""error("" + ErrorType.LABEL_TYPE_CONFLICT.code + ""): L.g4:11:15: label t3+=c type mismatch with previous definition: t3+=a\n"" + ""error("" + ErrorType.LABEL_TYPE_CONFLICT.code + ""): L.g4:24:0: label t7 type mismatch with previous definition: TOKEN_LABEL!=RULE_LABEL\n"" + ""error("" + ErrorType.LABEL_TYPE_CONFLICT.code + ""): L.g4:24:0: label t71 type mismatch with previous definition: RULE_LABEL!=TOKEN_LABEL\n"" + ""error("" + ErrorType.LABEL_TYPE_CONFLICT.code + ""): L.g4:24:0: label t72 type mismatch with previous definition: RULE_LABEL!=TOKEN_LABEL\n"" };",285,336,[0],0,[0],0,"[0, 0]",0,0,0,0,testLabelsForTokensWithMixedTypes(),org.antlr.v4.test.tool.TestSymbolIssues,testLabelsForTokensWithMixedTypes/0,False,285,2,1,0,1,1,1,4,0,1,0,1,0,0,0,0,0,0,49,0,1,2,0,0,0,0,55,1,0,False
881,..\projects\antlr4-4.11.0\tool-testsuite\test\org\antlr\v4\test\tool\TestSymbolIssues.java,org.antlr.v4.test.tool.TestSymbolIssues,void testLabelsForTokensWithMixedTypesLRWithLabels(),"// https://github.com/antlr/antlr4/issues/1543
@Test
public void testLabelsForTokensWithMixedTypesLRWithLabels() {
    String[] test = { ""grammar L;\n"" + ""\n"" + ""expr\n"" + ""    : left=A '+' right=A        #primary\n"" + ""    | left=expr '-' right=expr  #sub\n"" + ""    ;\n"" + ""\n"" + ""A: 'a';\n"" + ""B: 'b';\n"" + ""C: 'c';\n"", """" };
    testErrors(test, false);
}","// https://github.com/antlr/antlr4/issues/1543
", ,// https://github.com/antlr/antlr4/issues/1543,339,356,[0],0,[0],0,[0],0,0,0,0,testLabelsForTokensWithMixedTypesLRWithLabels(),org.antlr.v4.test.tool.TestSymbolIssues,testLabelsForTokensWithMixedTypesLRWithLabels/0,False,339,2,1,0,1,1,1,4,0,1,0,1,0,0,0,0,0,0,11,0,1,1,0,0,0,0,14,1,0,False
882,..\projects\antlr4-4.11.0\tool-testsuite\test\org\antlr\v4\test\tool\TestSymbolIssues.java,org.antlr.v4.test.tool.TestSymbolIssues,void testLabelsForTokensWithMixedTypesLRWithoutLabels(),"// https://github.com/antlr/antlr4/issues/1543
@Test
public void testLabelsForTokensWithMixedTypesLRWithoutLabels() {
    String[] test = { ""grammar L;\n"" + ""\n"" + ""expr\n"" + ""    : left=A '+' right=A\n"" + ""    | left=expr '-' right=expr\n"" + ""    ;\n"" + ""\n"" + ""A: 'a';\n"" + ""B: 'b';\n"" + ""C: 'c';\n"", ""error("" + ErrorType.LABEL_TYPE_CONFLICT.code + ""): L.g4:3:0: label left type mismatch with previous definition: TOKEN_LABEL!=RULE_LABEL\n"" + ""error("" + ErrorType.LABEL_TYPE_CONFLICT.code + ""): L.g4:3:0: label right type mismatch with previous definition: RULE_LABEL!=TOKEN_LABEL\n"" };
    testErrors(test, false);
}","// https://github.com/antlr/antlr4/issues/1543
", ,// https://github.com/antlr/antlr4/issues/1543,359,378,[0],0,[0],0,[0],0,0,0,0,testLabelsForTokensWithMixedTypesLRWithoutLabels(),org.antlr.v4.test.tool.TestSymbolIssues,testLabelsForTokensWithMixedTypesLRWithoutLabels/0,False,360,2,1,0,1,1,1,4,0,1,0,1,0,0,0,0,0,0,14,0,1,2,0,0,0,0,28,1,0,False
883,..\projects\antlr4-4.11.0\tool-testsuite\test\org\antlr\v4\test\tool\TestSymbolIssues.java,org.antlr.v4.test.tool.TestSymbolIssues,void testCaseInsensitiveWithUnicodeRanges(),"@Test
public void testCaseInsensitiveWithUnicodeRanges() {
    String[] test = { ""lexer grammar L;\n"" + ""options { caseInsensitive=true; }\n"" + ""FullWidthLetter\n"" + ""    : '\\u00c0'..'\\u00d6' // ÀÁÂÃÄÅÆÇÈÉÊËÌÍÎÏÐÑÒÓÔÕÖ\n"" + ""    | '\\u00f8'..'\\u00ff' // øùúûüýþÿ\n"" + ""    ;"", """" };
    // Don't transform øùúûüýþÿ to uppercase
    // ØÙÚÛÜÝÞßàáâãäåæçèéêëìíîïðñòóôõö÷øùúûüýþÿĀāĂăĄąĆćĈĉĊċČčĎďĐđĒēĔĕĖėĘęĚěĜĝĞğĠġĢģĤĥĦħĨĩĪīĬĭĮįİıĲĳĴĵĶķĸĹĺĻļĽľĿŀŁłŃńŅņŇňŉŊŋŌōŎŏŐőŒœŔŕŖŗŘřŚśŜŝŞşŠšŢţŤťŦŧŨũŪūŬŭŮůŰűŲųŴŵŶŷŸ
    // because of different length of lower and UPPER range
    testErrors(test, false);
}", ,"// Don't transform øùúûüýþÿ to uppercase
[[SEP]]// ØÙÚÛÜÝÞßàáâãäåæçèéêëìíîïðñòóôõö÷øùúûüýþÿĀāĂăĄąĆćĈĉĊċČčĎďĐđĒēĔĕĖėĘęĚěĜĝĞğĠġĢģĤĥĦħĨĩĪīĬĭĮįİıĲĳĴĵĶķĸĹĺĻļĽľĿŀŁłŃńŅņŇňŉŊŋŌōŎŏŐőŒœŔŕŖŗŘřŚśŜŝŞşŠšŢţŤťŦŧŨũŪūŬŭŮůŰűŲųŴŵŶŷŸ
[[SEP]]// because of different length of lower and UPPER range
","// ÀÁÂÃÄÅÆÇÈÉÊËÌÍÎÏÐÑÒÓÔÕÖ\n"" + ""    | '\\u00f8'..'\\u00ff' // øùúûüýþÿ\n"" + ""    ;"", """" };[[SEP]]// Don't transform øùúûüýþÿ to uppercase// ØÙÚÛÜÝÞßàáâãäåæçèéêëìíîïðñòóôõö÷øùúûüýþÿĀāĂăĄąĆćĈĉĊċČčĎďĐđĒēĔĕĖėĘęĚěĜĝĞğĠġĢģĤĥĦħĨĩĪīĬĭĮįİıĲĳĴĵĶķĸĹĺĻļĽľĿŀŁłŃńŅņŇňŉŊŋŌōŎŏŐőŒœŔŕŖŗŘřŚśŜŝŞşŠšŢţŤťŦŧŨũŪūŬŭŮůŰűŲųŴŵŶŷŸ// because of different length of lower and UPPER range",417,433,[0],0,"[0, 0, 0]",0,"[0, 0]",0,0,0,0,testCaseInsensitiveWithUnicodeRanges(),org.antlr.v4.test.tool.TestSymbolIssues,testCaseInsensitiveWithUnicodeRanges/0,False,417,2,1,0,1,1,1,4,0,1,0,1,0,0,0,0,0,0,7,0,1,1,0,0,0,0,11,1,0,False
884,..\projects\antlr4-4.11.0\tool-testsuite\test\org\antlr\v4\test\tool\TestSymbolIssues.java,org.antlr.v4.test.tool.TestSymbolIssues,void testUndefinedLabel(),"// ISSUE: https://github.com/antlr/antlr4/issues/2788
@Test
public void testUndefinedLabel() {
    String[] test = { ""grammar Test;"" + ""root\n"" + ""    : root a\n"" + ""    | b [error]\n"" + ""    ;\n"" + ""\n"" + ""a: 'a';\n"" + ""b: 'b';"", ""error("" + ErrorType.INTERNAL_ERROR.code + ""): Test.g4:2:30: internal error: Rule error undefined \n"" };
    testErrors(test, false);
}","// ISSUE: https://github.com/antlr/antlr4/issues/2788
", ,// ISSUE: https://github.com/antlr/antlr4/issues/2788,542,557,[0],0,[0],0,[0],0,0,0,0,testUndefinedLabel(),org.antlr.v4.test.tool.TestSymbolIssues,testUndefinedLabel/0,False,542,2,1,0,1,1,1,4,0,1,0,1,0,0,0,0,0,0,10,0,1,2,0,0,0,0,11,1,0,False
885,..\projects\antlr4-4.11.0\tool-testsuite\test\org\antlr\v4\test\tool\TestTokenTypeAssignment.java,org.antlr.v4.test.tool.TestTokenTypeAssignment,void testCombinedGrammarLiterals(),"@Test
public void testCombinedGrammarLiterals() throws Exception {
    Grammar g = new Grammar(""grammar t;\n"" + ""a : 'begin' b 'end';\n"" + ""b : C ';' ;\n"" + ""ID : 'a' ;\n"" + // ""foo"" is not a token name
    ""FOO : 'foo' ;\n"" + // nor is 'c'
    ""C : 'c' ;\n"");
    String rules = ""a, b"";
    String tokenNames = ""C, FOO, ID, 'begin', 'end', ';'"";
    checkSymbols(g, rules, tokenNames);
}", ,"// ""foo"" is not a token name
[[SEP]]// nor is 'c'
","// ""foo"" is not a token name[[SEP]]// nor is 'c'",60,71,[0],0,"[0, 0]",0,"[0, 0]",0,0,0,0,testCombinedGrammarLiterals(),org.antlr.v4.test.tool.TestTokenTypeAssignment,testCombinedGrammarLiterals/0,False,60,3,2,0,2,1,1,6,0,3,0,1,1,1,0,0,0,0,8,0,3,1,0,0,0,0,14,1,0,False
886,..\projects\antlr4-4.11.0\tool-testsuite\test\org\antlr\v4\test\tool\TestTokenTypeAssignment.java,org.antlr.v4.test.tool.TestTokenTypeAssignment,void testLiteralInParserAndLexer(),"@Test
public void testLiteralInParserAndLexer() throws Exception {
    // 'x' is token and char in lexer rule
    Grammar g = new Grammar(""grammar t;\n"" + ""a : 'x' E ; \n"" + ""E: 'x' '0' ;\n"");
    String literals = ""['x']"";
    String foundLiterals = g.stringLiteralToTypeMap.keySet().toString();
    assertEquals(literals, foundLiterals);
    foundLiterals = g.implicitLexer.stringLiteralToTypeMap.keySet().toString();
    // pushed in lexer from parser
    assertEquals(""['x']"", foundLiterals);
    String[] typeToTokenName = g.getTokenDisplayNames();
    Set<String> tokens = new LinkedHashSet<String>();
    for (String t : typeToTokenName) if (t != null)
        tokens.add(t);
    assertEquals(""[<INVALID>, 'x', E]"", tokens.toString());
}", ,"// 'x' is token and char in lexer rule
[[SEP]]// pushed in lexer from parser
",// 'x' is token and char in lexer rule[[SEP]]// pushed in lexer from parser,73,91,[0],0,"[0, 0]",0,"[0, 0]",0,0,0,0,testLiteralInParserAndLexer(),org.antlr.v4.test.tool.TestTokenTypeAssignment,testLiteralInParserAndLexer/0,False,73,2,2,0,2,3,5,12,0,5,0,5,0,0,1,1,0,0,6,0,6,1,2,0,0,0,22,1,0,False
887,..\projects\antlr4-4.11.0\tool-testsuite\test\org\antlr\v4\test\tool\TestTokenTypeAssignment.java,org.antlr.v4.test.tool.TestTokenTypeAssignment,void testPredDoesNotHideNameToLiteralMapInLexer(),"@Test
public void testPredDoesNotHideNameToLiteralMapInLexer() throws Exception {
    // 'x' is token and char in lexer rule
    Grammar g = new Grammar(""grammar t;\n"" + ""a : 'x' X ; \n"" + // must match as alias even with pred
    ""X: 'x' {true}?;\n"");
    assertEquals(""{'x'=1}"", g.stringLiteralToTypeMap.toString());
    assertEquals(""{EOF=-1, X=1}"", g.tokenNameToTypeMap.toString());
    // pushed in lexer from parser
    assertEquals(""{'x'=1}"", g.implicitLexer.stringLiteralToTypeMap.toString());
    assertEquals(""{EOF=-1, X=1}"", g.implicitLexer.tokenNameToTypeMap.toString());
}", ,"// 'x' is token and char in lexer rule
[[SEP]]// must match as alias even with pred
[[SEP]]// pushed in lexer from parser
",// 'x' is token and char in lexer rule[[SEP]]// must match as alias even with pred[[SEP]]// pushed in lexer from parser,93,106,[0],0,"[0, 0, 0]",0,"[0, 0, 0]",0,0,0,0,testPredDoesNotHideNameToLiteralMapInLexer(),org.antlr.v4.test.tool.TestTokenTypeAssignment,testPredDoesNotHideNameToLiteralMapInLexer/0,False,93,2,1,0,1,1,2,7,0,1,0,2,0,0,0,0,0,0,7,0,1,1,0,0,0,0,22,1,0,False
888,..\projects\antlr4-4.11.0\tool-testsuite\test\org\antlr\v4\test\tool\TestTokenTypeAssignment.java,org.antlr.v4.test.tool.TestTokenTypeAssignment,void testParserCharLiteralWithEscape(),"// T E S T  L I T E R A L  E S C A P E S
@Test
public void testParserCharLiteralWithEscape() throws Exception {
    Grammar g = new Grammar(""grammar t;\n"" + ""a : '\\n';\n"");
    Set<?> literals = g.stringLiteralToTypeMap.keySet();
    // must store literals how they appear in the antlr grammar
    assertEquals(""'\\n'"", literals.toArray()[0]);
}", ,"// must store literals how they appear in the antlr grammar
",// T E S T  L I T E R A L  E S C A P E S[[SEP]]// must store literals how they appear in the antlr grammar,131,138,[0],0,[0],0,"[0, 0]",0,0,1,0,testParserCharLiteralWithEscape(),org.antlr.v4.test.tool.TestTokenTypeAssignment,testParserCharLiteralWithEscape/0,False,131,2,1,0,1,1,3,5,0,2,0,3,0,0,0,0,0,0,3,1,2,1,0,0,0,0,13,1,0,False
889,..\projects\antlr4-4.11.0\tool-testsuite\test\org\antlr\v4\test\tool\TestTokenTypeAssignment.java,org.antlr.v4.test.tool.TestTokenTypeAssignment,void testParserCharLiteralWithBasicUnicodeEscape(),"@Test
public void testParserCharLiteralWithBasicUnicodeEscape() throws Exception {
    Grammar g = new Grammar(""grammar t;\n"" + ""a : '\\uABCD';\n"");
    Set<?> literals = g.stringLiteralToTypeMap.keySet();
    // must store literals how they appear in the antlr grammar
    assertEquals(""'\\uABCD'"", literals.toArray()[0]);
}", ,"// must store literals how they appear in the antlr grammar
",// must store literals how they appear in the antlr grammar,140,147,[0],0,[0],0,[0],0,0,1,0,testParserCharLiteralWithBasicUnicodeEscape(),org.antlr.v4.test.tool.TestTokenTypeAssignment,testParserCharLiteralWithBasicUnicodeEscape/0,False,140,2,1,0,1,1,3,5,0,2,0,3,0,0,0,0,0,0,3,1,2,1,0,0,0,0,15,1,0,False
890,..\projects\antlr4-4.11.0\tool-testsuite\test\org\antlr\v4\test\tool\TestTokenTypeAssignment.java,org.antlr.v4.test.tool.TestTokenTypeAssignment,void testParserCharLiteralWithExtendedUnicodeEscape(),"@Test
public void testParserCharLiteralWithExtendedUnicodeEscape() throws Exception {
    Grammar g = new Grammar(""grammar t;\n"" + ""a : '\\u{1ABCD}';\n"");
    Set<?> literals = g.stringLiteralToTypeMap.keySet();
    // must store literals how they appear in the antlr grammar
    assertEquals(""'\\u{1ABCD}'"", literals.toArray()[0]);
}", ,"// must store literals how they appear in the antlr grammar
",// must store literals how they appear in the antlr grammar,149,156,[0],0,[0],0,[0],0,0,1,0,testParserCharLiteralWithExtendedUnicodeEscape(),org.antlr.v4.test.tool.TestTokenTypeAssignment,testParserCharLiteralWithExtendedUnicodeEscape/0,False,149,2,1,0,1,1,3,5,0,2,0,3,0,0,0,0,0,0,3,1,2,1,0,0,0,0,20,1,0,False
891,..\projects\antlr4-4.11.0\tool-testsuite\test\org\antlr\v4\test\tool\TestTokenTypeAssignment.java,org.antlr.v4.test.tool.TestTokenTypeAssignment,"void checkSymbols(Grammar, String, String)","protected void checkSymbols(Grammar g, String rulesStr, String allValidTokensStr) throws Exception {
    String[] typeToTokenName = g.getTokenNames();
    Set<String> tokens = new HashSet<String>();
    for (int i = 0; i < typeToTokenName.length; i++) {
        String t = typeToTokenName[i];
        if (t != null) {
            if (t.startsWith(Grammar.AUTO_GENERATED_TOKEN_NAME_PREFIX)) {
                tokens.add(g.getTokenDisplayName(i));
            } else {
                tokens.add(t);
            }
        }
    }
    // make sure expected tokens are there
    StringTokenizer st = new StringTokenizer(allValidTokensStr, "", "");
    while (st.hasMoreTokens()) {
        String tokenName = st.nextToken();
        assertTrue(g.getTokenType(tokenName) != Token.INVALID_TYPE, ""token "" + tokenName + "" expected, but was undefined"");
        tokens.remove(tokenName);
    }
    // make sure there are not any others (other than <EOF> etc...)
    for (String tokenName : tokens) {
        assertTrue(g.getTokenType(tokenName) < Token.MIN_USER_TOKEN_TYPE, ""unexpected token name "" + tokenName);
    }
    // make sure all expected rules are there
    st = new StringTokenizer(rulesStr, "", "");
    int n = 0;
    while (st.hasMoreTokens()) {
        String ruleName = st.nextToken();
        assertNotNull(g.getRule(ruleName), ""rule "" + ruleName + "" expected"");
        n++;
    }
    // System.out.println(""rules=""+rules);
    // make sure there are no extra rules
    assertEquals(n, g.rules.size(), ""number of rules mismatch; expecting "" + n + ""; found "" + g.rules.size());
}", ,"// System.out.println(""rules=""+rules);
[[SEP]]// make sure expected tokens are there
[[SEP]]// make sure there are not any others (other than <EOF> etc...)
[[SEP]]// make sure all expected rules are there
[[SEP]]// make sure there are no extra rules
","// make sure expected tokens are there[[SEP]]// make sure there are not any others (other than <EOF> etc...)[[SEP]]// make sure all expected rules are there[[SEP]]// System.out.println(""rules=""+rules);// make sure there are no extra rules",158,200,[0],0,"[0, 0, 0, 0, 0]",0,"[0, 0, 0, 0]",0,0,0,0,"checkSymbols(Grammar, String, String)",org.antlr.v4.test.tool.TestTokenTypeAssignment,"checkSymbols/3[org.antlr.v4.tool.Grammar,java.lang.String,java.lang.String]",False,162,1,10,6,4,7,13,32,0,8,3,13,0,0,4,2,0,0,9,2,9,4,3,0,0,0,35,4,0,False
892,..\projects\antlr4-4.11.0\tool-testsuite\test\org\antlr\v4\test\tool\TestToolSyntaxErrors.java,org.antlr.v4.test.tool.TestToolSyntaxErrors,void testUnterminatedStringLiteral(),"/**
 * This is a regression test for antlr/antlr4#243
 * ""Generate a good message for unterminated strings""
 * https://github.com/antlr/antlr4/issues/243
 */
@Test
public void testUnterminatedStringLiteral() {
    String[] pair = new String[] { ""grammar A;\n"" + ""a : 'x\n"" + ""  ;\n"", ""error("" + ErrorType.UNTERMINATED_STRING_LITERAL.code + ""): A.g4:2:4: unterminated string literal\n"" };
    testErrors(pair, true);
}","/**
 * This is a regression test for antlr/antlr4#243
 * ""Generate a good message for unterminated strings""
 * https://github.com/antlr/antlr4/issues/243
 */
", ,"/** * This is a regression test for antlr/antlr4#243 * ""Generate a good message for unterminated strings"" * https://github.com/antlr/antlr4/issues/243 */",174,183,[0],0,[0],0,[0],0,0,0,0,testUnterminatedStringLiteral(),org.antlr.v4.test.tool.TestToolSyntaxErrors,testUnterminatedStringLiteral/0,False,174,2,1,0,1,1,1,4,0,1,0,1,0,0,0,0,0,0,5,0,1,2,0,0,0,0,18,1,0,True
893,..\projects\antlr4-4.11.0\tool-testsuite\test\org\antlr\v4\test\tool\TestToolSyntaxErrors.java,org.antlr.v4.test.tool.TestToolSyntaxErrors,void testParserRuleNameStartingWithUnderscore(),"/**
 * This is a regression test for antlr/antlr4#262
 * ""Parser Rule Name Starting With an Underscore""
 * https://github.com/antlr/antlr4/issues/262
 */
@Test
public void testParserRuleNameStartingWithUnderscore() {
    String[] pair = new String[] { ""grammar A;\n"" + ""_a : 'x' ;\n"", ""error("" + ErrorType.SYNTAX_ERROR.code + ""): A.g4:2:0: syntax error: '_' came as a complete surprise to me\n"" };
    testErrors(pair, true);
}","/**
 * This is a regression test for antlr/antlr4#262
 * ""Parser Rule Name Starting With an Underscore""
 * https://github.com/antlr/antlr4/issues/262
 */
", ,"/** * This is a regression test for antlr/antlr4#262 * ""Parser Rule Name Starting With an Underscore"" * https://github.com/antlr/antlr4/issues/262 */",190,198,[0],0,[0],0,[0],0,0,0,0,testParserRuleNameStartingWithUnderscore(),org.antlr.v4.test.tool.TestToolSyntaxErrors,testParserRuleNameStartingWithUnderscore/0,False,190,2,1,0,1,1,1,4,0,1,0,1,0,0,0,0,0,0,4,0,1,2,0,0,0,0,24,1,0,True
894,..\projects\antlr4-4.11.0\tool-testsuite\test\org\antlr\v4\test\tool\TestToolSyntaxErrors.java,org.antlr.v4.test.tool.TestToolSyntaxErrors,void testEmptyGrammarOptions(),"/**
 * This is a regression test for antlr/antlr4#194
 * ""NullPointerException on 'options{}' in grammar file""
 * https://github.com/antlr/antlr4/issues/194
 */
@Test
public void testEmptyGrammarOptions() {
    String[] pair = new String[] { ""grammar A;\n"" + ""options {}\n"" + ""a : 'x' ;\n"", """" };
    testErrors(pair, true);
}","/**
 * This is a regression test for antlr/antlr4#194
 * ""NullPointerException on 'options{}' in grammar file""
 * https://github.com/antlr/antlr4/issues/194
 */
", ,"/** * This is a regression test for antlr/antlr4#194 * ""NullPointerException on 'options{}' in grammar file"" * https://github.com/antlr/antlr4/issues/194 */",205,214,[0],0,[0],0,[0],0,0,0,0,testEmptyGrammarOptions(),org.antlr.v4.test.tool.TestToolSyntaxErrors,testEmptyGrammarOptions/0,False,205,2,1,0,1,1,1,4,0,1,0,1,0,0,0,0,0,0,4,0,1,1,0,0,0,0,17,1,0,True
895,..\projects\antlr4-4.11.0\tool-testsuite\test\org\antlr\v4\test\tool\TestToolSyntaxErrors.java,org.antlr.v4.test.tool.TestToolSyntaxErrors,void testEmptyRuleOptions(),"/**
 * This is a ""related"" regression test for antlr/antlr4#194
 * ""NullPointerException on 'options{}' in grammar file""
 * https://github.com/antlr/antlr4/issues/194
 */
@Test
public void testEmptyRuleOptions() {
    String[] pair = new String[] { ""grammar A;\n"" + ""a options{} : 'x' ;\n"", """" };
    testErrors(pair, true);
}","/**
 * This is a ""related"" regression test for antlr/antlr4#194
 * ""NullPointerException on 'options{}' in grammar file""
 * https://github.com/antlr/antlr4/issues/194
 */
", ,"/** * This is a ""related"" regression test for antlr/antlr4#194 * ""NullPointerException on 'options{}' in grammar file"" * https://github.com/antlr/antlr4/issues/194 */",221,229,[0],0,[0],0,[0],0,0,0,0,testEmptyRuleOptions(),org.antlr.v4.test.tool.TestToolSyntaxErrors,testEmptyRuleOptions/0,False,221,2,1,0,1,1,1,4,0,1,0,1,0,0,0,0,0,0,3,0,1,1,0,0,0,0,18,1,0,True
896,..\projects\antlr4-4.11.0\tool-testsuite\test\org\antlr\v4\test\tool\TestToolSyntaxErrors.java,org.antlr.v4.test.tool.TestToolSyntaxErrors,void testEmptyBlockOptions(),"/**
 * This is a ""related"" regression test for antlr/antlr4#194
 * ""NullPointerException on 'options{}' in grammar file""
 * https://github.com/antlr/antlr4/issues/194
 */
@Test
public void testEmptyBlockOptions() {
    String[] pair = new String[] { ""grammar A;\n"" + ""a : (options{} : 'x') ;\n"", """" };
    testErrors(pair, true);
}","/**
 * This is a ""related"" regression test for antlr/antlr4#194
 * ""NullPointerException on 'options{}' in grammar file""
 * https://github.com/antlr/antlr4/issues/194
 */
", ,"/** * This is a ""related"" regression test for antlr/antlr4#194 * ""NullPointerException on 'options{}' in grammar file"" * https://github.com/antlr/antlr4/issues/194 */",236,244,[0],0,[0],0,[0],0,0,0,0,testEmptyBlockOptions(),org.antlr.v4.test.tool.TestToolSyntaxErrors,testEmptyBlockOptions/0,False,236,2,1,0,1,1,1,4,0,1,0,1,0,0,0,0,0,0,3,0,1,1,0,0,0,0,18,1,0,True
897,..\projects\antlr4-4.11.0\tool-testsuite\test\org\antlr\v4\test\tool\TestToolSyntaxErrors.java,org.antlr.v4.test.tool.TestToolSyntaxErrors,void testInvalidLexerCommand(),"/**
 * This is a regression test for antlr/antlr4#190
 * ""NullPointerException building lexer grammar using bogus 'token' action""
 * https://github.com/antlr/antlr4/issues/190
 */
@Test
public void testInvalidLexerCommand() {
    String[] pair = new String[] { ""grammar A;\n"" + ""tokens{Foo}\n"" + ""b : Foo ;\n"" + // ""meant"" to use -> popMode
    ""X : 'foo1' -> popmode;\n"" + // ""meant"" to use -> type(Foo)
    ""Y : 'foo2' -> token(Foo);"", ""error("" + ErrorType.INVALID_LEXER_COMMAND.code + ""): A.g4:4:14: lexer command popmode does not exist or is not supported by the current target\n"" + ""error("" + ErrorType.INVALID_LEXER_COMMAND.code + ""): A.g4:5:14: lexer command token does not exist or is not supported by the current target\n"" };
    testErrors(pair, true);
}","/**
 * This is a regression test for antlr/antlr4#190
 * ""NullPointerException building lexer grammar using bogus 'token' action""
 * https://github.com/antlr/antlr4/issues/190
 */
","// ""meant"" to use -> popMode
[[SEP]]// ""meant"" to use -> type(Foo)
","/** * This is a regression test for antlr/antlr4#190 * ""NullPointerException building lexer grammar using bogus 'token' action"" * https://github.com/antlr/antlr4/issues/190 */[[SEP]]// ""meant"" to use -> popMode[[SEP]]// ""meant"" to use -> type(Foo)",262,274,[0],0,"[0, 0]",0,"[0, 0, 0]",0,0,0,0,testInvalidLexerCommand(),org.antlr.v4.test.tool.TestToolSyntaxErrors,testInvalidLexerCommand/0,False,262,2,1,0,1,1,1,4,0,1,0,1,0,0,0,0,0,0,9,0,1,2,0,0,0,0,31,1,0,True
898,..\projects\antlr4-4.11.0\tool-testsuite\test\org\antlr\v4\test\tool\TestToolSyntaxErrors.java,org.antlr.v4.test.tool.TestToolSyntaxErrors,void testLexerCommandArgumentValidation(),"@Test
public void testLexerCommandArgumentValidation() {
    String[] pair = new String[] { ""grammar A;\n"" + ""tokens{Foo}\n"" + ""b : Foo ;\n"" + // ""meant"" to use -> popMode
    ""X : 'foo1' -> popMode(Foo);\n"" + // ""meant"" to use -> type(Foo)
    ""Y : 'foo2' -> type;"", ""error("" + ErrorType.UNWANTED_LEXER_COMMAND_ARGUMENT.code + ""): A.g4:4:14: lexer command popMode does not take any arguments\n"" + ""error("" + ErrorType.MISSING_LEXER_COMMAND_ARGUMENT.code + ""): A.g4:5:14: missing argument for lexer command type\n"" };
    testErrors(pair, true);
}", ,"// ""meant"" to use -> popMode
[[SEP]]// ""meant"" to use -> type(Foo)
","// ""meant"" to use -> popMode[[SEP]]// ""meant"" to use -> type(Foo)",276,288,[0],0,"[0, 0]",0,"[0, 0]",0,0,0,0,testLexerCommandArgumentValidation(),org.antlr.v4.test.tool.TestToolSyntaxErrors,testLexerCommandArgumentValidation/0,False,276,2,1,0,1,1,1,4,0,1,0,1,0,0,0,0,0,0,9,0,1,2,0,0,0,0,20,1,0,False
899,..\projects\antlr4-4.11.0\tool-testsuite\test\org\antlr\v4\test\tool\TestToolSyntaxErrors.java,org.antlr.v4.test.tool.TestToolSyntaxErrors,void testEpsilonNestedClosureAnalysis(),"// Test for https://github.com/antlr/antlr4/issues/1203
@Test
public void testEpsilonNestedClosureAnalysis() {
    String grammar = ""grammar T;\n"" + ""s : (a a)* ;\n"" + ""a : 'foo'* ;\n"";
    String expected = ""error("" + ErrorType.EPSILON_CLOSURE.code + ""): T.g4:2:0: rule s contains a closure with at least one alternative that can match an empty string\n"";
    String[] pair = new String[] { grammar, expected };
    testErrors(pair, true);
}","// Test for https://github.com/antlr/antlr4/issues/1203
", ,// Test for https://github.com/antlr/antlr4/issues/1203,327,341,[0],0,[0],0,[0],0,0,0,0,testEpsilonNestedClosureAnalysis(),org.antlr.v4.test.tool.TestToolSyntaxErrors,testEpsilonNestedClosureAnalysis/0,False,327,2,1,0,1,1,1,6,0,3,0,1,0,0,0,0,0,0,5,0,3,2,0,0,0,0,25,1,0,False
900,..\projects\antlr4-4.11.0\tool-testsuite\test\org\antlr\v4\test\tool\TestToolSyntaxErrors.java,org.antlr.v4.test.tool.TestToolSyntaxErrors,void testEpsilonClosureInLexer(),"// Test for https://github.com/antlr/antlr4/issues/2860, https://github.com/antlr/antlr4/issues/1105
@Test
public void testEpsilonClosureInLexer() {
    String grammar = ""lexer grammar T;\n"" + ""TOKEN: '\\'' FRAGMENT '\\'';\n"" + ""fragment FRAGMENT: ('x'|)+;"";
    String expected = ""error("" + ErrorType.EPSILON_CLOSURE.code + ""): T.g4:3:9: rule FRAGMENT contains a closure with at least one alternative that can match an empty string\n"";
    String[] pair = new String[] { grammar, expected };
    testErrors(pair, true);
}","// Test for https://github.com/antlr/antlr4/issues/2860, https://github.com/antlr/antlr4/issues/1105
", ,"// Test for https://github.com/antlr/antlr4/issues/2860, https://github.com/antlr/antlr4/issues/1105",344,359,[0],0,[0],0,[0],0,0,0,0,testEpsilonClosureInLexer(),org.antlr.v4.test.tool.TestToolSyntaxErrors,testEpsilonClosureInLexer/0,False,344,2,1,0,1,1,1,6,0,3,0,1,0,0,0,0,0,0,5,0,3,2,0,0,0,0,31,1,0,False
901,..\projects\antlr4-4.11.0\tool-testsuite\test\org\antlr\v4\test\tool\TestToolSyntaxErrors.java,org.antlr.v4.test.tool.TestToolSyntaxErrors,void testEofClosure(),"// Test for https://github.com/antlr/antlr4/issues/3359
@Test
public void testEofClosure() {
    String grammar = ""lexer grammar EofClosure;\n"" + ""EofClosure: 'x' EOF*;\n"" + ""EofInAlternative: 'y' ('z' | EOF);"";
    String expected = ""error("" + ErrorType.EOF_CLOSURE.code + ""): EofClosure.g4:2:0: rule EofClosure contains a closure with at least one alternative that can match EOF\n"";
    String[] pair = new String[] { grammar, expected };
    testErrors(pair, true);
}","// Test for https://github.com/antlr/antlr4/issues/3359
", ,// Test for https://github.com/antlr/antlr4/issues/3359,362,377,[0],0,[0],0,[0],0,0,0,0,testEofClosure(),org.antlr.v4.test.tool.TestToolSyntaxErrors,testEofClosure/0,False,362,2,1,0,1,1,1,6,0,3,0,1,0,0,0,0,0,0,5,0,3,2,0,0,0,0,22,1,0,False
902,..\projects\antlr4-4.11.0\tool-testsuite\test\org\antlr\v4\test\tool\TestToolSyntaxErrors.java,org.antlr.v4.test.tool.TestToolSyntaxErrors,void testEpsilonOptionalAndClosureAnalysis(),"// Test for https://github.com/antlr/antlr4/issues/1203
@Test
public void testEpsilonOptionalAndClosureAnalysis() {
    String grammar = ""grammar T;\n"" + ""s : (a a)? ;\n"" + ""a : 'foo'* ;\n"";
    String expected = ""warning("" + ErrorType.EPSILON_OPTIONAL.code + ""): T.g4:2:0: rule s contains an optional block with at least one alternative that can match an empty string\n"";
    String[] pair = new String[] { grammar, expected };
    testErrors(pair, true);
}","// Test for https://github.com/antlr/antlr4/issues/1203
", ,// Test for https://github.com/antlr/antlr4/issues/1203,380,394,[0],0,[0],0,[0],0,0,0,0,testEpsilonOptionalAndClosureAnalysis(),org.antlr.v4.test.tool.TestToolSyntaxErrors,testEpsilonOptionalAndClosureAnalysis/0,False,380,2,1,0,1,1,1,6,0,3,0,1,0,0,0,0,0,0,5,0,3,2,0,0,0,0,27,1,0,False
903,..\projects\antlr4-4.11.0\tool-testsuite\test\org\antlr\v4\test\tool\TestToolSyntaxErrors.java,org.antlr.v4.test.tool.TestToolSyntaxErrors,void testActionAtEndOfOneLexerAlternative(),"/**
 * This is a regression test for antlr/antlr4#315
 * ""Inconsistent lexer error msg for actions""
 * https://github.com/antlr/antlr4/issues/315
 */
@Test
public void testActionAtEndOfOneLexerAlternative() {
    String grammar = ""grammar A;\n"" + ""stat : 'start' CharacterLiteral 'end' EOF;\n"" + ""\n"" + ""// Lexer\n"" + ""\n"" + ""CharacterLiteral\n"" + ""    :   '\\'' SingleCharacter '\\''\n"" + ""    |   '\\'' ~[\\r\\n] {notifyErrorListeners(\""unclosed character literal\"");}\n"" + ""    ;\n"" + ""\n"" + ""fragment\n"" + ""SingleCharacter\n"" + ""    :   ~['\\\\\\r\\n]\n"" + ""    ;\n"" + ""\n"" + ""WS   : [ \\r\\t\\n]+ -> skip ;\n"";
    String expected = """";
    String[] pair = new String[] { grammar, expected };
    testErrors(pair, true);
}","/**
 * This is a regression test for antlr/antlr4#315
 * ""Inconsistent lexer error msg for actions""
 * https://github.com/antlr/antlr4/issues/315
 */
", ,"/** * This is a regression test for antlr/antlr4#315 * ""Inconsistent lexer error msg for actions"" * https://github.com/antlr/antlr4/issues/315 */[[SEP]]// Lexer\n"" + ""\n"" + ""CharacterLiteral\n"" + ""    :   '\\'' SingleCharacter '\\''\n"" + ""    |   '\\'' ~[\\r\\n] {notifyErrorListeners(\""unclosed character literal\"");}\n"" + ""    ;\n"" + ""\n"" + ""fragment\n"" + ""SingleCharacter\n"" + ""    :   ~['\\\\\\r\\n]\n"" + ""    ;\n"" + ""\n"" + ""WS   : [ \\r\\t\\n]+ -> skip ;\n"";",420,443,[0],0,[0],0,"[0, 0]",0,0,0,0,testActionAtEndOfOneLexerAlternative(),org.antlr.v4.test.tool.TestToolSyntaxErrors,testActionAtEndOfOneLexerAlternative/0,False,420,2,1,0,1,1,1,6,0,3,0,1,0,0,0,0,0,0,17,0,3,1,0,0,0,0,34,1,0,True
904,..\projects\antlr4-4.11.0\tool-testsuite\test\org\antlr\v4\test\tool\TestToolSyntaxErrors.java,org.antlr.v4.test.tool.TestToolSyntaxErrors,void testDoubleQuotedStringLiteral(),"/**
 * This is a regression test for antlr/antlr4#308 ""NullPointer exception""
 * https://github.com/antlr/antlr4/issues/308
 */
@Test
public void testDoubleQuotedStringLiteral() {
    String grammar = ""lexer grammar A;\n"" + ""WHITESPACE : (\"" \"" | \""\\t\"" | \""\\n\"" | \""\\r\"" | \""\\f\"");\n"";
    String expected = ""error("" + ErrorType.SYNTAX_ERROR.code + ""): A.g4:2:14: syntax error: '\""' came as a complete surprise to me\n"" + ""error("" + ErrorType.SYNTAX_ERROR.code + ""): A.g4:2:16: syntax error: '\""' came as a complete surprise to me\n"" + ""error("" + ErrorType.SYNTAX_ERROR.code + ""): A.g4:2:20: syntax error: '\""' came as a complete surprise to me\n"" + ""error("" + ErrorType.SYNTAX_ERROR.code + ""): A.g4:2:21: syntax error: '\\' came as a complete surprise to me\n"" + ""error("" + ErrorType.SYNTAX_ERROR.code + ""): A.g4:2:23: syntax error: '\""' came as a complete surprise to me\n"" + ""error("" + ErrorType.SYNTAX_ERROR.code + ""): A.g4:2:27: syntax error: '\""' came as a complete surprise to me\n"" + ""error("" + ErrorType.SYNTAX_ERROR.code + ""): A.g4:2:28: syntax error: '\\' came as a complete surprise to me\n"" + ""error("" + ErrorType.SYNTAX_ERROR.code + ""): A.g4:2:30: syntax error: '\""' came as a complete surprise to me\n"" + ""error("" + ErrorType.SYNTAX_ERROR.code + ""): A.g4:2:34: syntax error: '\""' came as a complete surprise to me\n"" + ""error("" + ErrorType.SYNTAX_ERROR.code + ""): A.g4:2:35: syntax error: '\\' came as a complete surprise to me\n"" + ""error("" + ErrorType.SYNTAX_ERROR.code + ""): A.g4:2:37: syntax error: '\""' came as a complete surprise to me\n"" + ""error("" + ErrorType.SYNTAX_ERROR.code + ""): A.g4:2:41: syntax error: '\""' came as a complete surprise to me\n"" + ""error("" + ErrorType.SYNTAX_ERROR.code + ""): A.g4:2:42: syntax error: '\\' came as a complete surprise to me\n"" + ""error("" + ErrorType.SYNTAX_ERROR.code + ""): A.g4:2:44: syntax error: '\""' came as a complete surprise to me\n"";
    String[] pair = new String[] { grammar, expected };
    testErrors(pair, true);
}","/**
 * This is a regression test for antlr/antlr4#308 ""NullPointer exception""
 * https://github.com/antlr/antlr4/issues/308
 */
", ,"/** * This is a regression test for antlr/antlr4#308 ""NullPointer exception"" * https://github.com/antlr/antlr4/issues/308 */",449,475,[0],0,[0],0,[0],0,0,0,0,testDoubleQuotedStringLiteral(),org.antlr.v4.test.tool.TestToolSyntaxErrors,testDoubleQuotedStringLiteral/0,False,449,2,1,0,1,1,1,6,0,3,0,1,0,0,0,0,0,0,30,0,3,2,0,0,0,0,23,1,0,True
905,..\projects\antlr4-4.11.0\tool-testsuite\test\org\antlr\v4\test\tool\TestToolSyntaxErrors.java,org.antlr.v4.test.tool.TestToolSyntaxErrors,void testDoubleQuoteInTwoStringLiterals(),"/**
 * This is a regression test for https://github.com/antlr/antlr4/issues/1815
 * ""Null ptr exception in SqlBase.g4""
 */
@Test
public void testDoubleQuoteInTwoStringLiterals() {
    String grammar = ""lexer grammar A;\n"" + ""STRING : '\\\""' '\\\""' 'x' ;"";
    String expected = ""error("" + ErrorType.INVALID_ESCAPE_SEQUENCE.code + ""): A.g4:2:10: invalid escape sequence \\\""\n"" + ""error("" + ErrorType.INVALID_ESCAPE_SEQUENCE.code + ""): A.g4:2:15: invalid escape sequence \\\""\n"";
    String[] pair = new String[] { grammar, expected };
    testErrors(pair, true);
}","/**
 * This is a regression test for https://github.com/antlr/antlr4/issues/1815
 * ""Null ptr exception in SqlBase.g4""
 */
", ,"/** * This is a regression test for https://github.com/antlr/antlr4/issues/1815 * ""Null ptr exception in SqlBase.g4"" */",481,495,[0],0,[0],0,[0],0,0,0,0,testDoubleQuoteInTwoStringLiterals(),org.antlr.v4.test.tool.TestToolSyntaxErrors,testDoubleQuoteInTwoStringLiterals/0,False,481,2,1,0,1,1,1,6,0,3,0,1,0,0,0,0,0,0,6,0,3,2,0,0,0,0,25,1,0,True
906,..\projects\antlr4-4.11.0\tool-testsuite\test\org\antlr\v4\test\tool\TestToolSyntaxErrors.java,org.antlr.v4.test.tool.TestToolSyntaxErrors,void testValidEscapeSequences(),"/**
 * This test ensures that the {@link ErrorType#INVALID_ESCAPE_SEQUENCE}
 * error is not reported for escape sequences that are known to be valid.
 */
@Test
public void testValidEscapeSequences() {
    String grammar = ""lexer grammar A;\n"" + ""NORMAL_ESCAPE : '\\b \\t \\n \\f \\r \\' \\\\';\n"" + ""UNICODE_ESCAPE : '\\u0001 \\u00A1 \\u00a1 \\uaaaa \\uAAAA';\n"";
    String expected = """";
    String[] pair = new String[] { grammar, expected };
    testErrors(pair, true);
}","/**
 * This test ensures that the {@link ErrorType#INVALID_ESCAPE_SEQUENCE}
 * error is not reported for escape sequences that are known to be valid.
 */
", ,/** * This test ensures that the {@link ErrorType#INVALID_ESCAPE_SEQUENCE} * error is not reported for escape sequences that are known to be valid. */,501,515,[0],0,[0],0,[0],0,0,0,0,testValidEscapeSequences(),org.antlr.v4.test.tool.TestToolSyntaxErrors,testValidEscapeSequences/0,False,501,2,1,0,1,1,1,6,0,3,0,1,0,0,0,0,0,0,4,0,3,1,0,0,0,0,23,1,0,True
907,..\projects\antlr4-4.11.0\tool-testsuite\test\org\antlr\v4\test\tool\TestToolSyntaxErrors.java,org.antlr.v4.test.tool.TestToolSyntaxErrors,void testInvalidEscapeSequences(),"/**
 * This is a regression test for antlr/antlr4#507 ""NullPointerException When
 * Generating Code from Grammar"".
 * https://github.com/antlr/antlr4/issues/507
 */
@Test
public void testInvalidEscapeSequences() {
    String grammar = ""lexer grammar A;\n"" + ""RULE : 'Foo \\uAABG \\x \\u';\n"";
    String expected = ""error("" + ErrorType.INVALID_ESCAPE_SEQUENCE.code + ""): A.g4:2:12: invalid escape sequence \\uAABG\n"" + ""error("" + ErrorType.INVALID_ESCAPE_SEQUENCE.code + ""): A.g4:2:19: invalid escape sequence \\x\n"" + ""error("" + ErrorType.INVALID_ESCAPE_SEQUENCE.code + ""): A.g4:2:22: invalid escape sequence \\u\n"";
    String[] pair = new String[] { grammar, expected };
    testErrors(pair, true);
}","/**
 * This is a regression test for antlr/antlr4#507 ""NullPointerException When
 * Generating Code from Grammar"".
 * https://github.com/antlr/antlr4/issues/507
 */
", ,"/** * This is a regression test for antlr/antlr4#507 ""NullPointerException When * Generating Code from Grammar"". * https://github.com/antlr/antlr4/issues/507 */",522,537,[0],0,[0],0,[0],0,0,0,0,testInvalidEscapeSequences(),org.antlr.v4.test.tool.TestToolSyntaxErrors,testInvalidEscapeSequences/0,False,522,2,1,0,1,1,1,6,0,3,0,1,0,0,0,0,0,0,8,0,3,2,0,0,0,0,23,1,0,True
908,..\projects\antlr4-4.11.0\tool-testsuite\test\org\antlr\v4\test\tool\TestToolSyntaxErrors.java,org.antlr.v4.test.tool.TestToolSyntaxErrors,void testNotAllowedEmptyStrings(),"/**
 * This is a regression test for antlr/antlr4#959 ""NullPointerException"".
 * https://github.com/antlr/antlr4/issues/959
 */
@Test
public void testNotAllowedEmptyStrings() {
    String grammar = ""lexer grammar T;\n"" + ""Error0: '''test''';\n"" + ""Error1: '' 'test';\n"" + ""Error2: 'test' '';\n"" + ""Error3: '';\n"" + ""NotError: ' ';"";
    String expected = ""error("" + ErrorType.EMPTY_STRINGS_AND_SETS_NOT_ALLOWED.code + ""): T.g4:2:8: string literals and sets cannot be empty: ''\n"" + ""error("" + ErrorType.EMPTY_STRINGS_AND_SETS_NOT_ALLOWED.code + ""): T.g4:2:16: string literals and sets cannot be empty: ''\n"" + ""error("" + ErrorType.EMPTY_STRINGS_AND_SETS_NOT_ALLOWED.code + ""): T.g4:3:8: string literals and sets cannot be empty: ''\n"" + ""error("" + ErrorType.EMPTY_STRINGS_AND_SETS_NOT_ALLOWED.code + ""): T.g4:4:15: string literals and sets cannot be empty: ''\n"" + ""error("" + ErrorType.EMPTY_STRINGS_AND_SETS_NOT_ALLOWED.code + ""): T.g4:5:8: string literals and sets cannot be empty: ''\n"";
    String[] pair = new String[] { grammar, expected };
    testErrors(pair, true);
}","/**
 * This is a regression test for antlr/antlr4#959 ""NullPointerException"".
 * https://github.com/antlr/antlr4/issues/959
 */
", ,"/** * This is a regression test for antlr/antlr4#959 ""NullPointerException"". * https://github.com/antlr/antlr4/issues/959 */",543,564,[0],0,[0],0,[0],0,0,0,0,testNotAllowedEmptyStrings(),org.antlr.v4.test.tool.TestToolSyntaxErrors,testNotAllowedEmptyStrings/0,False,543,2,1,0,1,1,1,6,0,3,0,1,0,0,0,0,0,0,16,0,3,2,0,0,0,0,23,1,0,True
909,..\projects\antlr4-4.11.0\tool-testsuite\test\org\antlr\v4\test\tool\TestToolSyntaxErrors.java,org.antlr.v4.test.tool.TestToolSyntaxErrors,void testInvalidCharSetsAndStringLiterals(),"@Test
public void testInvalidCharSetsAndStringLiterals() {
    String grammar = ""lexer grammar Test;\n"" + ""INVALID_STRING_LITERAL_RANGE: 'GH'..'LM';\n"" + // https://github.com/antlr/antlr4/issues/1077
    ""INVALID_CHAR_SET:             [\\u24\\uA2][\\{];\n"" + ""EMPTY_STRING_LITERAL_RANGE:   'F'..'A' | 'Z';\n"" + ""EMPTY_CHAR_SET:               [f-az][];\n"" + ""START_HYPHEN_IN_CHAR_SET:     [-z];\n"" + ""END_HYPHEN_IN_CHAR_SET:       [a-];\n"" + ""SINGLE_HYPHEN_IN_CHAR_SET:    [-];\n"" + ""VALID_STRING_LITERALS:        '\\u1234' | '\\t' | '\\'';\n"" + ""VALID_CHAR_SET:               [`\\-=\\]];"" + // https://github.com/antlr/antlr4/issues/1556
    ""EMPTY_CHAR_SET_WITH_INVALID_ESCAPE_SEQUENCE: [\\'];"";
    String expected = ""error("" + ErrorType.INVALID_LITERAL_IN_LEXER_SET.code + ""): Test.g4:2:30: multi-character literals are not allowed in lexer sets: 'GH'\n"" + ""error("" + ErrorType.INVALID_LITERAL_IN_LEXER_SET.code + ""): Test.g4:2:36: multi-character literals are not allowed in lexer sets: 'LM'\n"" + ""error("" + ErrorType.INVALID_ESCAPE_SEQUENCE.code + ""): Test.g4:3:30: invalid escape sequence \\u24\\u\n"" + ""error("" + ErrorType.INVALID_ESCAPE_SEQUENCE.code + ""): Test.g4:3:40: invalid escape sequence \\{\n"" + ""error("" + ErrorType.EMPTY_STRINGS_AND_SETS_NOT_ALLOWED.code + ""): Test.g4:4:33: string literals and sets cannot be empty: 'F'..'A'\n"" + ""error("" + ErrorType.EMPTY_STRINGS_AND_SETS_NOT_ALLOWED.code + ""): Test.g4:5:30: string literals and sets cannot be empty: 'f'..'a'\n"" + ""error("" + ErrorType.EMPTY_STRINGS_AND_SETS_NOT_ALLOWED.code + ""): Test.g4:5:36: string literals and sets cannot be empty: []\n"" + ""error("" + ErrorType.INVALID_ESCAPE_SEQUENCE.code + ""): Test.g4:10:84: invalid escape sequence \\'\n"";
    String[] pair = new String[] { grammar, expected };
    testErrors(pair, true);
}", ,"// https://github.com/antlr/antlr4/issues/1077
[[SEP]]// https://github.com/antlr/antlr4/issues/1556
",// https://github.com/antlr/antlr4/issues/1077[[SEP]]// https://github.com/antlr/antlr4/issues/1556,566,596,[0],0,"[0, 0]",0,"[0, 0]",0,0,0,0,testInvalidCharSetsAndStringLiterals(),org.antlr.v4.test.tool.TestToolSyntaxErrors,testInvalidCharSetsAndStringLiterals/0,False,566,2,1,0,1,1,1,6,0,3,0,1,0,0,0,0,0,0,27,0,3,2,0,0,0,0,28,1,0,False
910,..\projects\antlr4-4.11.0\tool-testsuite\test\org\antlr\v4\test\tool\TestToolSyntaxErrors.java,org.antlr.v4.test.tool.TestToolSyntaxErrors,void testUnrecognizedAssocOption(),"/**
 * This test ensures the {@link ErrorType#UNRECOGNIZED_ASSOC_OPTION} warning
 * is produced as described in the documentation.
 */
@Test
public void testUnrecognizedAssocOption() {
    String grammar = ""grammar A;\n"" + ""x : 'x'\n"" + ""  | x '+'<assoc=right> x   // warning 157\n"" + ""  |<assoc=right> x '*' x   // ok\n"" + ""  ;\n"";
    String expected = ""warning("" + ErrorType.UNRECOGNIZED_ASSOC_OPTION.code + ""): A.g4:3:10: rule x contains an assoc terminal option in an unrecognized location\n"";
    String[] pair = new String[] { grammar, expected };
    testErrors(pair, true);
}","/**
 * This test ensures the {@link ErrorType#UNRECOGNIZED_ASSOC_OPTION} warning
 * is produced as described in the documentation.
 */
", ,"/** * This test ensures the {@link ErrorType#UNRECOGNIZED_ASSOC_OPTION} warning * is produced as described in the documentation. */[[SEP]]// warning 157\n"" + ""  |<assoc=right> x '*' x   // ok\n"" + ""  ;\n"";",642,658,[0],0,[0],0,"[0, 0]",0,0,0,0,testUnrecognizedAssocOption(),org.antlr.v4.test.tool.TestToolSyntaxErrors,testUnrecognizedAssocOption/0,False,642,2,1,0,1,1,1,6,0,3,0,1,0,0,0,0,0,0,7,0,3,2,0,0,0,0,27,1,0,True
911,..\projects\antlr4-4.11.0\tool-testsuite\test\org\antlr\v4\test\tool\TestToolSyntaxErrors.java,org.antlr.v4.test.tool.TestToolSyntaxErrors,void testFragmentActionIgnored(),"/**
 * This test ensures the {@link ErrorType#FRAGMENT_ACTION_IGNORED} warning
 * is produced as described in the documentation.
 */
@Test
public void testFragmentActionIgnored() {
    String grammar = ""lexer grammar A;\n"" + ""X1 : 'x' -> more    // ok\n"" + ""   ;\n"" + ""Y1 : 'x' {more();}  // ok\n"" + ""   ;\n"" + ""fragment\n"" + ""X2 : 'x' -> more    // warning 158\n"" + ""   ;\n"" + ""fragment\n"" + ""Y2 : 'x' {more();}  // warning 158\n"" + ""   ;\n"";
    String expected = ""warning("" + ErrorType.FRAGMENT_ACTION_IGNORED.code + ""): A.g4:7:12: fragment rule X2 contains an action or command which can never be executed\n"" + ""warning("" + ErrorType.FRAGMENT_ACTION_IGNORED.code + ""): A.g4:10:9: fragment rule Y2 contains an action or command which can never be executed\n"";
    String[] pair = new String[] { grammar, expected };
    testErrors(pair, true);
}","/**
 * This test ensures the {@link ErrorType#FRAGMENT_ACTION_IGNORED} warning
 * is produced as described in the documentation.
 */
", ,"/** * This test ensures the {@link ErrorType#FRAGMENT_ACTION_IGNORED} warning * is produced as described in the documentation. */[[SEP]]// ok\n"" + ""   ;\n"" + ""Y1 : 'x' {more();}  // ok\n"" + ""   ;\n"" + ""fragment\n"" + ""X2 : 'x' -> more    // warning 158\n"" + ""   ;\n"" + ""fragment\n"" + ""Y2 : 'x' {more();}  // warning 158\n"" + ""   ;\n"";",664,687,[0],0,[0],0,"[0, 0]",0,0,0,0,testFragmentActionIgnored(),org.antlr.v4.test.tool.TestToolSyntaxErrors,testFragmentActionIgnored/0,False,664,2,1,0,1,1,1,6,0,3,0,1,0,0,0,0,0,0,15,0,3,2,0,0,0,0,32,1,0,True
912,..\projects\antlr4-4.11.0\tool-testsuite\test\org\antlr\v4\test\tool\TestToolSyntaxErrors.java,org.antlr.v4.test.tool.TestToolSyntaxErrors,void testTokenNamedEOF(),"/**
 * This is a regression test for antlr/antlr4#500 ""Array Index Out Of
 * Bounds"".
 * https://github.com/antlr/antlr4/issues/500
 */
@Test
public void testTokenNamedEOF() {
    String grammar = ""lexer grammar A;\n"" + ""WS : ' ';\n"" + "" EOF : 'a';\n"";
    String expected = ""error("" + ErrorType.RESERVED_RULE_NAME.code + ""): A.g4:3:1: cannot declare a rule with reserved name EOF\n"";
    String[] pair = new String[] { grammar, expected };
    testErrors(pair, true);
}","/**
 * This is a regression test for antlr/antlr4#500 ""Array Index Out Of
 * Bounds"".
 * https://github.com/antlr/antlr4/issues/500
 */
", ,"/** * This is a regression test for antlr/antlr4#500 ""Array Index Out Of * Bounds"". * https://github.com/antlr/antlr4/issues/500 */",694,708,[0],0,[0],0,[0],0,0,0,0,testTokenNamedEOF(),org.antlr.v4.test.tool.TestToolSyntaxErrors,testTokenNamedEOF/0,False,694,2,1,0,1,1,1,6,0,3,0,1,0,0,0,0,0,0,5,0,3,2,0,0,0,0,27,1,0,True
913,..\projects\antlr4-4.11.0\tool-testsuite\test\org\antlr\v4\test\tool\TestToolSyntaxErrors.java,org.antlr.v4.test.tool.TestToolSyntaxErrors,void testInvalidLanguageInGrammarWithLexerCommand(),"/**
 * This is a regression test for antlr/antlr4#649 ""unknown target causes
 * null ptr exception."".
 * https://github.com/antlr/antlr4/issues/649
 * Stops before processing the lexer
 */
@Test
public void testInvalidLanguageInGrammarWithLexerCommand() {
    String grammar = ""grammar T;\n"" + ""options { language=Foo; }\n"" + ""start : 'T' EOF;\n"" + ""Something : 'something' -> channel(CUSTOM);"";
    String expected = ""error("" + ErrorType.CANNOT_CREATE_TARGET_GENERATOR.code + ""):  ANTLR cannot generate Foo code as of version "" + Tool.VERSION + ""\n"";
    String[] pair = new String[] { grammar, expected };
    testErrors(pair, true);
}","/**
 * This is a regression test for antlr/antlr4#649 ""unknown target causes
 * null ptr exception."".
 * https://github.com/antlr/antlr4/issues/649
 * Stops before processing the lexer
 */
", ,"/** * This is a regression test for antlr/antlr4#649 ""unknown target causes * null ptr exception."". * https://github.com/antlr/antlr4/issues/649 * Stops before processing the lexer */",716,730,[0],0,[0],0,[0],0,0,0,0,testInvalidLanguageInGrammarWithLexerCommand(),org.antlr.v4.test.tool.TestToolSyntaxErrors,testInvalidLanguageInGrammarWithLexerCommand/0,False,716,2,1,0,1,1,1,6,0,3,0,1,0,0,0,0,0,0,7,0,3,2,0,0,0,0,49,1,0,True
914,..\projects\antlr4-4.11.0\tool-testsuite\test\org\antlr\v4\test\tool\TestToolSyntaxErrors.java,org.antlr.v4.test.tool.TestToolSyntaxErrors,void testInvalidLanguageInGrammar(),"/**
 * This is a regression test for antlr/antlr4#649 ""unknown target causes
 * null ptr exception."".
 * https://github.com/antlr/antlr4/issues/649
 */
@Test
public void testInvalidLanguageInGrammar() {
    String grammar = ""grammar T;\n"" + ""options { language=Foo; }\n"" + ""start : 'T' EOF;\n"";
    String expected = ""error("" + ErrorType.CANNOT_CREATE_TARGET_GENERATOR.code + ""):  ANTLR cannot generate Foo code as of version "" + Tool.VERSION + ""\n"";
    String[] pair = new String[] { grammar, expected };
    testErrors(pair, true);
}","/**
 * This is a regression test for antlr/antlr4#649 ""unknown target causes
 * null ptr exception."".
 * https://github.com/antlr/antlr4/issues/649
 */
", ,"/** * This is a regression test for antlr/antlr4#649 ""unknown target causes * null ptr exception."". * https://github.com/antlr/antlr4/issues/649 */",737,751,[0],0,[0],0,[0],0,0,0,0,testInvalidLanguageInGrammar(),org.antlr.v4.test.tool.TestToolSyntaxErrors,testInvalidLanguageInGrammar/0,False,737,2,1,0,1,1,1,6,0,3,0,1,0,0,0,0,0,0,6,0,3,2,0,0,0,0,36,1,0,True
915,..\projects\antlr4-4.11.0\tool-testsuite\test\org\antlr\v4\test\tool\TestToolSyntaxErrors.java,org.antlr.v4.test.tool.TestToolSyntaxErrors,void testChannelDefinitions(),"/**
 * This is a regression test for antlr/antlr4#497 now that antlr/antlr4#309
 * is resolved.
 * https://github.com/antlr/antlr4/issues/497
 * https://github.com/antlr/antlr4/issues/309
 */
@Test
public void testChannelDefinitions() throws Exception {
    String grammar = ""lexer grammar T;\n"" + ""\n"" + ""channels {\n"" + ""	WHITESPACE_CHANNEL,\n"" + ""	COMMENT_CHANNEL\n"" + ""}\n"" + ""\n"" + ""COMMENT:    '//' ~[\\n]+ -> channel(COMMENT_CHANNEL);\n"" + ""WHITESPACE: [ \\t]+      -> channel(WHITESPACE_CHANNEL);\n"" + ""NEWLINE:    '\\r'? '\\n' -> channel(NEWLINE_CHANNEL);"";
    // WHITESPACE_CHANNEL and COMMENT_CHANNEL are defined, but NEWLINE_CHANNEL is not
    String expected = ""error("" + ErrorType.CONSTANT_VALUE_IS_NOT_A_RECOGNIZED_CHANNEL_NAME.code + ""): T.g4:10:34: NEWLINE_CHANNEL is not a recognized channel name\n"";
    String[] pair = { grammar, expected };
    testErrors(pair, true);
}","/**
 * This is a regression test for antlr/antlr4#497 now that antlr/antlr4#309
 * is resolved.
 * https://github.com/antlr/antlr4/issues/497
 * https://github.com/antlr/antlr4/issues/309
 */
","// WHITESPACE_CHANNEL and COMMENT_CHANNEL are defined, but NEWLINE_CHANNEL is not
","/** * This is a regression test for antlr/antlr4#497 now that antlr/antlr4#309 * is resolved. * https://github.com/antlr/antlr4/issues/497 * https://github.com/antlr/antlr4/issues/309 */[[SEP]]//' ~[\\n]+ -> channel(COMMENT_CHANNEL);\n"" + ""WHITESPACE: [ \\t]+      -> channel(WHITESPACE_CHANNEL);\n"" + ""NEWLINE:    '\\r'? '\\n' -> channel(NEWLINE_CHANNEL);"";[[SEP]]// WHITESPACE_CHANNEL and COMMENT_CHANNEL are defined, but NEWLINE_CHANNEL is not",818,837,[0],0,[0],0,"[0, 0, 0]",0,0,0,0,testChannelDefinitions(),org.antlr.v4.test.tool.TestToolSyntaxErrors,testChannelDefinitions/0,False,818,2,1,0,1,1,1,6,0,3,0,1,0,0,0,0,0,0,12,0,3,2,0,0,0,0,34,1,0,True
916,..\projects\antlr4-4.11.0\tool-testsuite\test\org\antlr\v4\test\tool\TestToolSyntaxErrors.java,org.antlr.v4.test.tool.TestToolSyntaxErrors,void testRangeInParserGrammar(),"// Test for https://github.com/antlr/antlr4/issues/1556
@Test
public void testRangeInParserGrammar() {
    String grammar = ""grammar T;\n"" + ""a:  'A'..'Z' ;\n"";
    String expected = ""error("" + ErrorType.TOKEN_RANGE_IN_PARSER.code + ""): T.g4:2:4: token ranges not allowed in parser: 'A'..'Z'\n"";
    String[] pair = new String[] { grammar, expected };
    testErrors(pair, true);
}","// Test for https://github.com/antlr/antlr4/issues/1556
", ,// Test for https://github.com/antlr/antlr4/issues/1556,840,853,[0],0,[0],0,[0],0,0,0,0,testRangeInParserGrammar(),org.antlr.v4.test.tool.TestToolSyntaxErrors,testRangeInParserGrammar/0,False,840,2,1,0,1,1,1,6,0,3,0,1,0,0,0,0,0,0,4,0,3,2,0,0,0,0,15,1,0,False
917,..\projects\antlr4-4.11.0\tool-testsuite\test\org\antlr\v4\test\tool\TestTopologicalSort.java,org.antlr.v4.test.tool.TestTopologicalSort,void testRepeatedEdges(),"@Test
public void testRepeatedEdges() throws Exception {
    Graph<String> g = new Graph<String>();
    g.addEdge(""A"", ""B"");
    g.addEdge(""B"", ""C"");
    // dup
    g.addEdge(""A"", ""B"");
    g.addEdge(""C"", ""D"");
    String expecting = ""[D, C, B, A]"";
    List<String> nodes = g.sort();
    String result = nodes.toString();
    assertEquals(expecting, result);
}", ,"// dup
",// dup,52,64,[0],0,[0],0,[0],0,0,0,0,testRepeatedEdges(),org.antlr.v4.test.tool.TestTopologicalSort,testRepeatedEdges/0,False,53,2,0,0,0,1,4,11,0,4,0,4,0,0,0,0,0,0,9,0,4,0,0,0,0,0,10,1,0,False
918,..\projects\antlr4-4.11.0\tool-testsuite\test\org\antlr\v4\test\tool\TestTopologicalSort.java,org.antlr.v4.test.tool.TestTopologicalSort,void testSimpleTokenDependence(),"@Test
public void testSimpleTokenDependence() throws Exception {
    Graph<String> g = new Graph<String>();
    // Java feeds off manual token file
    g.addEdge(""Java.g4"", ""MyJava.tokens"");
    g.addEdge(""Java.tokens"", ""Java.g4"");
    // walkers feed off generated tokens
    g.addEdge(""Def.g4"", ""Java.tokens"");
    g.addEdge(""Ref.g4"", ""Java.tokens"");
    String expecting = ""[MyJava.tokens, Java.g4, Java.tokens, Def.g4, Ref.g4]"";
    List<String> nodes = g.sort();
    String result = nodes.toString();
    assertEquals(expecting, result);
}", ,"// Java feeds off manual token file
[[SEP]]// walkers feed off generated tokens
",// Java feeds off manual token file[[SEP]]// walkers feed off generated tokens,66,78,[0],0,"[0, 0]",0,"[0, 0]",0,0,0,0,testSimpleTokenDependence(),org.antlr.v4.test.tool.TestTopologicalSort,testSimpleTokenDependence/0,False,67,2,0,0,0,1,4,11,0,4,0,4,0,0,0,0,0,0,9,0,4,0,0,0,0,0,11,1,0,False
919,..\projects\antlr4-4.11.0\tool-testsuite\test\org\antlr\v4\test\tool\TestUnbufferedCharStream.java,org.antlr.v4.test.tool.TestUnbufferedCharStream,void testConsumeEOF(),"/**
 * The {@link IntStream} interface does not specify the behavior when the
 * EOF symbol is consumed, but {@link UnbufferedCharStream} handles this
 * particular case by throwing an {@link IllegalStateException}.
 */
@Test
public void testConsumeEOF() {
    CharStream input = createStream("""");
    assertEquals(IntStream.EOF, input.LA(1));
    assertThrows(IllegalStateException.class, input::consume);
}","/**
 * The {@link IntStream} interface does not specify the behavior when the
 * EOF symbol is consumed, but {@link UnbufferedCharStream} handles this
 * particular case by throwing an {@link IllegalStateException}.
 */
", ,"/** * The {@link IntStream} interface does not specify the behavior when the * EOF symbol is consumed, but {@link UnbufferedCharStream} handles this * particular case by throwing an {@link IllegalStateException}. */",38,43,[0],0,[0],0,[0],0,0,0,0,testConsumeEOF(),org.antlr.v4.test.tool.TestUnbufferedCharStream,testConsumeEOF/0,False,39,3,1,0,1,1,4,5,0,1,0,4,1,1,0,0,0,0,1,1,1,0,0,0,0,0,32,1,0,True
920,..\projects\antlr4-4.11.0\tool-testsuite\test\org\antlr\v4\test\tool\TestUnbufferedCharStream.java,org.antlr.v4.test.tool.TestUnbufferedCharStream,void testMarkReleaseOutOfOrder(),"/**
 * The {@link IntStream} interface does not specify the behavior when marks
 * are not released in the reversed order they were created, but
 * {@link UnbufferedCharStream} handles this case by throwing an
 * {@link IllegalStateException}.
 */
@Test
public void testMarkReleaseOutOfOrder() {
    CharStream input = createStream("""");
    int m1 = input.mark();
    int m2 = input.mark();
    assertThrows(IllegalStateException.class, () -> input.release(m1));
}","/**
 * The {@link IntStream} interface does not specify the behavior when marks
 * are not released in the reversed order they were created, but
 * {@link UnbufferedCharStream} handles this case by throwing an
 * {@link IllegalStateException}.
 */
", ,"/** * The {@link IntStream} interface does not specify the behavior when marks * are not released in the reversed order they were created, but * {@link UnbufferedCharStream} handles this case by throwing an * {@link IllegalStateException}. */",65,71,[0],0,[0],0,[0],0,0,0,0,testMarkReleaseOutOfOrder(),org.antlr.v4.test.tool.TestUnbufferedCharStream,testMarkReleaseOutOfOrder/0,False,66,3,1,0,1,1,4,6,0,3,0,4,1,1,0,0,0,0,1,0,3,0,0,0,0,1,38,1,0,True
921,..\projects\antlr4-4.11.0\tool-testsuite\test\org\antlr\v4\test\tool\TestUnbufferedCharStream.java,org.antlr.v4.test.tool.TestUnbufferedCharStream,void testMarkReleasedTwice(),"/**
 * The {@link IntStream} interface does not specify the behavior when a mark
 * is released twice, but {@link UnbufferedCharStream} handles this case by
 * throwing an {@link IllegalStateException}.
 */
@Test
public void testMarkReleasedTwice() {
    CharStream input = createStream("""");
    int m1 = input.mark();
    input.release(m1);
    assertThrows(IllegalStateException.class, () -> input.release(m1));
}","/**
 * The {@link IntStream} interface does not specify the behavior when a mark
 * is released twice, but {@link UnbufferedCharStream} handles this case by
 * throwing an {@link IllegalStateException}.
 */
", ,"/** * The {@link IntStream} interface does not specify the behavior when a mark * is released twice, but {@link UnbufferedCharStream} handles this case by * throwing an {@link IllegalStateException}. */",78,84,[0],0,[0],0,[0],0,0,0,0,testMarkReleasedTwice(),org.antlr.v4.test.tool.TestUnbufferedCharStream,testMarkReleasedTwice/0,False,79,3,1,0,1,1,4,6,0,2,0,4,1,1,0,0,0,0,1,0,2,0,0,0,0,1,30,1,0,True
922,..\projects\antlr4-4.11.0\tool-testsuite\test\org\antlr\v4\test\tool\TestUnbufferedCharStream.java,org.antlr.v4.test.tool.TestUnbufferedCharStream,void testNestedMarkReleasedTwice(),"/**
 * The {@link IntStream} interface does not specify the behavior when a mark
 * is released twice, but {@link UnbufferedCharStream} handles this case by
 * throwing an {@link IllegalStateException}.
 */
@Test
public void testNestedMarkReleasedTwice() {
    CharStream input = createStream("""");
    int m1 = input.mark();
    int m2 = input.mark();
    input.release(m2);
    assertThrows(IllegalStateException.class, () -> input.release(m2));
}","/**
 * The {@link IntStream} interface does not specify the behavior when a mark
 * is released twice, but {@link UnbufferedCharStream} handles this case by
 * throwing an {@link IllegalStateException}.
 */
", ,"/** * The {@link IntStream} interface does not specify the behavior when a mark * is released twice, but {@link UnbufferedCharStream} handles this case by * throwing an {@link IllegalStateException}. */",91,98,[0],0,[0],0,[0],0,0,0,0,testNestedMarkReleasedTwice(),org.antlr.v4.test.tool.TestUnbufferedCharStream,testNestedMarkReleasedTwice/0,False,92,3,1,0,1,1,4,7,0,3,0,4,1,1,0,0,0,0,1,0,3,0,0,0,0,1,32,1,0,True
923,..\projects\antlr4-4.11.0\tool-testsuite\test\org\antlr\v4\test\tool\TestUnbufferedCharStream.java,org.antlr.v4.test.tool.TestUnbufferedCharStream,void testMarkPassedToSeek(),"/**
 * It is not valid to pass a mark to {@link IntStream#seek}, but
 * {@link UnbufferedCharStream} creates marks in such a way that this
 * invalid usage results in an {@link IllegalArgumentException}.
 */
@Test
public void testMarkPassedToSeek() {
    CharStream input = createStream("""");
    int m1 = input.mark();
    assertThrows(IllegalArgumentException.class, () -> input.seek(m1));
}","/**
 * It is not valid to pass a mark to {@link IntStream#seek}, but
 * {@link UnbufferedCharStream} creates marks in such a way that this
 * invalid usage results in an {@link IllegalArgumentException}.
 */
", ,"/** * It is not valid to pass a mark to {@link IntStream#seek}, but * {@link UnbufferedCharStream} creates marks in such a way that this * invalid usage results in an {@link IllegalArgumentException}. */",105,110,[0],0,[0],0,[0],0,0,0,0,testMarkPassedToSeek(),org.antlr.v4.test.tool.TestUnbufferedCharStream,testMarkPassedToSeek/0,False,106,3,1,0,1,1,4,5,0,2,0,4,1,1,0,0,0,0,1,0,2,0,0,0,0,1,35,1,0,True
924,..\projects\antlr4-4.11.0\tool-testsuite\test\org\antlr\v4\test\tool\TestUnbufferedCharStream.java,org.antlr.v4.test.tool.TestUnbufferedCharStream,void testLastChar(),"@Test
public void testLastChar() {
    CharStream input = createStream(""abcdef"");
    input.consume();
    assertEquals('a', input.LA(-1));
    int m1 = input.mark();
    input.consume();
    input.consume();
    input.consume();
    assertEquals('d', input.LA(-1));
    input.seek(2);
    assertEquals('b', input.LA(-1));
    input.release(m1);
    input.seek(3);
    assertEquals('c', input.LA(-1));
    // this special case is not required by the IntStream interface, but
    // UnbufferedCharStream allows it so we have to make sure the resulting
    // state is consistent
    input.seek(2);
    assertEquals('b', input.LA(-1));
}", ,"// this special case is not required by the IntStream interface, but
[[SEP]]// UnbufferedCharStream allows it so we have to make sure the resulting
[[SEP]]// state is consistent
","// this special case is not required by the IntStream interface, but// UnbufferedCharStream allows it so we have to make sure the resulting// state is consistent",142,166,[0],0,"[0, 0, 0]",0,[0],0,0,0,0,testLastChar(),org.antlr.v4.test.tool.TestUnbufferedCharStream,testLastChar/0,False,143,3,1,0,1,1,7,17,0,2,0,7,1,1,0,0,0,0,1,8,2,0,0,0,0,0,9,1,0,False
925,..\projects\antlr4-4.11.0\tool-testsuite\test\org\antlr\v4\test\tool\TestUnbufferedCharStream.java,org.antlr.v4.test.tool.TestUnbufferedCharStream,void test1Char(),"@Test
public void test1Char() throws Exception {
    TestingUnbufferedCharStream input = createStream(""x"");
    assertEquals('x', input.LA(1));
    input.consume();
    assertEquals(IntStream.EOF, input.LA(1));
    String r = input.getRemainingBuffer();
    // shouldn't include x
    assertEquals(""\uFFFF"", r);
    // whole buffer
    assertEquals(""\uFFFF"", input.getBuffer());
}", ,"// shouldn't include x
[[SEP]]// whole buffer
",// shouldn't include x[[SEP]]// whole buffer,168,176,[0],0,"[0, 0]",0,"[0, 0]",0,0,0,0,test1Char(),org.antlr.v4.test.tool.TestUnbufferedCharStream,test1Char/0,False,168,3,3,0,3,1,6,9,0,2,0,6,1,1,0,0,0,0,3,2,2,0,0,0,0,0,11,1,0,False
926,..\projects\antlr4-4.11.0\tool-testsuite\test\org\antlr\v4\test\tool\TestUnbufferedCharStream.java,org.antlr.v4.test.tool.TestUnbufferedCharStream,void test2Char(),"@Test
public void test2Char() throws Exception {
    TestingUnbufferedCharStream input = createStream(""xy"");
    assertEquals('x', input.LA(1));
    input.consume();
    assertEquals('y', input.LA(1));
    // shouldn't include x
    assertEquals(""y"", input.getRemainingBuffer());
    assertEquals(""y"", input.getBuffer());
    input.consume();
    assertEquals(IntStream.EOF, input.LA(1));
    assertEquals(""\uFFFF"", input.getBuffer());
}", ,"// shouldn't include x
",// shouldn't include x,178,188,[0],0,[0],0,[0],0,0,0,0,test2Char(),org.antlr.v4.test.tool.TestUnbufferedCharStream,test2Char/0,False,178,3,3,0,3,1,6,11,0,1,0,6,1,1,0,0,0,0,4,3,1,0,0,0,0,0,10,1,0,False
927,..\projects\antlr4-4.11.0\tool-testsuite\test\org\antlr\v4\test\tool\TestUnbufferedCharStream.java,org.antlr.v4.test.tool.TestUnbufferedCharStream,void test1MarkWithConsumesInSequence(),"@Test
public void test1MarkWithConsumesInSequence() throws Exception {
    TestingUnbufferedCharStream input = createStream(""xyz"");
    int m = input.mark();
    // x, moves to y
    input.consume();
    // y
    input.consume();
    // z, moves to EOF
    input.consume();
    assertEquals(IntStream.EOF, input.LA(1));
    assertEquals(""xyz\uFFFF"", input.getBuffer());
    // wipes buffer
    input.release(m);
    assertEquals(""\uFFFF"", input.getBuffer());
}", ,"// x, moves to y
[[SEP]]// y
[[SEP]]// z, moves to EOF
[[SEP]]// wipes buffer
","// x, moves to y[[SEP]]// y[[SEP]]// z, moves to EOF[[SEP]]// wipes buffer",249,259,[0],0,"[0, 0, 0, 0]",0,"[0, 0, 0, 0]",0,0,0,0,test1MarkWithConsumesInSequence(),org.antlr.v4.test.tool.TestUnbufferedCharStream,test1MarkWithConsumesInSequence/0,False,249,3,2,0,2,1,7,11,0,2,0,7,1,1,0,0,0,0,3,1,2,0,0,0,0,0,16,1,0,False
928,..\projects\antlr4-4.11.0\tool-testsuite\test\org\antlr\v4\test\tool\TestUnbufferedCharStream.java,org.antlr.v4.test.tool.TestUnbufferedCharStream,void test2Mark(),"@Test
public void test2Mark() throws Exception {
    TestingUnbufferedCharStream input = createStream(""xyz"", 100);
    assertEquals('x', input.LA(1));
    // reset buffer index (p) to 0
    input.consume();
    int m1 = input.mark();
    assertEquals('y', input.LA(1));
    input.consume();
    int m2 = input.mark();
    assertEquals(""yz"", input.getBuffer());
    // drop to 1 marker
    input.release(m2);
    input.consume();
    // shifts remaining char to beginning
    input.release(m1);
    assertEquals(IntStream.EOF, input.LA(1));
    assertEquals(""\uFFFF"", input.getBuffer());
}", ,"// reset buffer index (p) to 0
[[SEP]]// drop to 1 marker
[[SEP]]// shifts remaining char to beginning
",// reset buffer index (p) to 0[[SEP]]// drop to 1 marker[[SEP]]// shifts remaining char to beginning,261,275,[0],0,"[0, 0, 0]",0,"[0, 0, 0]",0,0,0,0,test2Mark(),org.antlr.v4.test.tool.TestUnbufferedCharStream,test2Mark/0,False,261,3,2,0,2,1,7,15,0,3,0,7,1,1,0,0,0,0,3,4,3,0,0,0,0,0,13,1,0,False
929,..\projects\antlr4-4.11.0\tool-testsuite\test\org\antlr\v4\test\tool\TestUnbufferedCharStream.java,org.antlr.v4.test.tool.TestUnbufferedCharStream,void testAFewTokens(),"@Test
public void testAFewTokens() throws Exception {
    LexerGrammar g = new LexerGrammar(""lexer grammar t;\n"" + ""ID : 'a'..'z'+;\n"" + ""INT : '0'..'9'+;\n"" + ""SEMI : ';';\n"" + ""ASSIGN : '=';\n"" + ""PLUS : '+';\n"" + ""MULT : '*';\n"" + ""WS : ' '+;\n"");
    // Tokens: 012345678901234567
    // Input:  x = 3 * 0 + 2 * 0;
    TestingUnbufferedCharStream input = createStream(""x = 302 * 91 + 20234234 * 0;"");
    LexerInterpreter lexEngine = g.createLexerInterpreter(input);
    // copy text into tokens from char stream
    lexEngine.setTokenFactory(new CommonTokenFactory(true));
    CommonTokenStream tokens = new CommonTokenStream(lexEngine);
    String result = tokens.LT(1).getText();
    String expecting = ""x"";
    assertEquals(expecting, result);
    tokens.fill();
    expecting = ""[[@0,0:0='x',<1>,1:0], [@1,1:1=' ',<7>,1:1], [@2,2:2='=',<4>,1:2],"" + "" [@3,3:3=' ',<7>,1:3], [@4,4:6='302',<2>,1:4], [@5,7:7=' ',<7>,1:7],"" + "" [@6,8:8='*',<6>,1:8], [@7,9:9=' ',<7>,1:9], [@8,10:11='91',<2>,1:10],"" + "" [@9,12:12=' ',<7>,1:12], [@10,13:13='+',<5>,1:13], [@11,14:14=' ',<7>,1:14],"" + "" [@12,15:22='20234234',<2>,1:15], [@13,23:23=' ',<7>,1:23],"" + "" [@14,24:24='*',<6>,1:24], [@15,25:25=' ',<7>,1:25], [@16,26:26='0',<2>,1:26],"" + "" [@17,27:27=';',<3>,1:27], [@18,28:27='',<-1>,1:28]]"";
    assertEquals(expecting, tokens.getTokens().toString());
}", ,"// Tokens: 012345678901234567
[[SEP]]// Input:  x = 3 * 0 + 2 * 0;
[[SEP]]// copy text into tokens from char stream
",// Tokens: 012345678901234567// Input:  x = 3 * 0 + 2 * 0;[[SEP]]// copy text into tokens from char stream,277,307,[0],0,"[0, 0, 0]",0,"[0, 0]",0,0,0,0,testAFewTokens(),org.antlr.v4.test.tool.TestUnbufferedCharStream,testAFewTokens/0,False,277,8,3,0,3,1,9,13,0,6,0,9,1,1,0,0,0,0,17,1,7,2,0,0,0,0,28,1,0,False
930,..\projects\antlr4-4.11.0\tool-testsuite\test\org\antlr\v4\test\tool\TestUnbufferedCharStream.java,org.antlr.v4.test.tool.TestUnbufferedCharStream.TestingUnbufferedCharStream,String getRemainingBuffer(),"/**
 * For testing.  What's in moving window into data stream from
 *  current index, LA(1) or data[p], to end of buffer?
 */
public String getRemainingBuffer() {
    if (n == 0)
        return """";
    int len = n;
    if (data[len - 1] == IntStream.EOF) {
        // Don't pass -1 to new String().
        return new String(data, p, len - p - 1) + ""\uFFFF"";
    } else {
        return new String(data, p, len - p);
    }
}","/**
 * For testing.  What's in moving window into data stream from
 *  current index, LA(1) or data[p], to end of buffer?
 */
","// Don't pass -1 to new String().
","/** * For testing.  What's in moving window into data stream from *  current index, LA(1) or data[p], to end of buffer? */[[SEP]]// Don't pass -1 to new String().",354,363,[0],0,[0],0,"[0, 0]",0,0,0,0,getRemainingBuffer(),org.antlr.v4.test.tool.TestUnbufferedCharStream$TestingUnbufferedCharStream,getRemainingBuffer/0,False,354,0,2,2,0,3,0,10,3,1,0,0,0,0,0,2,0,0,2,3,1,4,1,0,0,0,21,1,0,True
931,..\projects\antlr4-4.11.0\tool-testsuite\test\org\antlr\v4\test\tool\TestUnbufferedCharStream.java,org.antlr.v4.test.tool.TestUnbufferedCharStream.TestingUnbufferedCharStream,String getBuffer(),"/**
 * For testing.  What's in moving window buffer into data stream.
 *  From 0..p-1 have been consume.
 */
public String getBuffer() {
    if (n == 0)
        return """";
    int len = n;
    // Don't pass -1 to new String().
    if (data[len - 1] == IntStream.EOF) {
        // Don't pass -1 to new String().
        return new String(data, 0, len - 1) + ""\uFFFF"";
    } else {
        return new String(data, 0, len);
    }
}","/**
 * For testing.  What's in moving window buffer into data stream.
 *  From 0..p-1 have been consume.
 */
","// Don't pass -1 to new String().
[[SEP]]// Don't pass -1 to new String().
",/** * For testing.  What's in moving window buffer into data stream. *  From 0..p-1 have been consume. */[[SEP]]// Don't pass -1 to new String().[[SEP]]// Don't pass -1 to new String().,368,378,[0],0,"[0, 0]",0,"[0, 0, 0]",0,0,0,0,getBuffer(),org.antlr.v4.test.tool.TestUnbufferedCharStream$TestingUnbufferedCharStream,getBuffer/0,False,368,0,7,7,0,3,0,10,3,1,0,0,0,0,0,2,0,0,2,5,1,3,1,0,0,0,14,1,0,True
932,..\projects\antlr4-4.11.0\tool-testsuite\test\org\antlr\v4\test\tool\TestUnbufferedTokenStream.java,org.antlr.v4.test.tool.TestUnbufferedTokenStream,void testLookahead(),"@Test
public void testLookahead() throws Exception {
    LexerGrammar g = new LexerGrammar(""lexer grammar t;\n"" + ""ID : 'a'..'z'+;\n"" + ""INT : '0'..'9'+;\n"" + ""SEMI : ';';\n"" + ""ASSIGN : '=';\n"" + ""PLUS : '+';\n"" + ""MULT : '*';\n"" + ""WS : ' '+;\n"");
    // Tokens: 012345678901234567
    // Input:  x = 302;
    CharStream input = new ANTLRInputStream(new StringReader(""x = 302;""));
    LexerInterpreter lexEngine = g.createLexerInterpreter(input);
    TokenStream tokens = new UnbufferedTokenStream<Token>(lexEngine);
    assertEquals(""x"", tokens.LT(1).getText());
    assertEquals("" "", tokens.LT(2).getText());
    assertEquals(""="", tokens.LT(3).getText());
    assertEquals("" "", tokens.LT(4).getText());
    assertEquals(""302"", tokens.LT(5).getText());
    assertEquals("";"", tokens.LT(6).getText());
}", ,"// Tokens: 012345678901234567
[[SEP]]// Input:  x = 302;
",// Tokens: 012345678901234567// Input:  x = 302;,28,53,[0],0,"[0, 0]",0,[0],0,0,0,0,testLookahead(),org.antlr.v4.test.tool.TestUnbufferedTokenStream,testLookahead/0,False,29,8,2,0,2,1,4,12,0,4,0,4,0,0,0,0,0,0,15,6,4,1,0,0,0,0,26,1,0,False
933,..\projects\antlr4-4.11.0\tool-testsuite\test\org\antlr\v4\test\tool\TestUnbufferedTokenStream.java,org.antlr.v4.test.tool.TestUnbufferedTokenStream,void testNoBuffering(),"@Test
public void testNoBuffering() throws Exception {
    LexerGrammar g = new LexerGrammar(""lexer grammar t;\n"" + ""ID : 'a'..'z'+;\n"" + ""INT : '0'..'9'+;\n"" + ""SEMI : ';';\n"" + ""ASSIGN : '=';\n"" + ""PLUS : '+';\n"" + ""MULT : '*';\n"" + ""WS : ' '+;\n"");
    // Tokens: 012345678901234567
    // Input:  x = 302;
    CharStream input = new ANTLRInputStream(new StringReader(""x = 302;""));
    LexerInterpreter lexEngine = g.createLexerInterpreter(input);
    TestingUnbufferedTokenStream<Token> tokens = new TestingUnbufferedTokenStream<Token>(lexEngine);
    assertEquals(""[[@0,0:0='x',<1>,1:0]]"", tokens.getBuffer().toString());
    assertEquals(""x"", tokens.LT(1).getText());
    // move to WS
    tokens.consume();
    assertEquals("" "", tokens.LT(1).getText());
    assertEquals(""[[@1,1:1=' ',<7>,1:1]]"", tokens.getRemainingBuffer().toString());
    tokens.consume();
    assertEquals(""="", tokens.LT(1).getText());
    assertEquals(""[[@2,2:2='=',<4>,1:2]]"", tokens.getRemainingBuffer().toString());
    tokens.consume();
    assertEquals("" "", tokens.LT(1).getText());
    assertEquals(""[[@3,3:3=' ',<7>,1:3]]"", tokens.getRemainingBuffer().toString());
    tokens.consume();
    assertEquals(""302"", tokens.LT(1).getText());
    assertEquals(""[[@4,4:6='302',<2>,1:4]]"", tokens.getRemainingBuffer().toString());
    tokens.consume();
    assertEquals("";"", tokens.LT(1).getText());
    assertEquals(""[[@5,7:7=';',<3>,1:7]]"", tokens.getRemainingBuffer().toString());
}", ,"// Tokens: 012345678901234567
[[SEP]]// Input:  x = 302;
[[SEP]]// move to WS
",// Tokens: 012345678901234567// Input:  x = 302;[[SEP]]// move to WS,55,90,[0],0,"[0, 0, 0]",0,"[0, 0]",0,0,0,0,testNoBuffering(),org.antlr.v4.test.tool.TestUnbufferedTokenStream,testNoBuffering/0,False,55,8,3,0,3,1,8,23,0,4,0,8,0,0,0,0,0,0,21,6,4,1,0,0,0,0,26,1,0,False
934,..\projects\antlr4-4.11.0\tool-testsuite\test\org\antlr\v4\test\tool\TestUnbufferedTokenStream.java,org.antlr.v4.test.tool.TestUnbufferedTokenStream,void testMarkStart(),"@Test
public void testMarkStart() throws Exception {
    LexerGrammar g = new LexerGrammar(""lexer grammar t;\n"" + ""ID : 'a'..'z'+;\n"" + ""INT : '0'..'9'+;\n"" + ""SEMI : ';';\n"" + ""ASSIGN : '=';\n"" + ""PLUS : '+';\n"" + ""MULT : '*';\n"" + ""WS : ' '+;\n"");
    // Tokens: 012345678901234567
    // Input:  x = 302;
    CharStream input = new ANTLRInputStream(new StringReader(""x = 302;""));
    LexerInterpreter lexEngine = g.createLexerInterpreter(input);
    TestingUnbufferedTokenStream<Token> tokens = new TestingUnbufferedTokenStream<Token>(lexEngine);
    int m = tokens.mark();
    assertEquals(""[[@0,0:0='x',<1>,1:0]]"", tokens.getBuffer().toString());
    assertEquals(""x"", tokens.LT(1).getText());
    // consume x
    tokens.consume();
    assertEquals(""[[@0,0:0='x',<1>,1:0], [@1,1:1=' ',<7>,1:1]]"", tokens.getBuffer().toString());
    // ' '
    tokens.consume();
    // =
    tokens.consume();
    // ' '
    tokens.consume();
    // 302
    tokens.consume();
    // ;
    tokens.consume();
    assertEquals(""[[@0,0:0='x',<1>,1:0], [@1,1:1=' ',<7>,1:1],"" + "" [@2,2:2='=',<4>,1:2], [@3,3:3=' ',<7>,1:3],"" + "" [@4,4:6='302',<2>,1:4], [@5,7:7=';',<3>,1:7],"" + "" [@6,8:7='<EOF>',<-1>,1:8]]"", tokens.getBuffer().toString());
}", ,"// Tokens: 012345678901234567
[[SEP]]// Input:  x = 302;
[[SEP]]// consume x
[[SEP]]// ' '
[[SEP]]// =
[[SEP]]// ' '
[[SEP]]// 302
[[SEP]]// ;
",// Tokens: 012345678901234567// Input:  x = 302;[[SEP]]// consume x[[SEP]]// ' '[[SEP]]// =[[SEP]]// ' '[[SEP]]// 302[[SEP]]// ;,92,125,[0],0,"[0, 0, 0, 0, 0, 0, 0, 0]",0,"[0, 0, 0, 0, 0, 0, 0]",0,0,0,0,testMarkStart(),org.antlr.v4.test.tool.TestUnbufferedTokenStream,testMarkStart/0,False,92,8,3,0,3,1,8,17,0,5,0,8,0,0,0,0,0,0,16,1,5,2,0,0,0,0,27,1,0,False
935,..\projects\antlr4-4.11.0\tool-testsuite\test\org\antlr\v4\test\tool\TestUnbufferedTokenStream.java,org.antlr.v4.test.tool.TestUnbufferedTokenStream,void testMarkThenRelease(),"@Test
public void testMarkThenRelease() throws Exception {
    LexerGrammar g = new LexerGrammar(""lexer grammar t;\n"" + ""ID : 'a'..'z'+;\n"" + ""INT : '0'..'9'+;\n"" + ""SEMI : ';';\n"" + ""ASSIGN : '=';\n"" + ""PLUS : '+';\n"" + ""MULT : '*';\n"" + ""WS : ' '+;\n"");
    // Tokens: 012345678901234567
    // Input:  x = 302;
    CharStream input = new ANTLRInputStream(new StringReader(""x = 302 + 1;""));
    LexerInterpreter lexEngine = g.createLexerInterpreter(input);
    TestingUnbufferedTokenStream<Token> tokens = new TestingUnbufferedTokenStream<Token>(lexEngine);
    int m = tokens.mark();
    assertEquals(""[[@0,0:0='x',<1>,1:0]]"", tokens.getBuffer().toString());
    assertEquals(""x"", tokens.LT(1).getText());
    // consume x
    tokens.consume();
    assertEquals(""[[@0,0:0='x',<1>,1:0], [@1,1:1=' ',<7>,1:1]]"", tokens.getBuffer().toString());
    // ' '
    tokens.consume();
    // =
    tokens.consume();
    // ' '
    tokens.consume();
    assertEquals(""302"", tokens.LT(1).getText());
    // ""x = 302"" is in buffer. will kill buffer
    tokens.release(m);
    // 302
    tokens.consume();
    // ' '
    tokens.consume();
    // mark at the +
    m = tokens.mark();
    assertEquals(""+"", tokens.LT(1).getText());
    // '+'
    tokens.consume();
    // ' '
    tokens.consume();
    // 1
    tokens.consume();
    // ;
    tokens.consume();
    assertEquals(""<EOF>"", tokens.LT(1).getText());
    // we marked at the +, so that should be the start of the buffer
    assertEquals(""[[@6,8:8='+',<5>,1:8], [@7,9:9=' ',<7>,1:9],"" + "" [@8,10:10='1',<2>,1:10], [@9,11:11=';',<3>,1:11],"" + "" [@10,12:11='<EOF>',<-1>,1:12]]"", tokens.getBuffer().toString());
    tokens.release(m);
}", ,"// Tokens: 012345678901234567
[[SEP]]// Input:  x = 302;
[[SEP]]// consume x
[[SEP]]// ' '
[[SEP]]// =
[[SEP]]// ' '
[[SEP]]// ""x = 302"" is in buffer. will kill buffer
[[SEP]]// 302
[[SEP]]// ' '
[[SEP]]// mark at the +
[[SEP]]// '+'
[[SEP]]// ' '
[[SEP]]// 1
[[SEP]]// ;
[[SEP]]// we marked at the +, so that should be the start of the buffer
","// Tokens: 012345678901234567// Input:  x = 302;[[SEP]]// consume x[[SEP]]// ' '[[SEP]]// =[[SEP]]// ' '[[SEP]]// ""x = 302"" is in buffer. will kill buffer[[SEP]]// 302[[SEP]]// ' '[[SEP]]// mark at the +[[SEP]]// '+'[[SEP]]// ' '[[SEP]]// 1[[SEP]]// ;[[SEP]]// we marked at the +, so that should be the start of the buffer",127,170,[0],0,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]",0,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]",0,0,0,0,testMarkThenRelease(),org.antlr.v4.test.tool.TestUnbufferedTokenStream,testMarkThenRelease/0,False,127,8,3,0,3,1,9,27,0,5,0,9,0,0,0,0,0,0,18,4,6,2,0,0,0,0,28,1,0,False
936,..\projects\antlr4-4.11.0\tool-testsuite\test\org\antlr\v4\test\tool\TestUnbufferedTokenStream.java,org.antlr.v4.test.tool.TestUnbufferedTokenStream.TestingUnbufferedTokenStream,List<? extends Token> getRemainingBuffer(),"/**
 * For testing.  What's in moving window into token stream from
 *  current index, LT(1) or tokens[p], to end of buffer?
 */
protected List<? extends Token> getRemainingBuffer() {
    if (n == 0) {
        return Collections.emptyList();
    }
    return Arrays.asList(tokens).subList(p, n);
}","/**
 * For testing.  What's in moving window into token stream from
 *  current index, LT(1) or tokens[p], to end of buffer?
 */
", ,"/** * For testing.  What's in moving window into token stream from *  current index, LT(1) or tokens[p], to end of buffer? */",181,187,[0],0,[0],0,[0],0,0,0,0,getRemainingBuffer(),org.antlr.v4.test.tool.TestUnbufferedTokenStream$TestingUnbufferedTokenStream,getRemainingBuffer/0,False,181,0,0,0,0,2,3,6,2,0,0,3,0,0,0,1,0,0,0,1,0,0,1,0,0,0,21,4,0,True
937,..\projects\antlr4-4.11.0\tool-testsuite\test\org\antlr\v4\test\tool\TestUnbufferedTokenStream.java,org.antlr.v4.test.tool.TestUnbufferedTokenStream.TestingUnbufferedTokenStream,List<? extends Token> getBuffer(),"/**
 * For testing.  What's in moving window buffer into data stream.
 *  From 0..p-1 have been consume.
 */
protected List<? extends Token> getBuffer() {
    if (n == 0) {
        return Collections.emptyList();
    }
    return Arrays.asList(tokens).subList(0, n);
}","/**
 * For testing.  What's in moving window buffer into data stream.
 *  From 0..p-1 have been consume.
 */
", ,/** * For testing.  What's in moving window buffer into data stream. *  From 0..p-1 have been consume. */,192,198,[0],0,[0],0,[0],0,0,0,0,getBuffer(),org.antlr.v4.test.tool.TestUnbufferedTokenStream$TestingUnbufferedTokenStream,getBuffer/0,False,192,0,0,0,0,2,3,6,2,0,0,3,0,0,0,1,0,0,0,2,0,0,1,0,0,0,15,4,0,True
938,..\projects\antlr4-4.11.0\tool-testsuite\test\org\antlr\v4\test\tool\TestUnicodeGrammar.java,org.antlr.v4.test.tool.TestUnicodeGrammar,void unicodeSurrogatePairLiteralInGrammar(),"// TODO: This test cannot pass unless we change either the grammar
// parser to decode surrogate pair literals to code points (which
// would break existing clients) or to treat them as an
// alternative:
// 
// '\\uD83C\\uDF0D' -> ('\\u{1F30E}' | '\\uD83C\\uDF0D')
// 
// but I worry that might cause parse ambiguity if we're not careful.
// @Test
public void unicodeSurrogatePairLiteralInGrammar() throws Exception {
    String grammarText = ""grammar Unicode;\n"" + ""r : 'hello' WORLD;\n"" + ""WORLD : ('\\uD83C\\uDF0D' | '\\uD83C\\uDF0E' | '\\uD83C\\uDF0F' );\n"" + ""WS : [ \\t\\r\\n]+ -> skip;\n"";
    String inputText = new StringBuilder(""hello "").appendCodePoint(0x1F30E).toString();
    assertEquals(""(r:1 "" + inputText + "")"", parseTreeForGrammarWithInput(grammarText, ""r"", inputText));
}","// @Test
", ,// TODO: This test cannot pass unless we change either the grammar// parser to decode surrogate pair literals to code points (which// would break existing clients) or to treat them as an// alternative://// '\\uD83C\\uDF0D' -> ('\\u{1F30E}' | '\\uD83C\\uDF0D')//// but I worry that might cause parse ambiguity if we're not careful.// @Test,52,67,[0],0,[0],0,[1],1,1,1,1,unicodeSurrogatePairLiteralInGrammar(),org.antlr.v4.test.tool.TestUnicodeGrammar,unicodeSurrogatePairLiteralInGrammar/0,False,52,1,1,0,1,1,4,5,0,2,0,4,1,1,0,0,0,0,8,1,2,2,0,0,0,0,24,1,0,False
939,..\projects\antlr4-4.11.0\tool-testsuite\test\org\antlr\v4\test\tool\TestUnicodeGrammar.java,org.antlr.v4.test.tool.TestUnicodeGrammar,void binaryGrammar(),"@Test
public void binaryGrammar() throws Exception {
    String grammarText = ""grammar Binary;\n"" + ""r : HEADER PACKET+ FOOTER;\n"" + ""HEADER : '\\u0002\\u0000\\u0001\\u0007';\n"" + ""PACKET : '\\u00D0' ('\\u00D1' | '\\u00D2' | '\\u00D3') +;\n"" + ""FOOTER : '\\u00FF';\n"";
    byte[] toParse = new byte[] { (byte) 0x02, (byte) 0x00, (byte) 0x01, (byte) 0x07, (byte) 0xD0, (byte) 0xD2, (byte) 0xD2, (byte) 0xD3, (byte) 0xD3, (byte) 0xD3, (byte) 0xD0, (byte) 0xD3, (byte) 0xD3, (byte) 0xD1, (byte) 0xFF };
    CharStream charStream;
    try (ByteArrayInputStream is = new ByteArrayInputStream(toParse);
        // Note we use ISO_8859_1 to treat all byte values as Unicode ""characters"" from
        // U+0000 to U+00FF.
        InputStreamReader isr = new InputStreamReader(is, StandardCharsets.ISO_8859_1)) {
        charStream = new ANTLRInputStream(isr);
    }
    Grammar grammar = new Grammar(grammarText);
    LexerInterpreter lexEngine = grammar.createLexerInterpreter(charStream);
    CommonTokenStream tokens = new CommonTokenStream(lexEngine);
    GrammarParserInterpreter parser = grammar.createGrammarParserInterpreter(tokens);
    ParseTree parseTree = parser.parse(grammar.rules.get(""r"").index);
    InterpreterTreeTextProvider nodeTextProvider = new InterpreterTreeTextProvider(grammar.getRuleNames());
    String result = Trees.toStringTree(parseTree, nodeTextProvider);
    assertEquals(""(r:1 \u0002\u0000\u0001\u0007 \u00D0\u00D2\u00D2\u00D3\u00D3\u00D3 \u00D0\u00D3\u00D3\u00D1 \u00FF)"", result);
}", ,"// Note we use ISO_8859_1 to treat all byte values as Unicode ""characters"" from
[[SEP]]// U+0000 to U+00FF.
","// Note we use ISO_8859_1 to treat all byte values as Unicode ""characters"" from// U+0000 to U+00FF.",121,154,[0],0,"[0, 0]",0,[0],0,0,0,0,binaryGrammar(),org.antlr.v4.test.tool.TestUnicodeGrammar,binaryGrammar/0,False,122,10,5,0,5,1,7,16,0,12,0,7,0,0,0,0,1,0,7,15,12,1,1,0,0,0,47,1,0,False
940,..\projects\antlr4-4.11.0\tool-testsuite\test\org\antlr\v4\test\tool\TestXPath.java,org.antlr.v4.test.tool.TestXPath,void testValidPaths(),"@Test
public void testValidPaths() throws Exception {
    String[] xpath = { // all funcs under prog at root
    ""/prog/func"", // all children of prog at root
    ""/prog/*"", // all func kids of any root node
    ""/*/func"", // prog must be root node
    ""prog"", // prog must be root node
    ""/prog"", // any root
    ""/*"", // any root
    ""*"", // any ID in tree
    ""//ID"", // any ID child of a primary under any expr
    ""//expr/primary/ID"", // any ID under a body
    ""//body//ID"", // any 'return' literal in tree, matched by literal name
    ""//'return'"", // any 'return' literal in tree, matched by symbolic name
    ""//RETURN"", // all kids of any primary
    ""//primary/*"", // all stat nodes grandkids of any func node
    ""//func/*/stat"", // all def literal kids of func kid of prog
    ""/prog/func/'def'"", // all ';' under any stat node
    ""//stat/';'"", // anything but ID under primary under any expr node
    ""//expr/primary/!ID"", // anything but primary under any expr node
    ""//expr/!primary"", // nothing anywhere
    ""//!*"", // nothing at root
    ""/!*"", // any ID under any expression (tests antlr/antlr4#370)
    ""//expr//ID"" };
    String[] expected = { ""[func, func]"", ""[func, func]"", ""[func, func]"", ""[prog]"", ""[prog]"", ""[prog]"", ""[prog]"", ""[f, x, y, x, y, g, x, x]"", ""[y, x]"", ""[x, y, x]"", ""[return]"", ""[return]"", ""[3, 4, y, 1, 2, x]"", ""[stat, stat, stat, stat]"", ""[def, def]"", ""[;, ;, ;, ;]"", ""[3, 4, 1, 2]"", ""[expr, expr, expr, expr, expr, expr]"", ""[]"", ""[]"", ""[y, x]"" };
    for (int i = 0; i < xpath.length; i++) {
        List<String> nodes = getNodeStrings(""Expr.g4"", grammar, SAMPLE_PROGRAM, xpath[i], ""prog"", ""ExprParser"", ""ExprLexer"");
        String result = nodes.toString();
        assertEquals(expected[i], result, ""path "" + xpath[i] + "" failed"");
    }
}", ,"// all funcs under prog at root
[[SEP]]// all children of prog at root
[[SEP]]// all func kids of any root node
[[SEP]]// prog must be root node
[[SEP]]// prog must be root node
[[SEP]]// any root
[[SEP]]// any root
[[SEP]]// any ID in tree
[[SEP]]// any ID child of a primary under any expr
[[SEP]]// any ID under a body
[[SEP]]// any 'return' literal in tree, matched by literal name
[[SEP]]// any 'return' literal in tree, matched by symbolic name
[[SEP]]// all kids of any primary
[[SEP]]// all stat nodes grandkids of any func node
[[SEP]]// all def literal kids of func kid of prog
[[SEP]]// all ';' under any stat node
[[SEP]]// anything but ID under primary under any expr node
[[SEP]]// anything but primary under any expr node
[[SEP]]// nothing anywhere
[[SEP]]// nothing at root
[[SEP]]// any ID under any expression (tests antlr/antlr4#370)
","// all funcs under prog at root[[SEP]]// all children of prog at root[[SEP]]/*"", // all func kids of any root node    ""/*/[[SEP]]// prog must be root node[[SEP]]// any root",65,118,[0],0,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]",0,"[0, 0, 0, 0, 0]",0,0,0,0,testValidPaths(),org.antlr.v4.test.tool.TestXPath,testValidPaths/0,False,65,2,1,0,1,2,3,9,0,5,0,3,1,2,1,0,0,0,48,1,5,1,1,0,0,0,18,1,0,False
941,..\projects\antlr4-4.11.0\tool-testsuite\test\org\antlr\v4\test\tool\ToolTestUtils.java,org.antlr.v4.test.tool.ToolTestUtils,"ATN createATN(Grammar, boolean)","public static ATN createATN(Grammar g, boolean useSerializer) {
    if (g.atn == null) {
        semanticProcess(g);
        assertEquals(0, g.tool.getNumErrors());
        ParserATNFactory f = g.isLexer() ? new LexerATNFactory((LexerGrammar) g) : new ParserATNFactory(g);
        g.atn = f.createATN();
        assertEquals(0, g.tool.getNumErrors());
    }
    ATN atn = g.atn;
    if (useSerializer) {
        // sets some flags in ATN
        IntegerList serialized = ATNSerializer.getSerialized(atn);
        return new ATNDeserializer().deserialize(serialized.toArray());
    }
    return atn;
}", ,"// sets some flags in ATN
",// sets some flags in ATN,160,179,[0],0,[0],0,[0],0,0,0,0,"createATN(Grammar, boolean)",org.antlr.v4.test.tool.ToolTestUtils,"createATN/2[org.antlr.v4.tool.Grammar,boolean]",False,160,9,35,32,3,4,8,15,2,3,2,8,1,1,0,1,0,0,0,2,4,0,1,0,0,0,22,9,0,False
942,..\projects\antlr4-4.11.0\tool-testsuite\test\org\antlr\v4\test\tool\ToolTestUtils.java,org.antlr.v4.test.tool.ToolTestUtils,void semanticProcess(Grammar),"public static void semanticProcess(Grammar g) {
    if (g.ast != null && !g.ast.hasErrors) {
        // System.out.println(g.ast.toStringTree());
        Tool antlr = new Tool();
        SemanticPipeline sem = new SemanticPipeline(g);
        sem.process();
        if (g.getImportedGrammars() != null) {
            // process imported grammars (if any)
            for (Grammar imp : g.getImportedGrammars()) {
                antlr.processNonCombinedGrammar(imp, false);
            }
        }
    }
}", ,"// System.out.println(g.ast.toStringTree());
[[SEP]]// process imported grammars (if any)
",// System.out.println(g.ast.toStringTree());[[SEP]]// process imported grammars (if any),181,193,[0],0,"[0, 0]",0,"[0, 0]",0,0,0,0,semanticProcess(Grammar),org.antlr.v4.test.tool.ToolTestUtils,semanticProcess/1[org.antlr.v4.tool.Grammar],False,181,3,8,3,5,5,3,12,0,2,1,3,0,0,1,2,0,0,0,0,2,0,3,0,0,0,11,9,0,False
943,..\projects\antlr4-4.11.0\tool\src\org\antlr\v4\Tool.java,org.antlr.v4.Tool,void handleArgs(),"protected void handleArgs() {
    int i = 0;
    while (args != null && i < args.length) {
        String arg = args[i];
        i++;
        if (arg.startsWith(""-D"")) {
            // -Dlanguage=Java syntax
            handleOptionSetArg(arg);
            continue;
        }
        if (arg.charAt(0) != '-') {
            // file name
            if (!grammarFiles.contains(arg))
                grammarFiles.add(arg);
            continue;
        }
        boolean found = false;
        for (Option o : optionDefs) {
            if (arg.equals(o.name)) {
                found = true;
                String argValue = null;
                if (o.argType == OptionArgType.STRING) {
                    argValue = args[i];
                    i++;
                }
                // use reflection to set field
                Class<? extends Tool> c = this.getClass();
                try {
                    Field f = c.getField(o.fieldName);
                    if (argValue == null) {
                        if (arg.startsWith(""-no-""))
                            f.setBoolean(this, false);
                        else
                            f.setBoolean(this, true);
                    } else
                        f.set(this, argValue);
                } catch (Exception e) {
                    errMgr.toolError(ErrorType.INTERNAL_ERROR, ""can't access field "" + o.fieldName);
                }
            }
        }
        if (!found) {
            errMgr.toolError(ErrorType.INVALID_CMDLINE_ARG, arg);
        }
    }
    if (outputDirectory != null) {
        if (outputDirectory.endsWith(""/"") || outputDirectory.endsWith(""\\"")) {
            outputDirectory = outputDirectory.substring(0, outputDirectory.length() - 1);
        }
        File outDir = new File(outputDirectory);
        haveOutputDir = true;
        if (outDir.exists() && !outDir.isDirectory()) {
            errMgr.toolError(ErrorType.OUTPUT_DIR_IS_FILE, outputDirectory);
            outputDirectory = ""."";
        }
    } else {
        outputDirectory = ""."";
    }
    if (libDirectory != null) {
        if (libDirectory.endsWith(""/"") || libDirectory.endsWith(""\\"")) {
            libDirectory = libDirectory.substring(0, libDirectory.length() - 1);
        }
        File outDir = new File(libDirectory);
        if (!outDir.exists()) {
            errMgr.toolError(ErrorType.DIR_NOT_FOUND, libDirectory);
            libDirectory = ""."";
        }
    } else {
        libDirectory = ""."";
    }
    if (launch_ST_inspector) {
        STGroup.trackCreationEvents = true;
        return_dont_exit = true;
    }
}", ,"// -Dlanguage=Java syntax
[[SEP]]// file name
[[SEP]]// use reflection to set field
",// -Dlanguage=Java syntax[[SEP]]// file name[[SEP]]// use reflection to set field,195,270,[0],0,"[0, 0, 0]",0,"[0, 0, 0]",0,0,0,0,handleArgs(),org.antlr.v4.Tool,handleArgs/0,False,195,2,3,1,2,23,16,72,0,8,0,16,1,1,2,6,1,0,11,6,19,3,6,0,0,0,41,4,0,False
944,..\projects\antlr4-4.11.0\tool\src\org\antlr\v4\Tool.java,org.antlr.v4.Tool,void processGrammarsOnCommandLine(),"public void processGrammarsOnCommandLine() {
    List<GrammarRootAST> sortedGrammars = sortGrammarByTokenVocab(grammarFiles);
    for (GrammarRootAST t : sortedGrammars) {
        final Grammar g = createGrammar(t);
        g.fileName = t.fileName;
        if (gen_dependencies) {
            BuildDependencyGenerator dep = new BuildDependencyGenerator(this, g);
            /*
					List outputFiles = dep.getGeneratedFileList();
					List dependents = dep.getDependenciesFileList();
					System.out.println(""output: ""+outputFiles);
					System.out.println(""dependents: ""+dependents);
					 */
            System.out.println(dep.getDependencies().render());
        } else if (errMgr.getNumErrors() == 0) {
            process(g, true);
        }
    }
}", ,"/*
					List outputFiles = dep.getGeneratedFileList();
					List dependents = dep.getDependenciesFileList();
					System.out.println(""output: ""+outputFiles);
					System.out.println(""dependents: ""+dependents);
					 */
","/*					List outputFiles = dep.getGeneratedFileList();					List dependents = dep.getDependenciesFileList();					System.out.println(""output: ""+outputFiles);					System.out.println(""dependents: ""+dependents);					 */",299,321,[0],0,[0],0,[0],0,0,0,0,processGrammarsOnCommandLine(),org.antlr.v4.Tool,processGrammarsOnCommandLine/0,False,299,5,7,1,6,4,7,14,0,3,0,7,3,10,1,1,0,0,0,1,4,0,2,0,0,0,26,1,0,False
945,..\projects\antlr4-4.11.0\tool\src\org\antlr\v4\Tool.java,org.antlr.v4.Tool,"void process(Grammar, boolean)","/**
 *  To process a grammar, we load all of its imported grammars into
 * 		subordinate grammar objects. Then we merge the imported rules
 * 		into the root grammar. If a root grammar is a combined grammar,
 * 		we have to extract the implicit lexer. Once all this is done, we
 * 		process the lexer first, if present, and then the parser grammar
 */
public void process(Grammar g, boolean gencode) {
    g.loadImportedGrammars();
    GrammarTransformPipeline transform = new GrammarTransformPipeline(g, this);
    transform.process();
    LexerGrammar lexerg;
    GrammarRootAST lexerAST;
    if (g.ast != null && g.ast.grammarType == ANTLRParser.COMBINED && !g.ast.hasErrors) {
        // alters g.ast
        lexerAST = transform.extractImplicitLexer(g);
        if (lexerAST != null) {
            if (grammarOptions != null) {
                lexerAST.cmdLineOptions = grammarOptions;
            }
            lexerg = new LexerGrammar(this, lexerAST);
            lexerg.fileName = g.fileName;
            lexerg.originalGrammar = g;
            g.implicitLexer = lexerg;
            lexerg.implicitLexerOwner = g;
            processNonCombinedGrammar(lexerg, gencode);
            // System.out.println(""lexer tokens=""+lexerg.tokenNameToTypeMap);
            // System.out.println(""lexer strings=""+lexerg.stringLiteralToTypeMap);
        }
    }
    if (g.implicitLexer != null)
        g.importVocab(g.implicitLexer);
    // System.out.println(""tokens=""+g.tokenNameToTypeMap);
    // System.out.println(""strings=""+g.stringLiteralToTypeMap);
    processNonCombinedGrammar(g, gencode);
}","/**
 *  To process a grammar, we load all of its imported grammars into
 * 		subordinate grammar objects. Then we merge the imported rules
 * 		into the root grammar. If a root grammar is a combined grammar,
 * 		we have to extract the implicit lexer. Once all this is done, we
 * 		process the lexer first, if present, and then the parser grammar
 */
","// System.out.println(""tokens=""+g.tokenNameToTypeMap);
[[SEP]]// alters g.ast
[[SEP]]// System.out.println(""lexer tokens=""+lexerg.tokenNameToTypeMap);
[[SEP]]// System.out.println(""lexer strings=""+lexerg.stringLiteralToTypeMap);
[[SEP]]// System.out.println(""strings=""+g.stringLiteralToTypeMap);
","/** *  To process a grammar, we load all of its imported grammars into * 		subordinate grammar objects. Then we merge the imported rules * 		into the root grammar. If a root grammar is a combined grammar, * 		we have to extract the implicit lexer. Once all this is done, we * 		process the lexer first, if present, and then the parser grammar */[[SEP]]// alters g.ast[[SEP]]// System.out.println(""lexer tokens=""+lexerg.tokenNameToTypeMap);// System.out.println(""lexer strings=""+lexerg.stringLiteralToTypeMap);[[SEP]]// System.out.println(""tokens=""+g.tokenNameToTypeMap);// System.out.println(""strings=""+g.stringLiteralToTypeMap);",329,360,[0],0,"[0, 0, 0, 0, 0]",0,"[0, 0, 0, 0]",0,0,0,0,"process(Grammar, boolean)",org.antlr.v4.Tool,"process/2[org.antlr.v4.tool.Grammar,boolean]",False,329,5,12,5,7,7,5,23,0,3,2,5,1,7,0,5,0,0,0,0,8,0,3,0,0,0,46,1,0,True
946,..\projects\antlr4-4.11.0\tool\src\org\antlr\v4\Tool.java,org.antlr.v4.Tool,"void processNonCombinedGrammar(Grammar, boolean)","public void processNonCombinedGrammar(Grammar g, boolean gencode) {
    if (g.ast == null || g.ast.hasErrors)
        return;
    boolean ruleFail = checkForRuleIssues(g);
    if (ruleFail)
        return;
    int prevErrors = errMgr.getNumErrors();
    // MAKE SURE GRAMMAR IS SEMANTICALLY CORRECT (FILL IN GRAMMAR OBJECT)
    SemanticPipeline sem = new SemanticPipeline(g);
    sem.process();
    if (errMgr.getNumErrors() > prevErrors)
        return;
    CodeGenerator codeGenerator = CodeGenerator.create(g);
    if (codeGenerator == null) {
        return;
    }
    // BUILD ATN FROM AST
    ATNFactory factory;
    if (g.isLexer())
        factory = new LexerATNFactory((LexerGrammar) g, codeGenerator);
    else
        factory = new ParserATNFactory(g);
    g.atn = factory.createATN();
    if (generate_ATN_dot)
        generateATNs(g);
    if (gencode && g.tool.getNumErrors() == 0) {
        String interpFile = generateInterpreterData(g);
        try (Writer fw = getOutputFileWriter(g, g.name + "".interp"")) {
            fw.write(interpFile);
        } catch (IOException ioe) {
            errMgr.toolError(ErrorType.CANNOT_WRITE_FILE, ioe);
        }
    }
    // PERFORM GRAMMAR ANALYSIS ON ATN: BUILD DECISION DFAs
    AnalysisPipeline anal = new AnalysisPipeline(g);
    anal.process();
    // if ( generate_DFA_dot ) generateDFAs(g);
    if (g.tool.getNumErrors() > prevErrors)
        return;
    // GENERATE CODE
    if (gencode) {
        CodeGenPipeline gen = new CodeGenPipeline(g, codeGenerator);
        gen.process();
    }
}", ,"// if ( generate_DFA_dot ) generateDFAs(g);
[[SEP]]// MAKE SURE GRAMMAR IS SEMANTICALLY CORRECT (FILL IN GRAMMAR OBJECT)
[[SEP]]// BUILD ATN FROM AST
[[SEP]]// PERFORM GRAMMAR ANALYSIS ON ATN: BUILD DECISION DFAs
[[SEP]]// GENERATE CODE
",// MAKE SURE GRAMMAR IS SEMANTICALLY CORRECT (FILL IN GRAMMAR OBJECT)[[SEP]]// BUILD ATN FROM AST[[SEP]]// PERFORM GRAMMAR ANALYSIS ON ATN: BUILD DECISION DFAs[[SEP]]// if ( generate_DFA_dot ) generateDFAs(g);[[SEP]]// GENERATE CODE,362,411,[0],0,"[0, 0, 0, 0, 0]",0,"[0, 0, 0, 0, 0]",0,0,0,0,"processNonCombinedGrammar(Grammar, boolean)",org.antlr.v4.Tool,"processNonCombinedGrammar/2[org.antlr.v4.tool.Grammar,boolean]",False,362,11,12,2,10,13,13,34,5,9,2,13,5,6,0,3,1,0,1,1,11,1,2,0,0,0,48,1,0,False
947,..\projects\antlr4-4.11.0\tool\src\org\antlr\v4\Tool.java,org.antlr.v4.Tool,boolean checkForRuleIssues(Grammar),"/**
 * Important enough to avoid multiple definitions that we do very early,
 * right after AST construction. Also check for undefined rules in
 * parser/lexer to avoid exceptions later. Return true if we find multiple
 * definitions of the same rule or a reference to an undefined rule or
 * parser rule ref in lexer rule.
 */
public boolean checkForRuleIssues(final Grammar g) {
    // check for redefined rules
    GrammarAST RULES = (GrammarAST) g.ast.getFirstChildWithType(ANTLRParser.RULES);
    List<GrammarAST> rules = new ArrayList<GrammarAST>(RULES.getAllChildrenWithType(ANTLRParser.RULE));
    for (GrammarAST mode : g.ast.getAllChildrenWithType(ANTLRParser.MODE)) {
        rules.addAll(mode.getAllChildrenWithType(ANTLRParser.RULE));
    }
    boolean redefinition = false;
    final Map<String, RuleAST> ruleToAST = new HashMap<String, RuleAST>();
    for (GrammarAST r : rules) {
        RuleAST ruleAST = (RuleAST) r;
        GrammarAST ID = (GrammarAST) ruleAST.getChild(0);
        String ruleName = ID.getText();
        RuleAST prev = ruleToAST.get(ruleName);
        if (prev != null) {
            GrammarAST prevChild = (GrammarAST) prev.getChild(0);
            g.tool.errMgr.grammarError(ErrorType.RULE_REDEFINITION, g.fileName, ID.getToken(), ruleName, prevChild.getToken().getLine());
            redefinition = true;
            continue;
        }
        ruleToAST.put(ruleName, ruleAST);
    }
    // check for undefined rules
    class UndefChecker extends GrammarTreeVisitor {

        public boolean badref = false;

        @Override
        public void tokenRef(TerminalAST ref) {
            if (""EOF"".equals(ref.getText())) {
                // this is a special predefined reference
                return;
            }
            if (g.isLexer())
                ruleRef(ref, null);
        }

        @Override
        public void ruleRef(GrammarAST ref, ActionAST arg) {
            RuleAST ruleAST = ruleToAST.get(ref.getText());
            String fileName = ref.getToken().getInputStream().getSourceName();
            if (Character.isUpperCase(currentRuleName.charAt(0)) && Character.isLowerCase(ref.getText().charAt(0))) {
                badref = true;
                errMgr.grammarError(ErrorType.PARSER_RULE_REF_IN_LEXER_RULE, fileName, ref.getToken(), ref.getText(), currentRuleName);
            } else if (ruleAST == null) {
                badref = true;
                errMgr.grammarError(ErrorType.UNDEFINED_RULE_REF, fileName, ref.token, ref.getText());
            }
        }

        @Override
        public ErrorManager getErrorManager() {
            return errMgr;
        }
    }
    UndefChecker chk = new UndefChecker();
    chk.visitGrammar(g.ast);
    return redefinition || chk.badref;
}","/**
 * Important enough to avoid multiple definitions that we do very early,
 * right after AST construction. Also check for undefined rules in
 * parser/lexer to avoid exceptions later. Return true if we find multiple
 * definitions of the same rule or a reference to an undefined rule or
 * parser rule ref in lexer rule.
 */
","// check for redefined rules
[[SEP]]// check for undefined rules
[[SEP]]// this is a special predefined reference
","/** * Important enough to avoid multiple definitions that we do very early, * right after AST construction. Also check for undefined rules in * parser/lexer to avoid exceptions later. Return true if we find multiple * definitions of the same rule or a reference to an undefined rule or * parser rule ref in lexer rule. */[[SEP]]// check for redefined rules[[SEP]]// check for undefined rules[[SEP]]// this is a special predefined reference",420,486,[0],0,"[0, 0, 0]",0,"[0, 0, 0, 0]",0,0,0,0,checkForRuleIssues(Grammar),org.antlr.v4.Tool,checkForRuleIssues/1[org.antlr.v4.tool.Grammar],False,420,6,4,1,3,4,11,49,1,10,1,11,0,0,2,1,0,0,0,2,11,0,2,0,1,0,57,1,0,True
948,..\projects\antlr4-4.11.0\tool\src\org\antlr\v4\Tool.java,org.antlr.v4.Tool,List<GrammarRootAST> sortGrammarByTokenVocab(List<String>),"public List<GrammarRootAST> sortGrammarByTokenVocab(List<String> fileNames) {
    // System.out.println(fileNames);
    Graph<String> g = new Graph<String>();
    List<GrammarRootAST> roots = new ArrayList<GrammarRootAST>();
    for (String fileName : fileNames) {
        GrammarAST t = parseGrammar(fileName);
        // came back as error node
        if (t == null || t instanceof GrammarASTErrorNode)
            continue;
        if (((GrammarRootAST) t).hasErrors)
            continue;
        GrammarRootAST root = (GrammarRootAST) t;
        roots.add(root);
        root.fileName = fileName;
        String grammarName = root.getChild(0).getText();
        GrammarAST tokenVocabNode = findOptionValueAST(root, ""tokenVocab"");
        // Make grammars depend on any tokenVocab options
        if (tokenVocabNode != null) {
            String vocabName = tokenVocabNode.getText();
            // Strip quote characters if any
            int len = vocabName.length();
            int firstChar = vocabName.charAt(0);
            int lastChar = vocabName.charAt(len - 1);
            if (len >= 2 && firstChar == '\'' && lastChar == '\'') {
                vocabName = vocabName.substring(1, len - 1);
            }
            // If the name contains a path delimited by forward slashes,
            // use only the part after the last slash as the name
            int lastSlash = vocabName.lastIndexOf('/');
            if (lastSlash >= 0) {
                vocabName = vocabName.substring(lastSlash + 1);
            }
            g.addEdge(grammarName, vocabName);
        }
        // add cycle to graph so we always process a grammar if no error
        // even if no dependency
        g.addEdge(grammarName, grammarName);
    }
    List<String> sortedGrammarNames = g.sort();
    // System.out.println(""sortedGrammarNames=""+sortedGrammarNames);
    List<GrammarRootAST> sortedRoots = new ArrayList<GrammarRootAST>();
    for (String grammarName : sortedGrammarNames) {
        for (GrammarRootAST root : roots) {
            if (root.getGrammarName().equals(grammarName)) {
                sortedRoots.add(root);
                break;
            }
        }
    }
    return sortedRoots;
}", ,"// System.out.println(""sortedGrammarNames=""+sortedGrammarNames);
[[SEP]]// System.out.println(fileNames);
[[SEP]]// add cycle to graph so we always process a grammar if no error
[[SEP]]// came back as error node
[[SEP]]// Make grammars depend on any tokenVocab options
[[SEP]]// If the name contains a path delimited by forward slashes,
[[SEP]]// Strip quote characters if any
[[SEP]]// use only the part after the last slash as the name
[[SEP]]// even if no dependency
","// System.out.println(fileNames);[[SEP]]// came back as error node[[SEP]]// Make grammars depend on any tokenVocab options[[SEP]]// Strip quote characters if any[[SEP]]// If the name contains a path delimited by forward slashes,// use only the part after the last slash as the name[[SEP]]// add cycle to graph so we always process a grammar if no error// even if no dependency[[SEP]]// System.out.println(""sortedGrammarNames=""+sortedGrammarNames);",488,539,[0],0,"[0, 0, 0, 0, 0, 0, 0, 0, 0]",0,"[0, 0, 0, 0, 0, 0, 0]",0,0,1,0,sortGrammarByTokenVocab(List<String>),org.antlr.v4.Tool,sortGrammarByTokenVocab/1[java.util.List<java.lang.String>],False,488,5,4,1,3,13,14,40,1,13,1,14,2,2,3,4,0,1,1,8,16,3,3,0,0,0,33,1,0,False
949,..\projects\antlr4-4.11.0\tool\src\org\antlr\v4\Tool.java,org.antlr.v4.Tool,"GrammarAST findOptionValueAST(GrammarRootAST, String)","/**
 * Manually get option node from tree; return null if no defined.
 */
public static GrammarAST findOptionValueAST(GrammarRootAST root, String option) {
    GrammarAST options = (GrammarAST) root.getFirstChildWithType(ANTLRParser.OPTIONS);
    if (options != null && options.getChildCount() > 0) {
        for (Object o : options.getChildren()) {
            GrammarAST c = (GrammarAST) o;
            if (c.getType() == ANTLRParser.ASSIGN && c.getChild(0).getText().equals(option)) {
                return (GrammarAST) c.getChild(1);
            }
        }
    }
    return null;
}","/**
 * Manually get option node from tree; return null if no defined.
 */
", ,/** * Manually get option node from tree; return null if no defined. */,542,555,[0],0,[0],0,[0],0,0,0,0,"findOptionValueAST(GrammarRootAST, String)",org.antlr.v4.Tool,"findOptionValueAST/2[org.antlr.v4.tool.ast.GrammarRootAST,java.lang.String]",False,542,2,1,1,0,6,7,12,2,2,2,7,0,0,1,2,0,0,0,3,2,0,3,0,0,0,20,9,0,True
950,..\projects\antlr4-4.11.0\tool\src\org\antlr\v4\Tool.java,org.antlr.v4.Tool,Grammar createGrammar(GrammarRootAST),"/**
 *  Given the raw AST of a grammar, create a grammar object
 * 		associated with the AST. Once we have the grammar object, ensure
 * 		that all nodes in tree referred to this grammar. Later, we will
 * 		use it for error handling and generally knowing from where a rule
 * 		comes from.
 */
public Grammar createGrammar(GrammarRootAST ast) {
    final Grammar g;
    if (ast.grammarType == ANTLRParser.LEXER)
        g = new LexerGrammar(this, ast);
    else
        g = new Grammar(this, ast);
    // ensure each node has pointer to surrounding grammar
    GrammarTransformPipeline.setGrammarPtr(g, ast);
    return g;
}","/**
 *  Given the raw AST of a grammar, create a grammar object
 * 		associated with the AST. Once we have the grammar object, ensure
 * 		that all nodes in tree referred to this grammar. Later, we will
 * 		use it for error handling and generally knowing from where a rule
 * 		comes from.
 */
","// ensure each node has pointer to surrounding grammar
","/** *  Given the raw AST of a grammar, create a grammar object * 		associated with the AST. Once we have the grammar object, ensure * 		that all nodes in tree referred to this grammar. Later, we will * 		use it for error handling and generally knowing from where a rule * 		comes from. */[[SEP]]// ensure each node has pointer to surrounding grammar",564,572,[0],0,[0],0,"[0, 0]",0,0,0,0,createGrammar(GrammarRootAST),org.antlr.v4.Tool,createGrammar/1[org.antlr.v4.tool.ast.GrammarRootAST],False,564,4,7,4,3,2,1,7,1,1,1,1,0,0,0,1,0,0,0,0,2,0,1,0,0,0,41,1,0,True
951,..\projects\antlr4-4.11.0\tool\src\org\antlr\v4\Tool.java,org.antlr.v4.Tool,Grammar loadGrammar(String),"/**
 * Convenience method to load and process an ANTLR grammar. Useful
 *  when creating interpreters.  If you need to access to the lexer
 *  grammar created while processing a combined grammar, use
 *  getImplicitLexer() on returned grammar.
 */
public Grammar loadGrammar(String fileName) {
    GrammarRootAST grammarRootAST = parseGrammar(fileName);
    final Grammar g = createGrammar(grammarRootAST);
    g.fileName = fileName;
    process(g, false);
    return g;
}","/**
 * Convenience method to load and process an ANTLR grammar. Useful
 *  when creating interpreters.  If you need to access to the lexer
 *  grammar created while processing a combined grammar, use
 *  getImplicitLexer() on returned grammar.
 */
", ,"/** * Convenience method to load and process an ANTLR grammar. Useful *  when creating interpreters.  If you need to access to the lexer *  grammar created while processing a combined grammar, use *  getImplicitLexer() on returned grammar. */",596,602,[0],0,[0],0,[0],0,0,0,0,loadGrammar(String),org.antlr.v4.Tool,loadGrammar/1[java.lang.String],False,596,3,4,1,3,1,3,7,1,2,1,3,3,9,0,0,0,0,0,0,3,0,0,0,0,0,40,1,0,True
952,..\projects\antlr4-4.11.0\tool\src\org\antlr\v4\Tool.java,org.antlr.v4.Tool,"Grammar loadImportedGrammar(Grammar, GrammarAST)","/**
 * Try current dir then dir of g then lib dir
 * @param g
 * @param nameNode The node associated with the imported grammar name.
 */
public Grammar loadImportedGrammar(Grammar g, GrammarAST nameNode) throws IOException {
    String name = nameNode.getText();
    Grammar imported = importedGrammars.get(name);
    if (imported == null) {
        g.tool.log(""grammar"", ""load "" + name + "" from "" + g.fileName);
        File importedFile = null;
        for (String extension : ALL_GRAMMAR_EXTENSIONS) {
            importedFile = getImportedGrammarFile(g, name + extension);
            if (importedFile != null) {
                break;
            }
        }
        if (importedFile == null) {
            errMgr.grammarError(ErrorType.CANNOT_FIND_IMPORTED_GRAMMAR, g.fileName, nameNode.getToken(), name);
            return null;
        }
        String absolutePath = importedFile.getAbsolutePath();
        ANTLRFileStream in = new ANTLRFileStream(absolutePath, grammarEncoding);
        GrammarRootAST root = parse(g.fileName, in);
        if (root == null) {
            return null;
        }
        imported = createGrammar(root);
        imported.fileName = absolutePath;
        importedGrammars.put(root.getGrammarName(), imported);
    }
    return imported;
}","/**
 * Try current dir then dir of g then lib dir
 * @param g
 * @param nameNode The node associated with the imported grammar name.
 */
", ,/** * Try current dir then dir of g then lib dir * @param g * @param nameNode The node associated with the imported grammar name. */,611,642,[0],0,[0],0,[0],0,0,0,0,"loadImportedGrammar(Grammar, GrammarAST)",org.antlr.v4.Tool,"loadImportedGrammar/2[org.antlr.v4.tool.Grammar,org.antlr.v4.tool.ast.GrammarAST]",False,611,6,7,1,6,6,11,28,3,6,2,11,4,1,1,4,0,0,3,0,9,2,3,0,0,0,46,1,0,True
953,..\projects\antlr4-4.11.0\tool\src\org\antlr\v4\Tool.java,org.antlr.v4.Tool,"GrammarRootAST parse(String, CharStream)","public GrammarRootAST parse(String fileName, CharStream in) {
    try {
        GrammarASTAdaptor adaptor = new GrammarASTAdaptor(in);
        ToolANTLRLexer lexer = new ToolANTLRLexer(in, this);
        CommonTokenStream tokens = new CommonTokenStream(lexer);
        lexer.tokens = tokens;
        ToolANTLRParser p = new ToolANTLRParser(tokens, this);
        p.setTreeAdaptor(adaptor);
        ParserRuleReturnScope r = p.grammarSpec();
        GrammarAST root = (GrammarAST) r.getTree();
        if (root instanceof GrammarRootAST) {
            ((GrammarRootAST) root).hasErrors = lexer.getNumberOfSyntaxErrors() > 0 || p.getNumberOfSyntaxErrors() > 0;
            assert ((GrammarRootAST) root).tokenStream == tokens;
            if (grammarOptions != null) {
                ((GrammarRootAST) root).cmdLineOptions = grammarOptions;
            }
            return ((GrammarRootAST) root);
        }
        return null;
    } catch (RecognitionException re) {
        // TODO: do we gen errors now?
        ErrorManager.internalError(""can't generate this message at moment; antlr recovers"");
    }
    return null;
}", ,"// TODO: do we gen errors now?
",// TODO: do we gen errors now?,648,673,[0],0,[1],1,[1],1,1,1,1,"parse(String, CharStream)",org.antlr.v4.Tool,"parse/2[java.lang.String,org.antlr.v4.CharStream]",False,648,9,8,4,4,4,5,25,3,6,2,5,0,0,0,2,1,4,1,2,9,0,3,0,0,0,38,1,0,False
954,..\projects\antlr4-4.11.0\tool\src\org\antlr\v4\Tool.java,org.antlr.v4.Tool,String generateInterpreterData(Grammar),"public static String generateInterpreterData(Grammar g) {
    StringBuilder content = new StringBuilder();
    content.append(""token literal names:\n"");
    String[] names = g.getTokenLiteralNames();
    for (String name : names) {
        content.append(name + ""\n"");
    }
    content.append(""\n"");
    content.append(""token symbolic names:\n"");
    names = g.getTokenSymbolicNames();
    for (String name : names) {
        content.append(name + ""\n"");
    }
    content.append(""\n"");
    content.append(""rule names:\n"");
    names = g.getRuleNames();
    for (String name : names) {
        content.append(name + ""\n"");
    }
    content.append(""\n"");
    if (g.isLexer()) {
        content.append(""channel names:\n"");
        content.append(""DEFAULT_TOKEN_CHANNEL\n"");
        content.append(""HIDDEN\n"");
        for (String channel : g.channelValueToNameList) {
            content.append(channel + ""\n"");
        }
        content.append(""\n"");
        content.append(""mode names:\n"");
        for (String mode : ((LexerGrammar) g).modes.keySet()) {
            content.append(mode + ""\n"");
        }
    }
    content.append(""\n"");
    IntegerList serializedATN = ATNSerializer.getSerialized(g.atn);
    // Uncomment if you'd like to write out histogram info on the numbers of
    // each integer value:
    // Utils.writeSerializedATNIntegerHistogram(g.name+""-histo.csv"", serializedATN);
    content.append(""atn:\n"");
    content.append(serializedATN.toString());
    return content.toString();
}", ,"// Uncomment if you'd like to write out histogram info on the numbers of
[[SEP]]// each integer value:
[[SEP]]// Utils.writeSerializedATNIntegerHistogram(g.name+""-histo.csv"", serializedATN);
","// Uncomment if you'd like to write out histogram info on the numbers of// each integer value:// Utils.writeSerializedATNIntegerHistogram(g.name+""-histo.csv"", serializedATN);",696,745,[0],0,"[0, 0, 0]",0,[0],0,0,0,0,generateInterpreterData(Grammar),org.antlr.v4.Tool,generateInterpreterData/1[org.antlr.v4.tool.Grammar],False,696,3,5,1,4,7,10,39,1,3,1,10,0,0,5,0,0,1,18,0,5,5,2,0,0,0,21,9,0,False
955,..\projects\antlr4-4.11.0\tool\src\org\antlr\v4\Tool.java,org.antlr.v4.Tool,"Writer getOutputFileWriter(Grammar, String)","/**
 * This method is used by all code generators to create new output
 *  files. If the outputDir set by -o is not present it will be created.
 *  The final filename is sensitive to the output directory and
 *  the directory where the grammar file was found.  If -o is /tmp
 *  and the original grammar file was foo/t.g4 then output files
 *  go in /tmp/foo.
 *
 *  The output dir -o spec takes precedence if it's absolute.
 *  E.g., if the grammar file dir is absolute the output dir is given
 *  precedence. ""-o /tmp /usr/lib/t.g4"" results in ""/tmp/T.java"" as
 *  output (assuming t.g4 holds T.java).
 *
 *  If no -o is specified, then just write to the directory where the
 *  grammar file was found.
 *
 *  If outputDirectory==null then write a String.
 */
public Writer getOutputFileWriter(Grammar g, String fileName) throws IOException {
    if (outputDirectory == null) {
        return new StringWriter();
    }
    // output directory is a function of where the grammar file lives
    // for subdir/T.g4, you get subdir here.  Well, depends on -o etc...
    File outputDir = getOutputDirectory(g.fileName);
    File outputFile = new File(outputDir, fileName);
    if (!outputDir.exists()) {
        outputDir.mkdirs();
    }
    FileOutputStream fos = new FileOutputStream(outputFile);
    OutputStreamWriter osw;
    if (grammarEncoding != null) {
        osw = new OutputStreamWriter(fos, grammarEncoding);
    } else {
        osw = new OutputStreamWriter(fos);
    }
    return new BufferedWriter(osw);
}","/**
 * This method is used by all code generators to create new output
 *  files. If the outputDir set by -o is not present it will be created.
 *  The final filename is sensitive to the output directory and
 *  the directory where the grammar file was found.  If -o is /tmp
 *  and the original grammar file was foo/t.g4 then output files
 *  go in /tmp/foo.
 *
 *  The output dir -o spec takes precedence if it's absolute.
 *  E.g., if the grammar file dir is absolute the output dir is given
 *  precedence. ""-o /tmp /usr/lib/t.g4"" results in ""/tmp/T.java"" as
 *  output (assuming t.g4 holds T.java).
 *
 *  If no -o is specified, then just write to the directory where the
 *  grammar file was found.
 *
 *  If outputDirectory==null then write a String.
 */
","// output directory is a function of where the grammar file lives
[[SEP]]// for subdir/T.g4, you get subdir here.  Well, depends on -o etc...
","/** * This method is used by all code generators to create new output *  files. If the outputDir set by -o is not present it will be created. *  The final filename is sensitive to the output directory and *  the directory where the grammar file was found.  If -o is /tmp *  and the original grammar file was foo/t.g4 then output files *  go in /tmp/foo. * *  The output dir -o spec takes precedence if it's absolute. *  E.g., if the grammar file dir is absolute the output dir is given *  precedence. ""-o /tmp /usr/lib/t.g4"" results in ""/tmp/T.java"" as *  output (assuming t.g4 holds T.java). * *  If no -o is specified, then just write to the directory where the *  grammar file was found. * *  If outputDirectory==null then write a String. */[[SEP]]// output directory is a function of where the grammar file lives// for subdir/T.g4, you get subdir here.  Well, depends on -o etc...",764,785,[0],0,"[0, 0]",0,"[0, 0]",0,0,0,0,"getOutputFileWriter(Grammar, String)",org.antlr.v4.Tool,"getOutputFileWriter/2[org.antlr.v4.tool.Grammar,java.lang.String]",False,764,2,3,2,1,4,3,19,2,4,2,3,1,2,0,2,0,0,0,0,5,0,1,0,0,0,70,1,0,True
956,..\projects\antlr4-4.11.0\tool\src\org\antlr\v4\Tool.java,org.antlr.v4.Tool,"File getImportedGrammarFile(Grammar, String)","public File getImportedGrammarFile(Grammar g, String fileName) {
    File importedFile = new File(inputDirectory, fileName);
    if (!importedFile.exists()) {
        File gfile = new File(g.fileName);
        String parentDir = gfile.getParent();
        importedFile = new File(parentDir, fileName);
        if (!importedFile.exists()) {
            // try in lib dir
            importedFile = new File(libDirectory, fileName);
            if (!importedFile.exists()) {
                return null;
            }
        }
    }
    return importedFile;
}", ,"// try in lib dir
",// try in lib dir,787,801,[0],0,[0],0,[0],0,0,0,0,"getImportedGrammarFile(Grammar, String)",org.antlr.v4.Tool,"getImportedGrammarFile/2[org.antlr.v4.tool.Grammar,java.lang.String]",False,787,1,1,1,0,4,2,15,2,3,2,2,0,0,0,0,0,0,0,0,5,0,3,0,0,0,11,1,0,False
957,..\projects\antlr4-4.11.0\tool\src\org\antlr\v4\Tool.java,org.antlr.v4.Tool,File getOutputDirectory(String),"/**
 * Return the location where ANTLR will generate output files for a given
 * file. This is a base directory and output files will be relative to
 * here in some cases such as when -o option is used and input files are
 * given relative to the input directory.
 *
 * @param fileNameWithPath path to input source
 */
public File getOutputDirectory(String fileNameWithPath) {
    if (exact_output_dir) {
        return new_getOutputDirectory(fileNameWithPath);
    }
    File outputDir;
    String fileDirectory;
    // Some files are given to us without a PATH but should should
    // still be written to the output directory in the relative path of
    // the output directory. The file directory is either the set of sub directories
    // or just or the relative path recorded for the parent grammar. This means
    // that when we write the tokens files, or the .java files for imported grammars
    // taht we will write them in the correct place.
    if ((fileNameWithPath == null) || (fileNameWithPath.lastIndexOf(File.separatorChar) == -1)) {
        // No path is included in the file name, so make the file
        // directory the same as the parent grammar (which might sitll be just """"
        // but when it is not, we will write the file in the correct place.
        fileDirectory = ""."";
    } else {
        fileDirectory = fileNameWithPath.substring(0, fileNameWithPath.lastIndexOf(File.separatorChar));
    }
    if (haveOutputDir) {
        // -o /tmp /var/lib/t.g4 => /tmp/T.java
        // -o subdir/output /usr/lib/t.g4 => subdir/output/T.java
        // -o . /usr/lib/t.g4 => ./T.java
        if (fileDirectory != null && (new File(fileDirectory).isAbsolute() || fileDirectory.startsWith(""~""))) {
            // isAbsolute doesn't count this :(
            // somebody set the dir, it takes precendence; write new file there
            outputDir = new File(outputDirectory);
        } else {
            // -o /tmp subdir/t.g4 => /tmp/subdir/T.java
            if (fileDirectory != null) {
                outputDir = new File(outputDirectory, fileDirectory);
            } else {
                outputDir = new File(outputDirectory);
            }
        }
    } else {
        // they didn't specify a -o dir so just write to location
        // where grammar is, absolute or relative, this will only happen
        // with command line invocation as build tools will always
        // supply an output directory.
        outputDir = new File(fileDirectory);
    }
    return outputDir;
}","/**
 * Return the location where ANTLR will generate output files for a given
 * file. This is a base directory and output files will be relative to
 * here in some cases such as when -o option is used and input files are
 * given relative to the input directory.
 *
 * @param fileNameWithPath path to input source
 */
","// Some files are given to us without a PATH but should should
[[SEP]]// still be written to the output directory in the relative path of
[[SEP]]// the output directory. The file directory is either the set of sub directories
[[SEP]]// or just or the relative path recorded for the parent grammar. This means
[[SEP]]// that when we write the tokens files, or the .java files for imported grammars
[[SEP]]// taht we will write them in the correct place.
[[SEP]]// No path is included in the file name, so make the file
[[SEP]]// directory the same as the parent grammar (which might sitll be just """"
[[SEP]]// but when it is not, we will write the file in the correct place.
[[SEP]]// -o /tmp /var/lib/t.g4 => /tmp/T.java
[[SEP]]// -o subdir/output /usr/lib/t.g4 => subdir/output/T.java
[[SEP]]// -o . /usr/lib/t.g4 => ./T.java
[[SEP]]// isAbsolute doesn't count this :(
[[SEP]]// somebody set the dir, it takes precendence; write new file there
[[SEP]]// -o /tmp subdir/t.g4 => /tmp/subdir/T.java
[[SEP]]// they didn't specify a -o dir so just write to location
[[SEP]]// where grammar is, absolute or relative, this will only happen
[[SEP]]// with command line invocation as build tools will always
[[SEP]]// supply an output directory.
","/** * Return the location where ANTLR will generate output files for a given * file. This is a base directory and output files will be relative to * here in some cases such as when -o option is used and input files are * given relative to the input directory. * * @param fileNameWithPath path to input source */[[SEP]]// Some files are given to us without a PATH but should should// still be written to the output directory in the relative path of// the output directory. The file directory is either the set of sub directories// or just or the relative path recorded for the parent grammar. This means// that when we write the tokens files, or the .java files for imported grammars// taht we will write them in the correct place.[[SEP]]// No path is included in the file name, so make the file// directory the same as the parent grammar (which might sitll be just """"// but when it is not, we will write the file in the correct place.[[SEP]]// -o /tmp /var/lib/t.g4 => /tmp/T.java// -o subdir/output /usr/lib/t.g4 => subdir/output/T.java// -o . /usr/lib/t.g4 => ./T.java[[SEP]]// isAbsolute doesn't count this :(// somebody set the dir, it takes precendence; write new file there[[SEP]]// -o /tmp subdir/t.g4 => /tmp/subdir/T.java[[SEP]]// they didn't specify a -o dir so just write to location// where grammar is, absolute or relative, this will only happen// with command line invocation as build tools will always// supply an output directory.",811,863,[0],0,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]",0,"[0, 0, 0, 0, 0, 0, 0]",0,0,0,0,getOutputDirectory(String),org.antlr.v4.Tool,getOutputDirectory/1[java.lang.String],False,811,1,3,2,1,9,5,30,2,2,1,5,1,1,0,4,0,3,2,2,6,0,3,0,0,0,51,1,0,True
958,..\projects\antlr4-4.11.0\tool\src\org\antlr\v4\Tool.java,org.antlr.v4.Tool,File new_getOutputDirectory(String),"/**
 * @since 4.7.1 in response to -Xexact-output-dir
 */
public File new_getOutputDirectory(String fileNameWithPath) {
    File outputDir;
    String fileDirectory;
    if (fileNameWithPath.lastIndexOf(File.separatorChar) == -1) {
        // No path is included in the file name, so make the file
        // directory the same as the parent grammar (which might still be just """"
        // but when it is not, we will write the file in the correct place.
        fileDirectory = ""."";
    } else {
        fileDirectory = fileNameWithPath.substring(0, fileNameWithPath.lastIndexOf(File.separatorChar));
    }
    if (haveOutputDir) {
        // -o /tmp /var/lib/t.g4 => /tmp/T.java
        // -o subdir/output /usr/lib/t.g4 => subdir/output/T.java
        // -o . /usr/lib/t.g4 => ./T.java
        // -o /tmp subdir/t.g4 => /tmp/T.java
        outputDir = new File(outputDirectory);
    } else {
        // they didn't specify a -o dir so just write to location
        // where grammar is, absolute or relative, this will only happen
        // with command line invocation as build tools will always
        // supply an output directory.
        outputDir = new File(fileDirectory);
    }
    return outputDir;
}","/**
 * @since 4.7.1 in response to -Xexact-output-dir
 */
","// No path is included in the file name, so make the file
[[SEP]]// directory the same as the parent grammar (which might still be just """"
[[SEP]]// but when it is not, we will write the file in the correct place.
[[SEP]]// -o /tmp /var/lib/t.g4 => /tmp/T.java
[[SEP]]// -o subdir/output /usr/lib/t.g4 => subdir/output/T.java
[[SEP]]// -o . /usr/lib/t.g4 => ./T.java
[[SEP]]// -o /tmp subdir/t.g4 => /tmp/T.java
[[SEP]]// they didn't specify a -o dir so just write to location
[[SEP]]// where grammar is, absolute or relative, this will only happen
[[SEP]]// with command line invocation as build tools will always
[[SEP]]// supply an output directory.
","/** * @since 4.7.1 in response to -Xexact-output-dir */[[SEP]]// No path is included in the file name, so make the file// directory the same as the parent grammar (which might still be just """"// but when it is not, we will write the file in the correct place.[[SEP]]// -o /tmp /var/lib/t.g4 => /tmp/T.java// -o subdir/output /usr/lib/t.g4 => subdir/output/T.java// -o . /usr/lib/t.g4 => ./T.java// -o /tmp subdir/t.g4 => /tmp/T.java[[SEP]]// they didn't specify a -o dir so just write to location// where grammar is, absolute or relative, this will only happen// with command line invocation as build tools will always// supply an output directory.",866,894,[0],0,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]",0,"[0, 0, 0, 0]",0,0,0,0,new_getOutputDirectory(String),org.antlr.v4.Tool,new_getOutputDirectory/1[java.lang.String],False,866,0,1,1,0,3,2,17,1,2,1,2,0,0,0,1,0,0,1,2,4,0,1,0,0,0,17,1,0,True
960,..\projects\antlr4-4.11.0\tool\src\org\antlr\v4\analysis\AnalysisPipeline.java,org.antlr.v4.analysis.AnalysisPipeline,void process(),"public void process() {
    // LEFT-RECURSION CHECK
    LeftRecursionDetector lr = new LeftRecursionDetector(g, g.atn);
    lr.check();
    // bail out
    if (!lr.listOfRecursiveCycles.isEmpty())
        return;
    if (g.isLexer()) {
        processLexer();
    } else {
        // BUILD DFA FOR EACH DECISION
        processParser();
    }
}", ,"// LEFT-RECURSION CHECK
[[SEP]]// bail out
[[SEP]]// BUILD DFA FOR EACH DECISION
",// LEFT-RECURSION CHECK[[SEP]]// bail out[[SEP]]// BUILD DFA FOR EACH DECISION,29,42,[0],0,"[0, 0, 0]",0,"[0, 0, 0]",0,0,1,0,process(),org.antlr.v4.analysis.AnalysisPipeline,process/0,False,29,2,4,0,4,3,5,11,1,1,0,5,2,2,0,0,0,0,0,0,1,0,1,0,0,0,7,1,0,False
961,..\projects\antlr4-4.11.0\tool\src\org\antlr\v4\analysis\AnalysisPipeline.java,org.antlr.v4.analysis.AnalysisPipeline,void processLexer(),"protected void processLexer() {
    // make sure all non-fragment lexer rules must match at least one symbol
    for (Rule rule : g.rules.values()) {
        if (rule.isFragment()) {
            continue;
        }
        LL1Analyzer analyzer = new LL1Analyzer(g.atn);
        IntervalSet look = analyzer.LOOK(g.atn.ruleToStartState[rule.index], null);
        if (look.contains(Token.EPSILON)) {
            g.tool.errMgr.grammarError(ErrorType.EPSILON_TOKEN, g.fileName, ((GrammarAST) rule.ast.getChild(0)).getToken(), rule.name);
        }
    }
}", ,"// make sure all non-fragment lexer rules must match at least one symbol
",// make sure all non-fragment lexer rules must match at least one symbol,44,57,[0],0,[0],0,[0],0,0,0,0,processLexer(),org.antlr.v4.analysis.AnalysisPipeline,processLexer/0,False,44,3,4,1,3,4,7,12,0,2,0,7,0,0,1,0,0,1,0,1,2,0,2,0,0,0,15,4,0,False
962,..\projects\antlr4-4.11.0\tool\src\org\antlr\v4\analysis\AnalysisPipeline.java,org.antlr.v4.analysis.AnalysisPipeline,void processParser(),"protected void processParser() {
    g.decisionLOOK = new ArrayList<IntervalSet[]>(g.atn.getNumberOfDecisions() + 1);
    for (DecisionState s : g.atn.decisionToState) {
        g.tool.log(""LL1"", ""\nDECISION "" + s.decision + "" in rule "" + g.getRule(s.ruleIndex).name);
        IntervalSet[] look;
        if (s.nonGreedy) {
            // nongreedy decisions can't be LL(1)
            look = new IntervalSet[s.getNumberOfTransitions() + 1];
        } else {
            LL1Analyzer anal = new LL1Analyzer(g.atn);
            look = anal.getDecisionLookahead(s);
            g.tool.log(""LL1"", ""look="" + Arrays.toString(look));
        }
        assert s.decision + 1 >= g.decisionLOOK.size();
        Utils.setSize(g.decisionLOOK, s.decision + 1);
        g.decisionLOOK.set(s.decision, look);
        g.tool.log(""LL1"", ""LL(1)? "" + disjoint(look));
    }
}", ,"// nongreedy decisions can't be LL(1)
",// nongreedy decisions can't be LL(1),59,78,[0],0,[0],0,[0],0,0,0,0,processParser(),org.antlr.v4.analysis.AnalysisPipeline,processParser/0,False,59,4,5,1,4,3,10,19,0,2,0,10,1,1,1,0,0,0,7,4,4,7,2,0,0,0,14,4,0,False
963,..\projects\antlr4-4.11.0\tool\src\org\antlr\v4\analysis\AnalysisPipeline.java,org.antlr.v4.analysis.AnalysisPipeline,boolean disjoint(IntervalSet[]),"/**
 * Return whether lookahead sets are disjoint; no lookahead ⇒ not disjoint
 */
public static boolean disjoint(IntervalSet[] altLook) {
    boolean collision = false;
    IntervalSet combined = new IntervalSet();
    if (altLook == null)
        return false;
    for (IntervalSet look : altLook) {
        // lookahead must've computation failed
        if (look == null)
            return false;
        if (!look.and(combined).isNil()) {
            collision = true;
            break;
        }
        combined.addAll(look);
    }
    return !collision;
}","/**
 * Return whether lookahead sets are disjoint; no lookahead ⇒ not disjoint
 */
","// lookahead must've computation failed
",/** * Return whether lookahead sets are disjoint; no lookahead ⇒ not disjoint */[[SEP]]// lookahead must've computation failed,81,94,[0],0,[0],0,"[0, 0]",0,0,0,0,disjoint(IntervalSet[]),org.antlr.v4.analysis.AnalysisPipeline,disjoint/1[org.antlr.v4.runtime.misc.IntervalSet[]],False,81,1,7,3,4,5,3,14,3,2,1,3,0,0,1,2,0,0,0,0,3,0,2,0,0,0,18,9,0,True
964,..\projects\antlr4-4.11.0\tool\src\org\antlr\v4\analysis\LeftRecursionDetector.java,org.antlr.v4.analysis.LeftRecursionDetector,void check(),"public void check() {
    for (RuleStartState start : atn.ruleToStartState) {
        // System.out.print(""check ""+start.rule.name);
        rulesVisitedPerRuleCheck.clear();
        rulesVisitedPerRuleCheck.add(start);
        // FASerializer ser = new FASerializer(atn.g, start);
        // System.out.print("":\n""+ser+""\n"");
        check(g.getRule(start.ruleIndex), start, new HashSet<ATNState>());
    }
    // System.out.println(""cycles=""+listOfRecursiveCycles);
    if (!listOfRecursiveCycles.isEmpty()) {
        g.tool.errMgr.leftRecursionCycles(g.fileName, listOfRecursiveCycles);
    }
}", ,"// FASerializer ser = new FASerializer(atn.g, start);
[[SEP]]// System.out.print("":\n""+ser+""\n"");
[[SEP]]// System.out.print(""check ""+start.rule.name);
[[SEP]]// System.out.println(""cycles=""+listOfRecursiveCycles);
","// System.out.print(""check ""+start.rule.name);[[SEP]]// FASerializer ser = new FASerializer(atn.g, start);// System.out.print("":\n""+ser+""\n"");[[SEP]]// System.out.println(""cycles=""+listOfRecursiveCycles);",41,55,[0],0,"[0, 0, 0, 0]",0,"[0, 0, 0]",0,0,0,0,check(),org.antlr.v4.analysis.LeftRecursionDetector,check/0,False,41,2,2,1,1,3,6,10,0,0,0,6,1,2,1,0,0,0,0,0,0,0,1,0,0,0,5,1,0,False
965,..\projects\antlr4-4.11.0\tool\src\org\antlr\v4\analysis\LeftRecursionDetector.java,org.antlr.v4.analysis.LeftRecursionDetector,"boolean check(Rule, ATNState, Set<ATNState>)","/**
 * From state s, look for any transition to a rule that is currently
 *  being traced.  When tracing r, visitedPerRuleCheck has r
 *  initially.  If you reach a rule stop state, return but notify the
 *  invoking rule that the called rule is nullable. This implies that
 *  invoking rule must look at follow transition for that invoking state.
 *
 *  The visitedStates tracks visited states within a single rule so
 *  we can avoid epsilon-loop-induced infinite recursion here.  Keep
 *  filling the cycles in listOfRecursiveCycles and also, as a
 *  side-effect, set leftRecursiveRules.
 */
public boolean check(Rule enclosingRule, ATNState s, Set<ATNState> visitedStates) {
    if (s instanceof RuleStopState)
        return true;
    if (visitedStates.contains(s))
        return false;
    visitedStates.add(s);
    // System.out.println(""visit ""+s);
    int n = s.getNumberOfTransitions();
    boolean stateReachesStopState = false;
    for (int i = 0; i < n; i++) {
        Transition t = s.transition(i);
        if (t instanceof RuleTransition) {
            RuleTransition rt = (RuleTransition) t;
            Rule r = g.getRule(rt.ruleIndex);
            if (rulesVisitedPerRuleCheck.contains((RuleStartState) t.target)) {
                addRulesToCycle(enclosingRule, r);
            } else {
                // must visit if not already visited; mark target, pop when done
                rulesVisitedPerRuleCheck.add((RuleStartState) t.target);
                // send new visitedStates set per rule invocation
                boolean nullable = check(r, t.target, new HashSet<ATNState>());
                // we're back from visiting that rule
                rulesVisitedPerRuleCheck.remove((RuleStartState) t.target);
                if (nullable) {
                    stateReachesStopState |= check(enclosingRule, rt.followState, visitedStates);
                }
            }
        } else if (t.isEpsilon()) {
            stateReachesStopState |= check(enclosingRule, t.target, visitedStates);
        }
        // else ignore non-epsilon transitions
    }
    return stateReachesStopState;
}","/**
 * From state s, look for any transition to a rule that is currently
 *  being traced.  When tracing r, visitedPerRuleCheck has r
 *  initially.  If you reach a rule stop state, return but notify the
 *  invoking rule that the called rule is nullable. This implies that
 *  invoking rule must look at follow transition for that invoking state.
 *
 *  The visitedStates tracks visited states within a single rule so
 *  we can avoid epsilon-loop-induced infinite recursion here.  Keep
 *  filling the cycles in listOfRecursiveCycles and also, as a
 *  side-effect, set leftRecursiveRules.
 */
","// System.out.println(""visit ""+s);
[[SEP]]// else ignore non-epsilon transitions
[[SEP]]// must visit if not already visited; mark target, pop when done
[[SEP]]// send new visitedStates set per rule invocation
[[SEP]]// we're back from visiting that rule
","/** * From state s, look for any transition to a rule that is currently *  being traced.  When tracing r, visitedPerRuleCheck has r *  initially.  If you reach a rule stop state, return but notify the *  invoking rule that the called rule is nullable. This implies that *  invoking rule must look at follow transition for that invoking state. * *  The visitedStates tracks visited states within a single rule so *  we can avoid epsilon-loop-induced infinite recursion here.  Keep *  filling the cycles in listOfRecursiveCycles and also, as a *  side-effect, set leftRecursiveRules. */[[SEP]]// System.out.println(""visit ""+s);[[SEP]]// must visit if not already visited; mark target, pop when done[[SEP]]// send new visitedStates set per rule invocation[[SEP]]// we're back from visiting that rule[[SEP]]// else ignore non-epsilon transitions",68,102,[0],0,"[0, 0, 0, 0, 0]",0,"[0, 0, 0, 0, 0, 0]",0,0,0,0,"check(Rule, ATNState, Set<ATNState>)",org.antlr.v4.analysis.LeftRecursionDetector,"check/3[org.antlr.v4.analysis.Rule,org.antlr.v4.runtime.atn.ATNState,java.util.Set<org.antlr.v4.runtime.atn.ATNState>]",False,68,7,7,2,5,8,11,29,3,7,3,11,2,1,1,0,0,0,0,1,9,0,4,0,0,0,79,1,0,True
966,..\projects\antlr4-4.11.0\tool\src\org\antlr\v4\analysis\LeftRecursionDetector.java,org.antlr.v4.analysis.LeftRecursionDetector,"void addRulesToCycle(Rule, Rule)","/**
 * enclosingRule calls targetRule. Find the cycle containing
 *  the target and add the caller.  Find the cycle containing the caller
 *  and add the target.  If no cycles contain either, then create a new
 *  cycle.
 */
protected void addRulesToCycle(Rule enclosingRule, Rule targetRule) {
    // System.err.println(""left-recursion to ""+targetRule.name+"" from ""+enclosingRule.name);
    boolean foundCycle = false;
    for (Set<Rule> rulesInCycle : listOfRecursiveCycles) {
        // ensure both rules are in same cycle
        if (rulesInCycle.contains(targetRule)) {
            rulesInCycle.add(enclosingRule);
            foundCycle = true;
        }
        if (rulesInCycle.contains(enclosingRule)) {
            rulesInCycle.add(targetRule);
            foundCycle = true;
        }
    }
    if (!foundCycle) {
        Set<Rule> cycle = new OrderedHashSet<Rule>();
        cycle.add(targetRule);
        cycle.add(enclosingRule);
        listOfRecursiveCycles.add(cycle);
    }
}","/**
 * enclosingRule calls targetRule. Find the cycle containing
 *  the target and add the caller.  Find the cycle containing the caller
 *  and add the target.  If no cycles contain either, then create a new
 *  cycle.
 */
","// System.err.println(""left-recursion to ""+targetRule.name+"" from ""+enclosingRule.name);
[[SEP]]// ensure both rules are in same cycle
","/** * enclosingRule calls targetRule. Find the cycle containing *  the target and add the caller.  Find the cycle containing the caller *  and add the target.  If no cycles contain either, then create a new *  cycle. */[[SEP]]// System.err.println(""left-recursion to ""+targetRule.name+"" from ""+enclosingRule.name);[[SEP]]// ensure both rules are in same cycle",109,129,[0],0,"[0, 0]",0,"[0, 0, 0]",0,0,0,0,"addRulesToCycle(Rule, Rule)",org.antlr.v4.analysis.LeftRecursionDetector,"addRulesToCycle/2[org.antlr.v4.analysis.Rule,org.antlr.v4.analysis.Rule]",False,109,2,2,1,1,5,2,19,0,2,2,2,0,0,1,0,0,0,0,0,4,0,2,0,0,0,30,4,0,True
967,..\projects\antlr4-4.11.0\tool\src\org\antlr\v4\analysis\LeftRecursiveRuleAnalyzer.java,org.antlr.v4.analysis.LeftRecursiveRuleAnalyzer,"void setAltAssoc(AltAST, int)","@Override
public void setAltAssoc(AltAST t, int alt) {
    ASSOC assoc = ASSOC.left;
    if (t.getOptions() != null) {
        String a = t.getOptionString(""assoc"");
        if (a != null) {
            if (a.equals(ASSOC.right.toString())) {
                assoc = ASSOC.right;
            } else if (a.equals(ASSOC.left.toString())) {
                assoc = ASSOC.left;
            } else {
                tool.errMgr.grammarError(ErrorType.ILLEGAL_OPTION_VALUE, t.g.fileName, t.getOptionAST(""assoc"").getToken(), ""assoc"", assoc);
            }
        }
    }
    if (altAssociativity.get(alt) != null && altAssociativity.get(alt) != assoc) {
        tool.errMgr.toolError(ErrorType.INTERNAL_ERROR, ""all operators of alt "" + alt + "" of left-recursive rule must have same associativity"");
    }
    altAssociativity.put(alt, assoc);
    // System.out.println(""setAltAssoc: op "" + alt + "": "" + t.getText()+"", assoc=""+assoc);
}", ,"// System.out.println(""setAltAssoc: op "" + alt + "": "" + t.getText()+"", assoc=""+assoc);
","// System.out.println(""setAltAssoc: op "" + alt + "": "" + t.getText()+"", assoc=""+assoc);",98,122,[0],0,[0],0,[0],0,0,0,0,"setAltAssoc(AltAST, int)",org.antlr.v4.analysis.LeftRecursiveRuleAnalyzer,"setAltAssoc/2[org.antlr.v4.analysis.AltAST,int]",False,99,2,0,0,0,7,10,21,0,2,2,10,0,0,0,4,0,0,5,0,4,1,3,0,0,0,20,1,0,False
968,..\projects\antlr4-4.11.0\tool\src\org\antlr\v4\analysis\LeftRecursiveRuleAnalyzer.java,org.antlr.v4.analysis.LeftRecursiveRuleAnalyzer,"void binaryAlt(AltAST, int)","@Override
public void binaryAlt(AltAST originalAltTree, int alt) {
    AltAST altTree = (AltAST) originalAltTree.dupTree();
    String altLabel = altTree.altLabel != null ? altTree.altLabel.getText() : null;
    String label = null;
    boolean isListLabel = false;
    GrammarAST lrlabel = stripLeftRecursion(altTree);
    if (lrlabel != null) {
        label = lrlabel.getText();
        isListLabel = lrlabel.getParent().getType() == PLUS_ASSIGN;
        leftRecursiveRuleRefLabels.add(new Pair<GrammarAST, String>(lrlabel, altLabel));
    }
    stripAltLabel(altTree);
    // rewrite e to be e_[rec_arg]
    int nextPrec = nextPrecedence(alt);
    altTree = addPrecedenceArgToRules(altTree, nextPrec);
    stripAltLabel(altTree);
    String altText = text(altTree);
    altText = altText.trim();
    LeftRecursiveRuleAltInfo a = new LeftRecursiveRuleAltInfo(alt, altText, label, altLabel, isListLabel, originalAltTree);
    a.nextPrec = nextPrec;
    binaryAlts.put(alt, a);
    // System.out.println(""binaryAlt "" + alt + "": "" + altText + "", rewrite="" + rewriteText);
}", ,"// System.out.println(""binaryAlt "" + alt + "": "" + altText + "", rewrite="" + rewriteText);
[[SEP]]// rewrite e to be e_[rec_arg]
","// rewrite e to be e_[rec_arg][[SEP]]// System.out.println(""binaryAlt "" + alt + "": "" + altText + "", rewrite="" + rewriteText);",124,152,[0],0,"[0, 0]",0,"[0, 0]",0,0,0,0,"binaryAlt(AltAST, int)",org.antlr.v4.analysis.LeftRecursiveRuleAnalyzer,"binaryAlt/2[org.antlr.v4.analysis.AltAST,int]",False,125,5,7,0,7,3,12,21,0,8,2,12,5,2,0,3,0,0,0,0,13,0,1,0,0,0,38,1,0,False
969,..\projects\antlr4-4.11.0\tool\src\org\antlr\v4\analysis\LeftRecursiveRuleAnalyzer.java,org.antlr.v4.analysis.LeftRecursiveRuleAnalyzer,"void prefixAlt(AltAST, int)","@Override
public void prefixAlt(AltAST originalAltTree, int alt) {
    AltAST altTree = (AltAST) originalAltTree.dupTree();
    stripAltLabel(altTree);
    int nextPrec = precedence(alt);
    // rewrite e to be e_[prec]
    altTree = addPrecedenceArgToRules(altTree, nextPrec);
    String altText = text(altTree);
    altText = altText.trim();
    String altLabel = altTree.altLabel != null ? altTree.altLabel.getText() : null;
    LeftRecursiveRuleAltInfo a = new LeftRecursiveRuleAltInfo(alt, altText, null, altLabel, false, originalAltTree);
    a.nextPrec = nextPrec;
    prefixAndOtherAlts.add(a);
    // System.out.println(""prefixAlt "" + alt + "": "" + altText + "", rewrite="" + rewriteText);
}", ,"// System.out.println(""prefixAlt "" + alt + "": "" + altText + "", rewrite="" + rewriteText);
[[SEP]]// rewrite e to be e_[prec]
","// rewrite e to be e_[prec][[SEP]]// System.out.println(""prefixAlt "" + alt + "": "" + altText + "", rewrite="" + rewriteText);",154,170,[0],0,"[0, 0]",0,"[0, 0]",0,0,0,0,"prefixAlt(AltAST, int)",org.antlr.v4.analysis.LeftRecursiveRuleAnalyzer,"prefixAlt/2[org.antlr.v4.analysis.AltAST,int]",False,155,3,5,0,5,2,8,12,0,5,2,8,4,1,0,1,0,0,0,0,8,0,0,0,0,0,25,1,0,False
970,..\projects\antlr4-4.11.0\tool\src\org\antlr\v4\analysis\LeftRecursiveRuleAnalyzer.java,org.antlr.v4.analysis.LeftRecursiveRuleAnalyzer,"void suffixAlt(AltAST, int)","@Override
public void suffixAlt(AltAST originalAltTree, int alt) {
    AltAST altTree = (AltAST) originalAltTree.dupTree();
    String altLabel = altTree.altLabel != null ? altTree.altLabel.getText() : null;
    String label = null;
    boolean isListLabel = false;
    GrammarAST lrlabel = stripLeftRecursion(altTree);
    if (lrlabel != null) {
        label = lrlabel.getText();
        isListLabel = lrlabel.getParent().getType() == PLUS_ASSIGN;
        leftRecursiveRuleRefLabels.add(new Pair<GrammarAST, String>(lrlabel, altLabel));
    }
    stripAltLabel(altTree);
    String altText = text(altTree);
    altText = altText.trim();
    LeftRecursiveRuleAltInfo a = new LeftRecursiveRuleAltInfo(alt, altText, label, altLabel, isListLabel, originalAltTree);
    suffixAlts.put(alt, a);
    // System.out.println(""suffixAlt "" + alt + "": "" + altText + "", rewrite="" + rewriteText);
}", ,"// System.out.println(""suffixAlt "" + alt + "": "" + altText + "", rewrite="" + rewriteText);
","// System.out.println(""suffixAlt "" + alt + "": "" + altText + "", rewrite="" + rewriteText);",172,192,[0],0,[0],0,[0],0,0,0,0,"suffixAlt(AltAST, int)",org.antlr.v4.analysis.LeftRecursiveRuleAnalyzer,"suffixAlt/2[org.antlr.v4.analysis.AltAST,int]",False,173,5,5,0,5,3,10,17,0,7,2,10,3,1,0,3,0,0,0,0,10,0,1,0,0,0,31,1,0,False
971,..\projects\antlr4-4.11.0\tool\src\org\antlr\v4\analysis\LeftRecursiveRuleAnalyzer.java,org.antlr.v4.analysis.LeftRecursiveRuleAnalyzer,"void otherAlt(AltAST, int)","@Override
public void otherAlt(AltAST originalAltTree, int alt) {
    AltAST altTree = (AltAST) originalAltTree.dupTree();
    stripAltLabel(altTree);
    String altText = text(altTree);
    String altLabel = altTree.altLabel != null ? altTree.altLabel.getText() : null;
    LeftRecursiveRuleAltInfo a = new LeftRecursiveRuleAltInfo(alt, altText, null, altLabel, false, originalAltTree);
    // We keep other alts with prefix alts since they are all added to the start of the generated rule, and
    // we want to retain any prior ordering between them
    prefixAndOtherAlts.add(a);
    // System.out.println(""otherAlt "" + alt + "": "" + altText);
}", ,"// We keep other alts with prefix alts since they are all added to the start of the generated rule, and
[[SEP]]// System.out.println(""otherAlt "" + alt + "": "" + altText);
[[SEP]]// we want to retain any prior ordering between them
","// We keep other alts with prefix alts since they are all added to the start of the generated rule, and// we want to retain any prior ordering between them[[SEP]]// System.out.println(""otherAlt "" + alt + "": "" + altText);",194,206,[0],0,"[0, 0, 0]",0,"[0, 0]",0,0,0,0,"otherAlt(AltAST, int)",org.antlr.v4.analysis.LeftRecursiveRuleAnalyzer,"otherAlt/2[org.antlr.v4.analysis.AltAST,int]",False,195,3,3,0,3,2,5,8,0,4,2,5,2,1,0,1,0,0,0,0,4,0,0,0,0,0,17,1,0,False
972,..\projects\antlr4-4.11.0\tool\src\org\antlr\v4\analysis\LeftRecursiveRuleAnalyzer.java,org.antlr.v4.analysis.LeftRecursiveRuleAnalyzer,"AltAST addPrecedenceArgToRules(AltAST, int)","public AltAST addPrecedenceArgToRules(AltAST t, int prec) {
    if (t == null)
        return null;
    // get all top-level rule refs from ALT
    List<GrammarAST> outerAltRuleRefs = t.getNodesWithTypePreorderDFS(IntervalSet.of(RULE_REF));
    for (GrammarAST x : outerAltRuleRefs) {
        RuleRefAST rref = (RuleRefAST) x;
        boolean recursive = rref.getText().equals(ruleName);
        boolean rightmost = rref == outerAltRuleRefs.get(outerAltRuleRefs.size() - 1);
        if (recursive && rightmost) {
            GrammarAST dummyValueNode = new GrammarAST(new CommonToken(ANTLRParser.INT, """" + prec));
            rref.setOption(LeftRecursiveRuleTransformer.PRECEDENCE_OPTION_NAME, dummyValueNode);
        }
    }
    return t;
}", ,"// get all top-level rule refs from ALT
",// get all top-level rule refs from ALT,243,257,[0],0,[0],0,[0],0,0,0,0,"addPrecedenceArgToRules(AltAST, int)",org.antlr.v4.analysis.LeftRecursiveRuleAnalyzer,"addPrecedenceArgToRules/2[org.antlr.v4.analysis.AltAST,int]",False,243,5,3,2,1,5,7,14,2,5,2,7,0,0,1,2,0,0,1,1,5,2,2,0,0,0,34,1,0,False
973,..\projects\antlr4-4.11.0\tool\src\org\antlr\v4\analysis\LeftRecursiveRuleAnalyzer.java,org.antlr.v4.analysis.LeftRecursiveRuleAnalyzer,"boolean hasImmediateRecursiveRuleRefs(GrammarAST, String)","/**
 * Match (RULE RULE_REF (BLOCK (ALT .*) (ALT RULE_REF[self] .*) (ALT .*)))
 * Match (RULE RULE_REF (BLOCK (ALT .*) (ALT (ASSIGN ID RULE_REF[self]) .*) (ALT .*)))
 */
public static boolean hasImmediateRecursiveRuleRefs(GrammarAST t, String ruleName) {
    if (t == null)
        return false;
    GrammarAST blk = (GrammarAST) t.getFirstChildWithType(BLOCK);
    if (blk == null)
        return false;
    int n = blk.getChildren().size();
    for (int i = 0; i < n; i++) {
        GrammarAST alt = (GrammarAST) blk.getChildren().get(i);
        Tree first = alt.getChild(0);
        if (first == null)
            continue;
        if (first.getType() == ELEMENT_OPTIONS) {
            first = alt.getChild(1);
            if (first == null) {
                continue;
            }
        }
        if (first.getType() == RULE_REF && first.getText().equals(ruleName))
            return true;
        Tree rref = first.getChild(1);
        if (rref != null && rref.getType() == RULE_REF && rref.getText().equals(ruleName))
            return true;
    }
    return false;
}","/**
 * Match (RULE RULE_REF (BLOCK (ALT .*) (ALT RULE_REF[self] .*) (ALT .*)))
 * Match (RULE RULE_REF (BLOCK (ALT .*) (ALT (ASSIGN ID RULE_REF[self]) .*) (ALT .*)))
 */
", ,/** * Match (RULE RULE_REF (BLOCK (ALT .*) (ALT RULE_REF[self] .*) (ALT .*))) * Match (RULE RULE_REF (BLOCK (ALT .*) (ALT (ASSIGN ID RULE_REF[self]) .*) (ALT .*))) */,263,283,[0],0,[0],0,[0],0,0,0,0,"hasImmediateRecursiveRuleRefs(GrammarAST, String)",org.antlr.v4.analysis.LeftRecursiveRuleAnalyzer,"hasImmediateRecursiveRuleRefs/2[org.antlr.v4.analysis.GrammarAST,java.lang.String]",False,263,2,1,1,0,12,8,21,5,6,2,8,0,0,1,8,0,0,0,4,7,0,3,0,0,0,39,9,0,True
974,..\projects\antlr4-4.11.0\tool\src\org\antlr\v4\analysis\LeftRecursiveRuleAnalyzer.java,org.antlr.v4.analysis.LeftRecursiveRuleAnalyzer,GrammarAST stripLeftRecursion(GrammarAST),"// TODO: this strips the tree properly, but since text()
// uses the start of stop token index and gets text from that
// ineffectively ignores this routine.
public GrammarAST stripLeftRecursion(GrammarAST altAST) {
    GrammarAST lrlabel = null;
    GrammarAST first = (GrammarAST) altAST.getChild(0);
    int leftRecurRuleIndex = 0;
    if (first.getType() == ELEMENT_OPTIONS) {
        first = (GrammarAST) altAST.getChild(1);
        leftRecurRuleIndex = 1;
    }
    // if label=rule
    Tree rref = first.getChild(1);
    if ((first.getType() == RULE_REF && first.getText().equals(ruleName)) || (rref != null && rref.getType() == RULE_REF && rref.getText().equals(ruleName))) {
        if (first.getType() == ASSIGN || first.getType() == PLUS_ASSIGN)
            lrlabel = (GrammarAST) first.getChild(0);
        // remove rule ref (first child unless options present)
        altAST.deleteChild(leftRecurRuleIndex);
        // reset index so it prints properly (sets token range of
        // ALT to start to right of left recur rule we deleted)
        GrammarAST newFirstChild = (GrammarAST) altAST.getChild(leftRecurRuleIndex);
        altAST.setTokenStartIndex(newFirstChild.getTokenStartIndex());
    }
    return lrlabel;
}","// ineffectively ignores this routine.
","// if label=rule
[[SEP]]// reset index so it prints properly (sets token range of
[[SEP]]// remove rule ref (first child unless options present)
[[SEP]]// ALT to start to right of left recur rule we deleted)
","// TODO: this strips the tree properly, but since text()// uses the start of stop token index and gets text from that// ineffectively ignores this routine.[[SEP]]// if label=rule[[SEP]]// remove rule ref (first child unless options present)[[SEP]]// reset index so it prints properly (sets token range of// ALT to start to right of left recur rule we deleted)",288,309,[0],0,"[0, 0, 0, 0]",0,"[1, 0, 0, 0]",1,1,1,1,stripLeftRecursion(GrammarAST),org.antlr.v4.analysis.LeftRecursiveRuleAnalyzer,stripLeftRecursion/1[org.antlr.v4.analysis.GrammarAST],False,288,2,2,2,0,9,7,17,1,5,1,7,0,0,0,6,0,2,0,6,8,0,2,0,0,0,34,1,0,False
975,..\projects\antlr4-4.11.0\tool\src\org\antlr\v4\analysis\LeftRecursiveRuleAnalyzer.java,org.antlr.v4.analysis.LeftRecursiveRuleAnalyzer,void stripAltLabel(GrammarAST),"/**
 * Strip last 2 tokens if → label; alter indexes in altAST
 */
public void stripAltLabel(GrammarAST altAST) {
    int start = altAST.getTokenStartIndex();
    int stop = altAST.getTokenStopIndex();
    // find =>
    for (int i = stop; i >= start; i--) {
        if (tokenStream.get(i).getType() == POUND) {
            altAST.setTokenStopIndex(i - 1);
            return;
        }
    }
}","/**
 * Strip last 2 tokens if → label; alter indexes in altAST
 */
","// find =>
",/** * Strip last 2 tokens if → label; alter indexes in altAST */[[SEP]]// find =>,312,322,[0],0,[0],0,"[0, 0]",0,0,0,0,stripAltLabel(GrammarAST),org.antlr.v4.analysis.LeftRecursiveRuleAnalyzer,stripAltLabel/1[org.antlr.v4.analysis.GrammarAST],False,312,1,4,4,0,3,5,10,1,3,1,5,0,0,1,1,0,0,0,1,3,1,2,0,0,0,23,1,0,True
976,..\projects\antlr4-4.11.0\tool\src\org\antlr\v4\analysis\LeftRecursiveRuleAnalyzer.java,org.antlr.v4.analysis.LeftRecursiveRuleAnalyzer,String text(GrammarAST),"public String text(GrammarAST t) {
    if (t == null)
        return """";
    int tokenStartIndex = t.getTokenStartIndex();
    int tokenStopIndex = t.getTokenStopIndex();
    // ignore tokens from existing option subtrees like:
    // (ELEMENT_OPTIONS (= assoc right))
    // 
    // element options are added back according to the values in the map
    // returned by getOptions().
    IntervalSet ignore = new IntervalSet();
    List<GrammarAST> optionsSubTrees = t.getNodesWithType(ELEMENT_OPTIONS);
    for (GrammarAST sub : optionsSubTrees) {
        ignore.add(sub.getTokenStartIndex(), sub.getTokenStopIndex());
    }
    // Individual labels appear as RULE_REF or TOKEN_REF tokens in the tree,
    // but do not support the ELEMENT_OPTIONS syntax. Make sure to not try
    // and add the tokenIndex option when writing these tokens.
    IntervalSet noOptions = new IntervalSet();
    List<GrammarAST> labeledSubTrees = t.getNodesWithType(new IntervalSet(ASSIGN, PLUS_ASSIGN));
    for (GrammarAST sub : labeledSubTrees) {
        noOptions.add(sub.getChild(0).getTokenStartIndex());
    }
    StringBuilder buf = new StringBuilder();
    int i = tokenStartIndex;
    while (i <= tokenStopIndex) {
        if (ignore.contains(i)) {
            i++;
            continue;
        }
        Token tok = tokenStream.get(i);
        // Compute/hold any element options
        StringBuilder elementOptions = new StringBuilder();
        if (!noOptions.contains(i)) {
            GrammarAST node = t.getNodeWithTokenIndex(tok.getTokenIndex());
            if (node != null && (tok.getType() == TOKEN_REF || tok.getType() == STRING_LITERAL || tok.getType() == RULE_REF)) {
                elementOptions.append(""tokenIndex="").append(tok.getTokenIndex());
            }
            if (node instanceof GrammarASTWithOptions) {
                GrammarASTWithOptions o = (GrammarASTWithOptions) node;
                for (Map.Entry<String, GrammarAST> entry : o.getOptions().entrySet()) {
                    if (elementOptions.length() > 0) {
                        elementOptions.append(',');
                    }
                    elementOptions.append(entry.getKey());
                    elementOptions.append('=');
                    elementOptions.append(entry.getValue().getText());
                }
            }
        }
        // add actual text of the current token to the rewritten alternative
        buf.append(tok.getText());
        // move to the next token
        i++;
        // Are there args on a rule?
        if (tok.getType() == RULE_REF && i <= tokenStopIndex && tokenStream.get(i).getType() == ARG_ACTION) {
            buf.append('[' + tokenStream.get(i).getText() + ']');
            i++;
        }
        // now that we have the actual element, we can add the options.
        if (elementOptions.length() > 0) {
            buf.append('<').append(elementOptions).append('>');
        }
    }
    return buf.toString();
}", ,"// ignore tokens from existing option subtrees like:
[[SEP]]// (ELEMENT_OPTIONS (= assoc right))
[[SEP]]// 
[[SEP]]// element options are added back according to the values in the map
[[SEP]]// Individual labels appear as RULE_REF or TOKEN_REF tokens in the tree,
[[SEP]]// but do not support the ELEMENT_OPTIONS syntax. Make sure to not try
[[SEP]]// returned by getOptions().
[[SEP]]// and add the tokenIndex option when writing these tokens.
[[SEP]]// Compute/hold any element options
[[SEP]]// add actual text of the current token to the rewritten alternative
[[SEP]]// move to the next token
[[SEP]]// Are there args on a rule?
[[SEP]]// now that we have the actual element, we can add the options.
","// ignore tokens from existing option subtrees like:// (ELEMENT_OPTIONS (= assoc right))//// element options are added back according to the values in the map// returned by getOptions().[[SEP]]// Individual labels appear as RULE_REF or TOKEN_REF tokens in the tree,// but do not support the ELEMENT_OPTIONS syntax. Make sure to not try// and add the tokenIndex option when writing these tokens.[[SEP]]// Compute/hold any element options[[SEP]]// add actual text of the current token to the rewritten alternative[[SEP]]// move to the next token[[SEP]]// Are there args on a rule?[[SEP]]// now that we have the actual element, we can add the options.",324,401,[0],0,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]",0,"[0, 0, 0, 0, 0, 0, 0]",0,0,0,0,text(GrammarAST),org.antlr.v4.analysis.LeftRecursiveRuleAnalyzer,text/1[org.antlr.v4.analysis.GrammarAST],False,324,4,9,4,5,18,22,52,2,12,1,22,0,0,4,7,0,1,2,3,12,1,5,0,0,0,46,1,0,False
977,..\projects\antlr4-4.11.0\tool\src\org\antlr\v4\analysis\LeftRecursiveRuleAnalyzer.java,org.antlr.v4.analysis.LeftRecursiveRuleAnalyzer,int nextPrecedence(int),"// Assumes left assoc
public int nextPrecedence(int alt) {
    int p = precedence(alt);
    if (altAssociativity.get(alt) == ASSOC.right)
        return p;
    return p + 1;
}","// Assumes left assoc
", ,// Assumes left assoc,408,412,[0],0,[0],0,[0],0,0,0,0,nextPrecedence(int),org.antlr.v4.analysis.LeftRecursiveRuleAnalyzer,nextPrecedence/1[int],False,408,1,2,1,1,2,2,5,2,1,1,2,1,1,0,1,0,0,0,1,1,1,1,0,0,0,5,1,0,False
978,..\projects\antlr4-4.11.0\tool\src\org\antlr\v4\analysis\LeftRecursiveRuleTransformer.java,org.antlr.v4.analysis.LeftRecursiveRuleTransformer,void translateLeftRecursiveRules(),"public void translateLeftRecursiveRules() {
    String language = g.getLanguage();
    // translate all recursive rules
    List<String> leftRecursiveRuleNames = new ArrayList<String>();
    for (Rule r : rules) {
        if (!Grammar.isTokenName(r.name)) {
            if (LeftRecursiveRuleAnalyzer.hasImmediateRecursiveRuleRefs(r.ast, r.name)) {
                boolean fitsPattern = translateLeftRecursiveRule(ast, (LeftRecursiveRule) r, language);
                if (fitsPattern) {
                    leftRecursiveRuleNames.add(r.name);
                } else {
                    // better given an error that non-conforming left-recursion exists
                    tool.errMgr.grammarError(ErrorType.NONCONFORMING_LR_RULE, g.fileName, ((GrammarAST) r.ast.getChild(0)).token, r.name);
                }
            }
        }
    }
    // update all refs to recursive rules to have [0] argument
    for (GrammarAST r : ast.getNodesWithType(ANTLRParser.RULE_REF)) {
        // must be rule def
        if (r.getParent().getType() == ANTLRParser.RULE)
            continue;
        // already has arg; must be in rewritten rule
        if (((GrammarASTWithOptions) r).getOptionString(PRECEDENCE_OPTION_NAME) != null)
            continue;
        if (leftRecursiveRuleNames.contains(r.getText())) {
            // found ref to recursive rule not already rewritten with arg
            ((GrammarASTWithOptions) r).setOption(PRECEDENCE_OPTION_NAME, (GrammarAST) new GrammarASTAdaptor().create(ANTLRParser.INT, ""0""));
        }
    }
}", ,"// translate all recursive rules
[[SEP]]// better given an error that non-conforming left-recursion exists
[[SEP]]// update all refs to recursive rules to have [0] argument
[[SEP]]// must be rule def
[[SEP]]// already has arg; must be in rewritten rule
[[SEP]]// found ref to recursive rule not already rewritten with arg
",// translate all recursive rules[[SEP]]// better given an error that non-conforming left-recursion exists[[SEP]]// update all refs to recursive rules to have [0] argument[[SEP]]// must be rule def[[SEP]]// already has arg; must be in rewritten rule[[SEP]]// found ref to recursive rule not already rewritten with arg,64,91,[0],0,"[0, 0, 0, 0, 0, 0]",0,"[0, 0, 0, 0, 0, 0]",0,0,0,0,translateLeftRecursiveRules(),org.antlr.v4.analysis.LeftRecursiveRuleTransformer,translateLeftRecursiveRules/0,False,64,6,2,0,2,9,15,24,0,3,0,15,1,2,2,2,0,3,1,1,3,0,4,0,0,0,30,1,0,False
979,..\projects\antlr4-4.11.0\tool\src\org\antlr\v4\analysis\LeftRecursiveRuleTransformer.java,org.antlr.v4.analysis.LeftRecursiveRuleTransformer,"boolean translateLeftRecursiveRule(GrammarRootAST, LeftRecursiveRule, String)","/**
 * Return true if successful
 */
public boolean translateLeftRecursiveRule(GrammarRootAST ast, LeftRecursiveRule r, String language) {
    // tool.log(""grammar"", ruleAST.toStringTree());
    GrammarAST prevRuleAST = r.ast;
    String ruleName = prevRuleAST.getChild(0).getText();
    LeftRecursiveRuleAnalyzer leftRecursiveRuleWalker = new LeftRecursiveRuleAnalyzer(prevRuleAST, tool, ruleName, language);
    boolean isLeftRec;
    try {
        // System.out.println(""TESTING ---------------\n""+
        // leftRecursiveRuleWalker.text(ruleAST));
        isLeftRec = leftRecursiveRuleWalker.rec_rule();
    } catch (RecognitionException re) {
        // didn't match; oh well
        isLeftRec = false;
    }
    if (!isLeftRec)
        return false;
    // replace old rule's AST; first create text of altered rule
    GrammarAST RULES = (GrammarAST) ast.getFirstChildWithType(ANTLRParser.RULES);
    String newRuleText = leftRecursiveRuleWalker.getArtificialOpPrecRule();
    // System.out.println(""created: ""+newRuleText);
    // now parse within the context of the grammar that originally created
    // the AST we are transforming. This could be an imported grammar so
    // we cannot just reference this.g because the role might come from
    // the imported grammar and not the root grammar (this.g)
    RuleAST t = parseArtificialRule(prevRuleAST.g, newRuleText);
    // reuse the name token from the original AST since it refers to the proper source location in the original grammar
    ((GrammarAST) t.getChild(0)).token = ((GrammarAST) prevRuleAST.getChild(0)).getToken();
    // update grammar AST and set rule's AST.
    RULES.setChild(prevRuleAST.getChildIndex(), t);
    r.ast = t;
    // Reduce sets in newly created rule tree
    GrammarTransformPipeline transform = new GrammarTransformPipeline(g, g.tool);
    transform.reduceBlocksToSets(r.ast);
    transform.expandParameterizedLoops(r.ast);
    // Rerun semantic checks on the new rule
    RuleCollector ruleCollector = new RuleCollector(g);
    ruleCollector.visit(t, ""rule"");
    BasicSemanticChecks basics = new BasicSemanticChecks(g, ruleCollector);
    // disable the assoc element option checks because they are already
    // handled for the pre-transformed rule.
    basics.checkAssocElementOption = false;
    basics.visit(t, ""rule"");
    // track recursive alt info for codegen
    r.recPrimaryAlts = new ArrayList<LeftRecursiveRuleAltInfo>();
    r.recPrimaryAlts.addAll(leftRecursiveRuleWalker.prefixAndOtherAlts);
    if (r.recPrimaryAlts.isEmpty()) {
        tool.errMgr.grammarError(ErrorType.NO_NON_LR_ALTS, g.fileName, ((GrammarAST) r.ast.getChild(0)).getToken(), r.name);
    }
    r.recOpAlts = new OrderedHashMap<Integer, LeftRecursiveRuleAltInfo>();
    r.recOpAlts.putAll(leftRecursiveRuleWalker.binaryAlts);
    r.recOpAlts.putAll(leftRecursiveRuleWalker.ternaryAlts);
    r.recOpAlts.putAll(leftRecursiveRuleWalker.suffixAlts);
    // walk alt info records and set their altAST to point to appropriate ALT subtree
    // from freshly created AST
    setAltASTPointers(r, t);
    // update Rule to just one alt and add prec alt
    ActionAST arg = (ActionAST) r.ast.getFirstChildWithType(ANTLRParser.ARG_ACTION);
    if (arg != null) {
        r.args = ScopeParser.parseTypedArgList(arg, arg.getText(), g);
        r.args.type = AttributeDict.DictType.ARG;
        r.args.ast = arg;
        // todo: isn't this Rule or something?
        arg.resolver = r.alt[1];
    }
    // define labels on recursive rule refs we delete; they don't point to nodes of course
    // these are so $label in action translation works
    for (Pair<GrammarAST, String> pair : leftRecursiveRuleWalker.leftRecursiveRuleRefLabels) {
        GrammarAST labelNode = pair.a;
        GrammarAST labelOpNode = (GrammarAST) labelNode.getParent();
        GrammarAST elementNode = (GrammarAST) labelOpNode.getChild(1);
        LabelElementPair lp = new LabelElementPair(g, labelNode, elementNode, labelOpNode.getType());
        r.alt[1].labelDefs.map(labelNode.getText(), lp);
    }
    // copy to rule from walker
    r.leftRecursiveRuleRefLabels = leftRecursiveRuleWalker.leftRecursiveRuleRefLabels;
    tool.log(""grammar"", ""added: "" + t.toStringTree());
    return true;
}","/**
 * Return true if successful
 */
","// System.out.println(""created: ""+newRuleText);
[[SEP]]// now parse within the context of the grammar that originally created
[[SEP]]// the AST we are transforming. This could be an imported grammar so
[[SEP]]// we cannot just reference this.g because the role might come from
[[SEP]]// disable the assoc element option checks because they are already
[[SEP]]// walk alt info records and set their altAST to point to appropriate ALT subtree
[[SEP]]// define labels on recursive rule refs we delete; they don't point to nodes of course
[[SEP]]// tool.log(""grammar"", ruleAST.toStringTree());
[[SEP]]// System.out.println(""TESTING ---------------\n""+
[[SEP]]// leftRecursiveRuleWalker.text(ruleAST));
[[SEP]]// didn't match; oh well
[[SEP]]// replace old rule's AST; first create text of altered rule
[[SEP]]// the imported grammar and not the root grammar (this.g)
[[SEP]]// reuse the name token from the original AST since it refers to the proper source location in the original grammar
[[SEP]]// update grammar AST and set rule's AST.
[[SEP]]// Reduce sets in newly created rule tree
[[SEP]]// Rerun semantic checks on the new rule
[[SEP]]// handled for the pre-transformed rule.
[[SEP]]// track recursive alt info for codegen
[[SEP]]// from freshly created AST
[[SEP]]// update Rule to just one alt and add prec alt
[[SEP]]// todo: isn't this Rule or something?
[[SEP]]// these are so $label in action translation works
[[SEP]]// copy to rule from walker
","/** * Return true if successful */[[SEP]]// tool.log(""grammar"", ruleAST.toStringTree());[[SEP]]// System.out.println(""TESTING ---------------\n""+// leftRecursiveRuleWalker.text(ruleAST));[[SEP]]// didn't match; oh well[[SEP]]// replace old rule's AST; first create text of altered rule[[SEP]]// System.out.println(""created: ""+newRuleText);// now parse within the context of the grammar that originally created// the AST we are transforming. This could be an imported grammar so// we cannot just reference this.g because the role might come from// the imported grammar and not the root grammar (this.g)[[SEP]]// reuse the name token from the original AST since it refers to the proper source location in the original grammar[[SEP]]// update grammar AST and set rule's AST.[[SEP]]// Reduce sets in newly created rule tree[[SEP]]// Rerun semantic checks on the new rule[[SEP]]// disable the assoc element option checks because they are already// handled for the pre-transformed rule.[[SEP]]// track recursive alt info for codegen[[SEP]]// walk alt info records and set their altAST to point to appropriate ALT subtree// from freshly created AST[[SEP]]// update Rule to just one alt and add prec alt[[SEP]]// todo: isn't this Rule or something?[[SEP]]// define labels on recursive rule refs we delete; they don't point to nodes of course// these are so $label in action translation works[[SEP]]// copy to rule from walker",94,184,[0],0,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0]",1,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0]",1,1,1,1,"translateLeftRecursiveRule(GrammarRootAST, LeftRecursiveRule, String)",org.antlr.v4.analysis.LeftRecursiveRuleTransformer,"translateLeftRecursiveRule/3[org.antlr.v4.analysis.GrammarRootAST,org.antlr.v4.analysis.LeftRecursiveRule,java.lang.String]",False,97,14,6,1,5,6,23,54,2,15,3,23,2,1,1,1,1,3,4,7,26,1,1,0,0,0,58,1,0,True
980,..\projects\antlr4-4.11.0\tool\src\org\antlr\v4\analysis\LeftRecursiveRuleTransformer.java,org.antlr.v4.analysis.LeftRecursiveRuleTransformer,"void setAltASTPointers(LeftRecursiveRule, RuleAST)","/**
 *  <pre>
 *  (RULE e int _p (returns int v)
 *  	(BLOCK
 *  	  (ALT
 *  		(BLOCK
 *  			(ALT INT {$v = $INT.int;})
 *  			(ALT '(' (= x e) ')' {$v = $x.v;})
 *  			(ALT ID))
 *  		(* (BLOCK
 * 			(OPTIONS ...)
 *  			(ALT {7 &gt;= $_p}? '*' (= b e) {$v = $a.v * $b.v;})
 *  			(ALT {6 &gt;= $_p}? '+' (= b e) {$v = $a.v + $b.v;})
 *  			(ALT {3 &gt;= $_p}? '++') (ALT {2 &gt;= $_p}? '--'))))))
 *  </pre>
 */
public void setAltASTPointers(LeftRecursiveRule r, RuleAST t) {
    // System.out.println(""RULE: ""+t.toStringTree());
    BlockAST ruleBlk = (BlockAST) t.getFirstChildWithType(ANTLRParser.BLOCK);
    AltAST mainAlt = (AltAST) ruleBlk.getChild(0);
    BlockAST primaryBlk = (BlockAST) mainAlt.getChild(0);
    // (* BLOCK ...)
    BlockAST opsBlk = (BlockAST) mainAlt.getChild(1).getChild(0);
    for (int i = 0; i < r.recPrimaryAlts.size(); i++) {
        LeftRecursiveRuleAltInfo altInfo = r.recPrimaryAlts.get(i);
        altInfo.altAST = (AltAST) primaryBlk.getChild(i);
        altInfo.altAST.leftRecursiveAltInfo = altInfo;
        altInfo.originalAltAST.leftRecursiveAltInfo = altInfo;
        // altInfo.originalAltAST.parent = altInfo.altAST.parent;
        // System.out.println(altInfo.altAST.toStringTree());
    }
    for (int i = 0; i < r.recOpAlts.size(); i++) {
        LeftRecursiveRuleAltInfo altInfo = r.recOpAlts.getElement(i);
        altInfo.altAST = (AltAST) opsBlk.getChild(i);
        altInfo.altAST.leftRecursiveAltInfo = altInfo;
        altInfo.originalAltAST.leftRecursiveAltInfo = altInfo;
        // altInfo.originalAltAST.parent = altInfo.altAST.parent;
        // System.out.println(altInfo.altAST.toStringTree());
    }
}","/**
 *  <pre>
 *  (RULE e int _p (returns int v)
 *  	(BLOCK
 *  	  (ALT
 *  		(BLOCK
 *  			(ALT INT {$v = $INT.int;})
 *  			(ALT '(' (= x e) ')' {$v = $x.v;})
 *  			(ALT ID))
 *  		(* (BLOCK
 * 			(OPTIONS ...)
 *  			(ALT {7 &gt;= $_p}? '*' (= b e) {$v = $a.v * $b.v;})
 *  			(ALT {6 &gt;= $_p}? '+' (= b e) {$v = $a.v + $b.v;})
 *  			(ALT {3 &gt;= $_p}? '++') (ALT {2 &gt;= $_p}? '--'))))))
 *  </pre>
 */
","// System.out.println(""RULE: ""+t.toStringTree());
[[SEP]]// (* BLOCK ...)
[[SEP]]// altInfo.originalAltAST.parent = altInfo.altAST.parent;
[[SEP]]// System.out.println(altInfo.altAST.toStringTree());
[[SEP]]// altInfo.originalAltAST.parent = altInfo.altAST.parent;
[[SEP]]// System.out.println(altInfo.altAST.toStringTree());
","/** *  <pre> *  (RULE e int _p (returns int v) *  	(BLOCK *  	  (ALT *  		(BLOCK *  			(ALT INT {$v = $INT.int;}) *  			(ALT '(' (= x e) ')' {$v = $x.v;}) *  			(ALT ID)) *  		(* (BLOCK * 			(OPTIONS ...) *  			(ALT {7 &gt;= $_p}? '*' (= b e) {$v = $a.v * $b.v;}) *  			(ALT {6 &gt;= $_p}? '+' (= b e) {$v = $a.v + $b.v;}) *  			(ALT {3 &gt;= $_p}? '++') (ALT {2 &gt;= $_p}? '--')))))) *  </pre> */[[SEP]]// System.out.println(""RULE: ""+t.toStringTree());[[SEP]]// (* BLOCK ...)[[SEP]]// altInfo.originalAltAST.parent = altInfo.altAST.parent;// System.out.println(altInfo.altAST.toStringTree());[[SEP]]// altInfo.originalAltAST.parent = altInfo.altAST.parent;// System.out.println(altInfo.altAST.toStringTree());",227,249,[0],0,"[0, 0, 0, 0, 0, 0]",0,"[0, 0, 0, 0, 0]",0,0,0,0,"setAltASTPointers(LeftRecursiveRule, RuleAST)",org.antlr.v4.analysis.LeftRecursiveRuleTransformer,"setAltASTPointers/2[org.antlr.v4.analysis.LeftRecursiveRule,org.antlr.v4.analysis.RuleAST]",False,227,5,1,1,0,3,5,18,0,8,2,5,0,0,2,0,0,0,0,6,14,0,1,0,0,0,39,1,0,True
981,..\projects\antlr4-4.11.0\tool\src\org\antlr\v4\automata\ATNOptimizer.java,org.antlr.v4.automata.ATNOptimizer,"void optimizeSets(Grammar, ATN)","private static void optimizeSets(Grammar g, ATN atn) {
    if (g.isParser()) {
        // parser codegen doesn't currently support SetTransition
        return;
    }
    int removedStates = 0;
    List<DecisionState> decisions = atn.decisionToState;
    for (DecisionState decision : decisions) {
        if (decision.ruleIndex >= 0) {
            Rule rule = g.getRule(decision.ruleIndex);
            if (Character.isLowerCase(rule.name.charAt(0))) {
                // parser codegen doesn't currently support SetTransition
                continue;
            }
        }
        IntervalSet setTransitions = new IntervalSet();
        for (int i = 0; i < decision.getNumberOfTransitions(); i++) {
            Transition epsTransition = decision.transition(i);
            if (!(epsTransition instanceof EpsilonTransition)) {
                continue;
            }
            if (epsTransition.target.getNumberOfTransitions() != 1) {
                continue;
            }
            Transition transition = epsTransition.target.transition(0);
            if (!(transition.target instanceof BlockEndState)) {
                continue;
            }
            if (transition instanceof NotSetTransition) {
                // TODO: not yet implemented
                continue;
            }
            if (transition instanceof AtomTransition || transition instanceof RangeTransition || transition instanceof SetTransition) {
                setTransitions.add(i);
            }
        }
        // due to min alt resolution policies, can only collapse sequential alts
        for (int i = setTransitions.getIntervals().size() - 1; i >= 0; i--) {
            Interval interval = setTransitions.getIntervals().get(i);
            if (interval.length() <= 1) {
                continue;
            }
            ATNState blockEndState = decision.transition(interval.a).target.transition(0).target;
            IntervalSet matchSet = new IntervalSet();
            for (int j = interval.a; j <= interval.b; j++) {
                Transition matchTransition = decision.transition(j).target.transition(0);
                if (matchTransition instanceof NotSetTransition) {
                    throw new UnsupportedOperationException(""Not yet implemented."");
                }
                IntervalSet set = matchTransition.label();
                List<Interval> intervals = set.getIntervals();
                int n = intervals.size();
                for (int k = 0; k < n; k++) {
                    Interval setInterval = intervals.get(k);
                    int a = setInterval.a;
                    int b = setInterval.b;
                    if (a != -1 && b != -1) {
                        for (int v = a; v <= b; v++) {
                            if (matchSet.contains(v)) {
                                // TODO: Token is missing (i.e. position in source is not displayed).
                                g.tool.errMgr.grammarError(ErrorType.CHARACTERS_COLLISION_IN_SET, g.fileName, null, CharSupport.getANTLRCharLiteralForChar(v), CharSupport.getIntervalSetEscapedString(matchSet));
                                break;
                            }
                        }
                    }
                }
                matchSet.addAll(set);
            }
            Transition newTransition;
            if (matchSet.getIntervals().size() == 1) {
                if (matchSet.size() == 1) {
                    newTransition = CodePointTransitions.createWithCodePoint(blockEndState, matchSet.getMinElement());
                } else {
                    Interval matchInterval = matchSet.getIntervals().get(0);
                    newTransition = CodePointTransitions.createWithCodePointRange(blockEndState, matchInterval.a, matchInterval.b);
                }
            } else {
                newTransition = new SetTransition(blockEndState, matchSet);
            }
            decision.transition(interval.a).target.setTransition(0, newTransition);
            for (int j = interval.a + 1; j <= interval.b; j++) {
                Transition removed = decision.removeTransition(interval.a + 1);
                atn.removeState(removed.target);
                removedStates++;
            }
        }
    }
    // System.out.println(""ATN optimizer removed "" + removedStates + "" states by collapsing sets."");
}", ,"// System.out.println(""ATN optimizer removed "" + removedStates + "" states by collapsing sets."");
[[SEP]]// parser codegen doesn't currently support SetTransition
[[SEP]]// parser codegen doesn't currently support SetTransition
[[SEP]]// TODO: not yet implemented
[[SEP]]// due to min alt resolution policies, can only collapse sequential alts
[[SEP]]// TODO: Token is missing (i.e. position in source is not displayed).
","// parser codegen doesn't currently support SetTransition[[SEP]]// parser codegen doesn't currently support SetTransition[[SEP]]// TODO: not yet implemented[[SEP]]// due to min alt resolution policies, can only collapse sequential alts[[SEP]]// TODO: Token is missing (i.e. position in source is not displayed).[[SEP]]// System.out.println(""ATN optimizer removed "" + removedStates + "" states by collapsing sets."");",41,148,[0],0,"[0, 0, 0, 1, 0, 1]",1,"[0, 0, 1, 0, 1, 0]",1,1,1,1,"optimizeSets(Grammar, ATN)",org.antlr.v4.automata.ATNOptimizer,"optimizeSets/2[org.antlr.v4.automata.Grammar,org.antlr.v4.runtime.atn.ATN]",False,41,16,20,1,19,25,24,85,1,25,2,24,0,0,7,5,0,2,1,20,27,3,7,0,0,0,44,10,0,False
982,..\projects\antlr4-4.11.0\tool\src\org\antlr\v4\automata\ATNOptimizer.java,org.antlr.v4.automata.ATNOptimizer,void optimizeStates(ATN),"private static void optimizeStates(ATN atn) {
    // System.out.println(atn.states);
    List<ATNState> compressed = new ArrayList<ATNState>();
    // new state number
    int i = 0;
    for (ATNState s : atn.states) {
        if (s != null) {
            compressed.add(s);
            // reset state number as we shift to new position
            s.stateNumber = i;
            i++;
        }
    }
    // System.out.println(compressed);
    // System.out.println(""ATN optimizer removed "" + (atn.states.size() - compressed.size()) + "" null states."");
    atn.states.clear();
    atn.states.addAll(compressed);
}", ,"// System.out.println(compressed);
[[SEP]]// System.out.println(atn.states);
[[SEP]]// new state number
[[SEP]]// reset state number as we shift to new position
[[SEP]]// System.out.println(""ATN optimizer removed "" + (atn.states.size() - compressed.size()) + "" null states."");
","// System.out.println(atn.states);[[SEP]]// new state number[[SEP]]// reset state number as we shift to new position[[SEP]]// System.out.println(compressed);// System.out.println(""ATN optimizer removed "" + (atn.states.size() - compressed.size()) + "" null states."");",150,165,[0],0,"[0, 0, 0, 0, 0]",0,"[0, 0, 0, 0]",0,0,0,0,optimizeStates(ATN),org.antlr.v4.automata.ATNOptimizer,optimizeStates/1[org.antlr.v4.runtime.atn.ATN],False,150,2,1,1,0,3,3,13,0,2,1,3,0,0,1,1,0,0,0,1,3,0,2,0,0,0,11,10,0,False
983,..\projects\antlr4-4.11.0\tool\src\org\antlr\v4\automata\ATNPrinter.java,org.antlr.v4.automata.ATNPrinter,String asString(),"public String asString() {
    if (start == null)
        return null;
    marked = new HashSet<ATNState>();
    work = new ArrayList<ATNState>();
    work.add(start);
    StringBuilder buf = new StringBuilder();
    ATNState s;
    while (!work.isEmpty()) {
        s = work.remove(0);
        if (marked.contains(s))
            continue;
        int n = s.getNumberOfTransitions();
        // System.out.println(""visit ""+s+""; edges=""+n);
        marked.add(s);
        for (int i = 0; i < n; i++) {
            Transition t = s.transition(i);
            if (!(s instanceof RuleStopState)) {
                // don't add follow states to work
                if (t instanceof RuleTransition)
                    work.add(((RuleTransition) t).followState);
                else
                    work.add(t.target);
            }
            buf.append(getStateString(s));
            if (t instanceof EpsilonTransition) {
                buf.append(""->"").append(getStateString(t.target)).append('\n');
            } else if (t instanceof RuleTransition) {
                buf.append(""-"").append(g.getRule(((RuleTransition) t).ruleIndex).name).append(""->"").append(getStateString(t.target)).append('\n');
            } else if (t instanceof ActionTransition) {
                ActionTransition a = (ActionTransition) t;
                buf.append(""-"").append(a.toString()).append(""->"").append(getStateString(t.target)).append('\n');
            } else if (t instanceof SetTransition) {
                SetTransition st = (SetTransition) t;
                boolean not = st instanceof NotSetTransition;
                if (g.isLexer()) {
                    buf.append(""-"").append(not ? ""~"" : """").append(st.toString()).append(""->"").append(getStateString(t.target)).append('\n');
                } else {
                    buf.append(""-"").append(not ? ""~"" : """").append(st.label().toString(g.getVocabulary())).append(""->"").append(getStateString(t.target)).append('\n');
                }
            } else if (t instanceof AtomTransition) {
                AtomTransition a = (AtomTransition) t;
                String label = g.getTokenDisplayName(a.label);
                buf.append(""-"").append(label).append(""->"").append(getStateString(t.target)).append('\n');
            } else {
                buf.append(""-"").append(t.toString()).append(""->"").append(getStateString(t.target)).append('\n');
            }
        }
    }
    return buf.toString();
}", ,"// System.out.println(""visit ""+s+""; edges=""+n);
[[SEP]]// don't add follow states to work
","// System.out.println(""visit ""+s+""; edges=""+n);[[SEP]]// don't add follow states to work",45,99,[0],0,"[0, 0]",0,"[0, 0]",0,0,0,0,asString(),org.antlr.v4.automata.ATNPrinter,asString/0,False,45,11,8,1,7,15,22,51,2,10,0,22,1,1,2,1,0,3,17,2,12,0,4,0,0,0,29,1,0,False
984,..\projects\antlr4-4.11.0\tool\src\org\antlr\v4\automata\LexerATNFactory.java,org.antlr.v4.automata.LexerATNFactory,ATN createATN(),"@Override
public ATN createATN() {
    // BUILD ALL START STATES (ONE PER MODE)
    Set<String> modes = ((LexerGrammar) g).modes.keySet();
    for (String modeName : modes) {
        // create s0, start state; implied Tokens rule node
        TokensStartState startState = newState(TokensStartState.class, null);
        atn.modeNameToStartState.put(modeName, startState);
        atn.modeToStartState.add(startState);
        atn.defineDecisionState(startState);
    }
    // INIT ACTION, RULE->TOKEN_TYPE MAP
    atn.ruleToTokenType = new int[g.rules.size()];
    for (Rule r : g.rules.values()) {
        atn.ruleToTokenType[r.index] = g.getTokenType(r.name);
    }
    // CREATE ATN FOR EACH RULE
    _createATN(g.rules.values());
    atn.lexerActions = new LexerAction[indexToActionMap.size()];
    for (Map.Entry<Integer, LexerAction> entry : indexToActionMap.entrySet()) {
        atn.lexerActions[entry.getKey()] = entry.getValue();
    }
    // LINK MODE START STATE TO EACH TOKEN RULE
    for (String modeName : modes) {
        List<Rule> rules = ((LexerGrammar) g).modes.get(modeName);
        TokensStartState startState = atn.modeNameToStartState.get(modeName);
        for (Rule r : rules) {
            if (!r.isFragment()) {
                RuleStartState s = atn.ruleToStartState[r.index];
                epsilon(startState, s);
            }
        }
    }
    ATNOptimizer.optimize(g, atn);
    checkEpsilonClosure();
    return atn;
}", ,"// BUILD ALL START STATES (ONE PER MODE)
[[SEP]]// create s0, start state; implied Tokens rule node
[[SEP]]// INIT ACTION, RULE->TOKEN_TYPE MAP
[[SEP]]// CREATE ATN FOR EACH RULE
[[SEP]]// LINK MODE START STATE TO EACH TOKEN RULE
","// BUILD ALL START STATES (ONE PER MODE)[[SEP]]// create s0, start state; implied Tokens rule node[[SEP]]// INIT ACTION, RULE->TOKEN_TYPE MAP[[SEP]]// CREATE ATN FOR EACH RULE[[SEP]]// LINK MODE START STATE TO EACH TOKEN RULE",85,127,[0],0,"[0, 0, 0, 0, 0]",0,"[0, 0, 0, 0, 0]",0,0,0,0,createATN(),org.antlr.v4.automata.LexerATNFactory,createATN/0,False,86,9,6,0,6,7,19,31,1,5,0,19,0,0,5,0,0,2,0,0,9,0,3,0,0,0,26,1,0,False
985,..\projects\antlr4-4.11.0\tool\src\org\antlr\v4\automata\LexerATNFactory.java,org.antlr.v4.automata.LexerATNFactory,Handle action(String),"@Override
public Handle action(String action) {
    if (action.trim().isEmpty()) {
        ATNState left = newState(null);
        ATNState right = newState(null);
        epsilon(left, right);
        return new Handle(left, right);
    }
    // define action AST for this rule as if we had found in grammar
    ActionAST ast = new ActionAST(new CommonToken(ANTLRParser.ACTION, action));
    currentRule.defineActionInAlt(currentOuterAlt, ast);
    return action(ast);
}", ,"// define action AST for this rule as if we had found in grammar
",// define action AST for this rule as if we had found in grammar,154,167,[0],0,[0],0,[0],0,0,0,0,action(String),org.antlr.v4.automata.LexerATNFactory,action/1[java.lang.String],False,155,6,4,0,4,2,6,11,2,3,1,6,1,3,0,0,0,0,0,0,3,0,1,0,0,0,16,1,0,False
986,..\projects\antlr4-4.11.0\tool\src\org\antlr\v4\automata\LexerATNFactory.java,org.antlr.v4.automata.LexerATNFactory,"Handle lexerCallCommandOrCommand(GrammarAST, GrammarAST)","private Handle lexerCallCommandOrCommand(GrammarAST ID, GrammarAST arg) {
    LexerAction lexerAction = createLexerAction(ID, arg);
    if (lexerAction != null) {
        return action(ID, lexerAction);
    }
    // fall back to standard action generation for the command
    ST cmdST = codegenTemplates.getInstanceOf(""Lexer"" + CharSupport.capitalize(ID.getText()) + ""Command"");
    if (cmdST == null) {
        g.tool.errMgr.grammarError(ErrorType.INVALID_LEXER_COMMAND, g.fileName, ID.token, ID.getText());
        return epsilon(ID);
    }
    boolean callCommand = arg != null;
    boolean containsArg = cmdST.impl.formalArguments != null && cmdST.impl.formalArguments.containsKey(""arg"");
    if (callCommand != containsArg) {
        ErrorType errorType = callCommand ? ErrorType.UNWANTED_LEXER_COMMAND_ARGUMENT : ErrorType.MISSING_LEXER_COMMAND_ARGUMENT;
        g.tool.errMgr.grammarError(errorType, g.fileName, ID.token, ID.getText());
        return epsilon(ID);
    }
    if (callCommand) {
        cmdST.add(""arg"", arg.getText());
        cmdST.add(""grammar"", arg.g);
    }
    return action(cmdST.render());
}", ,"// fall back to standard action generation for the command
",// fall back to standard action generation for the command,199,228,[0],0,[0],0,[0],0,0,0,0,"lexerCallCommandOrCommand(GrammarAST, GrammarAST)",org.antlr.v4.automata.LexerATNFactory,"lexerCallCommandOrCommand/2[org.antlr.v4.automata.GrammarAST,org.antlr.v4.automata.GrammarAST]",False,199,8,7,2,5,8,11,23,4,5,2,11,3,4,0,5,0,0,5,0,5,1,1,0,0,0,25,2,0,False
987,..\projects\antlr4-4.11.0\tool\src\org\antlr\v4\automata\LexerATNFactory.java,org.antlr.v4.automata.LexerATNFactory,Handle stringLiteral(TerminalAST),"/**
 * For a lexer, a string is a sequence of char to match.  That is,
 *  ""fog"" is treated as 'f' 'o' 'g' not as a single transition in
 *  the DFA.  Machine== o-'f'-&gt;o-'o'-&gt;o-'g'-&gt;o and has n+1 states
 *  for n characters.
 *  if ""caseInsensitive"" option is enabled, ""fog"" will be treated as
 *  o-('f'|'F') -> o-('o'|'O') -> o-('g'|'G')
 */
@Override
public Handle stringLiteral(TerminalAST stringLiteralAST) {
    String chars = stringLiteralAST.getText();
    ATNState left = newState(stringLiteralAST);
    ATNState right;
    String s = CharSupport.getStringFromGrammarStringLiteral(chars);
    if (s == null) {
        // the lexer will already have given an error
        return new Handle(left, left);
    }
    int n = s.length();
    ATNState prev = left;
    right = null;
    for (int i = 0; i < n; ) {
        right = newState(stringLiteralAST);
        int codePoint = s.codePointAt(i);
        prev.addTransition(createTransition(right, codePoint, codePoint, stringLiteralAST));
        prev = right;
        i += Character.charCount(codePoint);
    }
    stringLiteralAST.atnState = left;
    return new Handle(left, right);
}","/**
 * For a lexer, a string is a sequence of char to match.  That is,
 *  ""fog"" is treated as 'f' 'o' 'g' not as a single transition in
 *  the DFA.  Machine== o-'f'-&gt;o-'o'-&gt;o-'g'-&gt;o and has n+1 states
 *  for n characters.
 *  if ""caseInsensitive"" option is enabled, ""fog"" will be treated as
 *  o-('f'|'F') -> o-('o'|'O') -> o-('g'|'G')
 */
","// the lexer will already have given an error
","/** * For a lexer, a string is a sequence of char to match.  That is, *  ""fog"" is treated as 'f' 'o' 'g' not as a single transition in *  the DFA.  Machine== o-'f'-&gt;o-'o'-&gt;o-'g'-&gt;o and has n+1 states *  for n characters. *  if ""caseInsensitive"" option is enabled, ""fog"" will be treated as *  o-('f'|'F') -> o-('o'|'O') -> o-('g'|'G') */[[SEP]]// the lexer will already have given an error",323,346,[0],0,[0],0,"[0, 0]",0,0,0,0,stringLiteral(TerminalAST),org.antlr.v4.automata.LexerATNFactory,stringLiteral/1[org.antlr.v4.automata.TerminalAST],False,324,6,5,0,5,3,8,21,2,8,1,8,1,1,1,1,0,0,0,1,12,0,1,0,0,0,45,1,0,True
988,..\projects\antlr4-4.11.0\tool\src\org\antlr\v4\automata\LexerATNFactory.java,org.antlr.v4.automata.LexerATNFactory,Handle charSetLiteral(GrammarAST),"/**
 * [Aa\t \u1234a-z\]\p{Letter}\-] char sets
 */
@Override
public Handle charSetLiteral(GrammarAST charSetAST) {
    ATNState left = newState(charSetAST);
    ATNState right = newState(charSetAST);
    IntervalSet set = getSetFromCharSetLiteral(charSetAST);
    left.addTransition(new SetTransition(right, set));
    charSetAST.atnState = left;
    return new Handle(left, right);
}","/**
 * [Aa\t \u1234a-z\]\p{Letter}\-] char sets
 */
", ,/** * [Aa\t \u1234a-z\]\p{Letter}\-] char sets */,349,358,[0],0,[0],0,[0],0,0,0,0,charSetLiteral(GrammarAST),org.antlr.v4.automata.LexerATNFactory,charSetLiteral/1[org.antlr.v4.automata.GrammarAST],False,350,7,5,0,5,1,3,8,1,3,1,3,1,6,0,0,0,0,0,0,4,0,0,0,0,0,21,1,0,True
989,..\projects\antlr4-4.11.0\tool\src\org\antlr\v4\automata\LexerATNFactory.java,org.antlr.v4.automata.LexerATNFactory,IntervalSet getSetFromCharSetLiteral(GrammarAST),"public IntervalSet getSetFromCharSetLiteral(GrammarAST charSetAST) {
    String chars = charSetAST.getText();
    chars = chars.substring(1, chars.length() - 1);
    IntervalSet set = new IntervalSet();
    CharSetParseState state = CharSetParseState.NONE;
    int n = chars.length();
    for (int i = 0; i < n; ) {
        if (state.mode == CharSetParseState.Mode.ERROR) {
            return new IntervalSet();
        }
        int c = chars.codePointAt(i);
        int offset = Character.charCount(c);
        if (c == '\\') {
            EscapeSequenceParsing.Result escapeParseResult = EscapeSequenceParsing.parseEscape(chars, i);
            switch(escapeParseResult.type) {
                case INVALID:
                    String invalid = chars.substring(escapeParseResult.startOffset, escapeParseResult.startOffset + escapeParseResult.parseLength);
                    g.tool.errMgr.grammarError(ErrorType.INVALID_ESCAPE_SEQUENCE, g.fileName, charSetAST.getToken(), invalid);
                    state = CharSetParseState.ERROR;
                    break;
                case CODE_POINT:
                    state = applyPrevStateAndMoveToCodePoint(charSetAST, set, state, escapeParseResult.codePoint);
                    break;
                case PROPERTY:
                    state = applyPrevStateAndMoveToProperty(charSetAST, set, state, escapeParseResult.propertyIntervalSet);
                    break;
            }
            offset = escapeParseResult.parseLength;
        } else if (c == '-' && !state.inRange && i != 0 && i != n - 1 && state.mode != CharSetParseState.Mode.NONE) {
            if (state.mode == CharSetParseState.Mode.PREV_PROPERTY) {
                g.tool.errMgr.grammarError(ErrorType.UNICODE_PROPERTY_NOT_ALLOWED_IN_RANGE, g.fileName, charSetAST.getToken(), charSetAST.getText());
                state = CharSetParseState.ERROR;
            } else {
                state = new CharSetParseState(state.mode, true, state.prevCodePoint, state.prevProperty);
            }
        } else {
            state = applyPrevStateAndMoveToCodePoint(charSetAST, set, state, c);
        }
        i += offset;
    }
    if (state.mode == CharSetParseState.Mode.ERROR) {
        return new IntervalSet();
    }
    // Whether or not we were in a range, we'll add the last code point found to the set.
    applyPrevState(charSetAST, set, state);
    if (set.isNil()) {
        g.tool.errMgr.grammarError(ErrorType.EMPTY_STRINGS_AND_SETS_NOT_ALLOWED, g.fileName, charSetAST.getToken(), ""[]"");
    }
    return set;
}", ,"// Whether or not we were in a range, we'll add the last code point found to the set.
","// Whether or not we were in a range, we'll add the last code point found to the set.",419,478,[0],0,[0],0,[0],0,0,0,0,getSetFromCharSetLiteral(GrammarAST),org.antlr.v4.automata.LexerATNFactory,getSetFromCharSetLiteral/1[org.antlr.v4.automata.GrammarAST],False,419,6,9,2,7,15,12,52,3,9,1,12,3,5,1,8,0,0,1,5,18,3,3,0,0,0,31,1,0,False
990,..\projects\antlr4-4.11.0\tool\src\org\antlr\v4\automata\LexerATNFactory.java,org.antlr.v4.automata.LexerATNFactory,"CharactersDataCheckStatus checkRangeAndAddToSet(GrammarAST, GrammarAST, IntervalSet, int, int, boolean, CharactersDataCheckStatus)","private CharactersDataCheckStatus checkRangeAndAddToSet(GrammarAST rootAst, GrammarAST ast, IntervalSet set, int a, int b, boolean caseInsensitive, CharactersDataCheckStatus previousStatus) {
    CharactersDataCheckStatus status;
    RangeBorderCharactersData charactersData = RangeBorderCharactersData.getAndCheckCharactersData(a, b, g, ast, previousStatus == null || !previousStatus.notImpliedCharacters);
    if (caseInsensitive) {
        status = new CharactersDataCheckStatus(false, charactersData.mixOfLowerAndUpperCharCase);
        if (charactersData.isSingleRange()) {
            status = checkRangeAndAddToSet(rootAst, ast, set, a, b, false, status);
        } else {
            status = checkRangeAndAddToSet(rootAst, ast, set, charactersData.lowerFrom, charactersData.lowerTo, false, status);
            // Don't report similar warning twice
            status = checkRangeAndAddToSet(rootAst, ast, set, charactersData.upperFrom, charactersData.upperTo, false, status);
        }
    } else {
        boolean charactersCollision = previousStatus != null && previousStatus.collision;
        if (!charactersCollision) {
            for (int i = a; i <= b; i++) {
                if (set.contains(i)) {
                    String setText;
                    if (rootAst.getChildren() == null) {
                        setText = rootAst.getText();
                    } else {
                        StringBuilder sb = new StringBuilder();
                        for (Object child : rootAst.getChildren()) {
                            if (child instanceof RangeAST) {
                                sb.append(((RangeAST) child).getChild(0).getText());
                                sb.append("".."");
                                sb.append(((RangeAST) child).getChild(1).getText());
                            } else {
                                sb.append(((GrammarAST) child).getText());
                            }
                            sb.append("" | "");
                        }
                        sb.replace(sb.length() - 3, sb.length(), """");
                        setText = sb.toString();
                    }
                    String charsString = a == b ? String.valueOf((char) a) : (char) a + ""-"" + (char) b;
                    g.tool.errMgr.grammarError(ErrorType.CHARACTERS_COLLISION_IN_SET, g.fileName, ast.getToken(), charsString, setText);
                    charactersCollision = true;
                    break;
                }
            }
        }
        status = new CharactersDataCheckStatus(charactersCollision, charactersData.mixOfLowerAndUpperCharCase);
        set.add(a, b);
    }
    return status;
}", ,"// Don't report similar warning twice
",// Don't report similar warning twice,550,602,[0],0,[0],0,[0],0,0,0,0,"checkRangeAndAddToSet(GrammarAST, GrammarAST, IntervalSet, int, int, boolean, CharactersDataCheckStatus)",org.antlr.v4.automata.LexerATNFactory,"checkRangeAndAddToSet/7[org.antlr.v4.automata.GrammarAST,org.antlr.v4.automata.GrammarAST,org.antlr.v4.runtime.misc.IntervalSet,int,int,boolean,org.antlr.v4.automata.CharactersDataCheckStatus]",False,550,6,10,4,6,11,16,50,1,7,7,16,1,0,2,4,0,3,4,3,13,2,7,0,0,0,34,2,0,False
991,..\projects\antlr4-4.11.0\tool\src\org\antlr\v4\automata\LexerATNFactory.java,org.antlr.v4.automata.LexerATNFactory,Handle tokenRef(TerminalAST),"@Override
public Handle tokenRef(TerminalAST node) {
    // Ref to EOF in lexer yields char transition on -1
    if (node.getText().equals(""EOF"")) {
        ATNState left = newState(node);
        ATNState right = newState(node);
        left.addTransition(new AtomTransition(right, IntStream.EOF));
        return new Handle(left, right);
    }
    return _ruleRef(node);
}", ,"// Ref to EOF in lexer yields char transition on -1
",// Ref to EOF in lexer yields char transition on -1,622,632,[0],0,[0],0,[0],0,0,0,0,tokenRef(TerminalAST),org.antlr.v4.automata.LexerATNFactory,tokenRef/1[org.antlr.v4.automata.TerminalAST],False,623,5,5,0,5,2,5,9,2,2,1,5,0,0,0,0,0,0,1,0,2,0,1,0,0,0,16,1,0,False
992,..\projects\antlr4-4.11.0\tool\src\org\antlr\v4\automata\LexerATNFactory.java,org.antlr.v4.automata.LexerATNFactory,"void checkCommands(String, Token)","private void checkCommands(String command, Token commandToken) {
    // Command combinations list: https://github.com/antlr/antlr4/issues/1388#issuecomment-263344701
    if (!command.equals(""pushMode"") && !command.equals(""popMode"")) {
        if (ruleCommands.contains(command)) {
            g.tool.errMgr.grammarError(ErrorType.DUPLICATED_COMMAND, g.fileName, commandToken, command);
        }
        String firstCommand = null;
        if (command.equals(""skip"")) {
            if (ruleCommands.contains(""more"")) {
                firstCommand = ""more"";
            } else if (ruleCommands.contains(""type"")) {
                firstCommand = ""type"";
            } else if (ruleCommands.contains(""channel"")) {
                firstCommand = ""channel"";
            }
        } else if (command.equals(""more"")) {
            if (ruleCommands.contains(""skip"")) {
                firstCommand = ""skip"";
            } else if (ruleCommands.contains(""type"")) {
                firstCommand = ""type"";
            } else if (ruleCommands.contains(""channel"")) {
                firstCommand = ""channel"";
            }
        } else if (command.equals(""type"") || command.equals(""channel"")) {
            if (ruleCommands.contains(""more"")) {
                firstCommand = ""more"";
            } else if (ruleCommands.contains(""skip"")) {
                firstCommand = ""skip"";
            }
        }
        if (firstCommand != null) {
            g.tool.errMgr.grammarError(ErrorType.INCOMPATIBLE_COMMANDS, g.fileName, commandToken, firstCommand, command);
        }
    }
    ruleCommands.add(command);
}", ,"// Command combinations list: https://github.com/antlr/antlr4/issues/1388#issuecomment-263344701
",// Command combinations list: https://github.com/antlr/antlr4/issues/1388#issuecomment-263344701,688,734,[0],0,[0],0,[0],0,0,0,0,"checkCommands(String, Token)",org.antlr.v4.automata.LexerATNFactory,"checkCommands/2[java.lang.String,org.antlr.v4.automata.Token]",False,688,1,1,1,0,17,4,42,0,1,2,4,0,0,0,1,0,0,22,0,9,0,3,0,0,0,7,2,0,False
993,..\projects\antlr4-4.11.0\tool\src\org\antlr\v4\automata\ParserATNFactory.java,org.antlr.v4.automata.ParserATNFactory,void _createATN(Collection<Rule>),"protected void _createATN(Collection<Rule> rules) {
    createRuleStartAndStopATNStates();
    GrammarASTAdaptor adaptor = new GrammarASTAdaptor();
    for (Rule r : rules) {
        // find rule's block
        GrammarAST blk = (GrammarAST) r.ast.getFirstChildWithType(ANTLRParser.BLOCK);
        CommonTreeNodeStream nodes = new CommonTreeNodeStream(adaptor, blk);
        ATNBuilder b = new ATNBuilder(nodes, this);
        try {
            setCurrentRuleName(r.name);
            Handle h = b.ruleBlock(null);
            rule(r.ast, r.name, h);
        } catch (RecognitionException re) {
            ErrorManager.fatalInternalError(""bad grammar AST structure"", re);
        }
    }
}", ,"// find rule's block
",// find rule's block,156,174,[0],0,[0],0,[0],0,0,0,0,_createATN(Collection<Rule>),org.antlr.v4.automata.ParserATNFactory,_createATN/1[java.util.Collection<org.antlr.v4.automata.Rule>],False,156,7,5,2,3,3,6,17,0,5,1,6,3,3,1,0,1,0,1,0,5,0,2,0,0,0,35,4,0,False
994,..\projects\antlr4-4.11.0\tool\src\org\antlr\v4\automata\ParserATNFactory.java,org.antlr.v4.automata.ParserATNFactory,"Handle rule(GrammarAST, String, Handle)","/* start->ruleblock->end */
@Override
public Handle rule(GrammarAST ruleAST, String name, Handle blk) {
    Rule r = g.getRule(name);
    RuleStartState start = atn.ruleToStartState[r.index];
    epsilon(start, blk.left);
    RuleStopState stop = atn.ruleToStopState[r.index];
    epsilon(blk.right, stop);
    Handle h = new Handle(start, stop);
    // ATNPrinter ser = new ATNPrinter(g, h.left);
    // System.out.println(ruleAST.toStringTree()+"":\n""+ser.asString());
    ruleAST.atnState = start;
    return h;
}", ,"// ATNPrinter ser = new ATNPrinter(g, h.left);
[[SEP]]// System.out.println(ruleAST.toStringTree()+"":\n""+ser.asString());
","/* start->ruleblock->end */[[SEP]]// ATNPrinter ser = new ATNPrinter(g, h.left);// System.out.println(ruleAST.toStringTree()+"":\n""+ser.asString());",188,200,[0],0,"[0, 0]",0,"[0, 0]",0,0,0,0,"rule(GrammarAST, String, Handle)",org.antlr.v4.automata.ParserATNFactory,"rule/3[org.antlr.v4.automata.GrammarAST,java.lang.String,org.antlr.v4.automata.ATNFactory.Handle]",False,189,6,3,1,2,1,2,10,1,4,3,2,1,2,0,0,0,0,0,0,5,0,0,0,0,0,17,1,0,False
995,..\projects\antlr4-4.11.0\tool\src\org\antlr\v4\automata\ParserATNFactory.java,org.antlr.v4.automata.ParserATNFactory,"Handle range(GrammarAST, GrammarAST)","/**
 * Not valid for non-lexers.
 */
@Override
public Handle range(GrammarAST a, GrammarAST b) {
    g.tool.errMgr.grammarError(ErrorType.TOKEN_RANGE_IN_PARSER, g.fileName, a.getToken(), a.getToken().getText(), b.getToken().getText());
    // From a..b, yield ATN for just a.
    return tokenRef((TerminalAST) a);
}", ,"// From a..b, yield ATN for just a.
","/** * Not valid for non-lexers. */[[SEP]]// From a..b, yield ATN for just a.",240,248,[0],0,[0],0,"[0, 0]",0,0,0,0,"range(GrammarAST, GrammarAST)",org.antlr.v4.automata.ParserATNFactory,"range/2[org.antlr.v4.automata.GrammarAST,org.antlr.v4.automata.GrammarAST]",False,241,4,1,0,1,1,4,4,1,0,2,4,1,2,0,0,0,0,0,0,0,0,0,0,0,0,14,1,0,True
996,..\projects\antlr4-4.11.0\tool\src\org\antlr\v4\automata\ParserATNFactory.java,org.antlr.v4.automata.ParserATNFactory,"void addFollowLink(int, ATNState)","public void addFollowLink(int ruleIndex, ATNState right) {
    // add follow edge from end of invoked rule
    RuleStopState stop = atn.ruleToStopState[ruleIndex];
    // System.out.println(""add follow link from ""+ruleIndex+"" to ""+right);
    epsilon(stop, right);
}", ,"// add follow edge from end of invoked rule
[[SEP]]// System.out.println(""add follow link from ""+ruleIndex+"" to ""+right);
","// add follow edge from end of invoked rule[[SEP]]// System.out.println(""add follow link from ""+ruleIndex+"" to ""+right);",314,319,[0],0,"[0, 0]",0,"[0, 0]",0,0,0,0,"addFollowLink(int, ATNState)",org.antlr.v4.automata.ParserATNFactory,"addFollowLink/2[int,org.antlr.v4.runtime.atn.ATNState]",False,314,3,2,1,1,1,1,4,0,1,2,1,1,2,0,0,0,0,0,0,1,0,0,0,0,0,9,1,0,False
997,..\projects\antlr4-4.11.0\tool\src\org\antlr\v4\automata\ParserATNFactory.java,org.antlr.v4.automata.ParserATNFactory,Handle sempred(PredAST),"/**
 * Build what amounts to an epsilon transition with a semantic
 *  predicate action.  The {@code pred} is a pointer into the AST of
 *  the {@link ANTLRParser#SEMPRED} token.
 */
@Override
public Handle sempred(PredAST pred) {
    // System.out.println(""sempred: ""+ pred);
    ATNState left = newState(pred);
    ATNState right = newState(pred);
    AbstractPredicateTransition p;
    if (pred.getOptionString(LeftRecursiveRuleTransformer.PRECEDENCE_OPTION_NAME) != null) {
        int precedence = Integer.parseInt(pred.getOptionString(LeftRecursiveRuleTransformer.PRECEDENCE_OPTION_NAME));
        p = new PrecedencePredicateTransition(right, precedence);
    } else {
        boolean isCtxDependent = UseDefAnalyzer.actionIsContextDependent(pred);
        p = new PredicateTransition(right, currentRule.index, g.sempreds.get(pred), isCtxDependent);
    }
    left.addTransition(p);
    pred.atnState = left;
    return new Handle(left, right);
}", ,"// System.out.println(""sempred: ""+ pred);
","/** * Build what amounts to an epsilon transition with a semantic *  predicate action.  The {@code pred} is a pointer into the AST of *  the {@link ANTLRParser#SEMPRED} token. */[[SEP]]// System.out.println(""sempred: ""+ pred);",337,356,[0],0,[0],0,"[0, 0]",0,0,0,0,sempred(PredAST),org.antlr.v4.automata.ParserATNFactory,sempred/1[org.antlr.v4.automata.PredAST],False,338,7,5,0,5,2,6,16,1,5,1,6,1,1,0,1,0,0,0,0,7,0,1,0,0,0,38,1,0,True
998,..\projects\antlr4-4.11.0\tool\src\org\antlr\v4\automata\ParserATNFactory.java,org.antlr.v4.automata.ParserATNFactory,Handle action(ActionAST),"/**
 * Build what amounts to an epsilon transition with an action.
 *  The action goes into ATN though it is ignored during prediction
 *  if {@link ActionTransition#actionIndex actionIndex}{@code <0}.
 */
@Override
public Handle action(ActionAST action) {
    // System.out.println(""action: ""+action);
    ATNState left = newState(action);
    ATNState right = newState(action);
    ActionTransition a = new ActionTransition(right, currentRule.index);
    left.addTransition(a);
    action.atnState = left;
    return new Handle(left, right);
}", ,"// System.out.println(""action: ""+action);
","/** * Build what amounts to an epsilon transition with an action. *  The action goes into ATN though it is ignored during prediction *  if {@link ActionTransition#actionIndex actionIndex}{@code <0}. */[[SEP]]// System.out.println(""action: ""+action);",363,372,[0],0,[0],0,"[0, 0]",0,0,0,0,action(ActionAST),org.antlr.v4.automata.ParserATNFactory,action/1[org.antlr.v4.automata.ActionAST],False,364,5,4,0,4,1,2,8,1,3,1,2,1,1,0,0,0,0,0,0,4,0,0,0,0,0,31,1,0,True
999,..\projects\antlr4-4.11.0\tool\src\org\antlr\v4\automata\ParserATNFactory.java,org.antlr.v4.automata.ParserATNFactory,"Handle makeBlock(BlockStartState, BlockAST, List<Handle>)","protected Handle makeBlock(BlockStartState start, BlockAST blkAST, List<Handle> alts) {
    BlockEndState end = newState(BlockEndState.class, blkAST);
    start.endState = end;
    for (Handle alt : alts) {
        // hook alts up to decision block
        epsilon(start, alt.left);
        epsilon(alt.right, end);
        // no back link in ATN so must walk entire alt to see if we can
        // strip out the epsilon to 'end' state
        TailEpsilonRemover opt = new TailEpsilonRemover(atn);
        opt.visit(alt.left);
    }
    Handle h = new Handle(start, end);
    // FASerializer ser = new FASerializer(g, h.left);
    // System.out.println(blkAST.toStringTree()+"":\n""+ser);
    blkAST.atnState = start;
    return h;
}", ,"// FASerializer ser = new FASerializer(g, h.left);
[[SEP]]// no back link in ATN so must walk entire alt to see if we can
[[SEP]]// hook alts up to decision block
[[SEP]]// strip out the epsilon to 'end' state
[[SEP]]// System.out.println(blkAST.toStringTree()+"":\n""+ser);
","// hook alts up to decision block[[SEP]]// no back link in ATN so must walk entire alt to see if we can// strip out the epsilon to 'end' state[[SEP]]// FASerializer ser = new FASerializer(g, h.left);// System.out.println(blkAST.toStringTree()+"":\n""+ser);",438,456,[0],0,"[0, 0, 0, 0, 0]",0,"[0, 0, 0]",0,0,0,0,"makeBlock(BlockStartState, BlockAST, List<Handle>)",org.antlr.v4.automata.ParserATNFactory,"makeBlock/3[org.antlr.v4.runtime.atn.BlockStartState,org.antlr.v4.automata.BlockAST,java.util.List<org.antlr.v4.automata.ATNFactory.Handle>]",False,438,7,6,1,5,2,3,13,1,3,3,3,1,2,1,0,0,0,0,0,5,0,1,0,0,0,18,4,0,False
1000,..\projects\antlr4-4.11.0\tool\src\org\antlr\v4\automata\ParserATNFactory.java,org.antlr.v4.automata.ParserATNFactory,Handle elemList(List<Handle>),"public Handle elemList(List<Handle> els) {
    int n = els.size();
    for (int i = 0; i < n - 1; i++) {
        // hook up elements (visit all but last)
        Handle el = els.get(i);
        // if el is of form o-x->o for x in {rule, action, pred, token, ...}
        // and not last in alt
        Transition tr = null;
        if (el.left.getNumberOfTransitions() == 1)
            tr = el.left.transition(0);
        boolean isRuleTrans = tr instanceof RuleTransition;
        if (el.left.getStateType() == ATNState.BASIC && el.right != null && el.right.getStateType() == ATNState.BASIC && tr != null && (isRuleTrans && ((RuleTransition) tr).followState == el.right || tr.target == el.right)) {
            // we can avoid epsilon edge to next el
            Handle handle = null;
            if (i + 1 < els.size()) {
                handle = els.get(i + 1);
            }
            if (handle != null) {
                if (isRuleTrans) {
                    ((RuleTransition) tr).followState = handle.left;
                } else {
                    tr.target = handle.left;
                }
            }
            // we skipped over this state
            atn.removeState(el.right);
        } else {
            // need epsilon if previous block's right end node is complicated
            epsilon(el.right, els.get(i + 1).left);
        }
    }
    Handle first = els.get(0);
    Handle last = els.get(n - 1);
    ATNState left = null;
    if (first != null) {
        left = first.left;
    }
    ATNState right = null;
    if (last != null) {
        right = last.right;
    }
    return new Handle(left, right);
}", ,"// if el is of form o-x->o for x in {rule, action, pred, token, ...}
[[SEP]]// hook up elements (visit all but last)
[[SEP]]// and not last in alt
[[SEP]]// we can avoid epsilon edge to next el
[[SEP]]// we skipped over this state
[[SEP]]// need epsilon if previous block's right end node is complicated
","// hook up elements (visit all but last)[[SEP]]// if el is of form o-x->o for x in {rule, action, pred, token, ...}// and not last in alt[[SEP]]// we can avoid epsilon edge to next el[[SEP]]// we skipped over this state[[SEP]]// need epsilon if previous block's right end node is complicated",465,507,[0],0,"[0, 0, 0, 0, 0, 0]",0,"[0, 0, 0, 0, 0]",0,0,0,0,elemList(List<Handle>),org.antlr.v4.automata.ParserATNFactory,elemList/1[java.util.List<org.antlr.v4.automata.ATNFactory.Handle>],False,465,6,7,1,6,15,7,38,1,10,1,7,1,2,1,10,0,3,0,9,16,5,4,0,0,0,23,1,0,False
1001,..\projects\antlr4-4.11.0\tool\src\org\antlr\v4\automata\ParserATNFactory.java,org.antlr.v4.automata.ParserATNFactory,"Handle plus(GrammarAST, Handle)","/**
 * From {@code (blk)+} build
 *
 * <pre>
 *   |---------|
 *   v         |
 *  [o-blk-o]-&gt;o-&gt;o
 * </pre>
 *
 * We add a decision for loop back node to the existing one at {@code blk}
 * start.
 */
@Override
public Handle plus(GrammarAST plusAST, Handle blk) {
    PlusBlockStartState blkStart = (PlusBlockStartState) blk.left;
    BlockEndState blkEnd = (BlockEndState) blk.right;
    preventEpsilonClosureBlocks.add(new Triple<Rule, ATNState, ATNState>(currentRule, blkStart, blkEnd));
    PlusLoopbackState loop = newState(PlusLoopbackState.class, plusAST);
    loop.nonGreedy = !((QuantifierAST) plusAST).isGreedy();
    atn.defineDecisionState(loop);
    LoopEndState end = newState(LoopEndState.class, plusAST);
    blkStart.loopBackState = loop;
    end.loopBackState = loop;
    plusAST.atnState = loop;
    // blk can see loop back
    epsilon(blkEnd, loop);
    BlockAST blkAST = (BlockAST) plusAST.getChild(0);
    if (((QuantifierAST) plusAST).isGreedy()) {
        if (expectNonGreedy(blkAST)) {
            g.tool.errMgr.grammarError(ErrorType.EXPECTED_NON_GREEDY_WILDCARD_BLOCK, g.fileName, plusAST.getToken(), plusAST.getToken().getText());
        }
        // loop back to start
        epsilon(loop, blkStart);
        // or exit
        epsilon(loop, end);
    } else {
        // if not greedy, priority to exit branch; make it first
        // exit
        epsilon(loop, end);
        // loop back to start
        epsilon(loop, blkStart);
    }
    return new Handle(blkStart, end);
}", ,"// blk can see loop back
[[SEP]]// loop back to start
[[SEP]]// or exit
[[SEP]]// if not greedy, priority to exit branch; make it first
[[SEP]]// exit
[[SEP]]// loop back to start
","/** * From {@code (blk)+} build * * <pre> *   |---------| *   v         | *  [o-blk-o]-&gt;o-&gt;o * </pre> * * We add a decision for loop back node to the existing one at {@code blk} * start. */[[SEP]]// blk can see loop back[[SEP]]// loop back to start[[SEP]]// or exit[[SEP]]// if not greedy, priority to exit branch; make it first// exit[[SEP]]// loop back to start",549,581,[0],0,"[0, 0, 0, 0, 0, 0]",0,"[0, 0, 0, 0, 0, 0]",0,0,0,0,"plus(GrammarAST, Handle)",org.antlr.v4.automata.ParserATNFactory,"plus/2[org.antlr.v4.automata.GrammarAST,org.antlr.v4.automata.ATNFactory.Handle]",False,550,13,7,1,6,3,10,26,1,5,2,10,2,3,0,0,0,2,0,1,9,0,2,0,0,0,38,1,0,True
1002,..\projects\antlr4-4.11.0\tool\src\org\antlr\v4\automata\ParserATNFactory.java,org.antlr.v4.automata.ParserATNFactory,"Handle star(GrammarAST, Handle)","/**
 * From {@code (blk)*} build {@code ( blk+ )?} with *two* decisions, one for
 * entry and one for choosing alts of {@code blk}.
 *
 * <pre>
 *   |-------------|
 *   v             |
 *   o--[o-blk-o]-&gt;o  o
 *   |                ^
 *   -----------------|
 * </pre>
 *
 * Note that the optional bypass must jump outside the loop as
 * {@code (A|B)*} is not the same thing as {@code (A|B|)+}.
 */
@Override
public Handle star(GrammarAST starAST, Handle elem) {
    StarBlockStartState blkStart = (StarBlockStartState) elem.left;
    BlockEndState blkEnd = (BlockEndState) elem.right;
    preventEpsilonClosureBlocks.add(new Triple<Rule, ATNState, ATNState>(currentRule, blkStart, blkEnd));
    StarLoopEntryState entry = newState(StarLoopEntryState.class, starAST);
    entry.nonGreedy = !((QuantifierAST) starAST).isGreedy();
    atn.defineDecisionState(entry);
    LoopEndState end = newState(LoopEndState.class, starAST);
    StarLoopbackState loop = newState(StarLoopbackState.class, starAST);
    entry.loopBackState = loop;
    end.loopBackState = loop;
    BlockAST blkAST = (BlockAST) starAST.getChild(0);
    if (((QuantifierAST) starAST).isGreedy()) {
        if (expectNonGreedy(blkAST)) {
            g.tool.errMgr.grammarError(ErrorType.EXPECTED_NON_GREEDY_WILDCARD_BLOCK, g.fileName, starAST.getToken(), starAST.getToken().getText());
        }
        // loop enter edge (alt 1)
        epsilon(entry, blkStart);
        // bypass loop edge (alt 2)
        epsilon(entry, end);
    } else {
        // if not greedy, priority to exit branch; make it first
        // bypass loop edge (alt 1)
        epsilon(entry, end);
        // loop enter edge (alt 2)
        epsilon(entry, blkStart);
    }
    // block end hits loop back
    epsilon(blkEnd, loop);
    // loop back to entry/exit decision
    epsilon(loop, entry);
    // decision is to enter/exit; blk is its own decision
    starAST.atnState = entry;
    return new Handle(entry, end);
}", ,"// loop enter edge (alt 1)
[[SEP]]// bypass loop edge (alt 2)
[[SEP]]// if not greedy, priority to exit branch; make it first
[[SEP]]// bypass loop edge (alt 1)
[[SEP]]// loop enter edge (alt 2)
[[SEP]]// block end hits loop back
[[SEP]]// loop back to entry/exit decision
[[SEP]]// decision is to enter/exit; blk is its own decision
","/** * From {@code (blk)*} build {@code ( blk+ )?} with *two* decisions, one for * entry and one for choosing alts of {@code blk}. * * <pre> *   |-------------| *   v             | *   o--[o-blk-o]-&gt;o  o *   |                ^ *   -----------------| * </pre> * * Note that the optional bypass must jump outside the loop as * {@code (A|B)*} is not the same thing as {@code (A|B|)+}. */[[SEP]]// loop enter edge (alt 1)[[SEP]]// bypass loop edge (alt 2)[[SEP]]// if not greedy, priority to exit branch; make it first// bypass loop edge (alt 1)[[SEP]]// loop enter edge (alt 2)[[SEP]]// block end hits loop back[[SEP]]// loop back to entry/exit decision[[SEP]]// decision is to enter/exit; blk is its own decision",599,632,[0],0,"[0, 0, 0, 0, 0, 0, 0, 0]",0,"[0, 0, 0, 0, 0, 0, 0, 0]",0,0,0,0,"star(GrammarAST, Handle)",org.antlr.v4.automata.ParserATNFactory,"star/2[org.antlr.v4.automata.GrammarAST,org.antlr.v4.automata.ATNFactory.Handle]",False,600,14,7,1,6,3,10,28,1,6,2,10,2,3,0,0,0,2,0,1,10,0,2,0,0,0,53,1,0,True
1003,..\projects\antlr4-4.11.0\tool\src\org\antlr\v4\automata\ParserATNFactory.java,org.antlr.v4.automata.ParserATNFactory,void createRuleStartAndStopATNStates(),"/**
 * Define all the rule begin/end ATNStates to solve forward reference
 *  issues.
 */
void createRuleStartAndStopATNStates() {
    atn.ruleToStartState = new RuleStartState[g.rules.size()];
    atn.ruleToStopState = new RuleStopState[g.rules.size()];
    for (Rule r : g.rules.values()) {
        RuleStartState start = newState(RuleStartState.class, r.ast);
        RuleStopState stop = newState(RuleStopState.class, r.ast);
        start.stopState = stop;
        start.isLeftRecursiveRule = r instanceof LeftRecursiveRule;
        start.setRuleIndex(r.index);
        stop.setRuleIndex(r.index);
        atn.ruleToStartState[r.index] = start;
        atn.ruleToStopState[r.index] = stop;
    }
}","/**
 * Define all the rule begin/end ATNStates to solve forward reference
 *  issues.
 */
", ,/** * Define all the rule begin/end ATNStates to solve forward reference *  issues. */,659,672,[0],0,[0],0,[0],0,0,0,0,createRuleStartAndStopATNStates(),org.antlr.v4.automata.ParserATNFactory,createRuleStartAndStopATNStates/0,False,659,6,3,1,2,2,4,14,0,2,0,4,0,0,1,0,0,0,0,0,8,0,1,0,0,0,26,0,0,True
1004,..\projects\antlr4-4.11.0\tool\src\org\antlr\v4\automata\ParserATNFactory.java,org.antlr.v4.automata.ParserATNFactory,int addEOFTransitionToStartRules(),"/**
 * Add an EOF transition to any rule end ATNState that points to nothing
 *  (i.e., for all those rules not invoked by another rule).  These
 *  are start symbols then.
 *
 *  Return the number of grammar entry points; i.e., how many rules are
 *  not invoked by another rule (they can only be invoked from outside).
 *  These are the start rules.
 */
public int addEOFTransitionToStartRules() {
    int n = 0;
    // one unique EOF target for all rules
    ATNState eofTarget = newState(null);
    for (Rule r : g.rules.values()) {
        ATNState stop = atn.ruleToStopState[r.index];
        if (stop.getNumberOfTransitions() > 0)
            continue;
        n++;
        Transition t = new AtomTransition(eofTarget, Token.EOF);
        stop.addTransition(t);
    }
    return n;
}","/**
 * Add an EOF transition to any rule end ATNState that points to nothing
 *  (i.e., for all those rules not invoked by another rule).  These
 *  are start symbols then.
 *
 *  Return the number of grammar entry points; i.e., how many rules are
 *  not invoked by another rule (they can only be invoked from outside).
 *  These are the start rules.
 */
","// one unique EOF target for all rules
","/** * Add an EOF transition to any rule end ATNState that points to nothing *  (i.e., for all those rules not invoked by another rule).  These *  are start symbols then. * *  Return the number of grammar entry points; i.e., how many rules are *  not invoked by another rule (they can only be invoked from outside). *  These are the start rules. */[[SEP]]// one unique EOF target for all rules",694,705,[0],0,[0],0,"[0, 0]",0,0,0,0,addEOFTransitionToStartRules(),org.antlr.v4.automata.ParserATNFactory,addEOFTransitionToStartRules/0,False,694,4,5,1,4,3,4,12,1,4,0,4,1,1,1,0,0,0,0,2,4,0,2,0,0,0,57,1,0,True
1005,..\projects\antlr4-4.11.0\tool\src\org\antlr\v4\automata\ParserATNFactory.java,org.antlr.v4.automata.ParserATNFactory,boolean blockHasWildcardAlt(GrammarAST),"/**
 * {@code (BLOCK (ALT .))} or {@code (BLOCK (ALT 'a') (ALT .))}.
 */
public static boolean blockHasWildcardAlt(GrammarAST block) {
    for (Object alt : block.getChildren()) {
        if (!(alt instanceof AltAST))
            continue;
        AltAST altAST = (AltAST) alt;
        if (altAST.getChildCount() == 1 || (altAST.getChildCount() == 2 && altAST.getChild(0).getType() == ANTLRParser.ELEMENT_OPTIONS)) {
            Tree e = altAST.getChild(altAST.getChildCount() - 1);
            if (e.getType() == ANTLRParser.WILDCARD) {
                return true;
            }
        }
    }
    return false;
}","/**
 * {@code (BLOCK (ALT .))} or {@code (BLOCK (ALT 'a') (ALT .))}.
 */
", ,/** * {@code (BLOCK (ALT .))} or {@code (BLOCK (ALT 'a') (ALT .))}. */,770,782,[0],0,[0],0,[0],0,0,0,0,blockHasWildcardAlt(GrammarAST),org.antlr.v4.automata.ParserATNFactory,blockHasWildcardAlt/1[org.antlr.v4.automata.GrammarAST],False,770,3,1,1,0,7,4,13,2,2,1,4,0,0,1,4,0,2,0,4,2,1,3,0,0,0,20,9,0,True
1006,..\projects\antlr4-4.11.0\tool\src\org\antlr\v4\automata\TailEpsilonRemover.java,org.antlr.v4.automata.TailEpsilonRemover,void visitState(ATNState),"@Override
public void visitState(ATNState p) {
    if (p.getStateType() == ATNState.BASIC && p.getNumberOfTransitions() == 1) {
        ATNState q = p.transition(0).target;
        if (p.transition(0) instanceof RuleTransition) {
            q = ((RuleTransition) p.transition(0)).followState;
        }
        if (q.getStateType() == ATNState.BASIC) {
            // we have p-x->q for x in {rule, action, pred, token, ...}
            // if edge out of q is single epsilon to block end
            // we can strip epsilon p-x->q-eps->r
            Transition trans = q.transition(0);
            if (q.getNumberOfTransitions() == 1 && trans instanceof EpsilonTransition) {
                ATNState r = trans.target;
                if (r instanceof BlockEndState || r instanceof PlusLoopbackState || r instanceof StarLoopbackState) {
                    // skip over q
                    if (p.transition(0) instanceof RuleTransition) {
                        ((RuleTransition) p.transition(0)).followState = r;
                    } else {
                        p.transition(0).target = r;
                    }
                    _atn.removeState(q);
                }
            }
        }
    }
}", ,"// we have p-x->q for x in {rule, action, pred, token, ...}
[[SEP]]// if edge out of q is single epsilon to block end
[[SEP]]// we can strip epsilon p-x->q-eps->r
[[SEP]]// skip over q
","// we have p-x->q for x in {rule, action, pred, token, ...}// if edge out of q is single epsilon to block end// we can strip epsilon p-x->q-eps->r[[SEP]]// skip over q",30,57,[0],0,"[0, 0, 0, 0]",0,"[0, 0]",0,0,0,0,visitState(ATNState),org.antlr.v4.automata.TailEpsilonRemover,visitState/1[org.antlr.v4.runtime.atn.ATNState],False,31,8,4,0,4,11,4,23,0,3,1,4,0,0,0,4,0,2,0,9,6,0,5,0,0,0,17,1,0,False
1007,..\projects\antlr4-4.11.0\tool\src\org\antlr\v4\codegen\ActionTranslator.java,org.antlr.v4.codegen.ActionTranslator,"List<ActionChunk> translateAction(OutputModelFactory, RuleFunction, Token, ActionAST)","public static List<ActionChunk> translateAction(OutputModelFactory factory, RuleFunction rf, Token tokenWithinAction, ActionAST node) {
    String action = tokenWithinAction.getText();
    if (action != null && action.length() > 0 && action.charAt(0) == '{') {
        int firstCurly = action.indexOf('{');
        int lastCurly = action.lastIndexOf('}');
        if (firstCurly >= 0 && lastCurly >= 0) {
            // trim {...}
            action = action.substring(firstCurly + 1, lastCurly);
        }
    }
    return translateActionChunk(factory, rf, action, node);
}", ,"// trim {...}
",// trim {...},113,127,[0],0,[0],0,[0],0,0,0,0,"translateAction(OutputModelFactory, RuleFunction, Token, ActionAST)",org.antlr.v4.codegen.ActionTranslator,"translateAction/4[org.antlr.v4.codegen.OutputModelFactory,org.antlr.v4.codegen.model.RuleFunction,org.antlr.v4.codegen.Token,org.antlr.v4.codegen.ActionAST]",False,117,6,4,3,1,6,7,11,1,3,4,7,1,1,0,2,0,0,0,5,4,1,2,0,0,0,12,9,0,False
1008,..\projects\antlr4-4.11.0\tool\src\org\antlr\v4\codegen\ActionTranslator.java,org.antlr.v4.codegen.ActionTranslator,"List<ActionChunk> translateActionChunk(OutputModelFactory, RuleFunction, String, ActionAST)","public static List<ActionChunk> translateActionChunk(OutputModelFactory factory, RuleFunction rf, String action, ActionAST node) {
    Token tokenWithinAction = node.token;
    ActionTranslator translator = new ActionTranslator(factory, node);
    translator.rf = rf;
    factory.getGrammar().tool.log(""action-translator"", ""translate "" + action);
    String altLabel = node.getAltLabel();
    if (rf != null) {
        translator.nodeContext = rf.ruleCtx;
        if (altLabel != null)
            translator.nodeContext = rf.altLabelCtxs.get(altLabel);
    }
    ANTLRStringStream in = new ANTLRStringStream(action);
    in.setLine(tokenWithinAction.getLine());
    in.setCharPositionInLine(tokenWithinAction.getCharPositionInLine());
    ActionSplitter trigger = new ActionSplitter(in, translator);
    // forces eval, triggers listener methods
    trigger.getActionTokens();
    return translator.chunks;
}", ,"// forces eval, triggers listener methods
","// forces eval, triggers listener methods",129,150,[0],0,[0],0,[0],0,0,0,0,"translateActionChunk(OutputModelFactory, RuleFunction, String, ActionAST)",org.antlr.v4.codegen.ActionTranslator,"translateActionChunk/4[org.antlr.v4.codegen.OutputModelFactory,org.antlr.v4.codegen.model.RuleFunction,java.lang.String,org.antlr.v4.codegen.ActionAST]",False,133,8,6,4,2,3,9,17,1,5,4,9,0,0,0,2,0,0,2,0,8,1,2,0,0,0,27,9,0,False
1009,..\projects\antlr4-4.11.0\tool\src\org\antlr\v4\codegen\ActionTranslator.java,org.antlr.v4.codegen.ActionTranslator,"void attr(String, Token)","@Override
public void attr(String expr, Token x) {
    gen.g.tool.log(""action-translator"", ""attr "" + x);
    Attribute a = node.resolver.resolveToAttribute(x.getText(), node);
    String name = x.getText();
    String escapedName = target.escapeIfNeeded(name);
    if (a != null) {
        switch(a.dict.type) {
            case ARG:
                chunks.add(new ArgRef(nodeContext, name, escapedName));
                break;
            case RET:
                chunks.add(new RetValueRef(rf.ruleCtx, name, escapedName));
                break;
            case LOCAL:
                chunks.add(new LocalRef(nodeContext, name, escapedName));
                break;
            case PREDEFINED_RULE:
                chunks.add(getRulePropertyRef(null, x));
                break;
            default:
                break;
        }
    }
    if (node.resolver.resolvesToToken(name, node)) {
        String tokenLabel = getTokenLabel(name);
        // $label
        chunks.add(new TokenRef(nodeContext, tokenLabel, target.escapeIfNeeded(tokenLabel)));
        return;
    }
    if (node.resolver.resolvesToLabel(name, node)) {
        String tokenLabel = getTokenLabel(name);
        // $x for x=ID etc...
        chunks.add(new LabelRef(nodeContext, tokenLabel, target.escapeIfNeeded(tokenLabel)));
        return;
    }
    if (node.resolver.resolvesToListLabel(name, node)) {
        // $ids for ids+=ID etc...
        chunks.add(new ListLabelRef(nodeContext, name, escapedName));
        return;
    }
    Rule r = factory.getGrammar().getRule(name);
    if (r != null) {
        String ruleLabel = getRuleLabel(name);
        // $r for r rule ref
        chunks.add(new LabelRef(nodeContext, ruleLabel, target.escapeIfNeeded(ruleLabel)));
    }
}", ,"// $label
[[SEP]]// $x for x=ID etc...
[[SEP]]// $ids for ids+=ID etc...
[[SEP]]// $r for r rule ref
",// $label[[SEP]]// $x for x=ID etc...[[SEP]]// $ids for ids+=ID etc...[[SEP]]// $r for r rule ref,152,195,[0],0,"[0, 0, 0, 0]",0,"[0, 0, 0, 0]",0,0,0,0,"attr(String, Token)",org.antlr.v4.codegen.ActionTranslator,"attr/2[java.lang.String,org.antlr.v4.codegen.Token]",False,153,12,12,1,11,10,13,43,3,7,2,13,3,2,0,2,0,0,2,0,7,1,2,0,0,0,22,1,0,False
1010,..\projects\antlr4-4.11.0\tool\src\org\antlr\v4\codegen\ActionTranslator.java,org.antlr.v4.codegen.ActionTranslator,"void qualifiedAttr(String, Token, Token)","@Override
public void qualifiedAttr(String expr, Token x, Token y) {
    gen.g.tool.log(""action-translator"", ""qattr "" + x + ""."" + y);
    if (node.resolver.resolveToAttribute(x.getText(), node) != null) {
        // must be a member access to a predefined attribute like $ctx.foo
        attr(expr, x);
        chunks.add(new ActionText(nodeContext, ""."" + y.getText()));
        return;
    }
    Attribute a = node.resolver.resolveToAttribute(x.getText(), y.getText(), node);
    if (a == null) {
        // Added in response to https://github.com/antlr/antlr4/issues/1211
        gen.g.tool.errMgr.grammarError(ErrorType.UNKNOWN_SIMPLE_ATTRIBUTE, gen.g.fileName, x, x.getText(), ""rule"");
        return;
    }
    switch(a.dict.type) {
        // has to be current rule
        case ARG:
            chunks.add(new ArgRef(nodeContext, y.getText(), target.escapeIfNeeded(y.getText())));
            break;
        case RET:
            chunks.add(new QRetValueRef(nodeContext, getRuleLabel(x.getText()), y.getText(), target.escapeIfNeeded(y.getText())));
            break;
        case PREDEFINED_RULE:
            chunks.add(getRulePropertyRef(x, y));
            break;
        case TOKEN:
            chunks.add(getTokenPropertyRef(x, y));
            break;
        default:
            break;
    }
}", ,"// must be a member access to a predefined attribute like $ctx.foo
[[SEP]]// Added in response to https://github.com/antlr/antlr4/issues/1211
[[SEP]]// has to be current rule
",// must be a member access to a predefined attribute like $ctx.foo[[SEP]]// Added in response to https://github.com/antlr/antlr4/issues/1211[[SEP]]// has to be current rule,197,229,[0],0,"[0, 0, 0]",0,"[0, 0, 0]",0,0,0,0,"qualifiedAttr(String, Token, Token)",org.antlr.v4.codegen.ActionTranslator,"qualifiedAttr/3[java.lang.String,org.antlr.v4.codegen.Token,org.antlr.v4.codegen.Token]",False,198,7,8,0,8,7,10,29,2,1,3,10,4,4,0,2,0,0,5,0,1,2,1,0,0,0,19,1,0,False
1011,..\projects\antlr4-4.11.0\tool\src\org\antlr\v4\codegen\CodeGenPipeline.java,org.antlr.v4.codegen.CodeGenPipeline,void process(),"public void process() {
    // all templates are generated in memory to report the most complete
    // error information possible, but actually writing output files stops
    // after the first error is reported
    int errorCount = g.tool.errMgr.getNumErrors();
    if (g.isLexer()) {
        if (gen.getTarget().needsHeader()) {
            // Header file if needed.
            ST lexer = gen.generateLexer(true);
            if (g.tool.errMgr.getNumErrors() == errorCount) {
                writeRecognizer(lexer, gen, true);
            }
        }
        ST lexer = gen.generateLexer(false);
        if (g.tool.errMgr.getNumErrors() == errorCount) {
            writeRecognizer(lexer, gen, false);
        }
    } else {
        if (gen.getTarget().needsHeader()) {
            ST parser = gen.generateParser(true);
            if (g.tool.errMgr.getNumErrors() == errorCount) {
                writeRecognizer(parser, gen, true);
            }
        }
        ST parser = gen.generateParser(false);
        if (g.tool.errMgr.getNumErrors() == errorCount) {
            writeRecognizer(parser, gen, false);
        }
        if (g.tool.gen_listener) {
            if (gen.getTarget().needsHeader()) {
                ST listener = gen.generateListener(true);
                if (g.tool.errMgr.getNumErrors() == errorCount) {
                    gen.writeListener(listener, true);
                }
            }
            ST listener = gen.generateListener(false);
            if (g.tool.errMgr.getNumErrors() == errorCount) {
                gen.writeListener(listener, false);
            }
            if (gen.getTarget().needsHeader()) {
                ST baseListener = gen.generateBaseListener(true);
                if (g.tool.errMgr.getNumErrors() == errorCount) {
                    gen.writeBaseListener(baseListener, true);
                }
            }
            if (gen.getTarget().wantsBaseListener()) {
                ST baseListener = gen.generateBaseListener(false);
                if (g.tool.errMgr.getNumErrors() == errorCount) {
                    gen.writeBaseListener(baseListener, false);
                }
            }
        }
        if (g.tool.gen_visitor) {
            if (gen.getTarget().needsHeader()) {
                ST visitor = gen.generateVisitor(true);
                if (g.tool.errMgr.getNumErrors() == errorCount) {
                    gen.writeVisitor(visitor, true);
                }
            }
            ST visitor = gen.generateVisitor(false);
            if (g.tool.errMgr.getNumErrors() == errorCount) {
                gen.writeVisitor(visitor, false);
            }
            if (gen.getTarget().needsHeader()) {
                ST baseVisitor = gen.generateBaseVisitor(true);
                if (g.tool.errMgr.getNumErrors() == errorCount) {
                    gen.writeBaseVisitor(baseVisitor, true);
                }
            }
            if (gen.getTarget().wantsBaseVisitor()) {
                ST baseVisitor = gen.generateBaseVisitor(false);
                if (g.tool.errMgr.getNumErrors() == errorCount) {
                    gen.writeBaseVisitor(baseVisitor, false);
                }
            }
        }
    }
    gen.writeVocabFile();
}", ,"// all templates are generated in memory to report the most complete
[[SEP]]// error information possible, but actually writing output files stops
[[SEP]]// after the first error is reported
[[SEP]]// Header file if needed.
","// all templates are generated in memory to report the most complete// error information possible, but actually writing output files stops// after the first error is reported[[SEP]]// Header file if needed.",23,105,[0],0,"[0, 0, 0, 0]",0,"[0, 0]",0,0,0,0,process(),org.antlr.v4.codegen.CodeGenPipeline,process/0,False,23,4,16,0,16,24,18,76,0,13,0,18,1,1,0,12,0,0,0,0,13,0,4,0,0,0,16,1,0,False
1012,..\projects\antlr4-4.11.0\tool\src\org\antlr\v4\codegen\CodeGenerator.java,org.antlr.v4.codegen.CodeGenerator,ST getTokenVocabOutput(),"/**
 * Generate a token vocab file with all the token names/types.  For example:
 *  ID=7
 *  FOR=8
 *  'for'=8
 *
 *  This is independent of the target language; used by antlr internally
 */
ST getTokenVocabOutput() {
    ST vocabFileST = new ST(vocabFilePattern);
    Map<String, Integer> tokens = new LinkedHashMap<String, Integer>();
    // make constants for the token names
    for (String t : g.tokenNameToTypeMap.keySet()) {
        int tokenType = g.tokenNameToTypeMap.get(t);
        if (tokenType >= Token.MIN_USER_TOKEN_TYPE) {
            tokens.put(t, tokenType);
        }
    }
    vocabFileST.add(""tokens"", tokens);
    // now dump the strings
    Map<String, Integer> literals = new LinkedHashMap<String, Integer>();
    for (String literal : g.stringLiteralToTypeMap.keySet()) {
        int tokenType = g.stringLiteralToTypeMap.get(literal);
        if (tokenType >= Token.MIN_USER_TOKEN_TYPE) {
            literals.put(literal, tokenType);
        }
    }
    vocabFileST.add(""literals"", literals);
    return vocabFileST;
}","/**
 * Generate a token vocab file with all the token names/types.  For example:
 *  ID=7
 *  FOR=8
 *  'for'=8
 *
 *  This is independent of the target language; used by antlr internally
 */
","// make constants for the token names
[[SEP]]// now dump the strings
",/** * Generate a token vocab file with all the token names/types.  For example: *  ID=7 *  FOR=8 *  'for'=8 * *  This is independent of the target language; used by antlr internally */[[SEP]]// make constants for the token names[[SEP]]// now dump the strings,116,139,[0],0,"[0, 0]",0,"[0, 0, 0]",0,0,0,0,getTokenVocabOutput(),org.antlr.v4.codegen.CodeGenerator,getTokenVocabOutput/0,False,116,1,1,1,0,5,4,20,1,5,0,4,0,0,2,0,0,0,2,0,5,0,2,0,0,0,38,0,0,True
1013,..\projects\antlr4-4.11.0\tool\src\org\antlr\v4\codegen\CodeGenerator.java,org.antlr.v4.codegen.CodeGenerator,void writeVocabFile(),"public void writeVocabFile() {
    // write out the vocab interchange file; used by antlr,
    // does not change per target
    ST tokenVocabSerialization = getTokenVocabOutput();
    String fileName = getVocabFileName();
    if (fileName != null) {
        target.genFile(g, tokenVocabSerialization, fileName);
    }
}", ,"// write out the vocab interchange file; used by antlr,
[[SEP]]// does not change per target
","// write out the vocab interchange file; used by antlr,// does not change per target",161,169,[0],0,"[0, 0]",0,[0],0,0,0,0,writeVocabFile(),org.antlr.v4.codegen.CodeGenerator,writeVocabFile/0,False,161,3,4,1,3,2,3,7,0,2,0,3,2,1,0,1,0,0,0,0,2,0,1,0,0,0,13,1,0,False
1014,..\projects\antlr4-4.11.0\tool\src\org\antlr\v4\codegen\CodeGenerator.java,org.antlr.v4.codegen.CodeGenerator,"void write(ST, String)","public void write(ST code, String fileName) {
    try {
        // long start = System.currentTimeMillis();
        Writer w = tool.getOutputFileWriter(g, fileName);
        STWriter wr = new AutoIndentWriter(w);
        wr.setLineWidth(lineWidth);
        code.write(wr);
        w.close();
        // long stop = System.currentTimeMillis();
    } catch (IOException ioe) {
        tool.errMgr.toolError(ErrorType.CANNOT_WRITE_FILE, ioe, fileName);
    }
}", ,"// long stop = System.currentTimeMillis();
[[SEP]]// long start = System.currentTimeMillis();
",// long start = System.currentTimeMillis();[[SEP]]// long stop = System.currentTimeMillis();,171,186,[0],0,"[0, 0]",0,"[0, 0]",0,0,0,0,"write(ST, String)",org.antlr.v4.codegen.CodeGenerator,"write/2[org.antlr.v4.codegen.ST,java.lang.String]",False,171,3,1,1,0,2,5,12,0,2,2,5,0,0,0,0,1,0,0,0,2,0,1,0,0,0,16,1,0,False
1015,..\projects\antlr4-4.11.0\tool\src\org\antlr\v4\codegen\CodeGenerator.java,org.antlr.v4.codegen.CodeGenerator,String getVocabFileName(),"/**
 * What is the name of the vocab file generated for this grammar?
 *  Returns null if no .tokens file should be generated.
 */
public String getVocabFileName() {
    return g.name + VOCAB_FILE_EXTENSION;
}","/**
 * What is the name of the vocab file generated for this grammar?
 *  Returns null if no .tokens file should be generated.
 */
", ,/** * What is the name of the vocab file generated for this grammar? *  Returns null if no .tokens file should be generated. */,203,205,[0],0,[0],0,[0],0,0,0,0,getVocabFileName(),org.antlr.v4.codegen.CodeGenerator,getVocabFileName/0,False,203,0,1,1,0,1,0,3,1,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,31,1,0,True
1016,..\projects\antlr4-4.11.0\tool\src\org\antlr\v4\codegen\DefaultOutputModelFactory.java,org.antlr.v4.codegen.DefaultOutputModelFactory,"List<SrcOp> rulePostamble(RuleFunction, Rule)","@Override
public List<SrcOp> rulePostamble(RuleFunction function, Rule r) {
    if (r.namedActions.containsKey(""after"") || r.namedActions.containsKey(""finally"")) {
        // See OutputModelController.buildLeftRecursiveRuleFunction
        // and Parser.exitRule for other places which set stop.
        CodeGenerator gen = getGenerator();
        STGroup codegenTemplates = gen.getTemplates();
        ST setStopTokenAST = codegenTemplates.getInstanceOf(""recRuleSetStopToken"");
        Action setStopTokenAction = new Action(this, function.ruleCtx, setStopTokenAST);
        List<SrcOp> ops = new ArrayList<SrcOp>(1);
        ops.add(setStopTokenAction);
        return ops;
    }
    return super.rulePostamble(function, r);
}", ,"// See OutputModelController.buildLeftRecursiveRuleFunction
[[SEP]]// and Parser.exitRule for other places which set stop.
",// See OutputModelController.buildLeftRecursiveRuleFunction// and Parser.exitRule for other places which set stop.,56,70,[0],0,"[0, 0]",0,[0],0,0,0,0,"rulePostamble(RuleFunction, Rule)",org.antlr.v4.codegen.DefaultOutputModelFactory,"rulePostamble/2[org.antlr.v4.codegen.model.RuleFunction,org.antlr.v4.codegen.Rule]",False,57,8,3,0,3,3,6,12,2,5,2,6,1,1,0,0,0,0,3,1,5,0,1,0,0,0,20,1,0,False
1017,..\projects\antlr4-4.11.0\tool\src\org\antlr\v4\codegen\OutputModelController.java,org.antlr.v4.codegen.OutputModelController,OutputModelObject buildParserOutputModel(boolean),"/**
 * Build a file with a parser containing rule functions. Use the
 *  controller as factory in SourceGenTriggers so it triggers codegen
 *  extensions too, not just the factory functions in this factory.
 */
public OutputModelObject buildParserOutputModel(boolean header) {
    CodeGenerator gen = delegate.getGenerator();
    ParserFile file = parserFile(gen.getRecognizerFileName(header));
    setRoot(file);
    file.parser = parser(file);
    Grammar g = delegate.getGrammar();
    for (Rule r : g.rules.values()) {
        buildRuleFunction(file.parser, r);
    }
    return file;
}","/**
 * Build a file with a parser containing rule functions. Use the
 *  controller as factory in SourceGenTriggers so it triggers codegen
 *  extensions too, not just the factory functions in this factory.
 */
", ,"/** * Build a file with a parser containing rule functions. Use the *  controller as factory in SourceGenTriggers so it triggers codegen *  extensions too, not just the factory functions in this factory. */",86,98,[0],0,[0],0,[0],0,0,0,0,buildParserOutputModel(boolean),org.antlr.v4.codegen.OutputModelController,buildParserOutputModel/1[boolean],False,86,6,8,1,7,2,8,11,1,3,1,8,4,3,1,0,0,0,0,0,4,0,1,0,0,0,41,1,0,True
1018,..\projects\antlr4-4.11.0\tool\src\org\antlr\v4\codegen\OutputModelController.java,org.antlr.v4.codegen.OutputModelController,"void buildRuleFunction(Parser, Rule)","/**
 * Create RuleFunction per rule and update sempreds,actions of parser
 *  output object with stuff found in r.
 */
public void buildRuleFunction(Parser parser, Rule r) {
    RuleFunction function = rule(r);
    parser.funcs.add(function);
    pushCurrentRule(function);
    function.fillNamedActions(delegate, r);
    if (r instanceof LeftRecursiveRule) {
        buildLeftRecursiveRuleFunction((LeftRecursiveRule) r, (LeftRecursiveRuleFunction) function);
    } else {
        buildNormalRuleFunction(r, function);
    }
    Grammar g = getGrammar();
    for (ActionAST a : r.actions) {
        if (a instanceof PredAST) {
            PredAST p = (PredAST) a;
            RuleSempredFunction rsf = parser.sempredFuncs.get(r);
            if (rsf == null) {
                rsf = new RuleSempredFunction(delegate, r, function.ctxType);
                parser.sempredFuncs.put(r, rsf);
            }
            rsf.actions.put(g.sempreds.get(p), new Action(delegate, p));
        }
    }
    popCurrentRule();
}","/**
 * Create RuleFunction per rule and update sempreds,actions of parser
 *  output object with stuff found in r.
 */
", ,"/** * Create RuleFunction per rule and update sempreds,actions of parser *  output object with stuff found in r. */",157,185,[0],0,[0],0,[0],0,0,0,0,"buildRuleFunction(Parser, Rule)",org.antlr.v4.codegen.OutputModelController,"buildRuleFunction/2[org.antlr.v4.codegen.model.Parser,org.antlr.v4.codegen.Rule]",False,157,11,10,1,9,5,11,25,0,4,2,11,6,2,1,1,0,0,0,0,5,0,3,0,0,0,38,1,0,True
1019,..\projects\antlr4-4.11.0\tool\src\org\antlr\v4\codegen\OutputModelController.java,org.antlr.v4.codegen.OutputModelController,"void buildLeftRecursiveRuleFunction(LeftRecursiveRule, LeftRecursiveRuleFunction)","public void buildLeftRecursiveRuleFunction(LeftRecursiveRule r, LeftRecursiveRuleFunction function) {
    buildNormalRuleFunction(r, function);
    // now inject code to start alts
    CodeGenerator gen = delegate.getGenerator();
    STGroup codegenTemplates = gen.getTemplates();
    // pick out alt(s) for primaries
    CodeBlockForOuterMostAlt outerAlt = (CodeBlockForOuterMostAlt) function.code.get(0);
    List<CodeBlockForAlt> primaryAltsCode = new ArrayList<CodeBlockForAlt>();
    SrcOp primaryStuff = outerAlt.ops.get(0);
    if (primaryStuff instanceof Choice) {
        Choice primaryAltBlock = (Choice) primaryStuff;
        primaryAltsCode.addAll(primaryAltBlock.alts);
    } else {
        // just a single alt I guess; no block
        primaryAltsCode.add((CodeBlockForAlt) primaryStuff);
    }
    // pick out alt(s) for op alts
    StarBlock opAltStarBlock = (StarBlock) outerAlt.ops.get(1);
    CodeBlockForAlt altForOpAltBlock = opAltStarBlock.alts.get(0);
    List<CodeBlockForAlt> opAltsCode = new ArrayList<CodeBlockForAlt>();
    SrcOp opStuff = altForOpAltBlock.ops.get(0);
    if (opStuff instanceof AltBlock) {
        AltBlock opAltBlock = (AltBlock) opStuff;
        opAltsCode.addAll(opAltBlock.alts);
    } else {
        // just a single alt I guess; no block
        opAltsCode.add((CodeBlockForAlt) opStuff);
    }
    // Insert code in front of each primary alt to create specialized ctx if there was a label
    for (int i = 0; i < primaryAltsCode.size(); i++) {
        LeftRecursiveRuleAltInfo altInfo = r.recPrimaryAlts.get(i);
        if (altInfo.altLabel == null)
            continue;
        ST altActionST = codegenTemplates.getInstanceOf(""recRuleReplaceContext"");
        altActionST.add(""ctxName"", Utils.capitalize(altInfo.altLabel));
        Action altAction = new Action(delegate, function.altLabelCtxs.get(altInfo.altLabel), altActionST);
        CodeBlockForAlt alt = primaryAltsCode.get(i);
        alt.insertOp(0, altAction);
    }
    // Insert code to set ctx.stop after primary block and before op * loop
    ST setStopTokenAST = codegenTemplates.getInstanceOf(""recRuleSetStopToken"");
    Action setStopTokenAction = new Action(delegate, function.ruleCtx, setStopTokenAST);
    outerAlt.insertOp(1, setStopTokenAction);
    // Insert code to set _prevctx at start of * loop
    ST setPrevCtx = codegenTemplates.getInstanceOf(""recRuleSetPrevCtx"");
    Action setPrevCtxAction = new Action(delegate, function.ruleCtx, setPrevCtx);
    opAltStarBlock.addIterationOp(setPrevCtxAction);
    // Insert code in front of each op alt to create specialized ctx if there was an alt label
    for (int i = 0; i < opAltsCode.size(); i++) {
        ST altActionST;
        LeftRecursiveRuleAltInfo altInfo = r.recOpAlts.getElement(i);
        String templateName;
        if (altInfo.altLabel != null) {
            templateName = ""recRuleLabeledAltStartAction"";
            altActionST = codegenTemplates.getInstanceOf(templateName);
            altActionST.add(""currentAltLabel"", altInfo.altLabel);
        } else {
            templateName = ""recRuleAltStartAction"";
            altActionST = codegenTemplates.getInstanceOf(templateName);
            altActionST.add(""ctxName"", Utils.capitalize(r.name));
        }
        altActionST.add(""ruleName"", r.name);
        // add label of any lr ref we deleted
        altActionST.add(""label"", altInfo.leftRecursiveRuleRefLabel);
        if (altActionST.impl.formalArguments.containsKey(""isListLabel"")) {
            altActionST.add(""isListLabel"", altInfo.isListLabel);
        } else if (altInfo.isListLabel) {
            delegate.getGenerator().tool.errMgr.toolError(ErrorType.CODE_TEMPLATE_ARG_ISSUE, templateName, ""isListLabel"");
        }
        Action altAction = new Action(delegate, function.altLabelCtxs.get(altInfo.altLabel), altActionST);
        CodeBlockForAlt alt = opAltsCode.get(i);
        alt.insertOp(0, altAction);
    }
}", ,"// now inject code to start alts
[[SEP]]// pick out alt(s) for primaries
[[SEP]]// just a single alt I guess; no block
[[SEP]]// pick out alt(s) for op alts
[[SEP]]// just a single alt I guess; no block
[[SEP]]// Insert code in front of each primary alt to create specialized ctx if there was a label
[[SEP]]// Insert code to set ctx.stop after primary block and before op * loop
[[SEP]]// Insert code to set _prevctx at start of * loop
[[SEP]]// Insert code in front of each op alt to create specialized ctx if there was an alt label
[[SEP]]// add label of any lr ref we deleted
",// now inject code to start alts[[SEP]]// pick out alt(s) for primaries[[SEP]]// just a single alt I guess; no block[[SEP]]// pick out alt(s) for op alts[[SEP]]// just a single alt I guess; no block[[SEP]]// Insert code in front of each primary alt to create specialized ctx if there was a label[[SEP]]// Insert code to set ctx.stop after primary block and before op * loop[[SEP]]// Insert code to set _prevctx at start of * loop[[SEP]]// Insert code in front of each op alt to create specialized ctx if there was an alt label[[SEP]]// add label of any lr ref we deleted,187,270,[0],0,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]",0,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]",0,0,0,0,"buildLeftRecursiveRuleFunction(LeftRecursiveRule, LeftRecursiveRuleFunction)",org.antlr.v4.codegen.OutputModelController,"buildLeftRecursiveRuleFunction/2[org.antlr.v4.codegen.LeftRecursiveRule,org.antlr.v4.codegen.model.LeftRecursiveRuleFunction]",False,187,17,7,1,6,9,18,67,0,26,2,18,1,2,2,2,0,0,13,10,28,0,2,0,0,0,42,1,0,False
1020,..\projects\antlr4-4.11.0\tool\src\org\antlr\v4\codegen\OutputModelController.java,org.antlr.v4.codegen.OutputModelController,"void buildNormalRuleFunction(Rule, RuleFunction)","public void buildNormalRuleFunction(Rule r, RuleFunction function) {
    CodeGenerator gen = delegate.getGenerator();
    // TRIGGER factory functions for rule alts, elements
    GrammarASTAdaptor adaptor = new GrammarASTAdaptor(r.ast.token.getInputStream());
    GrammarAST blk = (GrammarAST) r.ast.getFirstChildWithType(ANTLRParser.BLOCK);
    CommonTreeNodeStream nodes = new CommonTreeNodeStream(adaptor, blk);
    walker = new SourceGenTriggers(nodes, this);
    try {
        // walk AST of rule alts/elements
        function.code = DefaultOutputModelFactory.list(walker.block(null, null));
        function.hasLookaheadBlock = walker.hasLookaheadBlock;
    } catch (org.antlr.runtime.RecognitionException e) {
        e.printStackTrace(System.err);
    }
    function.ctxType = gen.getTarget().getRuleFunctionContextStructName(function);
    function.postamble = rulePostamble(function, r);
}", ,"// TRIGGER factory functions for rule alts, elements
[[SEP]]// walk AST of rule alts/elements
","// TRIGGER factory functions for rule alts, elements[[SEP]]// walk AST of rule alts/elements",272,291,[0],0,"[0, 0]",0,"[0, 0]",0,0,0,0,"buildNormalRuleFunction(Rule, RuleFunction)",org.antlr.v4.codegen.OutputModelController,"buildNormalRuleFunction/2[org.antlr.v4.codegen.Rule,org.antlr.v4.codegen.model.RuleFunction]",False,272,11,7,2,5,2,9,16,0,4,2,9,1,1,0,0,1,0,0,0,9,0,1,0,0,0,27,1,0,False
1021,..\projects\antlr4-4.11.0\tool\src\org\antlr\v4\codegen\OutputModelController.java,org.antlr.v4.codegen.OutputModelController,"void buildLexerRuleActions(Lexer, Rule)","public void buildLexerRuleActions(Lexer lexer, final Rule r) {
    if (r.actions.isEmpty()) {
        return;
    }
    CodeGenerator gen = delegate.getGenerator();
    Grammar g = delegate.getGrammar();
    String ctxType = gen.getTarget().getRuleFunctionContextStructName(r);
    RuleActionFunction raf = lexer.actionFuncs.get(r);
    if (raf == null) {
        raf = new RuleActionFunction(delegate, r, ctxType);
    }
    for (ActionAST a : r.actions) {
        if (a instanceof PredAST) {
            PredAST p = (PredAST) a;
            RuleSempredFunction rsf = lexer.sempredFuncs.get(r);
            if (rsf == null) {
                rsf = new RuleSempredFunction(delegate, r, ctxType);
                lexer.sempredFuncs.put(r, rsf);
            }
            rsf.actions.put(g.sempreds.get(p), new Action(delegate, p));
        } else if (a.getType() == ANTLRParser.ACTION) {
            raf.actions.put(g.lexerActions.get(a), new Action(delegate, a));
        }
    }
    if (!raf.actions.isEmpty() && !lexer.actionFuncs.containsKey(r)) {
        // only add to lexer if the function actually contains actions
        lexer.actionFuncs.put(r, raf);
    }
}", ,"// only add to lexer if the function actually contains actions
",// only add to lexer if the function actually contains actions,293,325,[0],0,[0],0,[0],0,0,0,0,"buildLexerRuleActions(Lexer, Rule)",org.antlr.v4.codegen.OutputModelController,"buildLexerRuleActions/2[org.antlr.v4.codegen.model.Lexer,org.antlr.v4.codegen.Rule]",False,293,11,8,1,7,9,11,29,1,6,2,11,0,0,1,3,0,0,0,0,8,0,3,0,0,0,24,1,0,False
1022,..\projects\antlr4-4.11.0\tool\src\org\antlr\v4\codegen\OutputModelController.java,org.antlr.v4.codegen.OutputModelController,"List<SrcOp> set(GrammarAST, GrammarAST, boolean)","/**
 * (A|B|C) possibly with ebnfRoot and label
 */
public List<SrcOp> set(GrammarAST setAST, GrammarAST labelAST, boolean invert) {
    List<SrcOp> ops = delegate.set(setAST, labelAST, invert);
    for (CodeGeneratorExtension ext : extensions) {
        ops = ext.set(ops);
    }
    return ops;
}","/**
 * (A|B|C) possibly with ebnfRoot and label
 */
", ,/** * (A|B|C) possibly with ebnfRoot and label */,386,392,[0],0,[0],0,[0],0,0,0,0,"set(GrammarAST, GrammarAST, boolean)",org.antlr.v4.codegen.OutputModelController,"set/3[org.antlr.v4.codegen.GrammarAST,org.antlr.v4.codegen.GrammarAST,boolean]",False,386,4,2,0,2,2,2,7,1,1,3,2,0,0,1,0,0,0,0,0,2,0,1,0,0,0,20,1,0,True
1023,..\projects\antlr4-4.11.0\tool\src\org\antlr\v4\codegen\OutputModelWalker.java,org.antlr.v4.codegen.OutputModelWalker,"ST walk(OutputModelObject, boolean)","public ST walk(OutputModelObject omo, boolean header) {
    // CREATE TEMPLATE FOR THIS OUTPUT OBJECT
    Class<? extends OutputModelObject> cl = omo.getClass();
    String templateName = cl.getSimpleName();
    if (templateName == null) {
        tool.errMgr.toolError(ErrorType.NO_MODEL_TO_TEMPLATE_MAPPING, cl.getSimpleName());
        return new ST(""["" + templateName + "" invalid]"");
    }
    if (header)
        templateName += ""Header"";
    ST st = templates.getInstanceOf(templateName);
    if (st == null) {
        tool.errMgr.toolError(ErrorType.CODE_GEN_TEMPLATES_INCOMPLETE, templateName);
        return new ST(""["" + templateName + "" invalid]"");
    }
    if (st.impl.formalArguments == null) {
        tool.errMgr.toolError(ErrorType.CODE_TEMPLATE_ARG_ISSUE, templateName, ""<none>"");
        return st;
    }
    Map<String, FormalArgument> formalArgs = st.impl.formalArguments;
    // PASS IN OUTPUT MODEL OBJECT TO TEMPLATE AS FIRST ARG
    Set<String> argNames = formalArgs.keySet();
    Iterator<String> arg_it = argNames.iterator();
    // ordered so this is first arg
    String modelArgName = arg_it.next();
    st.add(modelArgName, omo);
    // COMPUTE STs FOR EACH NESTED MODEL OBJECT MARKED WITH @ModelElement AND MAKE ST ATTRIBUTE
    Set<String> usedFieldNames = new HashSet<String>();
    Field[] fields = cl.getFields();
    for (Field fi : fields) {
        ModelElement annotation = fi.getAnnotation(ModelElement.class);
        if (annotation == null) {
            continue;
        }
        String fieldName = fi.getName();
        if (!usedFieldNames.add(fieldName)) {
            tool.errMgr.toolError(ErrorType.INTERNAL_ERROR, ""Model object "" + omo.getClass().getSimpleName() + "" has multiple fields named '"" + fieldName + ""'"");
            continue;
        }
        // Just don't set @ModelElement fields w/o formal arg in target ST
        if (formalArgs.get(fieldName) == null)
            continue;
        try {
            Object o = fi.get(omo);
            if (o instanceof OutputModelObject) {
                // SINGLE MODEL OBJECT?
                OutputModelObject nestedOmo = (OutputModelObject) o;
                ST nestedST = walk(nestedOmo, header);
                // System.out.println(""set ModelElement ""+fieldName+""=""+nestedST+"" in ""+templateName);
                st.add(fieldName, nestedST);
            } else if (o instanceof Collection || o instanceof OutputModelObject[]) {
                // LIST OF MODEL OBJECTS?
                if (o instanceof OutputModelObject[]) {
                    o = Arrays.asList((OutputModelObject[]) o);
                }
                Collection<?> nestedOmos = (Collection<?>) o;
                for (Object nestedOmo : nestedOmos) {
                    if (nestedOmo == null)
                        continue;
                    ST nestedST = walk((OutputModelObject) nestedOmo, header);
                    // System.out.println(""set ModelElement ""+fieldName+""=""+nestedST+"" in ""+templateName);
                    st.add(fieldName, nestedST);
                }
            } else if (o instanceof Map) {
                Map<?, ?> nestedOmoMap = (Map<?, ?>) o;
                Map<Object, ST> m = new LinkedHashMap<Object, ST>();
                for (Map.Entry<?, ?> entry : nestedOmoMap.entrySet()) {
                    ST nestedST = walk((OutputModelObject) entry.getValue(), header);
                    // System.out.println(""set ModelElement ""+fieldName+""=""+nestedST+"" in ""+templateName);
                    m.put(entry.getKey(), nestedST);
                }
                st.add(fieldName, m);
            } else if (o != null) {
                tool.errMgr.toolError(ErrorType.INTERNAL_ERROR, ""not recognized nested model element: "" + fieldName);
            }
        } catch (IllegalAccessException iae) {
            tool.errMgr.toolError(ErrorType.CODE_TEMPLATE_ARG_ISSUE, templateName, fieldName);
        }
    }
    // st.impl.dump();
    return st;
}", ,"// CREATE TEMPLATE FOR THIS OUTPUT OBJECT
[[SEP]]// PASS IN OUTPUT MODEL OBJECT TO TEMPLATE AS FIRST ARG
[[SEP]]// ordered so this is first arg
[[SEP]]// COMPUTE STs FOR EACH NESTED MODEL OBJECT MARKED WITH @ModelElement AND MAKE ST ATTRIBUTE
[[SEP]]// Just don't set @ModelElement fields w/o formal arg in target ST
[[SEP]]// SINGLE MODEL OBJECT?
[[SEP]]// System.out.println(""set ModelElement ""+fieldName+""=""+nestedST+"" in ""+templateName);
[[SEP]]// LIST OF MODEL OBJECTS?
[[SEP]]// System.out.println(""set ModelElement ""+fieldName+""=""+nestedST+"" in ""+templateName);
[[SEP]]// System.out.println(""set ModelElement ""+fieldName+""=""+nestedST+"" in ""+templateName);
[[SEP]]// st.impl.dump();
","// CREATE TEMPLATE FOR THIS OUTPUT OBJECT[[SEP]]// PASS IN OUTPUT MODEL OBJECT TO TEMPLATE AS FIRST ARG[[SEP]]// ordered so this is first arg[[SEP]]// COMPUTE STs FOR EACH NESTED MODEL OBJECT MARKED WITH @ModelElement AND MAKE ST ATTRIBUTE[[SEP]]// Just don't set @ModelElement fields w/o formal arg in target ST[[SEP]]// SINGLE MODEL OBJECT?[[SEP]]// System.out.println(""set ModelElement ""+fieldName+""=""+nestedST+"" in ""+templateName);[[SEP]]// LIST OF MODEL OBJECTS?[[SEP]]// System.out.println(""set ModelElement ""+fieldName+""=""+nestedST+"" in ""+templateName);[[SEP]]// System.out.println(""set ModelElement ""+fieldName+""=""+nestedST+"" in ""+templateName);[[SEP]]// st.impl.dump();",54,143,[0],0,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]",0,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]",0,0,0,0,"walk(OutputModelObject, boolean)",org.antlr.v4.codegen.OutputModelWalker,"walk/2[org.antlr.v4.codegen.model.OutputModelObject,boolean]",False,54,5,3,2,1,19,20,72,4,19,2,20,1,0,3,7,1,0,10,0,21,4,5,0,0,0,44,1,0,False
1024,..\projects\antlr4-4.11.0\tool\src\org\antlr\v4\codegen\ParserFactory.java,org.antlr.v4.codegen.ParserFactory,"List<SrcOp> ruleRef(GrammarAST, GrammarAST, GrammarAST)","@Override
public List<SrcOp> ruleRef(GrammarAST ID, GrammarAST label, GrammarAST args) {
    InvokeRule invokeOp = new InvokeRule(this, ID, label);
    // If no manual label and action refs as token/rule not label, we need to define implicit label
    if (controller.needsImplicitLabel(ID, invokeOp))
        defineImplicitLabel(ID, invokeOp);
    AddToLabelList listLabelOp = getAddToListOpIfListLabelPresent(invokeOp, label);
    return list(invokeOp, listLabelOp);
}", ,"// If no manual label and action refs as token/rule not label, we need to define implicit label
","// If no manual label and action refs as token/rule not label, we need to define implicit label",104,111,[0],0,[0],0,[0],0,0,0,0,"ruleRef(GrammarAST, GrammarAST, GrammarAST)",org.antlr.v4.codegen.ParserFactory,"ruleRef/3[org.antlr.v4.codegen.GrammarAST,org.antlr.v4.codegen.GrammarAST,org.antlr.v4.codegen.GrammarAST]",False,105,7,5,0,5,2,4,6,1,2,3,4,2,2,0,0,0,0,0,0,2,0,1,0,0,0,21,1,0,False
1025,..\projects\antlr4-4.11.0\tool\src\org\antlr\v4\codegen\ParserFactory.java,org.antlr.v4.codegen.ParserFactory,"List<SrcOp> tokenRef(GrammarAST, GrammarAST, GrammarAST)","@Override
public List<SrcOp> tokenRef(GrammarAST ID, GrammarAST labelAST, GrammarAST args) {
    MatchToken matchOp = new MatchToken(this, (TerminalAST) ID);
    if (labelAST != null) {
        String label = labelAST.getText();
        RuleFunction rf = getCurrentRuleFunction();
        if (labelAST.parent.getType() == ANTLRParser.PLUS_ASSIGN) {
            // add Token _X and List<Token> X decls
            // adds _X
            defineImplicitLabel(ID, matchOp);
            TokenListDecl l = getTokenListLabelDecl(label);
            rf.addContextDecl(ID.getAltLabel(), l);
        } else {
            Decl d = getTokenLabelDecl(label);
            matchOp.labels.add(d);
            rf.addContextDecl(ID.getAltLabel(), d);
        }
        // Decl d = getTokenLabelDecl(label);
        // ((MatchToken)matchOp).labels.add(d);
        // getCurrentRuleFunction().addContextDecl(ID.getAltLabel(), d);
        // if ( labelAST.parent.getType() == ANTLRParser.PLUS_ASSIGN ) {
        // TokenListDecl l = getTokenListLabelDecl(label);
        // getCurrentRuleFunction().addContextDecl(ID.getAltLabel(), l);
        // }
    }
    if (controller.needsImplicitLabel(ID, matchOp))
        defineImplicitLabel(ID, matchOp);
    AddToLabelList listLabelOp = getAddToListOpIfListLabelPresent(matchOp, labelAST);
    return list(matchOp, listLabelOp);
}", ,"// Decl d = getTokenLabelDecl(label);
[[SEP]]// ((MatchToken)matchOp).labels.add(d);
[[SEP]]// getCurrentRuleFunction().addContextDecl(ID.getAltLabel(), d);
[[SEP]]// if ( labelAST.parent.getType() == ANTLRParser.PLUS_ASSIGN ) {
[[SEP]]// TokenListDecl l = getTokenListLabelDecl(label);
[[SEP]]// getCurrentRuleFunction().addContextDecl(ID.getAltLabel(), l);
[[SEP]]// }
[[SEP]]// add Token _X and List<Token> X decls
[[SEP]]// adds _X
","// add Token _X and List<Token> X decls// adds _X[[SEP]]// Decl d = getTokenLabelDecl(label);// ((MatchToken)matchOp).labels.add(d);// getCurrentRuleFunction().addContextDecl(ID.getAltLabel(), d);// if ( labelAST.parent.getType() == ANTLRParser.PLUS_ASSIGN ) {// TokenListDecl l = getTokenListLabelDecl(label);// getCurrentRuleFunction().addContextDecl(ID.getAltLabel(), l);// }",113,142,[0],0,"[0, 0, 0, 0, 0, 0, 0, 0, 0]",0,"[0, 0]",0,0,0,0,"tokenRef(GrammarAST, GrammarAST, GrammarAST)",org.antlr.v4.codegen.ParserFactory,"tokenRef/3[org.antlr.v4.codegen.GrammarAST,org.antlr.v4.codegen.GrammarAST,org.antlr.v4.codegen.GrammarAST]",False,114,11,9,0,9,4,12,20,1,6,3,12,4,2,0,2,0,0,0,0,6,0,2,0,0,0,33,1,0,False
1026,..\projects\antlr4-4.11.0\tool\src\org\antlr\v4\codegen\ParserFactory.java,org.antlr.v4.codegen.ParserFactory,"List<SrcOp> wildcard(GrammarAST, GrammarAST)","@Override
public List<SrcOp> wildcard(GrammarAST ast, GrammarAST labelAST) {
    Wildcard wild = new Wildcard(this, ast);
    // TODO: dup with tokenRef
    if (labelAST != null) {
        String label = labelAST.getText();
        Decl d = getTokenLabelDecl(label);
        wild.labels.add(d);
        getCurrentRuleFunction().addContextDecl(ast.getAltLabel(), d);
        if (labelAST.parent.getType() == ANTLRParser.PLUS_ASSIGN) {
            TokenListDecl l = getTokenListLabelDecl(label);
            getCurrentRuleFunction().addContextDecl(ast.getAltLabel(), l);
        }
    }
    if (controller.needsImplicitLabel(ast, wild))
        defineImplicitLabel(ast, wild);
    AddToLabelList listLabelOp = getAddToListOpIfListLabelPresent(wild, labelAST);
    return list(wild, listLabelOp);
}", ,"// TODO: dup with tokenRef
",// TODO: dup with tokenRef,176,193,[0],0,[1],1,[1],1,1,1,1,"wildcard(GrammarAST, GrammarAST)",org.antlr.v4.codegen.ParserFactory,"wildcard/2[org.antlr.v4.codegen.GrammarAST,org.antlr.v4.codegen.GrammarAST]",False,177,10,9,0,9,4,12,16,1,5,2,12,4,2,0,2,0,0,0,0,5,0,2,0,0,0,27,1,0,False
1027,..\projects\antlr4-4.11.0\tool\src\org\antlr\v4\codegen\ParserFactory.java,org.antlr.v4.codegen.ParserFactory,"Choice getChoiceBlock(BlockAST, List<CodeBlockForAlt>, GrammarAST)","@Override
public Choice getChoiceBlock(BlockAST blkAST, List<CodeBlockForAlt> alts, GrammarAST labelAST) {
    int decision = ((DecisionState) blkAST.atnState).decision;
    Choice c;
    if (!g.tool.force_atn && AnalysisPipeline.disjoint(g.decisionLOOK.get(decision))) {
        c = getLL1ChoiceBlock(blkAST, alts);
    } else {
        c = getComplexChoiceBlock(blkAST, alts);
    }
    if (labelAST != null) {
        // for x=(...), define x or x_list
        String label = labelAST.getText();
        Decl d = getTokenLabelDecl(label);
        c.label = d;
        getCurrentRuleFunction().addContextDecl(labelAST.getAltLabel(), d);
        if (labelAST.parent.getType() == ANTLRParser.PLUS_ASSIGN) {
            String listLabel = gen.getTarget().getListLabel(label);
            TokenListDecl l = new TokenListDecl(this, listLabel);
            getCurrentRuleFunction().addContextDecl(labelAST.getAltLabel(), l);
        }
    }
    return c;
}", ,"// for x=(...), define x or x_list
","// for x=(...), define x or x_list",195,219,[0],0,[0],0,[0],0,0,0,0,"getChoiceBlock(BlockAST, List<CodeBlockForAlt>, GrammarAST)",org.antlr.v4.codegen.ParserFactory,"getChoiceBlock/3[org.antlr.v4.codegen.BlockAST,java.util.List<org.antlr.v4.codegen.model.CodeBlockForAlt>,org.antlr.v4.codegen.GrammarAST]",False,196,13,9,0,9,5,12,22,1,6,3,12,3,1,0,2,0,1,0,0,8,0,2,0,0,0,25,1,0,False
1028,..\projects\antlr4-4.11.0\tool\src\org\antlr\v4\codegen\ParserFactory.java,org.antlr.v4.codegen.ParserFactory,"void defineImplicitLabel(GrammarAST, LabeledOp)","// support
public void defineImplicitLabel(GrammarAST ast, LabeledOp op) {
    Decl d;
    if (ast.getType() == ANTLRParser.SET || ast.getType() == ANTLRParser.WILDCARD) {
        String implLabel = gen.getTarget().getImplicitSetLabel(String.valueOf(ast.token.getTokenIndex()));
        d = getTokenLabelDecl(implLabel);
        ((TokenDecl) d).isImplicit = true;
    } else if (ast.getType() == ANTLRParser.RULE_REF) {
        // a rule reference?
        Rule r = g.getRule(ast.getText());
        String implLabel = gen.getTarget().getImplicitRuleLabel(ast.getText());
        String ctxName = gen.getTarget().getRuleFunctionContextStructName(r);
        d = new RuleContextDecl(this, implLabel, ctxName);
        ((RuleContextDecl) d).isImplicit = true;
    } else {
        String implLabel = gen.getTarget().getImplicitTokenLabel(ast.getText());
        d = getTokenLabelDecl(implLabel);
        ((TokenDecl) d).isImplicit = true;
    }
    op.getLabels().add(d);
    // all labels must be in scope struct in case we exec action out of context
    getCurrentRuleFunction().addContextDecl(ast.getAltLabel(), d);
}", ,"// a rule reference?
[[SEP]]// all labels must be in scope struct in case we exec action out of context
",// support[[SEP]]// a rule reference?[[SEP]]// all labels must be in scope struct in case we exec action out of context,309,333,[0],0,"[0, 0]",0,"[0, 0, 0]",0,0,0,0,"defineImplicitLabel(GrammarAST, LabeledOp)",org.antlr.v4.codegen.ParserFactory,"defineImplicitLabel/2[org.antlr.v4.codegen.GrammarAST,org.antlr.v4.codegen.model.LabeledOp]",False,309,11,15,5,10,4,16,22,0,6,2,16,1,1,0,3,0,3,0,0,11,0,1,0,0,0,21,1,0,False
1029,..\projects\antlr4-4.11.0\tool\src\org\antlr\v4\codegen\Target.java,org.antlr.v4.codegen.Target,"Map<Character, String> getTargetCharValueEscape()","/**
 * For pure strings of Unicode char, how can we display
 *  it in the target language as a literal. Useful for dumping
 *  predicates and such that may refer to chars that need to be escaped
 *  when represented as strings.  Also, templates need to be escaped so
 *  that the target language can hold them as a string.
 *  Each target can have a different set in memory at same time.
 */
public Map<Character, String> getTargetCharValueEscape() {
    return defaultCharValueEscape;
}","/**
 * For pure strings of Unicode char, how can we display
 *  it in the target language as a literal. Useful for dumping
 *  predicates and such that may refer to chars that need to be escaped
 *  when represented as strings.  Also, templates need to be escaped so
 *  that the target language can hold them as a string.
 *  Each target can have a different set in memory at same time.
 */
", ,"/** * For pure strings of Unicode char, how can we display *  it in the target language as a literal. Useful for dumping *  predicates and such that may refer to chars that need to be escaped *  when represented as strings.  Also, templates need to be escaped so *  that the target language can hold them as a string. *  Each target can have a different set in memory at same time. */",60,62,[0],0,[0],0,[0],0,0,0,0,getTargetCharValueEscape(),org.antlr.v4.codegen.Target,getTargetCharValueEscape/0,False,60,0,2,2,0,1,0,3,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,48,1,0,True
1030,..\projects\antlr4-4.11.0\tool\src\org\antlr\v4\codegen\Target.java,org.antlr.v4.codegen.Target,String getVersion(),"/**
 * ANTLR tool should check output templates / target are compatible with tool code generation.
 *  For now, a simple string match used on x.y of x.y.z scheme. We use a method to avoid mismatches
 *  between a template called VERSION. This value is checked against Tool.VERSION during load of templates.
 *
 *  This additional method forces all targets 4.3 and beyond to add this method.
 *
 * @since 4.3
 */
public String getVersion() {
    return Tool.VERSION;
}","/**
 * ANTLR tool should check output templates / target are compatible with tool code generation.
 *  For now, a simple string match used on x.y of x.y.z scheme. We use a method to avoid mismatches
 *  between a template called VERSION. This value is checked against Tool.VERSION during load of templates.
 *
 *  This additional method forces all targets 4.3 and beyond to add this method.
 *
 * @since 4.3
 */
", ,"/** * ANTLR tool should check output templates / target are compatible with tool code generation. *  For now, a simple string match used on x.y of x.y.z scheme. We use a method to avoid mismatches *  between a template called VERSION. This value is checked against Tool.VERSION during load of templates. * *  This additional method forces all targets 4.3 and beyond to add this method. * * @since 4.3 */",86,88,[0],0,[0],0,[0],0,0,0,0,getVersion(),org.antlr.v4.codegen.Target,getVersion/0,False,86,0,1,1,0,1,0,3,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,48,1,0,True
1031,..\projects\antlr4-4.11.0\tool\src\org\antlr\v4\codegen\Target.java,org.antlr.v4.codegen.Target,"String getTokenTypeAsTargetLabel(Grammar, int)","/**
 * Get a meaningful name for a token type useful during code generation.
 *  Literals without associated names are converted to the string equivalent
 *  of their integer values. Used to generate x==ID and x==34 type comparisons
 *  etc...  Essentially we are looking for the most obvious way to refer
 *  to a token type in the generated code.
 */
public String getTokenTypeAsTargetLabel(Grammar g, int ttype) {
    String name = g.getTokenName(ttype);
    // If name is not valid, return the token type instead
    if (Grammar.INVALID_TOKEN_NAME.equals(name)) {
        return String.valueOf(ttype);
    }
    return name;
}","/**
 * Get a meaningful name for a token type useful during code generation.
 *  Literals without associated names are converted to the string equivalent
 *  of their integer values. Used to generate x==ID and x==34 type comparisons
 *  etc...  Essentially we are looking for the most obvious way to refer
 *  to a token type in the generated code.
 */
","// If name is not valid, return the token type instead
","/** * Get a meaningful name for a token type useful during code generation. *  Literals without associated names are converted to the string equivalent *  of their integer values. Used to generate x==ID and x==34 type comparisons *  etc...  Essentially we are looking for the most obvious way to refer *  to a token type in the generated code. */[[SEP]]// If name is not valid, return the token type instead",128,136,[0],0,[0],0,"[0, 0]",0,0,0,0,"getTokenTypeAsTargetLabel(Grammar, int)",org.antlr.v4.codegen.Target,"getTokenTypeAsTargetLabel/2[org.antlr.v4.codegen.Grammar,int]",False,128,1,6,6,0,2,3,7,2,1,2,3,0,0,0,0,0,0,0,0,1,0,1,0,0,0,46,1,0,True
1032,..\projects\antlr4-4.11.0\tool\src\org\antlr\v4\codegen\Target.java,org.antlr.v4.codegen.Target,"String getTargetStringLiteralFromString(String, boolean)","/**
 * Given a random string of Java unicode chars, return a new string with
 *  optionally appropriate quote characters for target language and possibly
 *  with some escaped characters.  For example, if the incoming string has
 *  actual newline characters, the output of this method would convert them
 *  to the two char sequence \n for Java, C, C++, ...  The new string has
 *  double-quotes around it as well.  Example String in memory:
 *
 *     a""[newlinechar]b'c[carriagereturnchar]d[tab]e\f
 *
 *  would be converted to the valid Java s:
 *
 *     ""a\""\nb'c\rd\te\\f""
 *
 *  or
 *
 *     a\""\nb'c\rd\te\\f
 *
 *  depending on the quoted arg.
 */
public String getTargetStringLiteralFromString(String s, boolean quoted) {
    if (s == null) {
        return null;
    }
    StringBuilder buf = new StringBuilder();
    if (quoted) {
        buf.append('""');
    }
    for (int i = 0; i < s.length(); ) {
        int c = s.codePointAt(i);
        String escaped = c <= Character.MAX_VALUE ? getTargetCharValueEscape().get((char) c) : null;
        if (c != '\'' && escaped != null) {
            // don't escape single quotes in strings for java
            buf.append(escaped);
        } else if (shouldUseUnicodeEscapeForCodePointInDoubleQuotedString(c)) {
            appendUnicodeEscapedCodePoint(i, buf);
        } else {
            buf.appendCodePoint(c);
        }
        i += Character.charCount(c);
    }
    if (quoted) {
        buf.append('""');
    }
    return buf.toString();
}","/**
 * Given a random string of Java unicode chars, return a new string with
 *  optionally appropriate quote characters for target language and possibly
 *  with some escaped characters.  For example, if the incoming string has
 *  actual newline characters, the output of this method would convert them
 *  to the two char sequence \n for Java, C, C++, ...  The new string has
 *  double-quotes around it as well.  Example String in memory:
 *
 *     a""[newlinechar]b'c[carriagereturnchar]d[tab]e\f
 *
 *  would be converted to the valid Java s:
 *
 *     ""a\""\nb'c\rd\te\\f""
 *
 *  or
 *
 *     a\""\nb'c\rd\te\\f
 *
 *  depending on the quoted arg.
 */
","// don't escape single quotes in strings for java
","/** * Given a random string of Java unicode chars, return a new string with *  optionally appropriate quote characters for target language and possibly *  with some escaped characters.  For example, if the incoming string has *  actual newline characters, the output of this method would convert them *  to the two char sequence \n for Java, C, C++, ...  The new string has *  double-quotes around it as well.  Example String in memory: * *     a""[newlinechar]b'c[carriagereturnchar]d[tab]e\f * *  would be converted to the valid Java s: * *     ""a\""\nb'c\rd\te\\f"" * *  or * *     a\""\nb'c\rd\te\\f * *  depending on the quoted arg. */[[SEP]]// don't escape single quotes in strings for java",165,193,[0],0,[0],0,"[0, 0]",0,0,0,0,"getTargetStringLiteralFromString(String, boolean)",org.antlr.v4.codegen.Target,"getTargetStringLiteralFromString/2[java.lang.String,boolean]",False,165,1,5,2,3,9,11,27,2,4,2,11,3,2,1,3,0,0,0,1,5,0,2,0,0,0,71,1,0,True
1033,..\projects\antlr4-4.11.0\tool\src\org\antlr\v4\codegen\Target.java,org.antlr.v4.codegen.Target,"void appendUnicodeEscapedCodePoint(int, StringBuilder)","/**
 * Escape the Unicode code point appropriately for this language
 * and append the escaped value to {@code sb}.
 * It exists for flexibility and backward compatibility with external targets
 * The static method {@link UnicodeEscapes#appendEscapedCodePoint(StringBuilder, int, String)} can be used as well
 * if default escaping method (Java) is used or language is officially supported
 */
protected void appendUnicodeEscapedCodePoint(int codePoint, StringBuilder sb) {
    UnicodeEscapes.appendEscapedCodePoint(sb, codePoint, getLanguage());
}","/**
 * Escape the Unicode code point appropriately for this language
 * and append the escaped value to {@code sb}.
 * It exists for flexibility and backward compatibility with external targets
 * The static method {@link UnicodeEscapes#appendEscapedCodePoint(StringBuilder, int, String)} can be used as well
 * if default escaping method (Java) is used or language is officially supported
 */
", ,"/** * Escape the Unicode code point appropriately for this language * and append the escaped value to {@code sb}. * It exists for flexibility and backward compatibility with external targets * The static method {@link UnicodeEscapes#appendEscapedCodePoint(StringBuilder, int, String)} can be used as well * if default escaping method (Java) is used or language is officially supported */",209,211,[0],0,[0],0,[0],0,0,0,0,"appendUnicodeEscapedCodePoint(int, StringBuilder)",org.antlr.v4.codegen.Target,"appendUnicodeEscapedCodePoint/2[int,java.lang.StringBuilder]",False,209,2,4,2,2,1,2,3,0,0,2,2,1,1,0,0,0,0,0,0,0,0,0,0,0,0,37,4,0,True
1034,..\projects\antlr4-4.11.0\tool\src\org\antlr\v4\codegen\Target.java,org.antlr.v4.codegen.Target,"String getTargetStringLiteralFromANTLRStringLiteral(CodeGenerator, String, boolean, boolean)","/**
 *  <p>Convert from an ANTLR string literal found in a grammar file to an
 *  equivalent string literal in the target language.
 * </p>
 *  <p>
 *  For Java, this is the translation {@code 'a\n""'} &rarr; {@code ""a\n\""""}.
 *  Expect single quotes around the incoming literal. Just flip the quotes
 *  and replace double quotes with {@code \""}.
 *  </p>
 *  <p>
 *  Note that we have decided to allow people to use '\""' without penalty, so
 *  we must build the target string in a loop as {@link String#replace}
 *  cannot handle both {@code \""} and {@code ""} without a lot of messing
 *  around.
 *  </p>
 */
public String getTargetStringLiteralFromANTLRStringLiteral(CodeGenerator generator, String literal, boolean addQuotes, boolean escapeSpecial) {
    StringBuilder sb = new StringBuilder();
    if (addQuotes)
        sb.append('""');
    for (int i = 1; i < literal.length() - 1; ) {
        int codePoint = literal.codePointAt(i);
        int toAdvance = Character.charCount(codePoint);
        if (codePoint == '\\') {
            // Anything escaped is what it is! We assume that
            // people know how to escape characters correctly. However
            // we catch anything that does not need an escape in Java (which
            // is what the default implementation is dealing with and remove
            // the escape. The C target does this for instance.
            // 
            int escapedCodePoint = literal.codePointAt(i + toAdvance);
            toAdvance++;
            switch(escapedCodePoint) {
                // Pass through any escapes that Java also needs
                // 
                case 'n':
                case 'r':
                case 't':
                case 'b':
                case 'f':
                case '\\':
                    // Pass the escape through
                    if (escapeSpecial && escapedCodePoint != '\\') {
                        sb.append('\\');
                    }
                    sb.append('\\');
                    sb.appendCodePoint(escapedCodePoint);
                    break;
                case // Either unnnn or u{nnnnnn}
                'u':
                    if (literal.charAt(i + toAdvance) == '{') {
                        while (literal.charAt(i + toAdvance) != '}') {
                            toAdvance++;
                        }
                        toAdvance++;
                    } else {
                        toAdvance += 4;
                    }
                    if (i + toAdvance <= literal.length()) {
                        // we might have an invalid \\uAB or something
                        String fullEscape = literal.substring(i, i + toAdvance);
                        appendUnicodeEscapedCodePoint(CharSupport.getCharValueFromCharInGrammarLiteral(fullEscape), sb, escapeSpecial);
                    }
                    break;
                default:
                    if (shouldUseUnicodeEscapeForCodePointInDoubleQuotedString(escapedCodePoint)) {
                        appendUnicodeEscapedCodePoint(escapedCodePoint, sb, escapeSpecial);
                    } else {
                        sb.appendCodePoint(escapedCodePoint);
                    }
                    break;
            }
        } else {
            if (codePoint == 0x22) {
                // ANTLR doesn't escape "" in literal strings,
                // but every other language needs to do so.
                sb.append(""\\\"""");
            } else if (shouldUseUnicodeEscapeForCodePointInDoubleQuotedString(codePoint)) {
                appendUnicodeEscapedCodePoint(codePoint, sb, escapeSpecial);
            } else {
                sb.appendCodePoint(codePoint);
            }
        }
        i += toAdvance;
    }
    if (addQuotes)
        sb.append('""');
    return sb.toString();
}","/**
 *  <p>Convert from an ANTLR string literal found in a grammar file to an
 *  equivalent string literal in the target language.
 * </p>
 *  <p>
 *  For Java, this is the translation {@code 'a\n""'} &rarr; {@code ""a\n\""""}.
 *  Expect single quotes around the incoming literal. Just flip the quotes
 *  and replace double quotes with {@code \""}.
 *  </p>
 *  <p>
 *  Note that we have decided to allow people to use '\""' without penalty, so
 *  we must build the target string in a loop as {@link String#replace}
 *  cannot handle both {@code \""} and {@code ""} without a lot of messing
 *  around.
 *  </p>
 */
","// Anything escaped is what it is! We assume that
[[SEP]]// people know how to escape characters correctly. However
[[SEP]]// we catch anything that does not need an escape in Java (which
[[SEP]]// is what the default implementation is dealing with and remove
[[SEP]]// the escape. The C target does this for instance.
[[SEP]]// 
[[SEP]]// Pass through any escapes that Java also needs
[[SEP]]// 
[[SEP]]// Pass the escape through
[[SEP]]// Either unnnn or u{nnnnnn}
[[SEP]]// we might have an invalid \\uAB or something
[[SEP]]// ANTLR doesn't escape "" in literal strings,
[[SEP]]// but every other language needs to do so.
","/** *  <p>Convert from an ANTLR string literal found in a grammar file to an *  equivalent string literal in the target language. * </p> *  <p> *  For Java, this is the translation {@code 'a\n""'} &rarr; {@code ""a\n\""""}. *  Expect single quotes around the incoming literal. Just flip the quotes *  and replace double quotes with {@code \""}. *  </p> *  <p> *  Note that we have decided to allow people to use '\""' without penalty, so *  we must build the target string in a loop as {@link String#replace} *  cannot handle both {@code \""} and {@code ""} without a lot of messing *  around. *  </p> */[[SEP]]// Anything escaped is what it is! We assume that// people know how to escape characters correctly. However// we catch anything that does not need an escape in Java (which// is what the default implementation is dealing with and remove// the escape. The C target does this for instance.//[[SEP]]// Pass through any escapes that Java also needs//[[SEP]]// Pass the escape through[[SEP]]// Either unnnn or u{nnnnnn}[[SEP]]// we might have an invalid \\uAB or something[[SEP]]// ANTLR doesn't escape "" in literal strings,// but every other language needs to do so.",237,323,[0],0,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]",0,"[0, 0, 0, 0, 0, 0, 0]",0,0,0,1,"getTargetStringLiteralFromANTLRStringLiteral(CodeGenerator, String, boolean, boolean)",org.antlr.v4.codegen.Target,"getTargetStringLiteralFromANTLRStringLiteral/4[org.antlr.v4.codegen.CodeGenerator,java.lang.String,boolean,boolean]",False,242,3,6,3,3,20,12,63,1,6,4,12,2,3,2,5,0,0,1,4,8,6,5,0,0,0,82,1,0,True
1035,..\projects\antlr4-4.11.0\tool\src\org\antlr\v4\codegen\Target.java,org.antlr.v4.codegen.Target,boolean shouldUseUnicodeEscapeForCodePointInDoubleQuotedString(int),"protected boolean shouldUseUnicodeEscapeForCodePointInDoubleQuotedString(int codePoint) {
    // We don't want anyone passing 0x0A (newline) or 0x22
    // (double-quote) here because Java treats \\u000A as
    // a literal newline and \\u0022 as a literal
    // double-quote, so Unicode escaping doesn't help.
    assert codePoint != 0x0A && codePoint != 0x22;
    return // control characters up to but not including space
    codePoint < 0x20 || // backslash
    codePoint == 0x5C || // DEL and beyond (keeps source code 7-bit US-ASCII)
    codePoint >= 0x7F;
}", ,"// We don't want anyone passing 0x0A (newline) or 0x22
[[SEP]]// (double-quote) here because Java treats \\u000A as
[[SEP]]// a literal newline and \\u0022 as a literal
[[SEP]]// double-quote, so Unicode escaping doesn't help.
[[SEP]]// control characters up to but not including space
[[SEP]]// backslash
[[SEP]]// DEL and beyond (keeps source code 7-bit US-ASCII)
","// We don't want anyone passing 0x0A (newline) or 0x22// (double-quote) here because Java treats \\u000A as// a literal newline and \\u0022 as a literal// double-quote, so Unicode escaping doesn't help.[[SEP]]// control characters up to but not including space[[SEP]]// backslash[[SEP]]// DEL and beyond (keeps source code 7-bit US-ASCII)",325,336,[0],0,"[0, 0, 0, 0, 0, 0, 0]",0,"[0, 0, 0, 0]",0,0,0,0,shouldUseUnicodeEscapeForCodePointInDoubleQuotedString(int),org.antlr.v4.codegen.Target,shouldUseUnicodeEscapeForCodePointInDoubleQuotedString/1[int],False,325,0,2,2,0,6,0,4,1,0,1,0,0,0,0,3,0,0,0,5,0,0,0,0,0,0,21,4,0,False
1036,..\projects\antlr4-4.11.0\tool\src\org\antlr\v4\codegen\Target.java,org.antlr.v4.codegen.Target,String encodeInt16AsCharEscape(int),"/**
 * Assume 16-bit char
 */
public String encodeInt16AsCharEscape(int v) {
    if (v < Character.MIN_VALUE || v > Character.MAX_VALUE) {
        throw new IllegalArgumentException(String.format(""Cannot encode the specified value: %d"", v));
    }
    if (isATNSerializedAsInts()) {
        return Integer.toString(v);
    }
    char c = (char) v;
    String escaped = getTargetCharValueEscape().get(c);
    if (escaped != null) {
        return escaped;
    }
    switch(Character.getType(c)) {
        case Character.CONTROL:
        case Character.LINE_SEPARATOR:
        case Character.PARAGRAPH_SEPARATOR:
            return escapeChar(v);
        default:
            if (v <= 127) {
                // ascii chars can be as-is, no encoding
                return String.valueOf(c);
            }
            // else we use hex encoding to ensure pure ascii chars generated
            return escapeChar(v);
    }
}","/**
 * Assume 16-bit char
 */
","// ascii chars can be as-is, no encoding
[[SEP]]// else we use hex encoding to ensure pure ascii chars generated
","/** * Assume 16-bit char */[[SEP]]// ascii chars can be as-is, no encoding[[SEP]]// else we use hex encoding to ensure pure ascii chars generated",339,366,[0],0,"[0, 0]",0,"[0, 0, 0]",0,0,0,0,encodeInt16AsCharEscape(int),org.antlr.v4.codegen.Target,encodeInt16AsCharEscape/1[int],False,339,1,4,1,3,9,8,24,5,2,1,8,3,1,0,1,0,0,1,1,2,0,2,0,0,0,26,1,0,True
1037,..\projects\antlr4-4.11.0\tool\src\org\antlr\v4\codegen\Target.java,org.antlr.v4.codegen.Target,String getRuleFunctionContextStructName(RuleFunction),"/**
 * If we know which actual function, we can provide the actual ctx type.
 *  This will contain implicit labels etc...  From outside, though, we
 *  see only ParserRuleContext unless there are externally visible stuff
 *  like args, locals, explicit labels, etc...
 */
public String getRuleFunctionContextStructName(RuleFunction function) {
    Rule r = function.rule;
    if (r.g.isLexer()) {
        return getTemplates().getInstanceOf(""LexerRuleContext"").render();
    }
    return Utils.capitalize(r.name) + getTemplates().getInstanceOf(""RuleContextNameSuffix"").render();
}","/**
 * If we know which actual function, we can provide the actual ctx type.
 *  This will contain implicit labels etc...  From outside, though, we
 *  see only ParserRuleContext unless there are externally visible stuff
 *  like args, locals, explicit labels, etc...
 */
", ,"/** * If we know which actual function, we can provide the actual ctx type. *  This will contain implicit labels etc...  From outside, though, we *  see only ParserRuleContext unless there are externally visible stuff *  like args, locals, explicit labels, etc... */",402,408,[0],0,[0],0,[0],0,0,0,0,getRuleFunctionContextStructName(RuleFunction),org.antlr.v4.codegen.Target,getRuleFunctionContextStructName/1[org.antlr.v4.codegen.model.RuleFunction],False,402,3,2,1,1,2,5,7,2,1,1,5,1,4,0,0,0,0,2,0,1,1,1,0,0,0,35,1,0,True
1038,..\projects\antlr4-4.11.0\tool\src\org\antlr\v4\codegen\Target.java,org.antlr.v4.codegen.Target,String getImplicitTokenLabel(String),"// should be same for all refs to same token like ctx.ID within single rule function
// for literals like 'while', we gen _s<ttype>
public String getImplicitTokenLabel(String tokenName) {
    ST st = getTemplates().getInstanceOf(""ImplicitTokenLabel"");
    int ttype = getCodeGenerator().g.getTokenType(tokenName);
    if (tokenName.startsWith(""'"")) {
        return ""s"" + ttype;
    }
    String text = getTokenTypeAsTargetLabel(getCodeGenerator().g, ttype);
    st.add(""tokenName"", text);
    return st.render();
}","// for literals like 'while', we gen _s<ttype>
", ,"// should be same for all refs to same token like ctx.ID within single rule function// for literals like 'while', we gen _s<ttype>",412,421,[0],0,[0],0,[0],0,0,1,0,getImplicitTokenLabel(String),org.antlr.v4.codegen.Target,getImplicitTokenLabel/1[java.lang.String],False,412,2,5,2,3,2,8,10,2,3,1,8,3,4,0,0,0,0,4,0,3,1,1,0,0,0,17,1,0,False
1039,..\projects\antlr4-4.11.0\tool\src\org\antlr\v4\codegen\Target.java,org.antlr.v4.codegen.Target,String getImplicitSetLabel(String),"// x=(A|B)
public String getImplicitSetLabel(String id) {
    ST st = getTemplates().getInstanceOf(""ImplicitSetLabel"");
    st.add(""id"", id);
    return st.render();
}","// x=(A|B)
", ,// x=(A|B),424,428,[0],0,[0],0,[0],0,0,0,0,getImplicitSetLabel(String),org.antlr.v4.codegen.Target,getImplicitSetLabel/1[java.lang.String],False,424,2,2,1,1,1,4,5,1,1,1,4,1,4,0,0,0,0,2,0,1,0,0,0,0,0,9,1,0,False
1040,..\projects\antlr4-4.11.0\tool\src\org\antlr\v4\codegen\Target.java,org.antlr.v4.codegen.Target,String getRecognizerFileName(boolean),"/**
 * Generate TParser.java and TLexer.java from T.g4 if combined, else
 *  just use T.java as output regardless of type.
 */
public String getRecognizerFileName(boolean header) {
    ST extST = getTemplates().getInstanceOf(""codeFileExtension"");
    String recognizerName = gen.g.getRecognizerName();
    return recognizerName + extST.render();
}","/**
 * Generate TParser.java and TLexer.java from T.g4 if combined, else
 *  just use T.java as output regardless of type.
 */
", ,"/** * Generate TParser.java and TLexer.java from T.g4 if combined, else *  just use T.java as output regardless of type. */",456,460,[0],0,[0],0,[0],0,0,0,0,getRecognizerFileName(boolean),org.antlr.v4.codegen.Target,getRecognizerFileName/1[boolean],False,456,2,2,1,1,1,4,5,1,2,1,4,1,4,0,0,0,0,1,0,2,1,0,0,0,0,19,1,0,True
1041,..\projects\antlr4-4.11.0\tool\src\org\antlr\v4\codegen\Target.java,org.antlr.v4.codegen.Target,String getListenerFileName(boolean),"/**
 * A given grammar T, return the listener name such as
 *  TListener.java, if we're using the Java target.
 */
public String getListenerFileName(boolean header) {
    assert gen.g.name != null;
    ST extST = getTemplates().getInstanceOf(""codeFileExtension"");
    String listenerName = gen.g.name + ""Listener"";
    return listenerName + extST.render();
}","/**
 * A given grammar T, return the listener name such as
 *  TListener.java, if we're using the Java target.
 */
", ,"/** * A given grammar T, return the listener name such as *  TListener.java, if we're using the Java target. */",465,470,[0],0,[0],0,[0],0,0,0,0,getListenerFileName(boolean),org.antlr.v4.codegen.Target,getListenerFileName/1[boolean],False,465,2,2,1,1,2,3,6,1,2,1,3,1,4,0,1,0,0,2,0,2,2,0,0,0,0,21,1,0,True
1042,..\projects\antlr4-4.11.0\tool\src\org\antlr\v4\codegen\Target.java,org.antlr.v4.codegen.Target,String getVisitorFileName(boolean),"/**
 * A given grammar T, return the visitor name such as
 *  TVisitor.java, if we're using the Java target.
 */
public String getVisitorFileName(boolean header) {
    assert gen.g.name != null;
    ST extST = getTemplates().getInstanceOf(""codeFileExtension"");
    String listenerName = gen.g.name + ""Visitor"";
    return listenerName + extST.render();
}","/**
 * A given grammar T, return the visitor name such as
 *  TVisitor.java, if we're using the Java target.
 */
", ,"/** * A given grammar T, return the visitor name such as *  TVisitor.java, if we're using the Java target. */",475,480,[0],0,[0],0,[0],0,0,0,0,getVisitorFileName(boolean),org.antlr.v4.codegen.Target,getVisitorFileName/1[boolean],False,475,2,2,1,1,2,3,6,1,2,1,3,1,4,0,1,0,0,2,0,2,2,0,0,0,0,22,1,0,True
1043,..\projects\antlr4-4.11.0\tool\src\org\antlr\v4\codegen\Target.java,org.antlr.v4.codegen.Target,String getBaseListenerFileName(boolean),"/**
 * A given grammar T, return a blank listener implementation
 *  such as TBaseListener.java, if we're using the Java target.
 */
public String getBaseListenerFileName(boolean header) {
    assert gen.g.name != null;
    ST extST = getTemplates().getInstanceOf(""codeFileExtension"");
    String listenerName = gen.g.name + ""BaseListener"";
    return listenerName + extST.render();
}","/**
 * A given grammar T, return a blank listener implementation
 *  such as TBaseListener.java, if we're using the Java target.
 */
", ,"/** * A given grammar T, return a blank listener implementation *  such as TBaseListener.java, if we're using the Java target. */",485,490,[0],0,[0],0,[0],0,0,0,0,getBaseListenerFileName(boolean),org.antlr.v4.codegen.Target,getBaseListenerFileName/1[boolean],False,485,2,2,1,1,2,3,6,1,2,1,3,1,4,0,1,0,0,2,0,2,2,0,0,0,0,24,1,0,True
1044,..\projects\antlr4-4.11.0\tool\src\org\antlr\v4\codegen\Target.java,org.antlr.v4.codegen.Target,String getBaseVisitorFileName(boolean),"/**
 * A given grammar T, return a blank listener implementation
 *  such as TBaseListener.java, if we're using the Java target.
 */
public String getBaseVisitorFileName(boolean header) {
    assert gen.g.name != null;
    ST extST = getTemplates().getInstanceOf(""codeFileExtension"");
    String listenerName = gen.g.name + ""BaseVisitor"";
    return listenerName + extST.render();
}","/**
 * A given grammar T, return a blank listener implementation
 *  such as TBaseListener.java, if we're using the Java target.
 */
", ,"/** * A given grammar T, return a blank listener implementation *  such as TBaseListener.java, if we're using the Java target. */",495,500,[0],0,[0],0,[0],0,0,0,0,getBaseVisitorFileName(boolean),org.antlr.v4.codegen.Target,getBaseVisitorFileName/1[boolean],False,495,2,2,1,1,2,3,6,1,2,1,3,1,4,0,1,0,0,2,0,2,2,0,0,0,0,24,1,0,True
1045,..\projects\antlr4-4.11.0\tool\src\org\antlr\v4\codegen\Target.java,org.antlr.v4.codegen.Target,int getSerializedATNSegmentLimit(),"/**
 * Gets the maximum number of 16-bit unsigned integers that can be encoded
 * in a single segment (a declaration in target language) of the serialized ATN.
 * E.g., in C++, a small segment length results in multiple decls like:
 *
 *   static const int32_t serializedATNSegment1[] = {
 *     0x7, 0x12, 0x2, 0x13, 0x7, 0x13, 0x2, 0x14, 0x7, 0x14, 0x2, 0x15, 0x7,
 *        0x15, 0x2, 0x16, 0x7, 0x16, 0x2, 0x17, 0x7, 0x17, 0x2, 0x18, 0x7,
 *        0x18, 0x2, 0x19, 0x7, 0x19, 0x2, 0x1a, 0x7, 0x1a, 0x2, 0x1b, 0x7,
 *        0x1b, 0x2, 0x1c, 0x7, 0x1c, 0x2, 0x1d, 0x7, 0x1d, 0x2, 0x1e, 0x7,
 *        0x1e, 0x2, 0x1f, 0x7, 0x1f, 0x2, 0x20, 0x7, 0x20, 0x2, 0x21, 0x7,
 *        0x21, 0x2, 0x22, 0x7, 0x22, 0x2, 0x23, 0x7, 0x23, 0x2, 0x24, 0x7,
 *        0x24, 0x2, 0x25, 0x7, 0x25, 0x2, 0x26,
 *   };
 *
 * instead of one big one.  Targets are free to ignore this like JavaScript does.
 *
 * This is primarily needed by Java target to limit size of any single ATN string
 * to 65k length.
 *
 * @see SerializedATN#getSegments
 *
 * @return the serialized ATN segment limit
 */
public int getSerializedATNSegmentLimit() {
    return Integer.MAX_VALUE;
}","/**
 * Gets the maximum number of 16-bit unsigned integers that can be encoded
 * in a single segment (a declaration in target language) of the serialized ATN.
 * E.g., in C++, a small segment length results in multiple decls like:
 *
 *   static const int32_t serializedATNSegment1[] = {
 *     0x7, 0x12, 0x2, 0x13, 0x7, 0x13, 0x2, 0x14, 0x7, 0x14, 0x2, 0x15, 0x7,
 *        0x15, 0x2, 0x16, 0x7, 0x16, 0x2, 0x17, 0x7, 0x17, 0x2, 0x18, 0x7,
 *        0x18, 0x2, 0x19, 0x7, 0x19, 0x2, 0x1a, 0x7, 0x1a, 0x2, 0x1b, 0x7,
 *        0x1b, 0x2, 0x1c, 0x7, 0x1c, 0x2, 0x1d, 0x7, 0x1d, 0x2, 0x1e, 0x7,
 *        0x1e, 0x2, 0x1f, 0x7, 0x1f, 0x2, 0x20, 0x7, 0x20, 0x2, 0x21, 0x7,
 *        0x21, 0x2, 0x22, 0x7, 0x22, 0x2, 0x23, 0x7, 0x23, 0x2, 0x24, 0x7,
 *        0x24, 0x2, 0x25, 0x7, 0x25, 0x2, 0x26,
 *   };
 *
 * instead of one big one.  Targets are free to ignore this like JavaScript does.
 *
 * This is primarily needed by Java target to limit size of any single ATN string
 * to 65k length.
 *
 * @see SerializedATN#getSegments
 *
 * @return the serialized ATN segment limit
 */
", ,"/** * Gets the maximum number of 16-bit unsigned integers that can be encoded * in a single segment (a declaration in target language) of the serialized ATN. * E.g., in C++, a small segment length results in multiple decls like: * *   static const int32_t serializedATNSegment1[] = { *     0x7, 0x12, 0x2, 0x13, 0x7, 0x13, 0x2, 0x14, 0x7, 0x14, 0x2, 0x15, 0x7, *        0x15, 0x2, 0x16, 0x7, 0x16, 0x2, 0x17, 0x7, 0x17, 0x2, 0x18, 0x7, *        0x18, 0x2, 0x19, 0x7, 0x19, 0x2, 0x1a, 0x7, 0x1a, 0x2, 0x1b, 0x7, *        0x1b, 0x2, 0x1c, 0x7, 0x1c, 0x2, 0x1d, 0x7, 0x1d, 0x2, 0x1e, 0x7, *        0x1e, 0x2, 0x1f, 0x7, 0x1f, 0x2, 0x20, 0x7, 0x20, 0x2, 0x21, 0x7, *        0x21, 0x2, 0x22, 0x7, 0x22, 0x2, 0x23, 0x7, 0x23, 0x2, 0x24, 0x7, *        0x24, 0x2, 0x25, 0x7, 0x25, 0x2, 0x26, *   }; * * instead of one big one.  Targets are free to ignore this like JavaScript does. * * This is primarily needed by Java target to limit size of any single ATN string * to 65k length. * * @see SerializedATN#getSegments * * @return the serialized ATN segment limit */",526,528,[0],0,[0],0,[0],0,0,0,0,getSerializedATNSegmentLimit(),org.antlr.v4.codegen.Target,getSerializedATNSegmentLimit/0,False,526,0,1,1,0,1,0,3,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,57,1,0,True
1046,..\projects\antlr4-4.11.0\tool\src\org\antlr\v4\codegen\Target.java,org.antlr.v4.codegen.Target,int getInlineTestSetWordSize(),"/**
 * How many bits should be used to do inline token type tests? Java assumes
 *  a 64-bit word for bitsets.  Must be a valid wordsize for your target like
 *  8, 16, 32, 64, etc...
 *
 *  @since 4.5
 */
public int getInlineTestSetWordSize() {
    return 64;
}","/**
 * How many bits should be used to do inline token type tests? Java assumes
 *  a 64-bit word for bitsets.  Must be a valid wordsize for your target like
 *  8, 16, 32, 64, etc...
 *
 *  @since 4.5
 */
", ,"/** * How many bits should be used to do inline token type tests? Java assumes *  a 64-bit word for bitsets.  Must be a valid wordsize for your target like *  8, 16, 32, 64, etc... * *  @since 4.5 */",536,536,[0],0,[0],0,[0],0,0,1,0,getInlineTestSetWordSize(),org.antlr.v4.codegen.Target,getInlineTestSetWordSize/0,False,536,0,2,2,0,1,0,3,1,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,27,1,0,True
1047,..\projects\antlr4-4.11.0\tool\src\org\antlr\v4\codegen\Target.java,org.antlr.v4.codegen.Target,boolean grammarSymbolCausesIssueInGeneratedCode(GrammarAST),"public boolean grammarSymbolCausesIssueInGeneratedCode(GrammarAST idNode) {
    switch(idNode.getParent().getType()) {
        case ANTLRParser.ASSIGN:
            switch(idNode.getParent().getParent().getType()) {
                case ANTLRParser.ELEMENT_OPTIONS:
                case ANTLRParser.OPTIONS:
                    return false;
                default:
                    break;
            }
            break;
        case ANTLRParser.AT:
        case ANTLRParser.ELEMENT_OPTIONS:
            return false;
        case ANTLRParser.LEXER_ACTION_CALL:
            if (idNode.getChildIndex() == 0) {
                // first child is the command name which is part of the ANTLR language
                return false;
            }
            // arguments to the command should be checked
            break;
        default:
            break;
    }
    return getReservedWords().contains(idNode.getText());
}", ,"// first child is the command name which is part of the ANTLR language
[[SEP]]// arguments to the command should be checked
",// first child is the command name which is part of the ANTLR language[[SEP]]// arguments to the command should be checked,538,570,[0],0,"[0, 0]",0,"[0, 0]",0,0,0,0,grammarSymbolCausesIssueInGeneratedCode(GrammarAST),org.antlr.v4.codegen.Target,grammarSymbolCausesIssueInGeneratedCode/1[org.antlr.v4.codegen.GrammarAST],False,538,2,1,0,1,8,6,24,4,0,1,6,1,1,0,1,0,0,0,1,0,0,2,0,0,0,17,1,0,False
1048,..\projects\antlr4-4.11.0\tool\src\org\antlr\v4\codegen\Target.java,org.antlr.v4.codegen.Target,boolean wantsBaseListener(),"/**
 * @since 4.3
 */
public boolean wantsBaseListener() {
    return true;
}","/**
 * @since 4.3
 */
", ,/** * @since 4.3 */,634,636,[0],0,[0],0,[0],0,0,0,0,wantsBaseListener(),org.antlr.v4.codegen.Target,wantsBaseListener/0,False,634,0,1,1,0,1,0,3,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,4,1,0,True
1049,..\projects\antlr4-4.11.0\tool\src\org\antlr\v4\codegen\Target.java,org.antlr.v4.codegen.Target,boolean wantsBaseVisitor(),"/**
 * @since 4.3
 */
public boolean wantsBaseVisitor() {
    return true;
}","/**
 * @since 4.3
 */
", ,/** * @since 4.3 */,641,643,[0],0,[0],0,[0],0,0,0,0,wantsBaseVisitor(),org.antlr.v4.codegen.Target,wantsBaseVisitor/0,False,641,0,1,1,0,1,0,3,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,4,1,0,True
1050,..\projects\antlr4-4.11.0\tool\src\org\antlr\v4\codegen\Target.java,org.antlr.v4.codegen.Target,boolean supportsOverloadedMethods(),"/**
 * @since 4.3
 */
public boolean supportsOverloadedMethods() {
    return true;
}","/**
 * @since 4.3
 */
", ,/** * @since 4.3 */,648,650,[0],0,[0],0,[0],0,0,0,0,supportsOverloadedMethods(),org.antlr.v4.codegen.Target,supportsOverloadedMethods/0,False,648,0,1,1,0,1,0,3,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,4,1,0,True
1051,..\projects\antlr4-4.11.0\tool\src\org\antlr\v4\codegen\Target.java,org.antlr.v4.codegen.Target,boolean needsHeader(),"/**
 * @since 4.6
 */
// Override in targets that need header files.
public boolean needsHeader() {
    return false;
}","// Override in targets that need header files.
", ,/** * @since 4.6 */[[SEP]]// Override in targets that need header files.,657,657,[0],0,[0],0,"[0, 0]",0,0,0,0,needsHeader(),org.antlr.v4.codegen.Target,needsHeader/0,False,657,0,1,1,0,1,0,3,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,3,1,0,True
1052,..\projects\antlr4-4.11.0\tool\src\org\antlr\v4\codegen\UnicodeEscapes.java,org.antlr.v4.codegen.UnicodeEscapes,"void appendEscapedCodePoint(StringBuilder, int, String)","public static void appendEscapedCodePoint(StringBuilder sb, int codePoint, String language) {
    switch(language) {
        case ""CSharp"":
        case ""Python2"":
        case ""Python3"":
        case ""Cpp"":
        case ""Go"":
        case ""PHP"":
            String format = Character.isSupplementaryCodePoint(codePoint) ? ""\\U%08X"" : ""\\u%04X"";
            sb.append(String.format(format, codePoint));
            break;
        case ""Swift"":
            sb.append(String.format(""\\u{%04X}"", codePoint));
            break;
        case ""Java"":
        case ""JavaScript"":
        case ""Dart"":
        default:
            if (Character.isSupplementaryCodePoint(codePoint)) {
                // char is not an 'integral' type, so we have to explicitly convert
                // to int before passing to the %X formatter or else it throws.
                sb.append(String.format(""\\u%04X"", (int) Character.highSurrogate(codePoint)));
                sb.append(String.format(""\\u%04X"", (int) Character.lowSurrogate(codePoint)));
            } else {
                sb.append(String.format(""\\u%04X"", codePoint));
            }
            break;
    }
}", ,"// char is not an 'integral' type, so we have to explicitly convert
[[SEP]]// to int before passing to the %X formatter or else it throws.
","// char is not an 'integral' type, so we have to explicitly convert// to int before passing to the %X formatter or else it throws.",20,49,[0],0,"[0, 0]",0,[0],0,0,0,0,"appendEscapedCodePoint(StringBuilder, int, String)",org.antlr.v4.codegen.UnicodeEscapes,"appendEscapedCodePoint/3[java.lang.StringBuilder,int,java.lang.String]",False,20,0,2,2,0,13,5,28,0,1,3,5,0,0,0,0,0,0,16,0,1,0,2,0,0,0,9,9,0,False
1053,..\projects\antlr4-4.11.0\tool\src\org\antlr\v4\codegen\model\ElementFrequenciesVisitor.java,org.antlr.v4.codegen.model.ElementFrequenciesVisitor,ErrorManager getErrorManager(),"/**
 * During code gen, we can assume tree is in good shape
 */
@Override
public ErrorManager getErrorManager() {
    return super.getErrorManager();
}","/**
 * During code gen, we can assume tree is in good shape
 */
", ,"/** * During code gen, we can assume tree is in good shape */",51,52,[0],0,[0],0,[0],0,0,0,0,getErrorManager(),org.antlr.v4.codegen.model.ElementFrequenciesVisitor,getErrorManager/0,False,52,1,0,0,0,1,1,3,1,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,13,1,0,True
1054,..\projects\antlr4-4.11.0\tool\src\org\antlr\v4\codegen\model\ElementFrequenciesVisitor.java,org.antlr.v4.codegen.model.ElementFrequenciesVisitor,"FrequencySet<String> combineMax(FrequencySet<String>, FrequencySet<String>)","/*
	 * Common
	 */
/**
 * Generate a frequency set as the union of two input sets. If an
 * element is contained in both sets, the value for the output will be
 * the maximum of the two input values.
 *
 * @param a The first set.
 * @param b The second set.
 * @return The union of the two sets, with the maximum value chosen
 * whenever both sets contain the same key.
 */
protected static FrequencySet<String> combineMax(FrequencySet<String> a, FrequencySet<String> b) {
    FrequencySet<String> result = combineAndClip(a, b, 1);
    for (Map.Entry<String, MutableInt> entry : a.entrySet()) {
        result.get(entry.getKey()).v = entry.getValue().v;
    }
    for (Map.Entry<String, MutableInt> entry : b.entrySet()) {
        MutableInt slot = result.get(entry.getKey());
        slot.v = Math.max(slot.v, entry.getValue().v);
    }
    return result;
}","/**
 * Generate a frequency set as the union of two input sets. If an
 * element is contained in both sets, the value for the output will be
 * the maximum of the two input values.
 *
 * @param a The first set.
 * @param b The second set.
 * @return The union of the two sets, with the maximum value chosen
 * whenever both sets contain the same key.
 */
", ,"/*	 * Common	 */[[SEP]]/** * Generate a frequency set as the union of two input sets. If an * element is contained in both sets, the value for the output will be * the maximum of the two input values. * * @param a The first set. * @param b The second set. * @return The union of the two sets, with the maximum value chosen * whenever both sets contain the same key. */",68,80,[0],0,[0],0,"[0, 0]",0,0,0,0,"combineMax(FrequencySet<String>, FrequencySet<String>)",org.antlr.v4.codegen.model.ElementFrequenciesVisitor,"combineMax/2[org.antlr.v4.misc.FrequencySet<java.lang.String>,org.antlr.v4.misc.FrequencySet<java.lang.String>]",False,68,3,3,2,1,3,6,11,1,2,2,6,1,1,2,0,0,0,0,1,4,0,1,0,0,0,40,12,0,True
1055,..\projects\antlr4-4.11.0\tool\src\org\antlr\v4\codegen\model\ElementFrequenciesVisitor.java,org.antlr.v4.codegen.model.ElementFrequenciesVisitor,"FrequencySet<String> combineMin(FrequencySet<String>, FrequencySet<String>)","/**
 * Generate a frequency set as the union of two input sets. If an
 * element is contained in both sets, the value for the output will be
 * the minimum of the two input values.
 *
 * @param a The first set.
 * @param b The second set. If this set is {@link #SENTINEL}, it is treated
 * as though no second set were provided.
 * @return The union of the two sets, with the minimum value chosen
 * whenever both sets contain the same key.
 */
protected static FrequencySet<String> combineMin(FrequencySet<String> a, FrequencySet<String> b) {
    if (b == SENTINEL) {
        return a;
    }
    assert a != SENTINEL;
    FrequencySet<String> result = combineAndClip(a, b, Integer.MAX_VALUE);
    for (Map.Entry<String, MutableInt> entry : result.entrySet()) {
        entry.getValue().v = Math.min(a.count(entry.getKey()), b.count(entry.getKey()));
    }
    return result;
}","/**
 * Generate a frequency set as the union of two input sets. If an
 * element is contained in both sets, the value for the output will be
 * the minimum of the two input values.
 *
 * @param a The first set.
 * @param b The second set. If this set is {@link #SENTINEL}, it is treated
 * as though no second set were provided.
 * @return The union of the two sets, with the minimum value chosen
 * whenever both sets contain the same key.
 */
", ,"/** * Generate a frequency set as the union of two input sets. If an * element is contained in both sets, the value for the output will be * the minimum of the two input values. * * @param a The first set. * @param b The second set. If this set is {@link #SENTINEL}, it is treated * as though no second set were provided. * @return The union of the two sets, with the minimum value chosen * whenever both sets contain the same key. */",93,105,[0],0,[0],0,[0],0,0,0,0,"combineMin(FrequencySet<String>, FrequencySet<String>)",org.antlr.v4.codegen.model.ElementFrequenciesVisitor,"combineMin/2[org.antlr.v4.misc.FrequencySet<java.lang.String>,org.antlr.v4.misc.FrequencySet<java.lang.String>]",False,93,3,4,2,2,4,6,11,2,1,2,6,1,1,1,2,0,0,0,0,2,0,1,0,0,0,49,12,0,True
1056,..\projects\antlr4-4.11.0\tool\src\org\antlr\v4\codegen\model\ElementFrequenciesVisitor.java,org.antlr.v4.codegen.model.ElementFrequenciesVisitor,"FrequencySet<String> combineAndClip(FrequencySet<String>, FrequencySet<String>, int)","/**
 * Generate a frequency set as the union of two input sets, with the
 * values clipped to a specified maximum value. If an element is
 * contained in both sets, the value for the output, prior to clipping,
 * will be the sum of the two input values.
 *
 * @param a The first set.
 * @param b The second set.
 * @param clip The maximum value to allow for any output.
 * @return The sum of the two sets, with the individual elements clipped
 * to the maximum value given by {@code clip}.
 */
protected static FrequencySet<String> combineAndClip(FrequencySet<String> a, FrequencySet<String> b, int clip) {
    FrequencySet<String> result = new FrequencySet<String>();
    for (Map.Entry<String, MutableInt> entry : a.entrySet()) {
        for (int i = 0; i < entry.getValue().v; i++) {
            result.add(entry.getKey());
        }
    }
    for (Map.Entry<String, MutableInt> entry : b.entrySet()) {
        for (int i = 0; i < entry.getValue().v; i++) {
            result.add(entry.getKey());
        }
    }
    for (Map.Entry<String, MutableInt> entry : result.entrySet()) {
        entry.getValue().v = Math.min(entry.getValue().v, clip);
    }
    return result;
}","/**
 * Generate a frequency set as the union of two input sets, with the
 * values clipped to a specified maximum value. If an element is
 * contained in both sets, the value for the output, prior to clipping,
 * will be the sum of the two input values.
 *
 * @param a The first set.
 * @param b The second set.
 * @param clip The maximum value to allow for any output.
 * @return The sum of the two sets, with the individual elements clipped
 * to the maximum value given by {@code clip}.
 */
", ,"/** * Generate a frequency set as the union of two input sets, with the * values clipped to a specified maximum value. If an element is * contained in both sets, the value for the output, prior to clipping, * will be the sum of the two input values. * * @param a The first set. * @param b The second set. * @param clip The maximum value to allow for any output. * @return The sum of the two sets, with the individual elements clipped * to the maximum value given by {@code clip}. */",119,138,[0],0,[0],0,[0],0,0,0,0,"combineAndClip(FrequencySet<String>, FrequencySet<String>, int)",org.antlr.v4.codegen.model.ElementFrequenciesVisitor,"combineAndClip/3[org.antlr.v4.misc.FrequencySet<java.lang.String>,org.antlr.v4.misc.FrequencySet<java.lang.String>,int]",False,119,2,7,5,2,6,5,17,1,3,3,5,0,0,5,0,0,0,0,2,4,0,2,0,0,0,46,12,0,True
1057,..\projects\antlr4-4.11.0\tool\src\org\antlr\v4\codegen\model\ElementFrequenciesVisitor.java,org.antlr.v4.codegen.model.ElementFrequenciesVisitor,void exitBlockSet(GrammarAST),"@Override
protected void exitBlockSet(GrammarAST tree) {
    for (Map.Entry<String, MutableInt> entry : frequencies.peek().entrySet()) {
        // This visitor counts a block set as a sequence of elements, not a
        // sequence of alternatives of elements. Reset the count back to 1
        // for all items when leaving the set to ensure duplicate entries in
        // the set are treated as a maximum of one item.
        entry.getValue().v = 1;
    }
    if (minFrequencies.peek().size() > 1) {
        // Everything is optional
        minFrequencies.peek().clear();
    }
    frequencies.push(combineAndClip(frequencies.pop(), frequencies.pop(), 2));
    minFrequencies.push(combineAndClip(minFrequencies.pop(), minFrequencies.pop(), 2));
}", ,"// This visitor counts a block set as a sequence of elements, not a
[[SEP]]// sequence of alternatives of elements. Reset the count back to 1
[[SEP]]// for all items when leaving the set to ensure duplicate entries in
[[SEP]]// the set are treated as a maximum of one item.
[[SEP]]// Everything is optional
","// This visitor counts a block set as a sequence of elements, not a// sequence of alternatives of elements. Reset the count back to 1// for all items when leaving the set to ensure duplicate entries in// the set are treated as a maximum of one item.[[SEP]]// Everything is optional",196,213,[0],0,"[0, 0, 0, 0, 0]",0,"[0, 0]",0,0,0,0,exitBlockSet(GrammarAST),org.antlr.v4.codegen.model.ElementFrequenciesVisitor,exitBlockSet/1[org.antlr.v4.codegen.model.GrammarAST],False,197,3,1,0,1,3,8,10,0,0,1,8,1,1,1,0,0,0,0,4,1,0,1,0,0,0,12,4,0,False
1058,..\projects\antlr4-4.11.0\tool\src\org\antlr\v4\codegen\model\ElementFrequenciesVisitor.java,org.antlr.v4.codegen.model.ElementFrequenciesVisitor,void exitSubrule(GrammarAST),"@Override
protected void exitSubrule(GrammarAST tree) {
    if (tree.getType() == CLOSURE || tree.getType() == POSITIVE_CLOSURE) {
        for (Map.Entry<String, MutableInt> entry : frequencies.peek().entrySet()) {
            entry.getValue().v = 2;
        }
    }
    if (tree.getType() == CLOSURE || tree.getType() == OPTIONAL) {
        // Everything inside a closure is optional, so the minimum
        // number of occurrences for all elements is 0.
        minFrequencies.peek().clear();
    }
}", ,"// Everything inside a closure is optional, so the minimum
[[SEP]]// number of occurrences for all elements is 0.
","// Everything inside a closure is optional, so the minimum// number of occurrences for all elements is 0.",215,228,[0],0,"[0, 0]",0,[0],0,0,0,0,exitSubrule(GrammarAST),org.antlr.v4.codegen.model.ElementFrequenciesVisitor,exitSubrule/1[org.antlr.v4.codegen.model.GrammarAST],False,216,2,0,0,0,6,5,10,0,0,1,5,0,0,1,4,0,0,0,1,1,0,2,0,0,0,19,4,0,False
1059,..\projects\antlr4-4.11.0\tool\src\org\antlr\v4\codegen\model\ElementFrequenciesVisitor.java,org.antlr.v4.codegen.model.ElementFrequenciesVisitor,void exitLexerSubrule(GrammarAST),"@Override
protected void exitLexerSubrule(GrammarAST tree) {
    if (tree.getType() == CLOSURE || tree.getType() == POSITIVE_CLOSURE) {
        for (Map.Entry<String, MutableInt> entry : frequencies.peek().entrySet()) {
            entry.getValue().v = 2;
        }
    }
    if (tree.getType() == CLOSURE) {
        // Everything inside a closure is optional, so the minimum
        // number of occurrences for all elements is 0.
        minFrequencies.peek().clear();
    }
}", ,"// Everything inside a closure is optional, so the minimum
[[SEP]]// number of occurrences for all elements is 0.
","// Everything inside a closure is optional, so the minimum// number of occurrences for all elements is 0.",258,271,[0],0,"[0, 0]",0,[0],0,0,0,0,exitLexerSubrule(GrammarAST),org.antlr.v4.codegen.model.ElementFrequenciesVisitor,exitLexerSubrule/1[org.antlr.v4.codegen.model.GrammarAST],False,259,2,0,0,0,5,5,10,0,0,1,5,0,0,1,3,0,0,0,1,1,0,2,0,0,0,19,4,0,False
1060,..\projects\antlr4-4.11.0\tool\src\org\antlr\v4\codegen\model\RuleFunction.java,org.antlr.v4.codegen.model.RuleFunction,"void addContextGetters(OutputModelFactory, Rule)","public void addContextGetters(OutputModelFactory factory, Rule r) {
    // Add ctx labels for elements in alts with no -> label
    List<AltAST> altsNoLabels = r.getUnlabeledAltASTs();
    if (altsNoLabels != null) {
        Set<Decl> decls = getDeclsForAllElements(altsNoLabels);
        // we know to put in rule ctx, so do it directly
        for (Decl d : decls) ruleCtx.addDecl(d);
    }
    // make structs for -> labeled alts, define ctx labels for elements
    altLabelCtxs = new HashMap<String, AltLabelStructDecl>();
    Map<String, List<Pair<Integer, AltAST>>> labels = r.getAltLabels();
    if (labels != null) {
        for (Map.Entry<String, List<Pair<Integer, AltAST>>> entry : labels.entrySet()) {
            String label = entry.getKey();
            List<AltAST> alts = new ArrayList<AltAST>();
            for (Pair<Integer, AltAST> pair : entry.getValue()) {
                alts.add(pair.b);
            }
            Set<Decl> decls = getDeclsForAllElements(alts);
            for (Pair<Integer, AltAST> pair : entry.getValue()) {
                Integer altNum = pair.a;
                altToContext[altNum] = new AltLabelStructDecl(factory, r, altNum, label);
                if (!altLabelCtxs.containsKey(label)) {
                    altLabelCtxs.put(label, altToContext[altNum]);
                }
                // we know which ctx to put in, so do it directly
                for (Decl d : decls) {
                    altToContext[altNum].addDecl(d);
                }
            }
        }
    }
}", ,"// Add ctx labels for elements in alts with no -> label
[[SEP]]// we know to put in rule ctx, so do it directly
[[SEP]]// make structs for -> labeled alts, define ctx labels for elements
[[SEP]]// we know which ctx to put in, so do it directly
","// Add ctx labels for elements in alts with no -> label[[SEP]]// we know to put in rule ctx, so do it directly[[SEP]]// make structs for -> labeled alts, define ctx labels for elements[[SEP]]// we know which ctx to put in, so do it directly",120,155,[0],0,"[0, 0, 0, 0]",0,"[0, 0, 0, 0]",0,0,0,0,"addContextGetters(OutputModelFactory, Rule)",org.antlr.v4.codegen.model.RuleFunction,"addContextGetters/2[org.antlr.v4.codegen.OutputModelFactory,org.antlr.v4.codegen.model.Rule]",False,120,8,4,1,3,9,10,29,0,7,2,10,1,2,5,2,0,0,0,0,9,0,4,0,0,0,30,1,0,False
1061,..\projects\antlr4-4.11.0\tool\src\org\antlr\v4\codegen\model\RuleFunction.java,org.antlr.v4.codegen.model.RuleFunction,Set<Decl> getDeclsForAllElements(List<AltAST>),"/**
 *  for all alts, find which ref X or r needs List
 * 	   Must see across alts. If any alt needs X or r as list, then
 * 	   define as list.
 */
public Set<Decl> getDeclsForAllElements(List<AltAST> altASTs) {
    Set<String> needsList = new HashSet<String>();
    Set<String> nonOptional = new HashSet<String>();
    List<GrammarAST> allRefs = new ArrayList<GrammarAST>();
    boolean firstAlt = true;
    IntervalSet reftypes = new IntervalSet(RULE_REF, TOKEN_REF, STRING_LITERAL);
    for (AltAST ast : altASTs) {
        List<GrammarAST> refs = getRuleTokens(ast.getNodesWithType(reftypes));
        allRefs.addAll(refs);
        Pair<FrequencySet<String>, FrequencySet<String>> minAndAltFreq = getElementFrequenciesForAlt(ast);
        FrequencySet<String> minFreq = minAndAltFreq.a;
        FrequencySet<String> altFreq = minAndAltFreq.b;
        for (GrammarAST t : refs) {
            String refLabelName = getName(t);
            if (refLabelName != null) {
                if (altFreq.count(refLabelName) > 1) {
                    needsList.add(refLabelName);
                }
                if (firstAlt && minFreq.count(refLabelName) != 0) {
                    nonOptional.add(refLabelName);
                }
            }
        }
        for (String ref : nonOptional.toArray(new String[0])) {
            if (minFreq.count(ref) == 0) {
                nonOptional.remove(ref);
            }
        }
        firstAlt = false;
    }
    Set<Decl> decls = new LinkedHashSet<Decl>();
    for (GrammarAST t : allRefs) {
        String refLabelName = getName(t);
        if (refLabelName == null) {
            continue;
        }
        List<Decl> d = getDeclForAltElement(t, refLabelName, needsList.contains(refLabelName), !nonOptional.contains(refLabelName));
        decls.addAll(d);
    }
    return decls;
}","/**
 *  for all alts, find which ref X or r needs List
 * 	   Must see across alts. If any alt needs X or r as list, then
 * 	   define as list.
 */
", ,"/** *  for all alts, find which ref X or r needs List * 	   Must see across alts. If any alt needs X or r as list, then * 	   define as list. */",173,222,[0],0,[0],0,[0],0,0,0,0,getDeclsForAllElements(List<AltAST>),org.antlr.v4.codegen.model.RuleFunction,getDeclsForAllElements/1[java.util.List<org.antlr.v4.codegen.model.AltAST>],False,173,7,7,1,6,11,12,41,1,13,1,12,4,1,4,4,0,0,0,4,14,0,4,0,0,0,54,1,0,True
1062,..\projects\antlr4-4.11.0\tool\src\org\antlr\v4\codegen\model\RuleFunction.java,org.antlr.v4.codegen.model.RuleFunction,List<GrammarAST> getRuleTokens(List<GrammarAST>),"private List<GrammarAST> getRuleTokens(List<GrammarAST> refs) {
    List<GrammarAST> result = new ArrayList<>(refs.size());
    for (GrammarAST ref : refs) {
        CommonTree r = ref;
        boolean ignore = false;
        while (r != null) {
            // Ignore string literals in predicates
            if (r instanceof PredAST) {
                ignore = true;
                break;
            }
            r = r.parent;
        }
        if (!ignore) {
            result.add(ref);
        }
    }
    return result;
}", ,"// Ignore string literals in predicates
",// Ignore string literals in predicates,224,245,[0],0,[0],0,[0],0,0,0,0,getRuleTokens(List<GrammarAST>),org.antlr.v4.codegen.model.RuleFunction,getRuleTokens/1[java.util.List<org.antlr.v4.codegen.model.GrammarAST>],False,224,3,1,1,0,5,2,18,1,3,1,2,0,0,2,1,0,0,0,0,5,0,3,0,0,0,18,2,0,False
1063,..\projects\antlr4-4.11.0\tool\src\org\antlr\v4\codegen\model\RuleFunction.java,org.antlr.v4.codegen.model.RuleFunction,String getName(GrammarAST),"private String getName(GrammarAST token) {
    String tokenText = token.getText();
    String tokenName = token.getType() != STRING_LITERAL ? tokenText : token.g.getTokenName(tokenText);
    // Do not include tokens with auto generated names
    return tokenName == null || tokenName.startsWith(""T__"") ? null : tokenName;
}", ,"// Do not include tokens with auto generated names
",// Do not include tokens with auto generated names,247,251,[0],0,[0],0,[0],0,0,0,0,getName(GrammarAST),org.antlr.v4.codegen.model.RuleFunction,getName/1[org.antlr.v4.codegen.model.GrammarAST],False,247,1,1,1,0,4,4,5,1,2,1,4,0,0,0,2,0,0,1,0,2,0,0,0,0,0,16,2,0,False
1064,..\projects\antlr4-4.11.0\tool\src\org\antlr\v4\codegen\model\RuleFunction.java,org.antlr.v4.codegen.model.RuleFunction,"Pair<FrequencySet<String>, FrequencySet<String>> getElementFrequenciesForAlt(AltAST)","/**
 * Given list of X and r refs in alt, compute how many of each there are
 */
protected Pair<FrequencySet<String>, FrequencySet<String>> getElementFrequenciesForAlt(AltAST ast) {
    try {
        ElementFrequenciesVisitor visitor = new ElementFrequenciesVisitor(new CommonTreeNodeStream(new GrammarASTAdaptor(), ast));
        visitor.outerAlternative();
        if (visitor.frequencies.size() != 1) {
            factory.getGrammar().tool.errMgr.toolError(ErrorType.INTERNAL_ERROR);
            return new Pair<>(new FrequencySet<String>(), new FrequencySet<String>());
        }
        return new Pair<>(visitor.getMinFrequencies(), visitor.frequencies.peek());
    } catch (RecognitionException ex) {
        factory.getGrammar().tool.errMgr.toolError(ErrorType.INTERNAL_ERROR, ex);
        return new Pair<>(new FrequencySet<String>(), new FrequencySet<String>());
    }
}","/**
 * Given list of X and r refs in alt, compute how many of each there are
 */
", ,"/** * Given list of X and r refs in alt, compute how many of each there are */",254,269,[0],0,[0],0,[0],0,0,0,0,getElementFrequenciesForAlt(AltAST),org.antlr.v4.codegen.model.RuleFunction,getElementFrequenciesForAlt/1[org.antlr.v4.codegen.model.AltAST],False,254,7,6,1,5,3,6,15,3,1,1,6,0,0,0,1,1,0,0,1,1,0,2,0,0,0,34,4,0,True
1065,..\projects\antlr4-4.11.0\tool\src\org\antlr\v4\codegen\model\RuleFunction.java,org.antlr.v4.codegen.model.RuleFunction,void addLocalDecl(Decl),"/**
 * Add local var decl
 */
public void addLocalDecl(Decl d) {
    if (locals == null)
        locals = new OrderedHashSet<Decl>();
    locals.add(d);
    d.isLocal = true;
}","/**
 * Add local var decl
 */
", ,/** * Add local var decl */,300,304,[0],0,[0],0,[0],0,0,0,0,addLocalDecl(Decl),org.antlr.v4.codegen.model.RuleFunction,addLocalDecl/1[org.antlr.v4.codegen.model.decl.Decl],False,300,2,4,2,2,2,1,5,0,0,1,1,0,0,0,1,0,0,0,0,2,0,1,0,0,0,11,1,0,True
1066,..\projects\antlr4-4.11.0\tool\src\org\antlr\v4\codegen\model\RuleFunction.java,org.antlr.v4.codegen.model.RuleFunction,"void addContextDecl(String, Decl)","/**
 * Add decl to struct ctx for rule or alt if labeled
 */
public void addContextDecl(String altLabel, Decl d) {
    CodeBlockForOuterMostAlt alt = d.getOuterMostAltCodeBlock();
    // if we found code blk and might be alt label, try to add to that label ctx
    if (alt != null && altLabelCtxs != null) {
        // System.out.println(d.name+"" lives in alt ""+alt.alt.altNum);
        AltLabelStructDecl altCtx = altLabelCtxs.get(altLabel);
        if (altCtx != null) {
            // we have an alt ctx
            // System.out.println(""ctx is ""+ altCtx.name);
            altCtx.addDecl(d);
            return;
        }
    }
    // stick in overall rule's ctx
    ruleCtx.addDecl(d);
}","/**
 * Add decl to struct ctx for rule or alt if labeled
 */
","// if we found code blk and might be alt label, try to add to that label ctx
[[SEP]]// System.out.println(d.name+"" lives in alt ""+alt.alt.altNum);
[[SEP]]// we have an alt ctx
[[SEP]]// System.out.println(""ctx is ""+ altCtx.name);
[[SEP]]// stick in overall rule's ctx
","/** * Add decl to struct ctx for rule or alt if labeled */[[SEP]]// if we found code blk and might be alt label, try to add to that label ctx[[SEP]]// System.out.println(d.name+"" lives in alt ""+alt.alt.altNum);[[SEP]]// we have an alt ctx// System.out.println(""ctx is ""+ altCtx.name);[[SEP]]// stick in overall rule's ctx",307,320,[0],0,"[0, 0, 0, 0, 0]",0,"[0, 0, 0, 0, 0]",0,0,0,0,"addContextDecl(String, Decl)",org.antlr.v4.codegen.model.RuleFunction,"addContextDecl/2[java.lang.String,org.antlr.v4.codegen.model.decl.Decl]",False,307,5,8,6,2,4,3,11,1,2,2,3,0,0,0,3,0,0,0,0,2,0,2,0,0,0,24,1,0,True
1067,..\projects\antlr4-4.11.0\tool\src\org\antlr\v4\codegen\model\SrcOp.java,org.antlr.v4.codegen.model.SrcOp,CodeBlockForOuterMostAlt getOuterMostAltCodeBlock(),"/**
 * Walk upwards in model tree, looking for outer alt's code block
 */
public CodeBlockForOuterMostAlt getOuterMostAltCodeBlock() {
    if (this instanceof CodeBlockForOuterMostAlt) {
        return (CodeBlockForOuterMostAlt) this;
    }
    CodeBlock p = enclosingBlock;
    while (p != null) {
        if (p instanceof CodeBlockForOuterMostAlt) {
            return (CodeBlockForOuterMostAlt) p;
        }
        p = p.enclosingBlock;
    }
    return null;
}","/**
 * Walk upwards in model tree, looking for outer alt's code block
 */
", ,"/** * Walk upwards in model tree, looking for outer alt's code block */",38,50,[0],0,[0],0,[0],0,0,0,0,getOuterMostAltCodeBlock(),org.antlr.v4.codegen.model.SrcOp,getOuterMostAltCodeBlock/0,False,38,3,2,2,0,4,0,13,3,1,0,0,0,0,1,1,0,0,0,0,2,0,2,0,0,0,18,1,0,True
1068,..\projects\antlr4-4.11.0\tool\src\org\antlr\v4\codegen\model\SrcOp.java,org.antlr.v4.codegen.model.SrcOp,String getContextName(),"/**
 * Return label alt or return name of rule
 */
public String getContextName() {
    CodeBlockForOuterMostAlt alt = getOuterMostAltCodeBlock();
    if (alt != null && alt.altLabel != null)
        return alt.altLabel;
    return enclosingRuleRunction.name;
}","/**
 * Return label alt or return name of rule
 */
", ,/** * Return label alt or return name of rule */,53,57,[0],0,[0],0,[0],0,0,0,0,getContextName(),org.antlr.v4.codegen.model.SrcOp,getContextName/0,False,53,2,1,0,1,3,1,5,2,1,0,1,1,1,0,2,0,0,0,0,1,0,1,0,0,0,17,1,0,True
1069,..\projects\antlr4-4.11.0\tool\src\org\antlr\v4\codegen\model\decl\CodeBlock.java,org.antlr.v4.codegen.model.decl.CodeBlock,void addLocalDecl(Decl),"/**
 * Add local var decl
 */
public void addLocalDecl(Decl d) {
    if (locals == null)
        locals = new OrderedHashSet<Decl>();
    locals.add(d);
    d.isLocal = true;
}","/**
 * Add local var decl
 */
", ,/** * Add local var decl */,36,40,[0],0,[0],0,[0],0,0,0,0,addLocalDecl(Decl),org.antlr.v4.codegen.model.decl.CodeBlock,addLocalDecl/1[org.antlr.v4.codegen.model.decl.Decl],False,36,2,2,0,2,2,1,5,0,0,1,1,0,0,0,1,0,0,0,0,2,0,1,0,0,0,11,1,0,True
1070,..\projects\antlr4-4.11.0\tool\src\org\antlr\v4\codegen\model\decl\ContextGetterDecl.java,org.antlr.v4.codegen.model.decl.ContextGetterDecl,String getArgType(),"/**
 * Not used for output; just used to distinguish between decl types
 *  to avoid dups.
 */
// assume no args
public String getArgType() {
    return """";
}","// assume no args
", ,/** * Not used for output; just used to distinguish between decl types *  to avoid dups. */[[SEP]]// assume no args,20,20,[0],0,[0],0,"[0, 0]",0,0,0,0,getArgType(),org.antlr.v4.codegen.model.decl.ContextGetterDecl,getArgType/0,False,20,0,2,2,0,1,0,3,1,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,13,1,0,True
1071,..\projects\antlr4-4.11.0\tool\src\org\antlr\v4\codegen\model\decl\ContextGetterDecl.java,org.antlr.v4.codegen.model.decl.ContextGetterDecl,boolean equals(Object),"/**
 * Make sure that a getter does not equal a label. X() and X are ok.
 *  OTOH, treat X() with two diff return values as the same.  Treat
 *  two X() with diff args as different.
 */
@Override
public boolean equals(Object obj) {
    if (this == obj)
        return true;
    // A() and label A are different
    if (!(obj instanceof ContextGetterDecl))
        return false;
    return name.equals(((Decl) obj).name) && getArgType().equals(((ContextGetterDecl) obj).getArgType());
}","/**
 * Make sure that a getter does not equal a label. X() and X are ok.
 *  OTOH, treat X() with two diff return values as the same.  Treat
 *  two X() with diff args as different.
 */
","// A() and label A are different
","/** * Make sure that a getter does not equal a label. X() and X are ok. *  OTOH, treat X() with two diff return values as the same.  Treat *  two X() with diff args as different. */[[SEP]]// A() and label A are different",35,42,[0],0,[0],0,"[0, 0]",0,0,0,0,equals(Object),org.antlr.v4.codegen.model.decl.ContextGetterDecl,equals/1[java.lang.Object],False,36,2,1,0,1,3,2,5,3,0,1,2,1,1,0,1,0,3,0,0,0,0,1,0,0,0,31,1,0,True
1072,..\projects\antlr4-4.11.0\tool\src\org\antlr\v4\codegen\model\decl\Decl.java,org.antlr.v4.codegen.model.decl.Decl,boolean equals(Object),"/**
 * If same name, can't redefine, unless it's a getter
 */
@Override
public boolean equals(Object obj) {
    if (this == obj)
        return true;
    if (!(obj instanceof Decl))
        return false;
    // A() and label A are different
    if (obj instanceof ContextGetterDecl)
        return false;
    return name.equals(((Decl) obj).name);
}","/**
 * If same name, can't redefine, unless it's a getter
 */
","// A() and label A are different
","/** * If same name, can't redefine, unless it's a getter */[[SEP]]// A() and label A are different",37,44,[0],0,[0],0,"[0, 0]",0,0,0,0,equals(Object),org.antlr.v4.codegen.model.decl.Decl,equals/1[java.lang.Object],False,38,2,0,0,0,4,1,6,4,0,1,1,0,0,0,1,0,2,0,0,0,0,1,0,0,0,13,1,0,True
1073,..\projects\antlr4-4.11.0\tool\src\org\antlr\v4\codegen\model\decl\StructDecl.java,org.antlr.v4.codegen.model.decl.StructDecl,void addDispatchMethods(Rule),"public void addDispatchMethods(Rule r) {
    dispatchMethods = new ArrayList<DispatchMethod>();
    if (!r.hasAltSpecificContexts()) {
        // no enter/exit for this ruleContext if rule has labels
        if (factory.getGrammar().tool.gen_listener) {
            dispatchMethods.add(new ListenerDispatchMethod(factory, true));
            dispatchMethods.add(new ListenerDispatchMethod(factory, false));
        }
        if (factory.getGrammar().tool.gen_visitor) {
            dispatchMethods.add(new VisitorDispatchMethod(factory));
        }
    }
}", ,"// no enter/exit for this ruleContext if rule has labels
",// no enter/exit for this ruleContext if rule has labels,57,69,[0],0,[0],0,[0],0,0,0,0,addDispatchMethods(Rule),org.antlr.v4.codegen.model.decl.StructDecl,addDispatchMethods/1[org.antlr.v4.codegen.model.decl.Rule],False,57,5,4,1,3,4,3,12,0,0,1,3,0,0,0,0,0,0,0,0,1,0,2,0,0,0,10,1,0,False
1074,..\projects\antlr4-4.11.0\tool\src\org\antlr\v4\codegen\model\decl\StructDecl.java,org.antlr.v4.codegen.model.decl.StructDecl,void addDecl(Decl),"public void addDecl(Decl d) {
    d.ctx = this;
    if (d instanceof ContextGetterDecl)
        getters.add(d);
    else
        attrs.add(d);
    // add to specific ""lists""
    if (d instanceof TokenTypeDecl) {
        tokenTypeDecls.add(d);
    } else if (d instanceof TokenListDecl) {
        tokenListDecls.add(d);
    } else if (d instanceof TokenDecl) {
        tokenDecls.add(d);
    } else if (d instanceof RuleContextListDecl) {
        ruleContextListDecls.add(d);
    } else if (d instanceof RuleContextDecl) {
        ruleContextDecls.add(d);
    } else if (d instanceof AttributeDecl) {
        attributeDecls.add(d);
    }
}", ,"// add to specific ""lists""
","// add to specific ""lists""",71,96,[0],0,[0],0,[0],0,0,0,0,addDecl(Decl),org.antlr.v4.codegen.model.decl.StructDecl,addDecl/1[org.antlr.v4.codegen.model.decl.Decl],False,71,9,6,5,1,8,1,23,0,0,1,1,0,0,0,0,0,0,0,0,1,0,1,0,0,0,10,1,0,False
1075,..\projects\antlr4-4.11.0\tool\src\org\antlr\v4\codegen\target\CppTarget.java,org.antlr.v4.codegen.target.CppTarget,boolean shouldUseUnicodeEscapeForCodePointInDoubleQuotedString(int),"@Override
protected boolean shouldUseUnicodeEscapeForCodePointInDoubleQuotedString(int codePoint) {
    if (codePoint == '?') {
        // in addition to the default escaped code points, also escape ? to prevent trigraphs
        // ideally, we would escape ? with \?, but escaping as unicode \u003F works as well
        return true;
    } else {
        return super.shouldUseUnicodeEscapeForCodePointInDoubleQuotedString(codePoint);
    }
}", ,"// in addition to the default escaped code points, also escape ? to prevent trigraphs
[[SEP]]// ideally, we would escape ? with \?, but escaping as unicode \u003F works as well
","// in addition to the default escaped code points, also escape ? to prevent trigraphs// ideally, we would escape ? with \?, but escaping as unicode \u003F works as well",70,80,[0],0,"[0, 0]",0,[0],0,0,0,0,shouldUseUnicodeEscapeForCodePointInDoubleQuotedString(int),org.antlr.v4.codegen.target.CppTarget,shouldUseUnicodeEscapeForCodePointInDoubleQuotedString/1[int],False,71,0,0,0,0,2,1,8,2,0,1,1,0,0,0,1,0,0,0,0,0,0,1,0,0,0,13,4,0,False
1076,..\projects\antlr4-4.11.0\tool\src\org\antlr\v4\codegen\target\GoTarget.java,org.antlr.v4.codegen.target.GoTarget,"void genFile(Grammar, ST, String)","@Override
protected void genFile(Grammar g, ST outputFileST, String fileName) {
    super.genFile(g, outputFileST, fileName);
    if (DO_GOFMT && !fileName.startsWith(""."") && /* criterion taken from gofmt */
    fileName.endsWith("".go"")) {
        gofmt(new File(getCodeGenerator().tool.getOutputDirectory(g.fileName), fileName));
    }
}", ,"/* criterion taken from gofmt */
",/* criterion taken from gofmt */,62,68,[0],0,[0],0,[0],0,0,0,0,"genFile(Grammar, ST, String)",org.antlr.v4.codegen.target.GoTarget,"genFile/3[org.antlr.v4.codegen.target.Grammar,org.antlr.v4.codegen.target.ST,java.lang.String]",False,63,4,2,0,2,4,6,6,0,0,3,6,1,1,0,0,0,0,2,0,0,0,1,0,0,0,16,4,0,False
1077,..\projects\antlr4-4.11.0\tool\src\org\antlr\v4\codegen\target\GoTarget.java,org.antlr.v4.codegen.target.GoTarget,void gofmt(File),"private void gofmt(File fileName) {
    // Optimistically run gofmt. If this fails, it doesn't matter at this point. Wait for termination though,
    // because ""gofmt -w"" uses ioutil.WriteFile internally, which means it literally writes in-place with O_TRUNC.
    // That could result in a race. (Why oh why doesn't it do tmpfile + rename?)
    try {
        // TODO: need something like: String goExecutable = locateGo();
        ProcessBuilder gofmtBuilder = new ProcessBuilder(""gofmt"", ""-w"", ""-s"", fileName.getPath());
        gofmtBuilder.redirectErrorStream(true);
        Process gofmt = gofmtBuilder.start();
        InputStream stdout = gofmt.getInputStream();
        // TODO(wjkohnen): simplify to `while (stdout.Read() > 1) {}`
        byte[] buf = new byte[1 << 10];
        for (int l = 0; l > -1; l = stdout.read(buf)) {
            // There should not be any output that exceeds the implicit output buffer. In normal ops there should be
            // zero output. In case there is output, blocking and therefore killing the process is acceptable. This
            // drains the buffer anyway to play it safe.
            // dirty debug (change -w above to -d):
            // System.err.write(buf, 0, l);
        }
        gofmt.waitFor();
    } catch (IOException e) {
        // Probably gofmt not in $PATH, in any case ignore.
    } catch (InterruptedException forward) {
        Thread.currentThread().interrupt();
    }
}", ,"// Optimistically run gofmt. If this fails, it doesn't matter at this point. Wait for termination though,
[[SEP]]// because ""gofmt -w"" uses ioutil.WriteFile internally, which means it literally writes in-place with O_TRUNC.
[[SEP]]// That could result in a race. (Why oh why doesn't it do tmpfile + rename?)
[[SEP]]// TODO: need something like: String goExecutable = locateGo();
[[SEP]]// TODO(wjkohnen): simplify to `while (stdout.Read() > 1) {}`
[[SEP]]// There should not be any output that exceeds the implicit output buffer. In normal ops there should be
[[SEP]]// zero output. In case there is output, blocking and therefore killing the process is acceptable. This
[[SEP]]// drains the buffer anyway to play it safe.
[[SEP]]// dirty debug (change -w above to -d):
[[SEP]]// System.err.write(buf, 0, l);
[[SEP]]// Probably gofmt not in $PATH, in any case ignore.
","// Optimistically run gofmt. If this fails, it doesn't matter at this point. Wait for termination though,// because ""gofmt -w"" uses ioutil.WriteFile internally, which means it literally writes in-place with O_TRUNC.// That could result in a race. (Why oh why doesn't it do tmpfile + rename?)[[SEP]]// TODO: need something like: String goExecutable = locateGo();[[SEP]]// TODO(wjkohnen): simplify to `while (stdout.Read() > 1) {}`[[SEP]]// There should not be any output that exceeds the implicit output buffer. In normal ops there should be// zero output. In case there is output, blocking and therefore killing the process is acceptable. This// drains the buffer anyway to play it safe.// dirty debug (change -w above to -d):// System.err.write(buf, 0, l);[[SEP]]// Probably gofmt not in $PATH, in any case ignore.",70,96,[0],0,"[0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0]",1,"[1, 1, 1, 0, 0]",1,1,1,1,gofmt(File),org.antlr.v4.codegen.target.GoTarget,gofmt/1[java.io.File],False,70,1,1,1,0,4,8,17,0,5,1,8,0,0,1,0,1,0,3,4,6,1,2,0,0,0,18,2,0,False
1078,..\projects\antlr4-4.11.0\tool\src\org\antlr\v4\codegen\target\GoTarget.java,org.antlr.v4.codegen.target.GoTarget,String getRecognizerFileName(boolean),"public String getRecognizerFileName(boolean header) {
    CodeGenerator gen = getCodeGenerator();
    Grammar g = gen.g;
    assert g != null;
    String name;
    switch(g.getType()) {
        case ANTLRParser.PARSER:
            name = g.name.endsWith(""Parser"") ? g.name.substring(0, g.name.length() - 6) : g.name;
            return name.toLowerCase() + ""_parser.go"";
        case ANTLRParser.LEXER:
            // trim off ""lexer""
            name = g.name.endsWith(""Lexer"") ? g.name.substring(0, g.name.length() - 5) : g.name;
            return name.toLowerCase() + ""_lexer.go"";
        case ANTLRParser.COMBINED:
            return g.name.toLowerCase() + ""_parser.go"";
        default:
            return ""INVALID_FILE_NAME"";
    }
}", ,"// trim off ""lexer""
","// trim off ""lexer""",98,115,[0],0,[0],0,[0],0,0,0,0,getRecognizerFileName(boolean),org.antlr.v4.codegen.target.GoTarget,getRecognizerFileName/1[boolean],False,98,3,1,0,1,7,7,18,4,3,1,7,0,0,0,1,0,0,6,4,4,5,1,0,0,0,13,1,0,False
1079,..\projects\antlr4-4.11.0\tool\src\org\antlr\v4\codegen\target\GoTarget.java,org.antlr.v4.codegen.target.GoTarget,String getListenerFileName(boolean),"/**
 * A given grammar T, return the listener name such as
 *  TListener.java, if we're using the Java target.
 */
public String getListenerFileName(boolean header) {
    CodeGenerator gen = getCodeGenerator();
    Grammar g = gen.g;
    assert g.name != null;
    return g.name.toLowerCase() + ""_listener.go"";
}","/**
 * A given grammar T, return the listener name such as
 *  TListener.java, if we're using the Java target.
 */
", ,"/** * A given grammar T, return the listener name such as *  TListener.java, if we're using the Java target. */",120,125,[0],0,[0],0,[0],0,0,0,0,getListenerFileName(boolean),org.antlr.v4.codegen.target.GoTarget,getListenerFileName/1[boolean],False,120,3,1,0,1,2,2,6,1,2,1,2,0,0,0,1,0,0,1,0,2,1,0,0,0,0,22,1,0,True
1080,..\projects\antlr4-4.11.0\tool\src\org\antlr\v4\codegen\target\GoTarget.java,org.antlr.v4.codegen.target.GoTarget,String getVisitorFileName(boolean),"/**
 * A given grammar T, return the visitor name such as
 *  TVisitor.java, if we're using the Java target.
 */
public String getVisitorFileName(boolean header) {
    CodeGenerator gen = getCodeGenerator();
    Grammar g = gen.g;
    assert g.name != null;
    return g.name.toLowerCase() + ""_visitor.go"";
}","/**
 * A given grammar T, return the visitor name such as
 *  TVisitor.java, if we're using the Java target.
 */
", ,"/** * A given grammar T, return the visitor name such as *  TVisitor.java, if we're using the Java target. */",130,135,[0],0,[0],0,[0],0,0,0,0,getVisitorFileName(boolean),org.antlr.v4.codegen.target.GoTarget,getVisitorFileName/1[boolean],False,130,3,1,0,1,2,2,6,1,2,1,2,0,0,0,1,0,0,1,0,2,1,0,0,0,0,22,1,0,True
1081,..\projects\antlr4-4.11.0\tool\src\org\antlr\v4\codegen\target\GoTarget.java,org.antlr.v4.codegen.target.GoTarget,String getBaseListenerFileName(boolean),"/**
 * A given grammar T, return a blank listener implementation
 *  such as TBaseListener.java, if we're using the Java target.
 */
public String getBaseListenerFileName(boolean header) {
    CodeGenerator gen = getCodeGenerator();
    Grammar g = gen.g;
    assert g.name != null;
    return g.name.toLowerCase() + ""_base_listener.go"";
}","/**
 * A given grammar T, return a blank listener implementation
 *  such as TBaseListener.java, if we're using the Java target.
 */
", ,"/** * A given grammar T, return a blank listener implementation *  such as TBaseListener.java, if we're using the Java target. */",140,145,[0],0,[0],0,[0],0,0,0,0,getBaseListenerFileName(boolean),org.antlr.v4.codegen.target.GoTarget,getBaseListenerFileName/1[boolean],False,140,3,1,0,1,2,2,6,1,2,1,2,0,0,0,1,0,0,1,0,2,1,0,0,0,0,25,1,0,True
1082,..\projects\antlr4-4.11.0\tool\src\org\antlr\v4\codegen\target\GoTarget.java,org.antlr.v4.codegen.target.GoTarget,String getBaseVisitorFileName(boolean),"/**
 * A given grammar T, return a blank listener implementation
 *  such as TBaseListener.java, if we're using the Java target.
 */
public String getBaseVisitorFileName(boolean header) {
    CodeGenerator gen = getCodeGenerator();
    Grammar g = gen.g;
    assert g.name != null;
    return g.name.toLowerCase() + ""_base_visitor.go"";
}","/**
 * A given grammar T, return a blank listener implementation
 *  such as TBaseListener.java, if we're using the Java target.
 */
", ,"/** * A given grammar T, return a blank listener implementation *  such as TBaseListener.java, if we're using the Java target. */",150,155,[0],0,[0],0,[0],0,0,0,0,getBaseVisitorFileName(boolean),org.antlr.v4.codegen.target.GoTarget,getBaseVisitorFileName/1[boolean],False,150,3,1,0,1,2,2,6,1,2,1,2,0,0,0,1,0,0,1,0,2,1,0,0,0,0,25,1,0,True
1083,..\projects\antlr4-4.11.0\tool\src\org\antlr\v4\codegen\target\JavaTarget.java,org.antlr.v4.codegen.target.JavaTarget,int getSerializedATNSegmentLimit(),"@Override
public int getSerializedATNSegmentLimit() {
    // 65535 is the class file format byte limit for a UTF-8 encoded string literal
    // 3 is the maximum number of bytes it takes to encode a value in the range 0-0xFFFF
    return 65535 / 3;
}", ,"// 65535 is the class file format byte limit for a UTF-8 encoded string literal
[[SEP]]// 3 is the maximum number of bytes it takes to encode a value in the range 0-0xFFFF
",// 65535 is the class file format byte limit for a UTF-8 encoded string literal// 3 is the maximum number of bytes it takes to encode a value in the range 0-0xFFFF,45,50,[0],0,"[0, 0]",0,[0],0,0,0,0,getSerializedATNSegmentLimit(),org.antlr.v4.codegen.target.JavaTarget,getSerializedATNSegmentLimit/0,False,46,0,0,0,0,1,0,3,1,0,0,0,0,0,0,0,0,0,0,2,0,1,0,0,0,0,7,1,0,False
1084,..\projects\antlr4-4.11.0\tool\src\org\antlr\v4\gui\BasicFontMetrics.java,org.antlr.v4.gui.BasicFontMetrics,"double getWidth(char, int)","public double getWidth(char c, int fontSize) {
    // return width('m')
    if (c > MAX_CHAR || widths[c] == 0)
        return widths['m'] / 1000.0;
    return widths[c] / 1000.0 * fontSize;
}", ,"// return width('m')
",// return width('m'),63,66,[0],0,[0],0,[0],0,0,0,0,"getWidth(char, int)",org.antlr.v4.gui.BasicFontMetrics,"getWidth/2[char,int]",False,63,0,2,2,0,3,0,4,2,0,2,0,0,0,0,1,0,0,0,3,0,3,1,0,0,0,12,1,0,False
1085,..\projects\antlr4-4.11.0\tool\src\org\antlr\v4\gui\GraphicsSupport.java,org.antlr.v4.gui.GraphicsSupport,"void saveImage(JComponent, String)","/**
 * 	 [The ""BSD license""]
 * 	 Copyright (c) 2011 Cay Horstmann
 * 	 All rights reserved.
 *
 * 	 Redistribution and use in source and binary forms, with or without
 * 	 modification, are permitted provided that the following conditions
 * 	 are met:
 *
 * 	 1. Redistributions of source code must retain the above copyright
 * 	 notice, this list of conditions and the following disclaimer.
 * 	 2. Redistributions in binary form must reproduce the above copyright
 * 	 notice, this list of conditions and the following disclaimer in the
 * 	 documentation and/or other materials provided with the distribution.
 * 	 3. The name of the author may not be used to endorse or promote products
 * 	 derived from this software without specific prior written permission.
 *
 * 	 THIS SOFTWARE IS PROVIDED BY THE AUTHOR ``AS IS'' AND ANY EXPRESS OR
 * 	 IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES
 * 	 OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED.
 * 	 IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR ANY DIRECT, INDIRECT,
 * 	 INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT
 * 	 NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,
 * 	 DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY
 * 	 THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
 * 	 (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF
 * 	 THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
 */
public static void saveImage(final JComponent comp, String fileName) throws IOException, PrintException {
    if (fileName.endsWith("".ps"") || fileName.endsWith("".eps"")) {
        DocFlavor flavor = DocFlavor.SERVICE_FORMATTED.PRINTABLE;
        String mimeType = ""application/postscript"";
        StreamPrintServiceFactory[] factories = StreamPrintServiceFactory.lookupStreamPrintServiceFactories(flavor, mimeType);
        System.out.println(Arrays.toString(factories));
        if (factories.length > 0) {
            FileOutputStream out = new FileOutputStream(fileName);
            PrintService service = factories[0].getPrintService(out);
            SimpleDoc doc = new SimpleDoc(new Printable() {

                @Override
                public int print(Graphics g, PageFormat pf, int page) {
                    if (page >= 1)
                        return Printable.NO_SUCH_PAGE;
                    else {
                        Graphics2D g2 = (Graphics2D) g;
                        g2.translate((pf.getWidth() - pf.getImageableWidth()) / 2, (pf.getHeight() - pf.getImageableHeight()) / 2);
                        if (comp.getWidth() > pf.getImageableWidth() || comp.getHeight() > pf.getImageableHeight()) {
                            double sf1 = pf.getImageableWidth() / (comp.getWidth() + 1);
                            double sf2 = pf.getImageableHeight() / (comp.getHeight() + 1);
                            double s = Math.min(sf1, sf2);
                            g2.scale(s, s);
                        }
                        comp.paint(g);
                        return Printable.PAGE_EXISTS;
                    }
                }
            }, flavor, null);
            DocPrintJob job = service.createPrintJob();
            PrintRequestAttributeSet attributes = new HashPrintRequestAttributeSet();
            job.print(doc, attributes);
            out.close();
        }
    } else {
        // parrt: works with [image/jpeg, image/png, image/x-png, image/vnd.wap.wbmp, image/bmp, image/gif]
        Rectangle rect = comp.getBounds();
        BufferedImage image = new BufferedImage(rect.width, rect.height, BufferedImage.TYPE_INT_RGB);
        Graphics2D g = (Graphics2D) image.getGraphics();
        g.setColor(Color.WHITE);
        g.fill(rect);
        // g.setColor(Color.BLACK);
        comp.paint(g);
        String extension = fileName.substring(fileName.lastIndexOf('.') + 1);
        boolean result = ImageIO.write(image, extension, new File(fileName));
        if (!result) {
            System.err.println(""Now imager for "" + extension);
        }
        g.dispose();
    }
}","/**
 * 	 [The ""BSD license""]
 * 	 Copyright (c) 2011 Cay Horstmann
 * 	 All rights reserved.
 *
 * 	 Redistribution and use in source and binary forms, with or without
 * 	 modification, are permitted provided that the following conditions
 * 	 are met:
 *
 * 	 1. Redistributions of source code must retain the above copyright
 * 	 notice, this list of conditions and the following disclaimer.
 * 	 2. Redistributions in binary form must reproduce the above copyright
 * 	 notice, this list of conditions and the following disclaimer in the
 * 	 documentation and/or other materials provided with the distribution.
 * 	 3. The name of the author may not be used to endorse or promote products
 * 	 derived from this software without specific prior written permission.
 *
 * 	 THIS SOFTWARE IS PROVIDED BY THE AUTHOR ``AS IS'' AND ANY EXPRESS OR
 * 	 IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES
 * 	 OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED.
 * 	 IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR ANY DIRECT, INDIRECT,
 * 	 INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT
 * 	 NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,
 * 	 DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY
 * 	 THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
 * 	 (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF
 * 	 THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
 */
","// parrt: works with [image/jpeg, image/png, image/x-png, image/vnd.wap.wbmp, image/bmp, image/gif]
[[SEP]]// g.setColor(Color.BLACK);
","/** * 	 [The ""BSD license""] * 	 Copyright (c) 2011 Cay Horstmann * 	 All rights reserved. * * 	 Redistribution and use in source and binary forms, with or without * 	 modification, are permitted provided that the following conditions * 	 are met: * * 	 1. Redistributions of source code must retain the above copyright * 	 notice, this list of conditions and the following disclaimer. * 	 2. Redistributions in binary form must reproduce the above copyright * 	 notice, this list of conditions and the following disclaimer in the * 	 documentation and/or other materials provided with the distribution. * 	 3. The name of the author may not be used to endorse or promote products * 	 derived from this software without specific prior written permission. * * 	 THIS SOFTWARE IS PROVIDED BY THE AUTHOR ``AS IS'' AND ANY EXPRESS OR * 	 IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES * 	 OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. * 	 IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR ANY DIRECT, INDIRECT, * 	 INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT * 	 NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, * 	 DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY * 	 THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT * 	 (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF * 	 THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE. */[[SEP]]// parrt: works with [image/jpeg, image/png, image/x-png, image/vnd.wap.wbmp, image/bmp, image/gif][[SEP]]// g.setColor(Color.BLACK);",57,114,[0],0,"[0, 0]",0,"[0, 0, 0]",0,0,0,0,"saveImage(JComponent, String)",org.antlr.v4.gui.GraphicsSupport,"saveImage/2[javax.swing.JComponent,java.lang.String]",False,59,0,2,1,1,5,17,48,0,13,2,17,0,0,0,0,0,0,4,3,13,2,2,1,0,0,124,9,0,True
1086,..\projects\antlr4-4.11.0\tool\src\org\antlr\v4\gui\Interpreter.java,org.antlr.v4.gui.Interpreter,"Object getValue(DecisionInfo, String[], int, int)","public static Object getValue(DecisionInfo decisionInfo, String[] ruleNamesByDecision, int decision, int col) {
    switch(// laborious but more efficient than reflection
    col) {
        case 0:
            return String.format(""%s:%d"", ruleNamesByDecision[decision], decision);
        case 1:
            return decisionInfo.invocations;
        case 2:
            return decisionInfo.timeInPrediction / (1000.0 * 1000.0);
        case 3:
            return decisionInfo.LL_TotalLook + decisionInfo.SLL_TotalLook;
        case 4:
            return Math.max(decisionInfo.LL_MaxLook, decisionInfo.SLL_MaxLook);
        case 5:
            return decisionInfo.ambiguities.size();
        case 6:
            return decisionInfo.SLL_ATNTransitions + decisionInfo.LL_ATNTransitions;
    }
    return ""n/a"";
}", ,"// laborious but more efficient than reflection
",// laborious but more efficient than reflection,250,273,[0],0,[0],0,[0],0,0,0,0,"getValue(DecisionInfo, String[], int, int)",org.antlr.v4.gui.Interpreter,"getValue/4[org.antlr.v4.runtime.atn.DecisionInfo,java.lang.String[],int,int]",False,254,1,1,1,0,8,3,19,8,0,4,3,0,0,0,0,0,1,2,9,0,4,1,0,0,0,6,9,0,False
1087,..\projects\antlr4-4.11.0\tool\src\org\antlr\v4\gui\Interpreter.java,org.antlr.v4.gui.Interpreter.IgnoreTokenVocabGrammar,void importTokensFromTokensFile(),"@Override
public void importTokensFromTokensFile() {
    // don't try to import tokens files; must give me both grammars if split
}", ,"// don't try to import tokens files; must give me both grammars if split
",// don't try to import tokens files; must give me both grammars if split,45,48,[0],0,[0],0,[0],0,0,0,0,importTokensFromTokensFile(),org.antlr.v4.gui.Interpreter$IgnoreTokenVocabGrammar,importTokensFromTokensFile/0,False,46,0,0,0,0,1,0,2,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,4,1,0,False
1088,..\projects\antlr4-4.11.0\tool\src\org\antlr\v4\gui\JFileChooserConfirmOverwrite.java,org.antlr.v4.gui.JFileChooserConfirmOverwrite,void approveSelection(),"@Override
public void approveSelection() {
    File selectedFile = getSelectedFile();
    if (selectedFile.exists()) {
        int answer = JOptionPane.showConfirmDialog(this, ""Overwrite existing file?"", ""Overwrite?"", JOptionPane.YES_NO_OPTION);
        if (answer != JOptionPane.YES_OPTION) {
            // do not call super.approveSelection
            return;
        }
    }
    super.approveSelection();
}", ,"// do not call super.approveSelection
",// do not call super.approveSelection,21,37,[0],0,[0],0,[0],0,0,1,0,approveSelection(),org.antlr.v4.gui.JFileChooserConfirmOverwrite,approveSelection/0,False,22,0,0,0,0,3,4,10,1,2,0,4,0,0,0,1,0,0,2,0,2,0,2,0,0,0,8,1,0,False
1089,..\projects\antlr4-4.11.0\tool\src\org\antlr\v4\gui\PostScriptDocument.java,org.antlr.v4.gui.PostScriptDocument,void close(),"public void close() {
    if (closed)
        return;
    // ps.append(""showpage\n"");
    ps.append(""%%Trailer\n"");
    closed = true;
}", ,"// ps.append(""showpage\n"");
","// ps.append(""showpage\n"");",67,72,[0],0,[0],0,[0],0,0,0,0,close(),org.antlr.v4.gui.PostScriptDocument,close/0,False,67,0,2,2,0,2,1,5,1,0,0,1,0,0,0,0,0,0,1,0,1,0,1,0,0,0,3,1,0,False
1090,..\projects\antlr4-4.11.0\tool\src\org\antlr\v4\gui\PostScriptDocument.java,org.antlr.v4.gui.PostScriptDocument,StringBuilder header(),"/**
 * Compute the header separately because we need to wait for the bounding box
 */
protected StringBuilder header() {
    StringBuilder b = new StringBuilder();
    b.append(""%!PS-Adobe-3.0 EPSF-3.0\n"");
    b.append(boundingBox).append(""\n"");
    b.append(""0.3 setlinewidth\n"");
    b.append(""%% x y w h highlight\n"" + ""/highlight {\n"" + ""        4 dict begin\n"" + ""        /h exch def\n"" + ""        /w exch def\n"" + ""        /y exch def\n"" + ""        /x exch def\n"" + ""        gsave\n"" + ""        newpath\n"" + ""        x y moveto\n"" + ""        0 h rlineto     % up to left corner\n"" + ""        w 0 rlineto     % to upper right corner\n"" + ""        0 h neg rlineto % to lower right corner\n"" + ""        w neg 0 rlineto % back home to lower left corner\n"" + ""        closepath\n"" + ""        .95 .83 .82 setrgbcolor\n"" + ""        fill\n"" + ""        grestore\n"" + ""        end\n"" + ""} def\n"");
    return b;
}","/**
 * Compute the header separately because we need to wait for the bounding box
 */
", ,/** * Compute the header separately because we need to wait for the bounding box */,75,102,[0],0,[0],0,[0],0,0,0,0,header(),org.antlr.v4.gui.PostScriptDocument,header/0,False,75,0,2,2,0,1,1,8,1,1,0,1,0,0,0,0,0,0,23,0,1,1,0,0,0,0,36,4,0,True
1091,..\projects\antlr4-4.11.0\tool\src\org\antlr\v4\gui\PostScriptDocument.java,org.antlr.v4.gui.PostScriptDocument,"void highlight(double, double, double, double)","/**
 * Make red box
 */
public void highlight(double x, double y, double width, double height) {
    ps.append(String.format(Locale.US, ""%1.3f %1.3f %1.3f %1.3f highlight\n"", x, y, width, height));
}","/**
 * Make red box
 */
", ,/** * Make red box */,143,145,[0],0,[0],0,[0],0,0,0,0,"highlight(double, double, double, double)",org.antlr.v4.gui.PostScriptDocument,"highlight/4[double,double,double,double]",False,143,0,1,1,0,1,2,3,0,0,4,2,0,0,0,0,0,0,1,0,0,0,0,0,0,0,5,1,0,True
1092,..\projects\antlr4-4.11.0\tool\src\org\antlr\v4\gui\PostScriptDocument.java,org.antlr.v4.gui.PostScriptDocument,"void text(String, double, double)","// public void rarrow(double x, double y) {
// ps.append(String.format(Locale.US, ""%1.3f %1.3f rarrow\n"", x,y));
// }
// 
// public void darrow(double x, double y) {
// ps.append(String.format(Locale.US, ""%1.3f %1.3f darrow\n"", x,y));
// }
public void text(String s, double x, double y) {
    StringBuilder buf = new StringBuilder();
    // escape \, (, ): \\,  \(,  \)
    for (char c : s.toCharArray()) {
        switch(c) {
            case '\\':
            case '(':
            case ')':
                buf.append('\\');
                buf.append(c);
                break;
            default:
                buf.append(c);
                break;
        }
    }
    s = buf.toString();
    move(x, y);
    ps.append(String.format(Locale.US, ""(%s) show\n"", s));
    stroke();
}", ,"// escape \, (, ): \\,  \(,  \)
","// public void rarrow(double x, double y) {// ps.append(String.format(Locale.US, ""%1.3f %1.3f rarrow\n"", x,y));// }//// public void darrow(double x, double y) {// ps.append(String.format(Locale.US, ""%1.3f %1.3f darrow\n"", x,y));// }[[SEP]]// escape \, (, ): \\,  \(,  \)",159,179,[0],0,[0],0,"[0, 0]",0,0,0,0,"text(String, double, double)",org.antlr.v4.gui.PostScriptDocument,"text/3[java.lang.String,double,double]",False,159,1,3,1,2,5,7,20,0,1,3,7,2,1,1,0,0,0,1,0,2,0,2,0,0,0,9,1,0,False
1093,..\projects\antlr4-4.11.0\tool\src\org\antlr\v4\gui\PostScriptDocument.java,org.antlr.v4.gui.PostScriptDocument,double getWidth(char),"// courier new: wid/hei 7.611979	10.0625
/**
 * All chars are 600 thousands of an 'em' wide if courier
 */
public double getWidth(char c) {
    return fontMetrics.getWidth(c, fontSize);
}","/**
 * All chars are 600 thousands of an 'em' wide if courier
 */
", ,// courier new: wid/hei 7.611979	10.0625[[SEP]]/** * All chars are 600 thousands of an 'em' wide if courier */,183,183,[0],0,[0],0,"[0, 0]",0,0,0,0,getWidth(char),org.antlr.v4.gui.PostScriptDocument,getWidth/1[char],False,183,1,1,0,1,1,1,3,1,0,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,11,1,0,True
1094,..\projects\antlr4-4.11.0\tool\src\org\antlr\v4\gui\TestRig.java,org.antlr.v4.gui.TestRig,void process(),"public void process() throws Exception {
    // System.out.println(""exec ""+grammarName+"".""+startRuleName);
    String lexerName = grammarName + ""Lexer"";
    ClassLoader cl = Thread.currentThread().getContextClassLoader();
    Class<? extends Lexer> lexerClass = null;
    try {
        lexerClass = cl.loadClass(lexerName).asSubclass(Lexer.class);
    } catch (java.lang.ClassNotFoundException cnfe) {
        // might be pure lexer grammar; no Lexer suffix then
        lexerName = grammarName;
        try {
            lexerClass = cl.loadClass(lexerName).asSubclass(Lexer.class);
        } catch (ClassNotFoundException cnfe2) {
            System.err.println(""Can't load "" + lexerName + "" as lexer or parser"");
            return;
        }
    }
    Constructor<? extends Lexer> lexerCtor = lexerClass.getConstructor(CharStream.class);
    Lexer lexer = lexerCtor.newInstance((CharStream) null);
    Class<? extends Parser> parserClass = null;
    Parser parser = null;
    if (!startRuleName.equals(LEXER_START_RULE_NAME)) {
        String parserName = grammarName + ""Parser"";
        parserClass = cl.loadClass(parserName).asSubclass(Parser.class);
        Constructor<? extends Parser> parserCtor = parserClass.getConstructor(TokenStream.class);
        parser = parserCtor.newInstance((TokenStream) null);
    }
    Charset charset = (encoding == null ? Charset.defaultCharset() : Charset.forName(encoding));
    if (inputFiles.size() == 0) {
        CharStream charStream = CharStreams.fromStream(System.in, charset);
        process(lexer, parserClass, parser, charStream);
        return;
    }
    for (String inputFile : inputFiles) {
        CharStream charStream = CharStreams.fromPath(Paths.get(inputFile), charset);
        if (inputFiles.size() > 1) {
            System.err.println(inputFile);
        }
        process(lexer, parserClass, parser, charStream);
    }
}", ,"// System.out.println(""exec ""+grammarName+"".""+startRuleName);
[[SEP]]// might be pure lexer grammar; no Lexer suffix then
","// System.out.println(""exec ""+grammarName+"".""+startRuleName);[[SEP]]// might be pure lexer grammar; no Lexer suffix then",123,168,[0],0,"[0, 0]",0,"[0, 0]",0,0,0,0,process(),org.antlr.v4.gui.TestRig,process/0,False,123,6,4,1,3,8,16,41,2,12,0,16,1,1,1,2,2,1,4,2,17,3,2,0,0,0,41,1,0,False
1095,..\projects\antlr4-4.11.0\tool\src\org\antlr\v4\gui\TestRig.java,org.antlr.v4.gui.TestRig,"void process(Lexer, Class<? extends Parser>, Parser, CharStream)","protected void process(Lexer lexer, Class<? extends Parser> parserClass, Parser parser, CharStream input) throws IOException, IllegalAccessException, InvocationTargetException, PrintException {
    lexer.setInputStream(input);
    CommonTokenStream tokens = new CommonTokenStream(lexer);
    tokens.fill();
    if (showTokens) {
        for (Token tok : tokens.getTokens()) {
            if (tok instanceof CommonToken) {
                System.out.println(((CommonToken) tok).toString(lexer));
            } else {
                System.out.println(tok.toString());
            }
        }
    }
    if (startRuleName.equals(LEXER_START_RULE_NAME))
        return;
    if (diagnostics) {
        parser.addErrorListener(new DiagnosticErrorListener());
        parser.getInterpreter().setPredictionMode(PredictionMode.LL_EXACT_AMBIG_DETECTION);
    }
    if (printTree || gui || psFile != null) {
        parser.setBuildParseTree(true);
    }
    if (SLL) {
        // overrides diagnostics
        parser.getInterpreter().setPredictionMode(PredictionMode.SLL);
    }
    parser.setTokenStream(tokens);
    parser.setTrace(trace);
    try {
        Method startRule = parserClass.getMethod(startRuleName);
        ParserRuleContext tree = (ParserRuleContext) startRule.invoke(parser, (Object[]) null);
        if (printTree) {
            System.out.println(tree.toStringTree(parser));
        }
        if (gui) {
            Trees.inspect(tree, parser);
        }
        if (psFile != null) {
            // Generate postscript
            Trees.save(tree, parser, psFile);
        }
    } catch (NoSuchMethodException nsme) {
        System.err.println(""No method for rule "" + startRuleName + "" or it has arguments"");
    }
}", ,"// overrides diagnostics
[[SEP]]// Generate postscript
",// overrides diagnostics[[SEP]]// Generate postscript,170,222,[0],0,"[0, 0]",0,"[0, 0]",0,0,0,0,"process(Lexer, Class<?Parser>, Parser, CharStream)",org.antlr.v4.gui.TestRig,"process/4[org.antlr.v4.runtime.Lexer,java.lang.Class<? extends org.antlr.v4.runtime.Parser>,org.antlr.v4.runtime.Parser,org.antlr.v4.runtime.CharStream]",False,170,13,16,1,15,14,18,44,1,3,4,18,0,0,1,2,1,1,2,0,3,1,3,0,0,0,52,4,0,False
1096,..\projects\antlr4-4.11.0\tool\src\org\antlr\v4\gui\TreePostScriptGenerator.java,org.antlr.v4.gui.TreePostScriptGenerator,TreeForTreeLayout<Tree> getTreeLayoutAdaptor(Tree),"/**
 * Get an adaptor for root that indicates how to walk ANTLR trees.
 *  Override to change the adapter from the default of {@link TreeLayoutAdaptor}
 */
public TreeForTreeLayout<Tree> getTreeLayoutAdaptor(Tree root) {
    return new TreeLayoutAdaptor(root);
}","/**
 * Get an adaptor for root that indicates how to walk ANTLR trees.
 *  Override to change the adapter from the default of {@link TreeLayoutAdaptor}
 */
", ,/** * Get an adaptor for root that indicates how to walk ANTLR trees. *  Override to change the adapter from the default of {@link TreeLayoutAdaptor} */,74,76,[0],0,[0],0,[0],0,0,0,0,getTreeLayoutAdaptor(Tree),org.antlr.v4.gui.TreePostScriptGenerator,getTreeLayoutAdaptor/1[org.antlr.v4.runtime.tree.Tree],False,74,3,2,1,1,1,0,3,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,24,1,0,True
1097,..\projects\antlr4-4.11.0\tool\src\org\antlr\v4\gui\TreePostScriptGenerator.java,org.antlr.v4.gui.TreePostScriptGenerator,String getPS(),"public String getPS() {
    // generate the edges and boxes (with text)
    generateEdges(getTree().getRoot());
    for (Tree node : treeLayout.getNodeBounds().keySet()) {
        generateNode(node);
    }
    Dimension size = treeLayout.getBounds().getBounds().getSize();
    doc.boundingBox(size.width, size.height);
    doc.close();
    return doc.getPS();
}", ,"// generate the edges and boxes (with text)
",// generate the edges and boxes (with text),78,89,[0],0,[0],0,[0],0,0,0,0,getPS(),org.antlr.v4.gui.TreePostScriptGenerator,getPS/0,False,78,4,10,1,9,2,12,10,1,1,0,12,3,4,1,0,0,0,0,0,1,0,1,0,0,0,10,1,0,False
1098,..\projects\antlr4-4.11.0\tool\src\org\antlr\v4\gui\TreePostScriptGenerator.java,org.antlr.v4.gui.TreePostScriptGenerator,void generateEdges(Tree),"protected void generateEdges(Tree parent) {
    if (!getTree().isLeaf(parent)) {
        Rectangle2D.Double parentBounds = getBoundsOfNode(parent);
        // System.out.println(""%% parent(""+getText(parent)+"")=""+parentBounds);
        double x1 = parentBounds.getCenterX();
        double y1 = parentBounds.y;
        for (Tree child : getChildren(parent)) {
            Rectangle2D.Double childBounds = getBoundsOfNode(child);
            // System.out.println(""%% child(""+getText(child)+"")=""+childBounds);
            double x2 = childBounds.getCenterX();
            double y2 = childBounds.getMaxY();
            doc.line(x1, y1, x2, y2);
            generateEdges(child);
        }
    }
}", ,"// System.out.println(""%% parent(""+getText(parent)+"")=""+parentBounds);
[[SEP]]// System.out.println(""%% child(""+getText(child)+"")=""+childBounds);
","// System.out.println(""%% parent(""+getText(parent)+"")=""+parentBounds);[[SEP]]// System.out.println(""%% child(""+getText(child)+"")=""+childBounds);",91,106,[0],0,"[0, 0]",0,"[0, 0]",0,0,0,0,generateEdges(Tree),org.antlr.v4.gui.TreePostScriptGenerator,generateEdges/1[org.antlr.v4.runtime.tree.Tree],False,91,4,8,2,6,3,8,14,0,6,1,8,4,2,1,0,0,0,0,0,6,0,2,0,0,0,14,4,0,False
1099,..\projects\antlr4-4.11.0\tool\src\org\antlr\v4\gui\TreePostScriptGenerator.java,org.antlr.v4.gui.TreePostScriptGenerator,void generateNode(Tree),"protected void generateNode(Tree t) {
    // draw the text on top of the box (possibly multiple lines)
    String[] lines = getText(t).split(""\n"");
    Rectangle2D.Double box = getBoundsOfNode(t);
    // for debugging, turn this on to see boundingbox of nodes
    // doc.rect(box.x, box.y, box.width, box.height);
    // make error nodes from parse tree red by default
    if (t instanceof ErrorNode) {
        doc.highlight(box.x, box.y, box.width, box.height);
    }
    double x = box.x + nodeWidthPadding;
    double y = box.y + nodeHeightPaddingBelow;
    for (int i = 0; i < lines.length; i++) {
        doc.text(lines[i], x, y);
        y += doc.getLineHeight();
    }
}", ,"// for debugging, turn this on to see boundingbox of nodes
[[SEP]]// doc.rect(box.x, box.y, box.width, box.height);
[[SEP]]// draw the text on top of the box (possibly multiple lines)
[[SEP]]// make error nodes from parse tree red by default
","// draw the text on top of the box (possibly multiple lines)[[SEP]]// for debugging, turn this on to see boundingbox of nodes// doc.rect(box.x, box.y, box.width, box.height);// make error nodes from parse tree red by default",108,124,[0],0,"[0, 0, 0, 0]",0,"[0, 0]",0,0,0,0,generateNode(Tree),org.antlr.v4.gui.TreePostScriptGenerator,generateNode/1[org.antlr.v4.runtime.tree.Tree],False,108,4,6,1,5,3,6,13,0,5,1,6,2,1,1,0,0,0,1,1,6,2,1,0,0,0,19,4,0,False
1100,..\projects\antlr4-4.11.0\tool\src\org\antlr\v4\gui\TreeViewer.java,org.antlr.v4.gui.TreeViewer,"void paintBox(Graphics, Tree)","protected void paintBox(Graphics g, Tree tree) {
    Rectangle2D.Double box = getBoundsOfNode(tree);
    // draw the box in the background
    boolean ruleFailedAndMatchedNothing = false;
    if (tree instanceof ParserRuleContext) {
        ParserRuleContext ctx = (ParserRuleContext) tree;
        ruleFailedAndMatchedNothing = ctx.exception != null && ctx.stop != null && ctx.stop.getTokenIndex() < ctx.start.getTokenIndex();
    }
    if (isHighlighted(tree) || boxColor != null || tree instanceof ErrorNode || ruleFailedAndMatchedNothing) {
        if (isHighlighted(tree))
            g.setColor(highlightedBoxColor);
        else if (tree instanceof ErrorNode || ruleFailedAndMatchedNothing)
            g.setColor(LIGHT_RED);
        else
            g.setColor(boxColor);
        g.fillRoundRect((int) box.x, (int) box.y, (int) box.width - 1, (int) box.height - 1, arcSize, arcSize);
    }
    if (borderColor != null) {
        g.setColor(borderColor);
        g.drawRoundRect((int) box.x, (int) box.y, (int) box.width - 1, (int) box.height - 1, arcSize, arcSize);
    }
    // draw the text on top of the box (possibly multiple lines)
    g.setColor(textColor);
    String s = getText(tree);
    String[] lines = s.split(""\n"");
    FontMetrics m = getFontMetrics(font);
    int x = (int) box.x + arcSize / 2 + nodeWidthPadding;
    int y = (int) box.y + m.getAscent() + m.getLeading() + 1 + nodeHeightPadding;
    for (int i = 0; i < lines.length; i++) {
        text(g, lines[i], x, y);
        y += m.getHeight();
    }
}", ,"// draw the box in the background
[[SEP]]// draw the text on top of the box (possibly multiple lines)
",// draw the box in the background[[SEP]]// draw the text on top of the box (possibly multiple lines),175,211,[0],0,"[0, 0]",0,"[0, 0]",0,0,0,0,"paintBox(Graphics, Tree)",org.antlr.v4.gui.TreeViewer,"paintBox/2[java.awt.Graphics,org.antlr.v4.runtime.tree.Tree]",False,175,5,6,1,5,11,13,28,0,9,2,13,4,2,1,4,0,0,1,7,11,8,3,0,0,0,52,4,0,False
1101,..\projects\antlr4-4.11.0\tool\src\org\antlr\v4\gui\TreeViewer.java,org.antlr.v4.gui.TreeViewer,"void text(Graphics, String, int, int)","public void text(Graphics g, String s, int x, int y) {
    // System.out.println(""drawing '""+s+""' @ ""+x+"",""+y);
    s = Utils.escapeWhitespace(s, true);
    g.drawString(s, x, y);
}", ,"// System.out.println(""drawing '""+s+""' @ ""+x+"",""+y);
","// System.out.println(""drawing '""+s+""' @ ""+x+"",""+y);",213,217,[0],0,[0],0,[0],0,0,0,0,"text(Graphics, String, int, int)",org.antlr.v4.gui.TreeViewer,"text/4[java.awt.Graphics,java.lang.String,int,int]",False,213,1,2,1,1,1,2,4,0,0,4,2,0,0,0,0,0,0,0,0,1,0,0,0,0,0,4,1,0,False
1102,..\projects\antlr4-4.11.0\tool\src\org\antlr\v4\gui\TreeViewer.java,org.antlr.v4.gui.TreeViewer,void paint(Graphics),"@Override
public void paint(Graphics g) {
    super.paint(g);
    if (treeLayout == null) {
        return;
    }
    Graphics2D g2 = (Graphics2D) g;
    // anti-alias the lines
    g2.setRenderingHint(RenderingHints.KEY_ANTIALIASING, RenderingHints.VALUE_ANTIALIAS_ON);
    // Anti-alias the text
    g2.setRenderingHint(RenderingHints.KEY_TEXT_ANTIALIASING, RenderingHints.VALUE_TEXT_ANTIALIAS_ON);
    // AffineTransform at = g2.getTransform();
    // g2.scale(
    // (double) this.getWidth() / 400,
    // (double) this.getHeight() / 400);
    // 
    // g2.setTransform(at);
    paintEdges(g, getTree().getRoot());
    // paint the boxes
    for (Tree Tree : treeLayout.getNodeBounds().keySet()) {
        paintBox(g, Tree);
    }
}", ,"// AffineTransform at = g2.getTransform();
[[SEP]]// g2.scale(
[[SEP]]// (double) this.getWidth() / 400,
[[SEP]]// (double) this.getHeight() / 400);
[[SEP]]// 
[[SEP]]// g2.setTransform(at);
[[SEP]]// anti-alias the lines
[[SEP]]// Anti-alias the text
[[SEP]]// paint the boxes
","// anti-alias the lines[[SEP]]// Anti-alias the text[[SEP]]// AffineTransform at = g2.getTransform();// g2.scale(// (double) this.getWidth() / 400,// (double) this.getHeight() / 400);//// g2.setTransform(at);[[SEP]]// paint the boxes",219,249,[0],0,"[0, 0, 0, 0, 0, 0, 0, 0, 0]",0,"[0, 0, 0, 0]",0,0,0,0,paint(Graphics),org.antlr.v4.gui.TreeViewer,paint/1[java.awt.Graphics],False,220,3,6,1,5,3,8,13,1,1,1,8,3,4,1,1,0,0,0,0,1,0,1,0,0,0,12,1,0,False
1103,..\projects\antlr4-4.11.0\tool\src\org\antlr\v4\gui\TreeViewer.java,org.antlr.v4.gui.TreeViewer,"void generateBox(Writer, Tree)","protected void generateBox(Writer writer, Tree parent) throws IOException {
    // draw the box in the background
    Rectangle2D.Double box = getBoundsOfNode(parent);
    writer.write(rect("""" + box.x, """" + box.y, """" + box.width, """" + box.height, ""fill:orange; stroke:rgb(0,0,0);"", ""rx=\""1\""""));
    // draw the text on top of the box (possibly multiple lines)
    String line = getText(parent).replace(""<"", ""&lt;"").replace("">"", ""&gt;"");
    int fontSize = 10;
    int x = (int) box.x + 2;
    int y = (int) box.y + fontSize - 1;
    String style = String.format(""font-family:sans-serif;font-size:%dpx;"", fontSize);
    writer.write(text("""" + x, """" + y, style, line));
}", ,"// draw the box in the background
[[SEP]]// draw the text on top of the box (possibly multiple lines)
",// draw the box in the background[[SEP]]// draw the text on top of the box (possibly multiple lines),268,283,[0],0,"[0, 0]",0,"[0, 0]",0,0,0,0,"generateBox(Writer, Tree)",org.antlr.v4.gui.TreeViewer,"generateBox/2[java.io.Writer,org.antlr.v4.runtime.tree.Tree]",False,268,2,5,1,4,1,7,10,0,6,2,7,4,1,0,0,0,0,13,3,6,9,0,0,0,0,24,4,0,False
1104,..\projects\antlr4-4.11.0\tool\src\org\antlr\v4\gui\TreeViewer.java,org.antlr.v4.gui.TreeViewer,JFrame showInDialog(TreeViewer),"protected static JFrame showInDialog(final TreeViewer viewer) {
    final JFrame dialog = new JFrame();
    dialog.setTitle(""Parse Tree Inspector"");
    final Preferences prefs = Preferences.userNodeForPackage(TreeViewer.class);
    // Make new content panes
    final Container mainPane = new JPanel(new BorderLayout(5, 5));
    final Container contentPane = new JPanel(new BorderLayout(0, 0));
    contentPane.setBackground(Color.white);
    // Wrap viewer in scroll pane
    JScrollPane scrollPane = new JScrollPane(viewer);
    // Make the scrollpane (containing the viewer) the center component
    contentPane.add(scrollPane, BorderLayout.CENTER);
    JPanel wrapper = new JPanel(new FlowLayout());
    // Add button to bottom
    JPanel bottomPanel = new JPanel(new BorderLayout(0, 0));
    contentPane.add(bottomPanel, BorderLayout.SOUTH);
    JButton ok = new JButton(""OK"");
    ok.addActionListener(new ActionListener() {

        @Override
        public void actionPerformed(ActionEvent e) {
            dialog.dispatchEvent(new WindowEvent(dialog, WindowEvent.WINDOW_CLOSING));
        }
    });
    wrapper.add(ok);
    // Add an export-to-png button right of the ""OK"" button
    JButton png = new JButton(""Export as PNG"");
    png.addActionListener(new ActionListener() {

        @Override
        public void actionPerformed(ActionEvent e) {
            generatePNGFile(viewer, dialog);
        }
    });
    wrapper.add(png);
    // Add an export-to-png button right of the ""OK"" button
    JButton svg = new JButton(""Export as SVG"");
    svg.addActionListener(new ActionListener() {

        @Override
        public void actionPerformed(ActionEvent e) {
            generateSVGFile(viewer, dialog);
        }
    });
    wrapper.add(svg);
    bottomPanel.add(wrapper, BorderLayout.SOUTH);
    // Add scale slider
    double lastKnownViewerScale = prefs.getDouble(DIALOG_VIEWER_SCALE_PREFS_KEY, viewer.getScale());
    viewer.setScale(lastKnownViewerScale);
    int sliderValue = (int) ((lastKnownViewerScale - 1.0) * 1000);
    final JSlider scaleSlider = new JSlider(JSlider.HORIZONTAL, -999, 1000, sliderValue);
    scaleSlider.addChangeListener(new ChangeListener() {

        @Override
        public void stateChanged(ChangeEvent e) {
            int v = scaleSlider.getValue();
            viewer.setScale(v / 1000.0 + 1.0);
        }
    });
    bottomPanel.add(scaleSlider, BorderLayout.CENTER);
    // Add a JTree representing the parser tree of the input.
    JPanel treePanel = new JPanel(new BorderLayout(5, 5));
    // An ""empty"" icon that will be used for the JTree's nodes.
    Icon empty = new EmptyIcon();
    UIManager.put(""Tree.closedIcon"", empty);
    UIManager.put(""Tree.openIcon"", empty);
    UIManager.put(""Tree.leafIcon"", empty);
    Tree parseTreeRoot = viewer.getTree().getRoot();
    TreeNodeWrapper nodeRoot = new TreeNodeWrapper(parseTreeRoot, viewer);
    fillTree(nodeRoot, parseTreeRoot, viewer);
    final JTree tree = new JTree(nodeRoot);
    tree.getSelectionModel().setSelectionMode(TreeSelectionModel.SINGLE_TREE_SELECTION);
    tree.addTreeSelectionListener(new TreeSelectionListener() {

        @Override
        public void valueChanged(TreeSelectionEvent e) {
            JTree selectedTree = (JTree) e.getSource();
            TreePath path = selectedTree.getSelectionPath();
            if (path != null) {
                TreeNodeWrapper treeNode = (TreeNodeWrapper) path.getLastPathComponent();
                // Set the clicked AST.
                viewer.setTree((Tree) treeNode.getUserObject());
            }
        }
    });
    treePanel.add(new JScrollPane(tree));
    // Create the pane for both the JTree and the AST
    final JSplitPane splitPane = new JSplitPane(JSplitPane.HORIZONTAL_SPLIT, treePanel, contentPane);
    mainPane.add(splitPane, BorderLayout.CENTER);
    dialog.setContentPane(mainPane);
    // make viz
    WindowListener exitListener = new WindowAdapter() {

        @Override
        public void windowClosing(WindowEvent e) {
            prefs.putInt(DIALOG_WIDTH_PREFS_KEY, (int) dialog.getSize().getWidth());
            prefs.putInt(DIALOG_HEIGHT_PREFS_KEY, (int) dialog.getSize().getHeight());
            prefs.putDouble(DIALOG_X_PREFS_KEY, dialog.getLocationOnScreen().getX());
            prefs.putDouble(DIALOG_Y_PREFS_KEY, dialog.getLocationOnScreen().getY());
            prefs.putInt(DIALOG_DIVIDER_LOC_PREFS_KEY, splitPane.getDividerLocation());
            prefs.putDouble(DIALOG_VIEWER_SCALE_PREFS_KEY, viewer.getScale());
            dialog.setVisible(false);
            dialog.dispose();
        }
    };
    dialog.addWindowListener(exitListener);
    dialog.setDefaultCloseOperation(JFrame.DO_NOTHING_ON_CLOSE);
    int width = prefs.getInt(DIALOG_WIDTH_PREFS_KEY, 600);
    int height = prefs.getInt(DIALOG_HEIGHT_PREFS_KEY, 500);
    dialog.setPreferredSize(new Dimension(width, height));
    dialog.pack();
    // After pack(): set the divider at 1/3 (200/600) of the frame.
    int dividerLocation = prefs.getInt(DIALOG_DIVIDER_LOC_PREFS_KEY, 200);
    splitPane.setDividerLocation(dividerLocation);
    if (prefs.getDouble(DIALOG_X_PREFS_KEY, -1) != -1) {
        dialog.setLocation((int) prefs.getDouble(DIALOG_X_PREFS_KEY, 100), (int) prefs.getDouble(DIALOG_Y_PREFS_KEY, 100));
    } else {
        dialog.setLocationRelativeTo(null);
    }
    dialog.setVisible(true);
    return dialog;
}", ,"// Make new content panes
[[SEP]]// Wrap viewer in scroll pane
[[SEP]]// Make the scrollpane (containing the viewer) the center component
[[SEP]]// Add button to bottom
[[SEP]]// Add an export-to-png button right of the ""OK"" button
[[SEP]]// Add an export-to-png button right of the ""OK"" button
[[SEP]]// Add scale slider
[[SEP]]// Add a JTree representing the parser tree of the input.
[[SEP]]// An ""empty"" icon that will be used for the JTree's nodes.
[[SEP]]// Set the clicked AST.
[[SEP]]// Create the pane for both the JTree and the AST
[[SEP]]// make viz
[[SEP]]// After pack(): set the divider at 1/3 (200/600) of the frame.
","// Make new content panes[[SEP]]// Wrap viewer in scroll pane[[SEP]]// Make the scrollpane (containing the viewer) the center component[[SEP]]// Add button to bottom[[SEP]]// Add an export-to-png button right of the ""OK"" button[[SEP]]// Add an export-to-png button right of the ""OK"" button[[SEP]]// Add scale slider[[SEP]]// Add a JTree representing the parser tree of the input.[[SEP]]// An ""empty"" icon that will be used for the JTree's nodes.[[SEP]]// Set the clicked AST.[[SEP]]// Create the pane for both the JTree and the AST[[SEP]]// make viz[[SEP]]// After pack(): set the divider at 1/3 (200/600) of the frame.",331,488,[0],0,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]",0,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]",0,0,0,0,showInDialog(TreeViewer),org.antlr.v4.gui.TreeViewer,showInDialog/1[org.antlr.v4.gui.TreeViewer],False,331,5,9,1,8,2,27,104,1,23,1,27,4,3,0,1,0,2,7,19,23,2,1,6,0,0,82,12,0,False
1105,..\projects\antlr4-4.11.0\tool\src\org\antlr\v4\gui\TreeViewer.java,org.antlr.v4.gui.TreeViewer,"void generatePNGFile(TreeViewer, JFrame)","private static void generatePNGFile(TreeViewer viewer, JFrame dialog) {
    BufferedImage bi = new BufferedImage(viewer.getSize().width, viewer.getSize().height, BufferedImage.TYPE_INT_ARGB);
    Graphics g = bi.createGraphics();
    viewer.paint(g);
    g.dispose();
    try {
        JFileChooser fileChooser = getFileChooser("".png"", ""PNG files"");
        int returnValue = fileChooser.showSaveDialog(dialog);
        if (returnValue == JFileChooser.APPROVE_OPTION) {
            File pngFile = fileChooser.getSelectedFile();
            ImageIO.write(bi, ""png"", pngFile);
            try {
                // Try to open the parent folder using the OS' native file manager.
                Desktop.getDesktop().open(pngFile.getParentFile());
            } catch (Exception ex) {
                // We could not launch the file manager: just show a popup that we
                // succeeded in saving the PNG file.
                JOptionPane.showMessageDialog(dialog, ""Saved PNG to: "" + pngFile.getAbsolutePath());
                ex.printStackTrace();
            }
        }
    } catch (Exception ex) {
        JOptionPane.showMessageDialog(dialog, ""Could not export to PNG: "" + ex.getMessage(), ""Error"", JOptionPane.ERROR_MESSAGE);
        ex.printStackTrace();
    }
}", ,"// Try to open the parent folder using the OS' native file manager.
[[SEP]]// We could not launch the file manager: just show a popup that we
[[SEP]]// succeeded in saving the PNG file.
",// Try to open the parent folder using the OS' native file manager.[[SEP]]// We could not launch the file manager: just show a popup that we// succeeded in saving the PNG file.,490,526,[0],0,"[0, 0, 0]",0,"[0, 0]",0,0,0,0,"generatePNGFile(TreeViewer, JFrame)",org.antlr.v4.gui.TreeViewer,"generatePNGFile/2[org.antlr.v4.gui.TreeViewer,javax.swing.JFrame]",False,490,1,3,1,2,4,16,25,0,5,2,16,2,6,0,1,2,0,6,0,5,2,3,0,0,0,25,10,0,False
1106,..\projects\antlr4-4.11.0\tool\src\org\antlr\v4\gui\TreeViewer.java,org.antlr.v4.gui.TreeViewer,"void generateSVGFile(TreeViewer, JFrame)","private static void generateSVGFile(TreeViewer viewer, JFrame dialog) {
    try {
        JFileChooser fileChooser = getFileChooser("".svg"", ""SVG files"");
        int returnValue = fileChooser.showSaveDialog(dialog);
        if (returnValue == JFileChooser.APPROVE_OPTION) {
            File svgFile = fileChooser.getSelectedFile();
            // save the new svg file here!
            BufferedWriter writer = new BufferedWriter(new FileWriter(svgFile));
            // HACK: multiplying with 1.1 should be replaced wit an accurate number
            writer.write(""<svg width=\"""" + viewer.getSize().getWidth() * 1.1 + ""\"" height=\"""" + viewer.getSize().getHeight() * 1.1 + ""\"" xmlns=\""http://www.w3.org/2000/svg\"" xmlns:xlink=\""http://www.w3.org/1999/xlink\"">"");
            viewer.paintSVG(writer);
            writer.write(""</svg>"");
            writer.flush();
            writer.close();
            try {
                // Try to open the parent folder using the OS' native file manager.
                Desktop.getDesktop().open(svgFile.getParentFile());
            } catch (Exception ex) {
                // We could not launch the file manager: just show a popup that we
                // succeeded in saving the PNG file.
                JOptionPane.showMessageDialog(dialog, ""Saved SVG to: "" + svgFile.getAbsolutePath());
                ex.printStackTrace();
            }
        }
    } catch (Exception ex) {
        JOptionPane.showMessageDialog(dialog, ""Could not export to SVG: "" + ex.getMessage(), ""Error"", JOptionPane.ERROR_MESSAGE);
        ex.printStackTrace();
    }
}", ,"// save the new svg file here!
[[SEP]]// HACK: multiplying with 1.1 should be replaced wit an accurate number
[[SEP]]// Try to open the parent folder using the OS' native file manager.
[[SEP]]// We could not launch the file manager: just show a popup that we
[[SEP]]// succeeded in saving the PNG file.
","// save the new svg file here![[SEP]]// HACK: multiplying with 1.1 should be replaced wit an accurate number[[SEP]]//www.w3.org/2000/svg\"" xmlns:xlink=\""http://www.w3.org/1999/xlink\"">"");[[SEP]]// Try to open the parent folder using the OS' native file manager.[[SEP]]// We could not launch the file manager: just show a popup that we// succeeded in saving the PNG file.",555,589,[0],0,"[0, 1, 0, 0, 0]",1,"[0, 1, 0, 0, 0]",1,1,1,1,"generateSVGFile(TreeViewer, JFrame)",org.antlr.v4.gui.TreeViewer,"generateSVGFile/2[org.antlr.v4.gui.TreeViewer,javax.swing.JFrame]",False,555,1,3,1,2,4,18,26,0,4,2,18,2,5,0,1,2,0,9,2,4,8,3,0,0,0,26,10,0,False
1107,..\projects\antlr4-4.11.0\tool\src\org\antlr\v4\gui\TreeViewer.java,org.antlr.v4.gui.TreeViewer,File generateNonExistingFile(String),"private static File generateNonExistingFile(String extension) {
    final String parent = ""."";
    final String name = ""antlr4_parse_tree"";
    File file = new File(parent, name + extension);
    int counter = 1;
    // Keep looping until we create a File that does not yet exist.
    while (file.exists()) {
        file = new File(parent, name + ""_"" + counter + extension);
        counter++;
    }
    return file;
}", ,"// Keep looping until we create a File that does not yet exist.
",// Keep looping until we create a File that does not yet exist.,591,607,[0],0,[0],0,[0],0,0,0,0,generateNonExistingFile(String),org.antlr.v4.gui.TreeViewer,generateNonExistingFile/1[java.lang.String],False,591,0,1,1,0,2,1,11,1,4,1,1,0,0,1,0,0,0,3,1,5,2,1,0,0,0,9,10,0,False
1108,..\projects\antlr4-4.11.0\tool\src\org\antlr\v4\gui\TreeViewer.java,org.antlr.v4.gui.TreeViewer,void addHighlightedNodes(Collection<Tree>),"/**
 * Slow for big lists of highlighted nodes
 */
public void addHighlightedNodes(Collection<Tree> nodes) {
    highlightedNodes = new ArrayList<Tree>();
    highlightedNodes.addAll(nodes);
}","/**
 * Slow for big lists of highlighted nodes
 */
", ,/** * Slow for big lists of highlighted nodes */,708,711,[0],0,[0],0,[0],0,0,0,0,addHighlightedNodes(Collection<Tree>),org.antlr.v4.gui.TreeViewer,addHighlightedNodes/1[java.util.Collection<org.antlr.v4.runtime.tree.Tree>],False,708,1,0,0,0,1,1,4,0,0,1,1,0,0,0,0,0,0,0,0,1,0,0,0,0,0,9,1,0,True
1109,..\projects\antlr4-4.11.0\tool\src\org\antlr\v4\gui\TreeViewer.java,org.antlr.v4.gui.TreeViewer,void removeHighlightedNodes(Collection<Tree>),"public void removeHighlightedNodes(Collection<Tree> nodes) {
    if (highlightedNodes != null) {
        // only remove exact objects defined by ==, not equals()
        for (Tree t : nodes) {
            int i = getHighlightedNodeIndex(t);
            if (i >= 0)
                highlightedNodes.remove(i);
        }
    }
}", ,"// only remove exact objects defined by ==, not equals()
","// only remove exact objects defined by ==, not equals()",713,721,[0],0,[0],0,[0],0,0,0,0,removeHighlightedNodes(Collection<Tree>),org.antlr.v4.gui.TreeViewer,removeHighlightedNodes/1[java.util.Collection<org.antlr.v4.runtime.tree.Tree>],False,713,2,1,0,1,4,2,8,0,1,1,2,1,1,1,1,0,0,0,1,1,0,3,0,0,0,12,1,0,False
1110,..\projects\antlr4-4.11.0\tool\src\org\antlr\v4\gui\TreeViewer.java,org.antlr.v4.gui.TreeViewer,void setTree(Tree),"public void setTree(Tree root) {
    if (root != null) {
        // compare node identity
        boolean useIdentity = true;
        this.treeLayout = new TreeLayout<Tree>(getTreeLayoutAdaptor(root), new TreeViewer.VariableExtentProvide(this), new DefaultConfiguration<Tree>(gapBetweenLevels, gapBetweenNodes), useIdentity);
        // Let the UI display this new AST.
        updatePreferredSize();
    } else {
        this.treeLayout = null;
        repaint();
    }
}", ,"// compare node identity
[[SEP]]// Let the UI display this new AST.
",// compare node identity[[SEP]]// Let the UI display this new AST.,790,806,[0],0,"[0, 0]",0,"[0, 0]",0,0,0,0,setTree(Tree),org.antlr.v4.gui.TreeViewer,setTree/1[org.antlr.v4.runtime.tree.Tree],False,790,5,7,2,5,2,3,11,0,1,1,3,2,2,0,1,0,0,0,0,3,0,1,0,0,0,14,1,0,False
1111,..\projects\antlr4-4.11.0\tool\src\org\antlr\v4\gui\TreeViewer.java,org.antlr.v4.gui.TreeViewer,TreeForTreeLayout<Tree> getTreeLayoutAdaptor(Tree),"/**
 * Get an adaptor for root that indicates how to walk ANTLR trees.
 *  Override to change the adapter from the default of {@link TreeLayoutAdaptor}
 */
public TreeForTreeLayout<Tree> getTreeLayoutAdaptor(Tree root) {
    return new TreeLayoutAdaptor(root);
}","/**
 * Get an adaptor for root that indicates how to walk ANTLR trees.
 *  Override to change the adapter from the default of {@link TreeLayoutAdaptor}
 */
", ,/** * Get an adaptor for root that indicates how to walk ANTLR trees. *  Override to change the adapter from the default of {@link TreeLayoutAdaptor} */,810,812,[0],0,[0],0,[0],0,0,0,0,getTreeLayoutAdaptor(Tree),org.antlr.v4.gui.TreeViewer,getTreeLayoutAdaptor/1[org.antlr.v4.runtime.tree.Tree],False,810,3,2,1,1,1,0,3,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,24,1,0,True
1112,..\projects\antlr4-4.11.0\tool\src\org\antlr\v4\gui\TreeViewer.java,org.antlr.v4.gui.TreeViewer.EmptyIcon,"void paintIcon(Component, Graphics, int, int)","@Override
public void paintIcon(Component c, Graphics g, int x, int y) {
    /* Do nothing. */
}", ,"/* Do nothing. */
",/* Do nothing. */,857,860,[0],0,[0],0,[0],0,0,0,0,"paintIcon(Component, Graphics, int, int)",org.antlr.v4.gui.TreeViewer$EmptyIcon,"paintIcon/4[java.awt.Component,java.awt.Graphics,int,int]",False,858,0,0,0,0,1,0,2,0,0,4,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,4,1,0,False
1113,..\projects\antlr4-4.11.0\tool\src\org\antlr\v4\gui\Trees.java,org.antlr.v4.gui.Trees,"Future<JFrame> inspect(Tree, List<String>)","/**
 * Call this method to view a parse tree in a dialog box visually.
 */
public static Future<JFrame> inspect(Tree t, List<String> ruleNames) {
    TreeViewer viewer = new TreeViewer(ruleNames, t);
    return viewer.open();
}","/**
 * Call this method to view a parse tree in a dialog box visually.
 */
", ,/** * Call this method to view a parse tree in a dialog box visually. */,24,27,[0],0,[0],0,[0],0,0,0,0,"inspect(Tree, List<String>)",org.antlr.v4.gui.Trees,"inspect/2[org.antlr.v4.runtime.tree.Tree,java.util.List<java.lang.String>]",False,24,2,4,2,2,1,1,4,1,1,2,1,0,0,0,0,0,0,0,0,1,0,0,0,0,0,16,9,0,True
1114,..\projects\antlr4-4.11.0\tool\src\org\antlr\v4\gui\Trees.java,org.antlr.v4.gui.Trees,"Future<JFrame> inspect(Tree, Parser)","/**
 * Call this method to view a parse tree in a dialog box visually.
 */
public static Future<JFrame> inspect(Tree t, Parser parser) {
    List<String> ruleNames = parser != null ? Arrays.asList(parser.getRuleNames()) : null;
    return inspect(t, ruleNames);
}","/**
 * Call this method to view a parse tree in a dialog box visually.
 */
", ,/** * Call this method to view a parse tree in a dialog box visually. */,30,33,[0],0,[0],0,[0],0,0,0,0,"inspect(Tree, Parser)",org.antlr.v4.gui.Trees,"inspect/2[org.antlr.v4.runtime.tree.Tree,org.antlr.v4.runtime.Parser]",False,30,4,3,1,2,2,3,4,1,1,2,3,1,1,0,1,0,0,0,0,1,0,0,0,0,0,16,9,0,True
1115,..\projects\antlr4-4.11.0\tool\src\org\antlr\v4\gui\Trees.java,org.antlr.v4.gui.Trees,"void save(Tree, Parser, String)","/**
 * Save this tree in a postscript file
 */
public static void save(Tree t, Parser parser, String fileName) throws IOException, PrintException {
    List<String> ruleNames = parser != null ? Arrays.asList(parser.getRuleNames()) : null;
    save(t, ruleNames, fileName);
}","/**
 * Save this tree in a postscript file
 */
", ,/** * Save this tree in a postscript file */,36,41,[0],0,[0],0,[0],0,0,0,0,"save(Tree, Parser, String)",org.antlr.v4.gui.Trees,"save/3[org.antlr.v4.runtime.tree.Tree,org.antlr.v4.runtime.Parser,java.lang.String]",False,38,4,3,1,2,2,3,4,0,1,3,3,1,4,0,1,0,0,0,0,1,0,0,0,0,0,15,9,0,True
1116,..\projects\antlr4-4.11.0\tool\src\org\antlr\v4\gui\Trees.java,org.antlr.v4.gui.Trees,"void save(Tree, Parser, String, String, int)","/**
 * Save this tree in a postscript file using a particular font name and size
 */
public static void save(Tree t, Parser parser, String fileName, String fontName, int fontSize) throws IOException {
    List<String> ruleNames = parser != null ? Arrays.asList(parser.getRuleNames()) : null;
    save(t, ruleNames, fileName, fontName, fontSize);
}","/**
 * Save this tree in a postscript file using a particular font name and size
 */
", ,/** * Save this tree in a postscript file using a particular font name and size */,44,50,[0],0,[0],0,[0],0,0,0,0,"save(Tree, Parser, String, String, int)",org.antlr.v4.gui.Trees,"save/5[org.antlr.v4.runtime.tree.Tree,org.antlr.v4.runtime.Parser,java.lang.String,java.lang.String,int]",False,47,4,2,0,2,2,3,4,0,1,5,3,1,3,0,1,0,0,0,0,1,0,0,0,0,0,22,9,0,True
1117,..\projects\antlr4-4.11.0\tool\src\org\antlr\v4\gui\Trees.java,org.antlr.v4.gui.Trees,"void save(Tree, List<String>, String)","/**
 * Save this tree in a postscript file
 */
public static void save(Tree t, List<String> ruleNames, String fileName) throws IOException, PrintException {
    writePS(t, ruleNames, fileName);
}","/**
 * Save this tree in a postscript file
 */
", ,/** * Save this tree in a postscript file */,53,57,[0],0,[0],0,[0],0,0,0,0,"save(Tree, List<String>, String)",org.antlr.v4.gui.Trees,"save/3[org.antlr.v4.runtime.tree.Tree,java.util.List<java.lang.String>,java.lang.String]",False,55,2,2,1,1,1,1,3,0,0,3,1,1,3,0,0,0,0,0,0,0,0,0,0,0,0,14,9,0,True
1118,..\projects\antlr4-4.11.0\tool\src\org\antlr\v4\gui\Trees.java,org.antlr.v4.gui.Trees,"void save(Tree, List<String>, String, String, int)","/**
 * Save this tree in a postscript file using a particular font name and size
 */
public static void save(Tree t, List<String> ruleNames, String fileName, String fontName, int fontSize) throws IOException {
    writePS(t, ruleNames, fileName, fontName, fontSize);
}","/**
 * Save this tree in a postscript file using a particular font name and size
 */
", ,/** * Save this tree in a postscript file using a particular font name and size */,60,66,[0],0,[0],0,[0],0,0,0,0,"save(Tree, List<String>, String, String, int)",org.antlr.v4.gui.Trees,"save/5[org.antlr.v4.runtime.tree.Tree,java.util.List<java.lang.String>,java.lang.String,java.lang.String,int]",False,64,2,2,1,1,1,1,3,0,0,5,1,1,2,0,0,0,0,0,0,0,0,0,0,0,0,21,9,0,True
1119,..\projects\antlr4-4.11.0\tool\src\org\antlr\v4\gui\Trees.java,org.antlr.v4.gui.Trees,"String toStringTree(Tree, TreeTextProvider)","/**
 * Print out a whole tree in LISP form. Arg nodeTextProvider is used on the
 *  node payloads to get the text for the nodes.
 *
 *  @since 4.5.1
 */
public static String toStringTree(Tree t, TreeTextProvider nodeTextProvider) {
    if (t == null)
        return ""null"";
    String s = Utils.escapeWhitespace(nodeTextProvider.getText(t), false);
    if (t.getChildCount() == 0)
        return s;
    StringBuilder buf = new StringBuilder();
    buf.append(""("");
    s = Utils.escapeWhitespace(nodeTextProvider.getText(t), false);
    buf.append(s);
    buf.append(' ');
    for (int i = 0; i < t.getChildCount(); i++) {
        if (i > 0)
            buf.append(' ');
        buf.append(toStringTree(t.getChild(i), nodeTextProvider));
    }
    buf.append("")"");
    return buf.toString();
}","/**
 * Print out a whole tree in LISP form. Arg nodeTextProvider is used on the
 *  node payloads to get the text for the nodes.
 *
 *  @since 4.5.1
 */
", ,/** * Print out a whole tree in LISP form. Arg nodeTextProvider is used on the *  node payloads to get the text for the nodes. * *  @since 4.5.1 */,107,122,[0],0,[0],0,[0],0,0,0,0,"toStringTree(Tree, TreeTextProvider)",org.antlr.v4.gui.Trees,"toStringTree/2[org.antlr.v4.runtime.tree.Tree,org.antlr.v4.gui.TreeTextProvider]",False,107,4,6,1,5,5,8,16,3,3,2,8,1,0,1,2,0,0,3,3,4,0,2,0,0,0,30,9,0,True
1120,..\projects\antlr4-4.11.0\tool\src\org\antlr\v4\misc\CharSupport.java,org.antlr.v4.misc.CharSupport,String getANTLRCharLiteralForChar(int),"/**
 * Return a string representing the escaped char for code c.  E.g., If c
 *  has value 0x100, you will get ""\\u0100"".  ASCII gets the usual
 *  char (non-hex) representation.  Non-ASCII characters are spit out
 *  as \\uXXXX or \\u{XXXXXX} escapes.
 */
public static String getANTLRCharLiteralForChar(int c) {
    String result;
    if (c < Lexer.MIN_CHAR_VALUE) {
        result = ""<INVALID>"";
    } else {
        String charValueEscape = c < ANTLRLiteralCharValueEscape.length ? ANTLRLiteralCharValueEscape[c] : null;
        if (charValueEscape != null) {
            result = charValueEscape;
        } else if (Character.UnicodeBlock.of((char) c) == Character.UnicodeBlock.BASIC_LATIN && !Character.isISOControl((char) c)) {
            if (c == '\\') {
                result = ""\\\\"";
            } else if (c == '\'') {
                result = ""\\'"";
            } else {
                result = Character.toString((char) c);
            }
        } else if (c <= 0xFFFF) {
            result = String.format(""\\u%04X"", c);
        } else {
            result = String.format(""\\u{%06X}"", c);
        }
    }
    return '\'' + result + '\'';
}","/**
 * Return a string representing the escaped char for code c.  E.g., If c
 *  has value 0x100, you will get ""\\u0100"".  ASCII gets the usual
 *  char (non-hex) representation.  Non-ASCII characters are spit out
 *  as \\uXXXX or \\u{XXXXXX} escapes.
 */
", ,"/** * Return a string representing the escaped char for code c.  E.g., If c *  has value 0x100, you will get ""\\u0100"".  ASCII gets the usual *  char (non-hex) representation.  Non-ASCII characters are spit out *  as \\uXXXX or \\u{XXXXXX} escapes. */",46,75,[0],0,[0],0,[0],0,0,0,0,getANTLRCharLiteralForChar(int),org.antlr.v4.misc.CharSupport,getANTLRCharLiteralForChar/1[int],False,46,0,2,2,0,9,4,30,1,2,1,4,0,0,0,4,0,0,5,1,8,1,3,0,0,0,44,9,0,True
1121,..\projects\antlr4-4.11.0\tool\src\org\antlr\v4\misc\CharSupport.java,org.antlr.v4.misc.CharSupport,int getCharValueFromGrammarCharLiteral(String),"/**
 * Given a literal like (the 3 char sequence with single quotes) 'a',
 *  return the int value of 'a'. Convert escape sequences here also.
 *  Return -1 if not single char.
 */
public static int getCharValueFromGrammarCharLiteral(String literal) {
    if (literal == null || literal.length() < 3)
        return -1;
    return getCharValueFromCharInGrammarLiteral(literal.substring(1, literal.length() - 1));
}","/**
 * Given a literal like (the 3 char sequence with single quotes) 'a',
 *  return the int value of 'a'. Convert escape sequences here also.
 *  Return -1 if not single char.
 */
", ,"/** * Given a literal like (the 3 char sequence with single quotes) 'a', *  return the int value of 'a'. Convert escape sequences here also. *  Return -1 if not single char. */",81,84,[0],0,[0],0,[0],0,0,0,0,getCharValueFromGrammarCharLiteral(String),org.antlr.v4.misc.CharSupport,getCharValueFromGrammarCharLiteral/1[java.lang.String],False,81,1,4,3,1,3,3,4,2,0,1,3,1,2,0,1,0,0,0,4,0,1,1,0,0,0,25,9,0,True
1122,..\projects\antlr4-4.11.0\tool\src\org\antlr\v4\misc\CharSupport.java,org.antlr.v4.misc.CharSupport,String getStringFromGrammarStringLiteral(String),"public static String getStringFromGrammarStringLiteral(String literal) {
    StringBuilder buf = new StringBuilder();
    // skip first quote
    int i = 1;
    // skip last quote
    int n = literal.length() - 1;
    while (i < n) {
        // scan all but last quote
        int end = i + 1;
        if (literal.charAt(i) == '\\') {
            end = i + 2;
            if (i + 1 < n && literal.charAt(i + 1) == 'u') {
                if (i + 2 < n && literal.charAt(i + 2) == '{') {
                    // extended escape sequence
                    end = i + 3;
                    while (true) {
                        // invalid escape sequence.
                        if (end + 1 > n)
                            return null;
                        char charAt = literal.charAt(end++);
                        if (charAt == '}') {
                            break;
                        }
                        if (!Character.isDigit(charAt) && !(charAt >= 'a' && charAt <= 'f') && !(charAt >= 'A' && charAt <= 'F')) {
                            // invalid escape sequence.
                            return null;
                        }
                    }
                } else {
                    for (end = i + 2; end < i + 6; end++) {
                        // invalid escape sequence.
                        if (end > n)
                            return null;
                        char charAt = literal.charAt(end);
                        if (!Character.isDigit(charAt) && !(charAt >= 'a' && charAt <= 'f') && !(charAt >= 'A' && charAt <= 'F')) {
                            // invalid escape sequence.
                            return null;
                        }
                    }
                }
            }
        }
        // invalid escape sequence.
        if (end > n)
            return null;
        String esc = literal.substring(i, end);
        int c = getCharValueFromCharInGrammarLiteral(esc);
        if (c == -1) {
            // invalid escape sequence.
            return null;
        } else
            buf.appendCodePoint(c);
        i = end;
    }
    return buf.toString();
}", ,"// skip first quote
[[SEP]]// skip last quote
[[SEP]]// scan all but last quote
[[SEP]]// extended escape sequence
[[SEP]]// invalid escape sequence.
[[SEP]]// invalid escape sequence.
[[SEP]]// invalid escape sequence.
[[SEP]]// invalid escape sequence.
[[SEP]]// invalid escape sequence.
[[SEP]]// invalid escape sequence.
",// skip first quote[[SEP]]// skip last quote[[SEP]]// scan all but last quote[[SEP]]// extended escape sequence[[SEP]]// invalid escape sequence.[[SEP]]// invalid escape sequence.[[SEP]]// invalid escape sequence.[[SEP]]// invalid escape sequence.[[SEP]]// invalid escape sequence.[[SEP]]// invalid escape sequence.,86,129,[0],0,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]",0,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]",0,0,0,0,getStringFromGrammarStringLiteral(String),org.antlr.v4.misc.CharSupport,getStringFromGrammarStringLiteral/1[java.lang.String],False,86,1,2,1,1,24,7,44,7,8,1,7,1,2,3,5,0,4,0,13,12,11,6,0,0,0,20,9,0,False
1123,..\projects\antlr4-4.11.0\tool\src\org\antlr\v4\misc\CharSupport.java,org.antlr.v4.misc.CharSupport,int getCharValueFromCharInGrammarLiteral(String),"/**
 * Given char x or \\t or \\u1234 return the char value;
 *  Unnecessary escapes like '\{' yield -1.
 */
public static int getCharValueFromCharInGrammarLiteral(String cstr) {
    switch(cstr.length()) {
        case 1:
            // 'x'
            return // no escape char
            cstr.charAt(0);
        case 2:
            if (cstr.charAt(0) != '\\')
                return -1;
            // '\x'  (antlr lexer will catch invalid char)
            char escChar = cstr.charAt(1);
            // escape quote only in string literals.
            if (escChar == '\'')
                return escChar;
            int charVal = ANTLRLiteralEscapedCharValue[escChar];
            if (charVal == 0)
                return -1;
            return charVal;
        case 6:
            // '\\u1234' or '\\u{12}'
            if (!cstr.startsWith(""\\u""))
                return -1;
            int startOff;
            int endOff;
            if (cstr.charAt(2) == '{') {
                startOff = 3;
                endOff = cstr.indexOf('}');
            } else {
                startOff = 2;
                endOff = cstr.length();
            }
            return parseHexValue(cstr, startOff, endOff);
        default:
            if (cstr.startsWith(""\\u{"")) {
                return parseHexValue(cstr, 3, cstr.indexOf('}'));
            }
            return -1;
    }
}","/**
 * Given char x or \\t or \\u1234 return the char value;
 *  Unnecessary escapes like '\{' yield -1.
 */
","// 'x'
[[SEP]]// no escape char
[[SEP]]// '\x'  (antlr lexer will catch invalid char)
[[SEP]]// escape quote only in string literals.
[[SEP]]// '\\u1234' or '\\u{12}'
",/** * Given char x or \\t or \\u1234 return the char value; *  Unnecessary escapes like '\{' yield -1. */[[SEP]]// 'x'[[SEP]]// no escape char[[SEP]]// '\x'  (antlr lexer will catch invalid char)[[SEP]]// escape quote only in string literals.[[SEP]]// '\\u1234' or '\\u{12}',134,167,[0],0,"[0, 0, 0, 0, 0]",0,"[0, 0, 0, 0, 0, 0]",0,0,0,0,getCharValueFromCharInGrammarLiteral(String),org.antlr.v4.misc.CharSupport,getCharValueFromCharInGrammarLiteral/1[java.lang.String],False,134,1,4,3,1,10,5,31,9,4,1,5,1,1,0,4,0,0,2,15,6,0,2,0,0,0,25,9,0,True
1124,..\projects\antlr4-4.11.0\tool\src\org\antlr\v4\misc\EscapeSequenceParsing.java,org.antlr.v4.misc.EscapeSequenceParsing,"Result parseEscape(String, int)","/**
 * Parses a single escape sequence starting at {@code startOff}.
 *
 * Returns a type of INVALID if no valid escape sequence was found, a Result otherwise.
 */
public static Result parseEscape(String s, int startOff) {
    int offset = startOff;
    if (offset + 2 > s.length() || s.codePointAt(offset) != '\\') {
        return invalid(startOff, s.length() - 1);
    }
    // Move past backslash
    offset++;
    int escaped = s.codePointAt(offset);
    // Move past escaped code point
    offset += Character.charCount(escaped);
    if (escaped == 'u') {
        // \\u{1} is the shortest we support
        if (offset + 3 > s.length()) {
            return invalid(startOff, s.length() - 1);
        }
        int hexStartOffset;
        // appears to be exclusive
        int hexEndOffset;
        if (s.codePointAt(offset) == '{') {
            hexStartOffset = offset + 1;
            hexEndOffset = s.indexOf('}', hexStartOffset);
            if (hexEndOffset == -1) {
                return invalid(startOff, s.length() - 1);
            }
            offset = hexEndOffset + 1;
        } else {
            if (offset + 4 > s.length()) {
                return invalid(startOff, s.length() - 1);
            }
            hexStartOffset = offset;
            hexEndOffset = offset + 4;
            offset = hexEndOffset;
        }
        int codePointValue = CharSupport.parseHexValue(s, hexStartOffset, hexEndOffset);
        if (codePointValue == -1 || codePointValue > Character.MAX_CODE_POINT) {
            return invalid(startOff, startOff + 6 - 1);
        }
        return new Result(Result.Type.CODE_POINT, codePointValue, IntervalSet.EMPTY_SET, startOff, offset - startOff);
    } else if (escaped == 'p' || escaped == 'P') {
        // \p{L} is the shortest we support
        if (offset + 3 > s.length()) {
            return invalid(startOff, s.length() - 1);
        }
        if (s.codePointAt(offset) != '{') {
            return invalid(startOff, offset);
        }
        int openBraceOffset = offset;
        int closeBraceOffset = s.indexOf('}', openBraceOffset);
        if (closeBraceOffset == -1) {
            return invalid(startOff, s.length() - 1);
        }
        String propertyName = s.substring(openBraceOffset + 1, closeBraceOffset);
        IntervalSet propertyIntervalSet = UnicodeData.getPropertyCodePoints(propertyName);
        if (propertyIntervalSet == null || propertyIntervalSet.isNil()) {
            return invalid(startOff, closeBraceOffset);
        }
        offset = closeBraceOffset + 1;
        if (escaped == 'P') {
            propertyIntervalSet = propertyIntervalSet.complement(IntervalSet.COMPLETE_CHAR_SET);
        }
        return new Result(Result.Type.PROPERTY, -1, propertyIntervalSet, startOff, offset - startOff);
    } else if (escaped < CharSupport.ANTLRLiteralEscapedCharValue.length) {
        int codePoint = CharSupport.ANTLRLiteralEscapedCharValue[escaped];
        if (codePoint == 0) {
            if (escaped != ']' && escaped != '-') {
                // escape ']' and '-' only in char sets.
                return invalid(startOff, startOff + 1);
            } else {
                codePoint = escaped;
            }
        }
        return new Result(Result.Type.CODE_POINT, codePoint, IntervalSet.EMPTY_SET, startOff, offset - startOff);
    } else {
        return invalid(startOff, s.length() - 1);
    }
}","/**
 * Parses a single escape sequence starting at {@code startOff}.
 *
 * Returns a type of INVALID if no valid escape sequence was found, a Result otherwise.
 */
","// Move past backslash
[[SEP]]// Move past escaped code point
[[SEP]]// \\u{1} is the shortest we support
[[SEP]]// appears to be exclusive
[[SEP]]// \p{L} is the shortest we support
[[SEP]]// escape ']' and '-' only in char sets.
","/** * Parses a single escape sequence starting at {@code startOff}. * * Returns a type of INVALID if no valid escape sequence was found, a Result otherwise. */[[SEP]]// Move past backslash[[SEP]]// Move past escaped code point[[SEP]]// \\u{1} is the shortest we support[[SEP]]// appears to be exclusive[[SEP]]// \p{L} is the shortest we support[[SEP]]// escape ']' and '-' only in char sets.",83,176,[0],0,"[0, 0, 0, 0, 0, 0]",0,"[0, 0, 0, 0, 0, 0, 0]",0,0,0,0,"parseEscape(String, int)",org.antlr.v4.misc.EscapeSequenceParsing,"parseEscape/2[java.lang.String,int]",False,83,4,6,1,5,22,10,75,14,10,2,10,1,1,0,14,0,0,0,24,18,22,3,0,0,0,42,9,0,True
1125,..\projects\antlr4-4.11.0\tool\src\org\antlr\v4\misc\EscapeSequenceParsing.java,org.antlr.v4.misc.EscapeSequenceParsing,"Result invalid(int, int)","private static Result invalid(int start, int stop) {
    // start..stop is inclusive
    return new Result(Result.Type.INVALID, 0, IntervalSet.EMPTY_SET, start, stop - start + 1);
}", ,"// start..stop is inclusive
",// start..stop is inclusive,178,185,[0],0,[0],0,[0],0,0,0,0,"invalid(int, int)",org.antlr.v4.misc.EscapeSequenceParsing,"invalid/2[int,int]",False,178,1,2,1,1,1,0,3,1,0,2,0,0,0,0,0,0,0,0,2,0,2,0,0,0,0,4,10,0,False
1126,..\projects\antlr4-4.11.0\tool\src\org\antlr\v4\misc\Graph.java,org.antlr.v4.misc.Graph,"void addEdge(T, T)","public void addEdge(T a, T b) {
    // System.out.println(""add edge ""+a+"" to ""+b);
    Node<T> a_node = getNode(a);
    Node<T> b_node = getNode(b);
    a_node.addEdge(b_node);
}", ,"// System.out.println(""add edge ""+a+"" to ""+b);
","// System.out.println(""add edge ""+a+"" to ""+b);",43,48,[0],0,[0],0,[0],0,0,0,0,"addEdge(T, T)",org.antlr.v4.misc.Graph,"addEdge/2[T,T]",False,43,3,2,0,2,1,2,5,0,2,2,2,0,0,0,0,0,0,0,0,2,0,0,0,0,0,8,1,0,False
1127,..\projects\antlr4-4.11.0\tool\src\org\antlr\v4\misc\Graph.java,org.antlr.v4.misc.Graph,List<T> sort(),"/**
 * DFS-based topological sort.  A valid sort is the reverse of
 *  the post-order DFA traversal.  Amazingly simple but true.
 *  For sorting, I'm not following convention here since ANTLR
 *  needs the opposite.  Here's what I assume for sorting:
 *
 *    If there exists an edge u -&gt; v then u depends on v and v
 *    must happen before u.
 *
 *  So if this gives nonreversed postorder traversal, I get the order
 *  I want.
 */
public List<T> sort() {
    Set<Node<T>> visited = new OrderedHashSet<Node<T>>();
    ArrayList<T> sorted = new ArrayList<T>();
    while (visited.size() < nodes.size()) {
        // pick any unvisited node, n
        Node<T> n = null;
        for (Node<T> tNode : nodes.values()) {
            n = tNode;
            if (!visited.contains(n))
                break;
        }
        if (n != null) {
            // if at least one unvisited
            DFS(n, visited, sorted);
        }
    }
    return sorted;
}","/**
 * DFS-based topological sort.  A valid sort is the reverse of
 *  the post-order DFA traversal.  Amazingly simple but true.
 *  For sorting, I'm not following convention here since ANTLR
 *  needs the opposite.  Here's what I assume for sorting:
 *
 *    If there exists an edge u -&gt; v then u depends on v and v
 *    must happen before u.
 *
 *  So if this gives nonreversed postorder traversal, I get the order
 *  I want.
 */
","// pick any unvisited node, n
[[SEP]]// if at least one unvisited
","/** * DFS-based topological sort.  A valid sort is the reverse of *  the post-order DFA traversal.  Amazingly simple but true. *  For sorting, I'm not following convention here since ANTLR *  needs the opposite.  Here's what I assume for sorting: * *    If there exists an edge u -&gt; v then u depends on v and v *    must happen before u. * *  So if this gives nonreversed postorder traversal, I get the order *  I want. */[[SEP]]// pick any unvisited node, n[[SEP]]// if at least one unvisited",69,84,[0],0,"[0, 0]",0,"[0, 0, 0]",0,0,0,0,sort(),org.antlr.v4.misc.Graph,sort/0,False,69,4,2,0,2,5,5,15,1,3,0,5,0,0,2,1,0,0,0,0,4,0,3,0,0,0,57,1,0,True
1128,..\projects\antlr4-4.11.0\tool\src\org\antlr\v4\misc\Utils.java,org.antlr.v4.misc.Utils,"List<To> select(List<From>, Func1<From, To>)","/**
 * apply methodName to list and return list of results. method has
 *  no args.  This pulls data out of a list essentially.
 */
public static <From, To> List<To> select(List<From> list, Func1<From, To> selector) {
    if (list == null)
        return null;
    List<To> b = new ArrayList<To>();
    for (From f : list) {
        b.add(selector.exec(f));
    }
    return b;
}","/**
 * apply methodName to list and return list of results. method has
 *  no args.  This pulls data out of a list essentially.
 */
", ,/** * apply methodName to list and return list of results. method has *  no args.  This pulls data out of a list essentially. */,116,123,[0],0,[0],0,[0],0,0,0,0,"select(List<From>, Func1<From, To>)",org.antlr.v4.misc.Utils,"select/2[java.util.List<From>,org.antlr.v4.misc.Utils.Func1<From,To>]",False,116,3,1,0,1,3,2,8,2,1,2,2,0,0,1,1,0,0,0,0,1,0,1,0,0,0,20,9,0,True
1129,..\projects\antlr4-4.11.0\tool\src\org\antlr\v4\misc\Utils.java,org.antlr.v4.misc.Utils,"T find(List<?>, Class<T>)","/**
 * Find exact object type or subclass of cl in list
 */
public static <T> T find(List<?> ops, Class<T> cl) {
    for (Object o : ops) {
        if (cl.isInstance(o))
            return cl.cast(o);
        // if ( o.getClass() == cl ) return o;
    }
    return null;
}","/**
 * Find exact object type or subclass of cl in list
 */
","// if ( o.getClass() == cl ) return o;
",/** * Find exact object type or subclass of cl in list */[[SEP]]// if ( o.getClass() == cl ) return o;,126,132,[0],0,[0],0,"[0, 0]",0,0,0,0,"find(List<?>, Class<T>)",org.antlr.v4.misc.Utils,"find/2[java.util.List<?>,java.lang.Class<T>]",False,126,1,0,0,0,3,2,6,2,0,2,2,0,0,1,0,0,0,0,0,0,0,2,0,0,0,16,9,0,True
1130,..\projects\antlr4-4.11.0\tool\src\org\antlr\v4\parse\GrammarASTAdaptor.java,org.antlr.v4.parse.GrammarASTAdaptor,"Object create(int, String)","@Override
public /**
 * Make sure even imaginary nodes know the input stream
 */
Object create(int tokenType, String text) {
    GrammarAST t;
    if (tokenType == ANTLRParser.RULE) {
        // needed by TreeWizard to make RULE tree
        t = new RuleAST(new CommonToken(tokenType, text));
    } else if (tokenType == ANTLRParser.STRING_LITERAL) {
        // implicit lexer construction done with wizard; needs this node type
        // whereas grammar ANTLRParser.g can use token option to spec node type
        t = new TerminalAST(new CommonToken(tokenType, text));
    } else {
        t = (GrammarAST) super.create(tokenType, text);
    }
    t.token.setInputStream(input);
    return t;
}", ,"/**
 * Make sure even imaginary nodes know the input stream
 */
[[SEP]]// needed by TreeWizard to make RULE tree
[[SEP]]// implicit lexer construction done with wizard; needs this node type
[[SEP]]// whereas grammar ANTLRParser.g can use token option to spec node type
",/** * Make sure even imaginary nodes know the input stream */[[SEP]]// needed by TreeWizard to make RULE tree[[SEP]]// implicit lexer construction done with wizard; needs this node type// whereas grammar ANTLRParser.g can use token option to spec node type,27,45,[0],0,"[0, 0, 0, 0]",0,"[0, 0, 0]",0,0,0,0,"create(int, String)",org.antlr.v4.parse.GrammarASTAdaptor,"create/2[int,java.lang.String]",False,29,4,4,2,2,3,2,14,1,1,2,2,0,0,0,2,0,0,0,0,3,0,1,0,0,0,15,1,0,False
1131,..\projects\antlr4-4.11.0\tool\src\org\antlr\v4\parse\GrammarASTAdaptor.java,org.antlr.v4.parse.GrammarASTAdaptor,Object dupNode(Object),"@Override
public Object dupNode(Object t) {
    if (t == null)
        return null;
    // create(((GrammarAST)t).token);
    return ((GrammarAST) t).dupNode();
}", ,"// create(((GrammarAST)t).token);
",// create(((GrammarAST)t).token);,47,51,[0],0,[0],0,[0],0,0,0,0,dupNode(Object),org.antlr.v4.parse.GrammarASTAdaptor,dupNode/1[java.lang.Object],False,48,1,2,1,1,2,1,4,2,0,1,1,0,0,0,1,0,1,0,0,0,0,1,0,0,0,9,1,0,False
1132,..\projects\antlr4-4.11.0\tool\src\org\antlr\v4\parse\ScopeParser.java,org.antlr.v4.parse.ScopeParser,"AttributeDict parseTypedArgList(ActionAST, String, Grammar)","/**
 * Given an arg or retval scope definition list like
 * <p>
 * <code>
 * Map&lt;String, String&gt;, int[] j3, char *foo32[3]
 * </code>
 * <p>
 * or
 * <p>
 * <code>
 * int i=3, j=a[34]+20
 * </code>
 * <p>
 * convert to an attribute scope.
 */
public static AttributeDict parseTypedArgList(ActionAST action, String s, Grammar g) {
    return parse(action, s, ',', g);
}","/**
 * Given an arg or retval scope definition list like
 * <p>
 * <code>
 * Map&lt;String, String&gt;, int[] j3, char *foo32[3]
 * </code>
 * <p>
 * or
 * <p>
 * <code>
 * int i=3, j=a[34]+20
 * </code>
 * <p>
 * convert to an attribute scope.
 */
", ,"/** * Given an arg or retval scope definition list like * <p> * <code> * Map&lt;String, String&gt;, int[] j3, char *foo32[3] * </code> * <p> * or * <p> * <code> * int i=3, j=a[34]+20 * </code> * <p> * convert to an attribute scope. */",46,48,[0],0,[0],0,[0],0,0,0,0,"parseTypedArgList(ActionAST, String, Grammar)",org.antlr.v4.parse.ScopeParser,"parseTypedArgList/3[org.antlr.v4.tool.ast.ActionAST,java.lang.String,org.antlr.v4.tool.Grammar]",False,46,4,3,2,1,1,1,3,1,0,3,1,1,4,0,0,0,0,0,0,0,0,0,0,0,0,29,9,0,True
1133,..\projects\antlr4-4.11.0\tool\src\org\antlr\v4\parse\ScopeParser.java,org.antlr.v4.parse.ScopeParser,"Attribute parseAttributeDef(ActionAST, Pair<String, Integer>, Grammar)","/**
 * For decls like ""String foo"" or ""char *foo32[]"" compute the ID
 * and type declarations.  Also handle ""int x=3"" and 'T t = new T(""foo"")'
 * but if the separator is ',' you cannot use ',' in the initvalue
 * unless you escape use ""\,"" escape.
 */
public static Attribute parseAttributeDef(ActionAST action, Pair<String, Integer> decl, Grammar g) {
    if (decl.a == null)
        return null;
    Attribute attr = new Attribute();
    int rightEdgeOfDeclarator = decl.a.length() - 1;
    int equalsIndex = decl.a.indexOf('=');
    if (equalsIndex > 0) {
        // everything after the '=' is the init value
        attr.initValue = decl.a.substring(equalsIndex + 1, decl.a.length()).trim();
        rightEdgeOfDeclarator = equalsIndex - 1;
    }
    String declarator = decl.a.substring(0, rightEdgeOfDeclarator + 1);
    Pair<Integer, Integer> p;
    String text = decl.a;
    text = text.replaceAll(""::"", """");
    if (text.contains("":"")) {
        // declarator has type appearing after the name like ""x:T""
        p = _parsePostfixDecl(attr, declarator, action, g);
    } else {
        // declarator has type appearing before the name like ""T x""
        p = _parsePrefixDecl(attr, declarator, action, g);
    }
    int idStart = p.a;
    int idStop = p.b;
    attr.decl = decl.a;
    if (action != null) {
        String actionText = action.getText();
        int[] lines = new int[actionText.length()];
        int[] charPositionInLines = new int[actionText.length()];
        for (int i = 0, line = 0, col = 0; i < actionText.length(); i++, col++) {
            lines[i] = line;
            charPositionInLines[i] = col;
            if (actionText.charAt(i) == '\n') {
                line++;
                col = -1;
            }
        }
        int[] charIndexes = new int[actionText.length()];
        for (int i = 0, j = 0; i < actionText.length(); i++, j++) {
            charIndexes[j] = i;
            // skip comments
            if (i < actionText.length() - 1 && actionText.charAt(i) == '/' && actionText.charAt(i + 1) == '/') {
                while (i < actionText.length() && actionText.charAt(i) != '\n') {
                    i++;
                }
            }
        }
        int declOffset = charIndexes[decl.b];
        int declLine = lines[declOffset + idStart];
        int line = action.getToken().getLine() + declLine;
        int charPositionInLine = charPositionInLines[declOffset + idStart];
        if (declLine == 0) {
            /* offset for the start position of the ARG_ACTION token, plus 1
				 * since the ARG_ACTION text had the leading '[' stripped before
				 * reaching the scope parser.
				 */
            charPositionInLine += action.getToken().getCharPositionInLine() + 1;
        }
        int offset = ((CommonToken) action.getToken()).getStartIndex();
        attr.token = new CommonToken(action.getToken().getInputStream(), ANTLRParser.ID, BaseRecognizer.DEFAULT_TOKEN_CHANNEL, offset + declOffset + idStart + 1, offset + declOffset + idStop);
        attr.token.setLine(line);
        attr.token.setCharPositionInLine(charPositionInLine);
        assert attr.name.equals(attr.token.getText()) : ""Attribute text should match the pseudo-token text at this point."";
    }
    return attr;
}","/**
 * For decls like ""String foo"" or ""char *foo32[]"" compute the ID
 * and type declarations.  Also handle ""int x=3"" and 'T t = new T(""foo"")'
 * but if the separator is ',' you cannot use ',' in the initvalue
 * unless you escape use ""\,"" escape.
 */
","// everything after the '=' is the init value
[[SEP]]// declarator has type appearing after the name like ""x:T""
[[SEP]]// declarator has type appearing before the name like ""T x""
[[SEP]]// skip comments
[[SEP]]/* offset for the start position of the ARG_ACTION token, plus 1
				 * since the ARG_ACTION text had the leading '[' stripped before
				 * reaching the scope parser.
				 */
","/** * For decls like ""String foo"" or ""char *foo32[]"" compute the ID * and type declarations.  Also handle ""int x=3"" and 'T t = new T(""foo"")' * but if the separator is ',' you cannot use ',' in the initvalue * unless you escape use ""\,"" escape. */[[SEP]]// everything after the '=' is the init value[[SEP]]// declarator has type appearing after the name like ""x:T""[[SEP]]// declarator has type appearing before the name like ""T x""[[SEP]]// skip comments[[SEP]]/* offset for the start position of the ARG_ACTION token, plus 1				 * since the ARG_ACTION text had the leading '[' stripped before				 * reaching the scope parser.				 */",68,142,[0],0,"[0, 0, 0, 0, 0]",0,"[0, 0, 0, 0, 0, 0]",0,0,0,0,"parseAttributeDef(ActionAST, Pair<String, Integer>, Grammar)",org.antlr.v4.parse.ScopeParser,"parseAttributeDef/3[org.antlr.v4.tool.ast.ActionAST,org.antlr.v4.parse.Pair<java.lang.String,java.lang.Integer>,org.antlr.v4.tool.Grammar]",False,68,7,4,1,3,14,19,58,2,22,3,19,2,1,3,7,0,1,4,17,33,12,4,0,0,0,74,9,0,True
1134,..\projects\antlr4-4.11.0\tool\src\org\antlr\v4\parse\ScopeParser.java,org.antlr.v4.parse.ScopeParser,"Pair<Integer, Integer> _parsePrefixDecl(Attribute, String, ActionAST, Grammar)","public static Pair<Integer, Integer> _parsePrefixDecl(Attribute attr, String decl, ActionAST a, Grammar g) {
    // walk backwards looking for start of an ID
    boolean inID = false;
    int start = -1;
    for (int i = decl.length() - 1; i >= 0; i--) {
        char ch = decl.charAt(i);
        // if we haven't found the end yet, keep going
        if (!inID && Character.isLetterOrDigit(ch)) {
            inID = true;
        } else if (inID && !(Character.isLetterOrDigit(ch) || ch == '_')) {
            start = i + 1;
            break;
        }
    }
    if (start < 0 && inID) {
        start = 0;
    }
    if (start < 0) {
        g.tool.errMgr.grammarError(ErrorType.CANNOT_FIND_ATTRIBUTE_NAME_IN_DECL, g.fileName, a.token, decl);
    }
    // walk forward looking for end of an ID
    int stop = -1;
    for (int i = start; i < decl.length(); i++) {
        char ch = decl.charAt(i);
        // if we haven't found the end yet, keep going
        if (!(Character.isLetterOrDigit(ch) || ch == '_')) {
            stop = i;
            break;
        }
        if (i == decl.length() - 1) {
            stop = i + 1;
        }
    }
    // the name is the last ID
    attr.name = decl.substring(start, stop);
    // the type is the decl minus the ID (could be empty)
    attr.type = decl.substring(0, start);
    if (stop <= decl.length() - 1) {
        attr.type += decl.substring(stop, decl.length());
    }
    attr.type = attr.type.trim();
    if (attr.type.length() == 0) {
        attr.type = null;
    }
    return new Pair<Integer, Integer>(start, stop);
}", ,"// walk backwards looking for start of an ID
[[SEP]]// if we haven't found the end yet, keep going
[[SEP]]// walk forward looking for end of an ID
[[SEP]]// if we haven't found the end yet, keep going
[[SEP]]// the name is the last ID
[[SEP]]// the type is the decl minus the ID (could be empty)
","// walk backwards looking for start of an ID[[SEP]]// if we haven't found the end yet, keep going[[SEP]]// walk forward looking for end of an ID[[SEP]]// if we haven't found the end yet, keep going[[SEP]]// the name is the last ID[[SEP]]// the type is the decl minus the ID (could be empty)",144,194,[0],0,"[0, 0, 0, 0, 0, 0]",0,"[0, 0, 0, 0, 0, 0]",0,0,0,0,"_parsePrefixDecl(Attribute, String, ActionAST, Grammar)",org.antlr.v4.parse.ScopeParser,"_parsePrefixDecl/4[org.antlr.v4.tool.Attribute,java.lang.String,org.antlr.v4.tool.ast.ActionAST,org.antlr.v4.tool.Grammar]",False,144,5,2,1,1,16,6,41,1,7,4,6,0,0,2,4,0,2,0,13,17,5,2,0,0,0,15,9,0,False
1135,..\projects\antlr4-4.11.0\tool\src\org\antlr\v4\parse\ScopeParser.java,org.antlr.v4.parse.ScopeParser,"Pair<Integer, Integer> _parsePostfixDecl(Attribute, String, ActionAST, Grammar)","public static Pair<Integer, Integer> _parsePostfixDecl(Attribute attr, String decl, ActionAST a, Grammar g) {
    int start = -1;
    int stop = -1;
    int colon = decl.indexOf(':');
    int namePartEnd = colon == -1 ? decl.length() : colon;
    // look for start of name
    for (int i = 0; i < namePartEnd; ++i) {
        char ch = decl.charAt(i);
        if (Character.isLetterOrDigit(ch) || ch == '_') {
            start = i;
            break;
        }
    }
    if (start == -1) {
        start = 0;
        g.tool.errMgr.grammarError(ErrorType.CANNOT_FIND_ATTRIBUTE_NAME_IN_DECL, g.fileName, a.token, decl);
    }
    // look for stop of name
    for (int i = start; i < namePartEnd; ++i) {
        char ch = decl.charAt(i);
        if (!(Character.isLetterOrDigit(ch) || ch == '_')) {
            stop = i;
            break;
        }
        if (i == namePartEnd - 1) {
            stop = namePartEnd;
        }
    }
    if (stop == -1) {
        stop = start;
    }
    // extract name from decl
    attr.name = decl.substring(start, stop);
    // extract type from decl (could be empty)
    if (colon == -1) {
        attr.type = """";
    } else {
        attr.type = decl.substring(colon + 1, decl.length());
    }
    attr.type = attr.type.trim();
    if (attr.type.length() == 0) {
        attr.type = null;
    }
    return new Pair<Integer, Integer>(start, stop);
}", ,"// look for start of name
[[SEP]]// look for stop of name
[[SEP]]// extract name from decl
[[SEP]]// extract type from decl (could be empty)
",// look for start of name[[SEP]]// look for stop of name[[SEP]]// extract name from decl[[SEP]]// extract type from decl (could be empty),196,248,[0],0,"[0, 0, 0, 0]",0,"[0, 0, 0, 0]",0,0,0,0,"_parsePostfixDecl(Attribute, String, ActionAST, Grammar)",org.antlr.v4.parse.ScopeParser,"_parsePostfixDecl/4[org.antlr.v4.tool.Attribute,java.lang.String,org.antlr.v4.tool.ast.ActionAST,org.antlr.v4.tool.Grammar]",False,196,5,2,1,1,13,7,42,1,8,4,7,0,0,2,8,0,1,1,11,18,2,2,0,0,0,14,9,0,False
1136,..\projects\antlr4-4.11.0\tool\src\org\antlr\v4\parse\ScopeParser.java,org.antlr.v4.parse.ScopeParser,"List<Pair<String, Integer>> splitDecls(String, int)","/**
 * Given an argument list like
 * <p>
 * x, (*a).foo(21,33), 3.2+1, '\n',
 * ""a,oo\nick"", {bl, ""fdkj""eck}, [""cat\n,"", x, 43]
 * <p>
 * convert to a list of attributes.  Allow nested square brackets etc...
 * Set separatorChar to ';' or ',' or whatever you want.
 */
public static List<Pair<String, Integer>> splitDecls(String s, int separatorChar) {
    List<Pair<String, Integer>> args = new ArrayList<Pair<String, Integer>>();
    _splitArgumentList(s, 0, -1, separatorChar, args);
    return args;
}","/**
 * Given an argument list like
 * <p>
 * x, (*a).foo(21,33), 3.2+1, '\n',
 * ""a,oo\nick"", {bl, ""fdkj""eck}, [""cat\n,"", x, 43]
 * <p>
 * convert to a list of attributes.  Allow nested square brackets etc...
 * Set separatorChar to ';' or ',' or whatever you want.
 */
", ,"/** * Given an argument list like * <p> * x, (*a).foo(21,33), 3.2+1, '\n', * ""a,oo\nick"", {bl, ""fdkj""eck}, [""cat\n,"", x, 43] * <p> * convert to a list of attributes.  Allow nested square brackets etc... * Set separatorChar to ';' or ',' or whatever you want. */",259,263,[0],0,[0],0,[0],0,0,0,0,"splitDecls(String, int)",org.antlr.v4.parse.ScopeParser,"splitDecls/2[java.lang.String,int]",False,259,2,2,1,1,1,1,5,1,1,2,1,1,1,0,0,0,0,0,2,1,0,0,0,0,0,25,9,0,True
1137,..\projects\antlr4-4.11.0\tool\src\org\antlr\v4\parse\ScopeParser.java,org.antlr.v4.parse.ScopeParser,"int _splitArgumentList(String, int, int, int, List<Pair<String, Integer>>)","public static int _splitArgumentList(String actionText, int start, int targetChar, int separatorChar, List<Pair<String, Integer>> args) {
    if (actionText == null) {
        return -1;
    }
    actionText = actionText.replaceAll(""//[^\\n]*"", """");
    int n = actionText.length();
    // System.out.println(""actionText@""+start+""->""+(char)targetChar+""=""+actionText.substring(start,n));
    int p = start;
    int last = p;
    while (p < n && actionText.charAt(p) != targetChar) {
        int c = actionText.charAt(p);
        switch(c) {
            case '\'':
                p++;
                while (p < n && actionText.charAt(p) != '\'') {
                    if (actionText.charAt(p) == '\\' && (p + 1) < n && actionText.charAt(p + 1) == '\'') {
                        // skip escaped quote
                        p++;
                    }
                    p++;
                }
                p++;
                break;
            case '""':
                p++;
                while (p < n && actionText.charAt(p) != '\""') {
                    if (actionText.charAt(p) == '\\' && (p + 1) < n && actionText.charAt(p + 1) == '\""') {
                        // skip escaped quote
                        p++;
                    }
                    p++;
                }
                p++;
                break;
            case '(':
                p = _splitArgumentList(actionText, p + 1, ')', separatorChar, args);
                break;
            case '{':
                p = _splitArgumentList(actionText, p + 1, '}', separatorChar, args);
                break;
            case '<':
                if (actionText.indexOf('>', p + 1) >= p) {
                    // do we see a matching '>' ahead?  if so, hope it's a generic
                    // and not less followed by expr with greater than
                    p = _splitArgumentList(actionText, p + 1, '>', separatorChar, args);
                } else {
                    // treat as normal char
                    p++;
                }
                break;
            case '[':
                p = _splitArgumentList(actionText, p + 1, ']', separatorChar, args);
                break;
            default:
                if (c == separatorChar && targetChar == -1) {
                    String arg = actionText.substring(last, p);
                    int index = last;
                    while (index < p && Character.isWhitespace(actionText.charAt(index))) {
                        index++;
                    }
                    // System.out.println(""arg=""+arg);
                    args.add(new Pair<String, Integer>(arg.trim(), index));
                    last = p + 1;
                }
                p++;
                break;
        }
    }
    if (targetChar == -1 && p <= n) {
        String arg = actionText.substring(last, p).trim();
        int index = last;
        while (index < p && Character.isWhitespace(actionText.charAt(index))) {
            index++;
        }
        // System.out.println(""arg=""+arg);
        if (arg.length() > 0) {
            args.add(new Pair<String, Integer>(arg.trim(), index));
        }
    }
    p++;
    return p;
}", ,"// System.out.println(""actionText@""+start+""->""+(char)targetChar+""=""+actionText.substring(start,n));
[[SEP]]// skip escaped quote
[[SEP]]// skip escaped quote
[[SEP]]// do we see a matching '>' ahead?  if so, hope it's a generic
[[SEP]]// and not less followed by expr with greater than
[[SEP]]// treat as normal char
[[SEP]]// System.out.println(""arg=""+arg);
[[SEP]]// System.out.println(""arg=""+arg);
","//[^\\n]*"", """");[[SEP]]// System.out.println(""actionText@""+start+""->""+(char)targetChar+""=""+actionText.substring(start,n));[[SEP]]// skip escaped quote[[SEP]]// skip escaped quote[[SEP]]// do we see a matching '>' ahead?  if so, hope it's a generic// and not less followed by expr with greater than[[SEP]]// treat as normal char[[SEP]]// System.out.println(""arg=""+arg);[[SEP]]// System.out.println(""arg=""+arg);",265,351,[0],0,"[0, 0, 0, 0, 0, 0, 0, 0]",0,"[0, 0, 0, 0, 0, 0, 0, 0]",0,0,0,0,"_splitArgumentList(String, int, int, int, List<Pair<String, Integer>>)",org.antlr.v4.parse.ScopeParser,"_splitArgumentList/5[java.lang.String,int,int,int,java.util.List<org.antlr.v4.parse.Pair<java.lang.String,java.lang.Integer>>]",False,269,2,3,2,1,30,9,75,2,8,5,9,1,0,5,11,0,2,2,14,14,10,4,0,0,0,17,9,0,False
1138,..\projects\antlr4-4.11.0\tool\src\org\antlr\v4\parse\TokenVocabParser.java,org.antlr.v4.parse.TokenVocabParser,"Map<String, Integer> load()","/**
 * Load a vocab file {@code <vocabName>.tokens} and return mapping.
 */
public Map<String, Integer> load() {
    Map<String, Integer> tokens = new LinkedHashMap<String, Integer>();
    int maxTokenType = -1;
    File fullFile = getImportedVocabFile();
    FileInputStream fis = null;
    BufferedReader br = null;
    Tool tool = g.tool;
    String vocabName = g.getOptionString(""tokenVocab"");
    try {
        Pattern tokenDefPattern = Pattern.compile(""([^\n]+?)[ \\t]*?=[ \\t]*?([0-9]+)"");
        fis = new FileInputStream(fullFile);
        InputStreamReader isr;
        if (tool.grammarEncoding != null) {
            isr = new InputStreamReader(fis, tool.grammarEncoding);
        } else {
            isr = new InputStreamReader(fis);
        }
        br = new BufferedReader(isr);
        String tokenDef = br.readLine();
        int lineNum = 1;
        while (tokenDef != null) {
            Matcher matcher = tokenDefPattern.matcher(tokenDef);
            if (matcher.find()) {
                String tokenID = matcher.group(1);
                String tokenTypeS = matcher.group(2);
                int tokenType;
                try {
                    tokenType = Integer.valueOf(tokenTypeS);
                } catch (NumberFormatException nfe) {
                    tool.errMgr.toolError(ErrorType.TOKENS_FILE_SYNTAX_ERROR, vocabName + CodeGenerator.VOCAB_FILE_EXTENSION, "" bad token type: "" + tokenTypeS, lineNum);
                    tokenType = Token.INVALID_TOKEN_TYPE;
                }
                tool.log(""grammar"", ""import "" + tokenID + ""="" + tokenType);
                tokens.put(tokenID, tokenType);
                maxTokenType = Math.max(maxTokenType, tokenType);
                lineNum++;
            } else {
                if (tokenDef.length() > 0) {
                    // ignore blank lines
                    tool.errMgr.toolError(ErrorType.TOKENS_FILE_SYNTAX_ERROR, vocabName + CodeGenerator.VOCAB_FILE_EXTENSION, "" bad token def: "" + tokenDef, lineNum);
                }
            }
            tokenDef = br.readLine();
        }
    } catch (FileNotFoundException fnfe) {
        GrammarAST inTree = g.ast.getOptionAST(""tokenVocab"");
        String inTreeValue = inTree.getToken().getText();
        if (vocabName.equals(inTreeValue)) {
            tool.errMgr.grammarError(ErrorType.CANNOT_FIND_TOKENS_FILE_REFD_IN_GRAMMAR, g.fileName, inTree.getToken(), fullFile);
        } else {
            // must be from -D option on cmd-line not token in tree
            tool.errMgr.toolError(ErrorType.CANNOT_FIND_TOKENS_FILE_GIVEN_ON_CMDLINE, fullFile, g.name);
        }
    } catch (Exception e) {
        tool.errMgr.toolError(ErrorType.ERROR_READING_TOKENS_FILE, e, fullFile, e.getMessage());
    } finally {
        try {
            if (br != null)
                br.close();
        } catch (IOException ioe) {
            tool.errMgr.toolError(ErrorType.ERROR_READING_TOKENS_FILE, ioe, fullFile, ioe.getMessage());
        }
    }
    return tokens;
}","/**
 * Load a vocab file {@code <vocabName>.tokens} and return mapping.
 */
","// ignore blank lines
[[SEP]]// must be from -D option on cmd-line not token in tree
",/** * Load a vocab file {@code <vocabName>.tokens} and return mapping. */[[SEP]]// ignore blank lines[[SEP]]// must be from -D option on cmd-line not token in tree,36,123,[0],0,"[0, 0]",0,"[0, 0, 0]",0,0,0,0,load(),org.antlr.v4.parse.TokenVocabParser,load/0,False,36,6,8,1,7,11,21,70,1,17,0,21,1,1,1,3,3,0,8,5,23,5,4,0,0,0,53,1,0,True
1139,..\projects\antlr4-4.11.0\tool\src\org\antlr\v4\parse\TokenVocabParser.java,org.antlr.v4.parse.TokenVocabParser,File getImportedVocabFile(),"/**
 * Return a File descriptor for vocab file.  Look in library or
 *  in -o output path.  antlr -o foo T.g4 U.g4 where U needs T.tokens
 *  won't work unless we look in foo too. If we do not find the
 *  file in the lib directory then must assume that the .tokens file
 *  is going to be generated as part of this build and we have defined
 *  .tokens files so that they ALWAYS are generated in the base output
 *  directory, which means the current directory for the command line tool if there
 *  was no output directory specified.
 */
public File getImportedVocabFile() {
    String vocabName = g.getOptionString(""tokenVocab"");
    File f = new File(g.tool.libDirectory, File.separator + vocabName + CodeGenerator.VOCAB_FILE_EXTENSION);
    if (f.exists()) {
        return f;
    }
    // We did not find the vocab file in the lib directory, so we need
    // to look for it in the output directory which is where .tokens
    // files are generated (in the base, not relative to the input
    // location.)
    f = new File(g.tool.outputDirectory, vocabName + CodeGenerator.VOCAB_FILE_EXTENSION);
    if (f.exists()) {
        return f;
    }
    // Still not found? Use the grammar's subfolder then.
    String fileDirectory;
    if (g.fileName.lastIndexOf(File.separatorChar) == -1) {
        // No path is included in the file name, so make the file
        // directory the same as the parent grammar (which might still be just """"
        // but when it is not, we will write the file in the correct place.
        fileDirectory = ""."";
    } else {
        fileDirectory = g.fileName.substring(0, g.fileName.lastIndexOf(File.separatorChar));
    }
    return new File(fileDirectory, vocabName + CodeGenerator.VOCAB_FILE_EXTENSION);
}","/**
 * Return a File descriptor for vocab file.  Look in library or
 *  in -o output path.  antlr -o foo T.g4 U.g4 where U needs T.tokens
 *  won't work unless we look in foo too. If we do not find the
 *  file in the lib directory then must assume that the .tokens file
 *  is going to be generated as part of this build and we have defined
 *  .tokens files so that they ALWAYS are generated in the base output
 *  directory, which means the current directory for the command line tool if there
 *  was no output directory specified.
 */
","// We did not find the vocab file in the lib directory, so we need
[[SEP]]// to look for it in the output directory which is where .tokens
[[SEP]]// files are generated (in the base, not relative to the input
[[SEP]]// location.)
[[SEP]]// Still not found? Use the grammar's subfolder then.
[[SEP]]// No path is included in the file name, so make the file
[[SEP]]// directory the same as the parent grammar (which might still be just """"
[[SEP]]// but when it is not, we will write the file in the correct place.
","/** * Return a File descriptor for vocab file.  Look in library or *  in -o output path.  antlr -o foo T.g4 U.g4 where U needs T.tokens *  won't work unless we look in foo too. If we do not find the *  file in the lib directory then must assume that the .tokens file *  is going to be generated as part of this build and we have defined *  .tokens files so that they ALWAYS are generated in the base output *  directory, which means the current directory for the command line tool if there *  was no output directory specified. */[[SEP]]// We did not find the vocab file in the lib directory, so we need// to look for it in the output directory which is where .tokens// files are generated (in the base, not relative to the input// location.)[[SEP]]// Still not found? Use the grammar's subfolder then.[[SEP]]// No path is included in the file name, so make the file// directory the same as the parent grammar (which might still be just """"// but when it is not, we will write the file in the correct place.",134,166,[0],0,"[0, 0, 0, 0, 0, 0, 0, 0]",0,"[0, 0, 0, 0]",0,0,0,0,getImportedVocabFile(),org.antlr.v4.parse.TokenVocabParser,getImportedVocabFile/0,False,134,1,2,1,1,4,4,19,3,3,0,4,0,0,0,1,0,0,2,2,5,3,1,0,0,0,68,1,0,True
1140,..\projects\antlr4-4.11.0\tool\src\org\antlr\v4\parse\ToolANTLRParser.java,org.antlr.v4.parse.ToolANTLRParser,"void displayRecognitionError(String[], RecognitionException)","@Override
public void displayRecognitionError(String[] tokenNames, RecognitionException e) {
    String msg = getParserErrorMessage(this, e);
    if (!paraphrases.isEmpty()) {
        String paraphrase = paraphrases.peek();
        msg = msg + "" while "" + paraphrase;
    }
    // List stack = getRuleInvocationStack(e, this.getClass().getName());
    // msg += "", rule stack = ""+stack;
    tool.errMgr.syntaxError(ErrorType.SYNTAX_ERROR, getSourceName(), e.token, e, msg);
}", ,"// List stack = getRuleInvocationStack(e, this.getClass().getName());
[[SEP]]// msg += "", rule stack = ""+stack;
","// List stack = getRuleInvocationStack(e, this.getClass().getName());// msg += "", rule stack = ""+stack;",27,39,[0],0,"[0, 0]",0,[0],0,0,0,0,"displayRecognitionError(String[], RecognitionException)",org.antlr.v4.parse.ToolANTLRParser,"displayRecognitionError/2[java.lang.String[],org.antlr.v4.parse.RecognitionException]",False,30,3,2,0,2,2,5,8,0,2,2,5,1,1,0,0,0,0,1,0,3,1,1,0,0,0,9,1,0,False
1141,..\projects\antlr4-4.11.0\tool\src\org\antlr\v4\semantics\ActionSniffer.java,org.antlr.v4.semantics.ActionSniffer,void examineAction(),"public void examineAction() {
    // System.out.println(""examine ""+actionToken);
    ANTLRStringStream in = new ANTLRStringStream(actionToken.getText());
    in.setLine(actionToken.getLine());
    in.setCharPositionInLine(actionToken.getCharPositionInLine());
    ActionSplitter splitter = new ActionSplitter(in, this);
    // forces eval, triggers listener methods
    node.chunks = splitter.getActionTokens();
}", ,"// System.out.println(""examine ""+actionToken);
[[SEP]]// forces eval, triggers listener methods
","// System.out.println(""examine ""+actionToken);[[SEP]]// forces eval, triggers listener methods",42,50,[0],0,"[0, 0]",0,"[0, 0]",0,0,0,0,examineAction(),org.antlr.v4.semantics.ActionSniffer,examineAction/0,False,42,2,1,1,0,1,6,7,0,2,0,6,0,0,0,0,0,0,0,0,3,0,0,0,0,0,12,1,0,False
1142,..\projects\antlr4-4.11.0\tool\src\org\antlr\v4\semantics\ActionSniffer.java,org.antlr.v4.semantics.ActionSniffer,void processNested(Token),"public void processNested(Token actionToken) {
    ANTLRStringStream in = new ANTLRStringStream(actionToken.getText());
    in.setLine(actionToken.getLine());
    in.setCharPositionInLine(actionToken.getCharPositionInLine());
    ActionSplitter splitter = new ActionSplitter(in, this);
    // forces eval, triggers listener methods
    splitter.getActionTokens();
}", ,"// forces eval, triggers listener methods
","// forces eval, triggers listener methods",52,59,[0],0,[0],0,[0],0,0,0,0,processNested(Token),org.antlr.v4.semantics.ActionSniffer,processNested/1[org.antlr.v4.semantics.Token],False,52,3,2,2,0,1,6,7,0,2,1,6,0,0,0,0,0,0,0,0,2,0,0,0,0,0,15,1,0,False
1143,..\projects\antlr4-4.11.0\tool\src\org\antlr\v4\semantics\AttributeChecks.java,org.antlr.v4.semantics.AttributeChecks,void examineAction(),"public void examineAction() {
    // System.out.println(""examine ""+actionToken);
    ANTLRStringStream in = new ANTLRStringStream(actionToken.getText());
    in.setLine(actionToken.getLine());
    in.setCharPositionInLine(actionToken.getCharPositionInLine());
    ActionSplitter splitter = new ActionSplitter(in, this);
    // forces eval, triggers listener methods
    node.chunks = splitter.getActionTokens();
}", ,"// System.out.println(""examine ""+actionToken);
[[SEP]]// forces eval, triggers listener methods
","// System.out.println(""examine ""+actionToken);[[SEP]]// forces eval, triggers listener methods",77,85,[0],0,"[0, 0]",0,"[0, 0]",0,0,0,0,examineAction(),org.antlr.v4.semantics.AttributeChecks,examineAction/0,False,77,2,2,2,0,1,6,7,0,2,0,6,0,0,0,0,0,0,0,0,3,0,0,0,0,0,12,1,0,False
1144,..\projects\antlr4-4.11.0\tool\src\org\antlr\v4\semantics\AttributeChecks.java,org.antlr.v4.semantics.AttributeChecks,"void qualifiedAttr(String, Token, Token)","// LISTENER METHODS
// $x.y
@Override
public void qualifiedAttr(String expr, Token x, Token y) {
    if (g.isLexer()) {
        errMgr.grammarError(ErrorType.ATTRIBUTE_IN_LEXER_ACTION, g.fileName, x, x.getText() + ""."" + y.getText(), expr);
        return;
    }
    if (node.resolver.resolveToAttribute(x.getText(), node) != null) {
        // must be a member access to a predefined attribute like $ctx.foo
        attr(expr, x);
        return;
    }
    if (node.resolver.resolveToAttribute(x.getText(), y.getText(), node) == null) {
        Rule rref = isolatedRuleRef(x.getText());
        if (rref != null) {
            if (rref.args != null && rref.args.get(y.getText()) != null) {
                g.tool.errMgr.grammarError(ErrorType.INVALID_RULE_PARAMETER_REF, g.fileName, y, y.getText(), rref.name, expr);
            } else {
                errMgr.grammarError(ErrorType.UNKNOWN_RULE_ATTRIBUTE, g.fileName, y, y.getText(), rref.name, expr);
            }
        } else if (!node.resolver.resolvesToAttributeDict(x.getText(), node)) {
            errMgr.grammarError(ErrorType.UNKNOWN_SIMPLE_ATTRIBUTE, g.fileName, x, x.getText(), expr);
        } else {
            errMgr.grammarError(ErrorType.UNKNOWN_ATTRIBUTE_IN_SCOPE, g.fileName, y, y.getText(), expr);
        }
    }
}","// $x.y
","// must be a member access to a predefined attribute like $ctx.foo
",// LISTENER METHODS// $x.y[[SEP]]// must be a member access to a predefined attribute like $ctx.foo,90,124,[0],0,[0],0,"[0, 0]",0,0,0,0,"qualifiedAttr(String, Token, Token)",org.antlr.v4.semantics.AttributeChecks,"qualifiedAttr/3[java.lang.String,org.antlr.v4.semantics.Token,org.antlr.v4.semantics.Token]",False,91,7,8,0,8,8,9,27,2,1,3,9,2,2,0,5,0,0,1,0,1,1,3,0,0,0,9,1,0,False
1145,..\projects\antlr4-4.11.0\tool\src\org\antlr\v4\semantics\AttributeChecks.java,org.antlr.v4.semantics.AttributeChecks,"void setAttr(String, Token, Token)","@Override
public void setAttr(String expr, Token x, Token rhs) {
    if (g.isLexer()) {
        errMgr.grammarError(ErrorType.ATTRIBUTE_IN_LEXER_ACTION, g.fileName, x, x.getText(), expr);
        return;
    }
    if (node.resolver.resolveToAttribute(x.getText(), node) == null) {
        ErrorType errorType = ErrorType.UNKNOWN_SIMPLE_ATTRIBUTE;
        if (node.resolver.resolvesToListLabel(x.getText(), node)) {
            // $ids for ids+=ID etc...
            errorType = ErrorType.ASSIGNMENT_TO_LIST_LABEL;
        }
        errMgr.grammarError(errorType, g.fileName, x, x.getText(), expr);
    }
    new AttributeChecks(g, r, alt, node, rhs).examineAction();
}", ,"// $ids for ids+=ID etc...
",// $ids for ids+=ID etc...,126,144,[0],0,[0],0,[0],0,0,0,0,"setAttr(String, Token, Token)",org.antlr.v4.semantics.AttributeChecks,"setAttr/3[java.lang.String,org.antlr.v4.semantics.Token,org.antlr.v4.semantics.Token]",False,127,6,6,0,6,4,6,14,1,1,3,6,1,1,0,1,0,0,0,0,2,0,2,0,0,0,9,1,0,False
1146,..\projects\antlr4-4.11.0\tool\src\org\antlr\v4\semantics\AttributeChecks.java,org.antlr.v4.semantics.AttributeChecks,"void attr(String, Token)","@Override
public void attr(String expr, Token x) {
    if (g.isLexer()) {
        errMgr.grammarError(ErrorType.ATTRIBUTE_IN_LEXER_ACTION, g.fileName, x, x.getText(), expr);
        return;
    }
    if (node.resolver.resolveToAttribute(x.getText(), node) == null) {
        if (node.resolver.resolvesToToken(x.getText(), node)) {
            // $ID for token ref or label of token
            return;
        }
        if (node.resolver.resolvesToListLabel(x.getText(), node)) {
            // $ids for ids+=ID etc...
            return;
        }
        if (isolatedRuleRef(x.getText()) != null) {
            errMgr.grammarError(ErrorType.ISOLATED_RULE_REF, g.fileName, x, x.getText(), expr);
            return;
        }
        errMgr.grammarError(ErrorType.UNKNOWN_SIMPLE_ATTRIBUTE, g.fileName, x, x.getText(), expr);
    }
}", ,"// $ID for token ref or label of token
[[SEP]]// $ids for ids+=ID etc...
",// $ID for token ref or label of token[[SEP]]// $ids for ids+=ID etc...,146,168,[0],0,"[0, 0]",0,"[0, 0]",0,0,0,0,"attr(String, Token)",org.antlr.v4.semantics.AttributeChecks,"attr/2[java.lang.String,org.antlr.v4.semantics.Token]",False,147,5,7,1,6,6,7,19,4,0,2,7,1,1,0,2,0,0,0,0,0,0,2,0,0,0,6,1,0,False
1147,..\projects\antlr4-4.11.0\tool\src\org\antlr\v4\semantics\AttributeChecks.java,org.antlr.v4.semantics.AttributeChecks,void templateInstance(String),"// don't care
public void templateInstance(String expr) {
}","// don't care
", ,// don't care,202,202,[0],0,[0],0,[0],0,0,0,0,templateInstance(String),org.antlr.v4.semantics.AttributeChecks,templateInstance/1[java.lang.String],False,202,0,0,0,0,1,0,2,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,3,1,0,False
1148,..\projects\antlr4-4.11.0\tool\src\org\antlr\v4\semantics\AttributeChecks.java,org.antlr.v4.semantics.AttributeChecks,Rule isolatedRuleRef(String),"// SUPPORT
public Rule isolatedRuleRef(String x) {
    if (node.resolver instanceof Grammar)
        return null;
    if (x.equals(r.name))
        return r;
    List<LabelElementPair> labels = null;
    if (node.resolver instanceof Rule) {
        labels = r.getElementLabelDefs().get(x);
    } else if (node.resolver instanceof Alternative) {
        labels = ((Alternative) node.resolver).labelDefs.get(x);
    }
    if (labels != null) {
        // it's a label ref. is it a rule label?
        LabelElementPair anyLabelDef = labels.get(0);
        if (anyLabelDef.type == LabelType.RULE_LABEL) {
            return g.getRule(anyLabelDef.element.getText());
        }
    }
    if (node.resolver instanceof Alternative) {
        if (((Alternative) node.resolver).ruleRefs.get(x) != null) {
            return g.getRule(x);
        }
    }
    return null;
}", ,"// it's a label ref. is it a rule label?
",// SUPPORT[[SEP]]// it's a label ref. is it a rule label?,210,233,[0],0,[0],0,"[0, 0]",0,0,0,0,isolatedRuleRef(String),org.antlr.v4.semantics.AttributeChecks,isolatedRuleRef/1[java.lang.String],False,210,5,4,2,2,9,6,23,5,2,1,6,0,0,0,3,0,2,0,1,4,0,2,0,0,0,14,1,0,False
1149,..\projects\antlr4-4.11.0\tool\src\org\antlr\v4\semantics\BasicSemanticChecks.java,org.antlr.v4.semantics.BasicSemanticChecks,"void discoverRule(RuleAST, GrammarAST, List<GrammarAST>, ActionAST, ActionAST, GrammarAST, GrammarAST, ActionAST, List<GrammarAST>, GrammarAST)","@Override
public void discoverRule(RuleAST rule, GrammarAST ID, List<GrammarAST> modifiers, ActionAST arg, ActionAST returns, GrammarAST thrws, GrammarAST options, ActionAST locals, List<GrammarAST> actions, GrammarAST block) {
    // TODO: chk that all or no alts have ""# label""
    checkInvalidRuleDef(ID.token);
}", ,"// TODO: chk that all or no alts have ""# label""
","// TODO: chk that all or no alts have ""# label""",178,188,[0],0,[1],1,[1],1,1,0,1,"discoverRule(RuleAST, GrammarAST, List<GrammarAST>, ActionAST, ActionAST, GrammarAST, GrammarAST, ActionAST, List<GrammarAST>, GrammarAST)",org.antlr.v4.semantics.BasicSemanticChecks,"discoverRule/10[org.antlr.v4.tool.ast.RuleAST,org.antlr.v4.tool.ast.GrammarAST,java.util.List<org.antlr.v4.tool.ast.GrammarAST>,org.antlr.v4.tool.ast.ActionAST,org.antlr.v4.tool.ast.ActionAST,org.antlr.v4.tool.ast.GrammarAST,org.antlr.v4.tool.ast.GrammarAST,org.antlr.v4.tool.ast.ActionAST,java.util.List<org.antlr.v4.tool.ast.GrammarAST>,org.antlr.v4.tool.ast.GrammarAST]",False,185,4,1,0,1,1,1,3,0,0,10,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,9,1,0,False
1150,..\projects\antlr4-4.11.0\tool\src\org\antlr\v4\semantics\BasicSemanticChecks.java,org.antlr.v4.semantics.BasicSemanticChecks,"void finishRule(RuleAST, GrammarAST, GrammarAST)","@Override
public void finishRule(RuleAST rule, GrammarAST ID, GrammarAST block) {
    if (rule.isLexerRule())
        return;
    BlockAST blk = (BlockAST) rule.getFirstChildWithType(BLOCK);
    int nalts = blk.getChildCount();
    GrammarAST idAST = (GrammarAST) rule.getChild(0);
    for (int i = 0; i < nalts; i++) {
        AltAST altAST = (AltAST) blk.getChild(i);
        if (altAST.altLabel != null) {
            String altLabel = altAST.altLabel.getText();
            // first check that label doesn't conflict with a rule
            // label X or x can't be rule x.
            Rule r = ruleCollector.rules.get(Utils.decapitalize(altLabel));
            if (r != null) {
                g.tool.errMgr.grammarError(ErrorType.ALT_LABEL_CONFLICTS_WITH_RULE, g.fileName, altAST.altLabel.token, altLabel, r.name);
            }
            // Now verify that label X or x doesn't conflict with label
            // in another rule. altLabelToRuleName has both X and x mapped.
            String prevRuleForLabel = ruleCollector.altLabelToRuleName.get(altLabel);
            if (prevRuleForLabel != null && !prevRuleForLabel.equals(rule.getRuleName())) {
                g.tool.errMgr.grammarError(ErrorType.ALT_LABEL_REDEF, g.fileName, altAST.altLabel.token, altLabel, rule.getRuleName(), prevRuleForLabel);
            }
        }
    }
    List<GrammarAST> altLabels = ruleCollector.ruleToAltLabels.get(rule.getRuleName());
    int numAltLabels = 0;
    if (altLabels != null)
        numAltLabels = altLabels.size();
    if (numAltLabels > 0 && nalts != numAltLabels) {
        g.tool.errMgr.grammarError(ErrorType.RULE_WITH_TOO_FEW_ALT_LABELS, g.fileName, idAST.token, rule.getRuleName());
    }
}", ,"// first check that label doesn't conflict with a rule
[[SEP]]// Now verify that label X or x doesn't conflict with label
[[SEP]]// label X or x can't be rule x.
[[SEP]]// in another rule. altLabelToRuleName has both X and x mapped.
",// first check that label doesn't conflict with a rule// label X or x can't be rule x.[[SEP]]// Now verify that label X or x doesn't conflict with label// in another rule. altLabelToRuleName has both X and x mapped.,261,299,[0],0,"[0, 0, 0, 0]",0,"[0, 0]",0,0,0,0,"finishRule(RuleAST, GrammarAST, GrammarAST)",org.antlr.v4.semantics.BasicSemanticChecks,"finishRule/3[org.antlr.v4.tool.ast.RuleAST,org.antlr.v4.tool.ast.GrammarAST,org.antlr.v4.tool.ast.GrammarAST]",False,262,7,4,0,4,10,12,26,1,10,3,12,0,0,1,5,0,0,0,4,11,0,3,0,0,0,26,1,0,False
1151,..\projects\antlr4-4.11.0\tool\src\org\antlr\v4\semantics\BasicSemanticChecks.java,org.antlr.v4.semantics.BasicSemanticChecks,void checkGrammarName(Token),"// Routines to do the actual work of checking issues with a grammar.
// They are triggered by the visitor methods above.
void checkGrammarName(Token nameToken) {
    String fullyQualifiedName = nameToken.getInputStream().getSourceName();
    if (fullyQualifiedName == null) {
        // This wasn't read from a file.
        return;
    }
    File f = new File(fullyQualifiedName);
    String fileName = f.getName();
    // don't warn about diff if this is implicit lexer
    if (g.originalGrammar != null)
        return;
    if (!Utils.stripFileExtension(fileName).equals(nameToken.getText()) && !fileName.equals(Grammar.GRAMMAR_FROM_STRING_NAME)) {
        g.tool.errMgr.grammarError(ErrorType.FILE_AND_GRAMMAR_NAME_DIFFER, fileName, nameToken, nameToken.getText(), fileName);
    }
}", ,"// This wasn't read from a file.
[[SEP]]// don't warn about diff if this is implicit lexer
",// Routines to do the actual work of checking issues with a grammar.// They are triggered by the visitor methods above.[[SEP]]// This wasn't read from a file.[[SEP]]// don't warn about diff if this is implicit lexer,304,319,[0],0,"[0, 0]",0,"[0, 0, 0]",0,0,0,0,checkGrammarName(Token),org.antlr.v4.semantics.BasicSemanticChecks,checkGrammarName/1[org.antlr.v4.semantics.Token],False,304,3,3,1,2,5,7,12,2,3,1,7,0,0,0,2,0,0,0,0,3,0,1,0,0,0,11,0,0,False
1152,..\projects\antlr4-4.11.0\tool\src\org\antlr\v4\semantics\BasicSemanticChecks.java,org.antlr.v4.semantics.BasicSemanticChecks,void checkElementIsOuterMostInSingleAlt(GrammarAST),"/**
 * 	 Make sure that action is last element in outer alt; here action,
 * 	 a2, z, and zz are bad, but a3 is ok:
 * 	 (RULE A (BLOCK (ALT {action} 'a')))
 * 	 (RULE B (BLOCK (ALT (BLOCK (ALT {a2} 'x') (ALT 'y')) {a3})))
 * 	 (RULE C (BLOCK (ALT 'd' {z}) (ALT 'e' {zz})))
 */
protected void checkElementIsOuterMostInSingleAlt(GrammarAST tree) {
    CommonTree alt = tree.parent;
    CommonTree blk = alt.parent;
    boolean outerMostAlt = blk.parent.getType() == RULE;
    Tree rule = tree.getAncestor(RULE);
    String fileName = tree.getToken().getInputStream().getSourceName();
    if (!outerMostAlt || blk.getChildCount() > 1) {
        ErrorType e = ErrorType.LEXER_COMMAND_PLACEMENT_ISSUE;
        g.tool.errMgr.grammarError(e, fileName, tree.getToken(), rule.getChild(0).getText());
    }
}","/**
 * 	 Make sure that action is last element in outer alt; here action,
 * 	 a2, z, and zz are bad, but a3 is ok:
 * 	 (RULE A (BLOCK (ALT {action} 'a')))
 * 	 (RULE B (BLOCK (ALT (BLOCK (ALT {a2} 'x') (ALT 'y')) {a3})))
 * 	 (RULE C (BLOCK (ALT 'd' {z}) (ALT 'e' {zz})))
 */
", ,"/** * 	 Make sure that action is last element in outer alt; here action, * 	 a2, z, and zz are bad, but a3 is ok: * 	 (RULE A (BLOCK (ALT {action} 'a'))) * 	 (RULE B (BLOCK (ALT (BLOCK (ALT {a2} 'x') (ALT 'y')) {a3}))) * 	 (RULE C (BLOCK (ALT 'd' {z}) (ALT 'e' {zz}))) */",420,435,[0],0,[0],0,[0],0,0,0,0,checkElementIsOuterMostInSingleAlt(GrammarAST),org.antlr.v4.semantics.BasicSemanticChecks,checkElementIsOuterMostInSingleAlt/1[org.antlr.v4.tool.ast.GrammarAST],False,420,5,2,1,1,4,9,11,0,6,1,9,0,0,0,1,0,0,0,2,6,0,1,0,0,0,48,4,0,True
1153,..\projects\antlr4-4.11.0\tool\src\org\antlr\v4\semantics\BasicSemanticChecks.java,org.antlr.v4.semantics.BasicSemanticChecks,"void label(GrammarAST, GrammarAST, GrammarAST)","@Override
public void label(GrammarAST op, GrammarAST ID, GrammarAST element) {
    switch(element.getType()) {
        // token atoms
        case TOKEN_REF:
        case STRING_LITERAL:
        case RANGE:
        // token sets
        case SET:
        case NOT:
        // rule atoms
        case RULE_REF:
        case WILDCARD:
            return;
        default:
            String fileName = ID.token.getInputStream().getSourceName();
            g.tool.errMgr.grammarError(ErrorType.LABEL_BLOCK_NOT_A_SET, fileName, ID.token, ID.getText());
            break;
    }
}", ,"// token atoms
[[SEP]]// token sets
[[SEP]]// rule atoms
",// token atoms[[SEP]]// token sets[[SEP]]// rule atoms,437,457,[0],0,"[0, 0, 0]",0,"[0, 0, 0]",0,0,0,0,"label(GrammarAST, GrammarAST, GrammarAST)",org.antlr.v4.semantics.BasicSemanticChecks,"label/3[org.antlr.v4.tool.ast.GrammarAST,org.antlr.v4.tool.ast.GrammarAST,org.antlr.v4.tool.ast.GrammarAST]",False,438,2,1,0,1,8,5,16,1,1,3,5,0,0,0,0,0,0,0,0,1,0,1,0,0,0,8,1,0,False
1154,..\projects\antlr4-4.11.0\tool\src\org\antlr\v4\semantics\BasicSemanticChecks.java,org.antlr.v4.semantics.BasicSemanticChecks,"void checkOptions(GrammarAST, Token, GrammarAST)","/**
 * Check option is appropriate for grammar, rule, subrule
 */
void checkOptions(GrammarAST parent, Token optionID, GrammarAST valueAST) {
    Set<String> optionsToCheck = null;
    int parentType = parent.getType();
    switch(parentType) {
        case ANTLRParser.BLOCK:
            optionsToCheck = g.isLexer() ? Grammar.lexerBlockOptions : Grammar.parserBlockOptions;
            break;
        case ANTLRParser.RULE:
            optionsToCheck = g.isLexer() ? Grammar.lexerRuleOptions : Grammar.parseRuleOptions;
            break;
        case ANTLRParser.GRAMMAR:
            optionsToCheck = g.getType() == ANTLRParser.LEXER ? Grammar.lexerOptions : Grammar.parserOptions;
            break;
    }
    String optionName = optionID.getText();
    if (optionsToCheck != null && !optionsToCheck.contains(optionName)) {
        g.tool.errMgr.grammarError(ErrorType.ILLEGAL_OPTION, g.fileName, optionID, optionName);
    } else {
        checkCaseInsensitiveOption(optionID, valueAST, parentType);
    }
}","/**
 * Check option is appropriate for grammar, rule, subrule
 */
", ,"/** * Check option is appropriate for grammar, rule, subrule */",468,491,[0],0,[0],0,[0],0,0,0,0,"checkOptions(GrammarAST, Token, GrammarAST)",org.antlr.v4.semantics.BasicSemanticChecks,"checkOptions/3[org.antlr.v4.tool.ast.GrammarAST,org.antlr.v4.semantics.Token,org.antlr.v4.tool.ast.GrammarAST]",False,468,5,7,3,4,9,7,22,0,3,3,7,1,1,0,2,0,0,0,0,6,0,1,0,0,0,21,0,0,True
1155,..\projects\antlr4-4.11.0\tool\src\org\antlr\v4\semantics\BasicSemanticChecks.java,org.antlr.v4.semantics.BasicSemanticChecks,"boolean checkElementOptions(GrammarASTWithOptions, GrammarAST, GrammarAST)","/**
 * Check option is appropriate for elem; parent of ID is ELEMENT_OPTIONS
 */
boolean checkElementOptions(GrammarASTWithOptions elem, GrammarAST ID, GrammarAST valueAST) {
    if (checkAssocElementOption && ID != null && ""assoc"".equals(ID.getText())) {
        if (elem.getType() != ANTLRParser.ALT) {
            Token optionID = ID.token;
            String fileName = optionID.getInputStream().getSourceName();
            g.tool.errMgr.grammarError(ErrorType.UNRECOGNIZED_ASSOC_OPTION, fileName, optionID, currentRuleName);
        }
    }
    if (elem instanceof RuleRefAST) {
        return checkRuleRefOptions((RuleRefAST) elem, ID, valueAST);
    }
    if (elem instanceof TerminalAST) {
        return checkTokenOptions((TerminalAST) elem, ID, valueAST);
    }
    if (elem.getType() == ANTLRParser.ACTION) {
        return false;
    }
    if (elem.getType() == ANTLRParser.SEMPRED) {
        Token optionID = ID.token;
        String fileName = optionID.getInputStream().getSourceName();
        if (valueAST != null && !Grammar.semPredOptions.contains(optionID.getText())) {
            g.tool.errMgr.grammarError(ErrorType.ILLEGAL_OPTION, fileName, optionID, optionID.getText());
            return false;
        }
    }
    return false;
}","/**
 * Check option is appropriate for elem; parent of ID is ELEMENT_OPTIONS
 */
", ,/** * Check option is appropriate for elem; parent of ID is ELEMENT_OPTIONS */,517,553,[0],0,[0],0,[0],0,0,0,0,"checkElementOptions(GrammarASTWithOptions, GrammarAST, GrammarAST)",org.antlr.v4.semantics.BasicSemanticChecks,"checkElementOptions/3[org.antlr.v4.tool.ast.GrammarASTWithOptions,org.antlr.v4.tool.ast.GrammarAST,org.antlr.v4.tool.ast.GrammarAST]",False,520,7,4,1,3,11,9,27,5,4,3,9,2,1,0,5,0,0,1,0,4,0,2,0,0,0,35,0,0,True
1156,..\projects\antlr4-4.11.0\tool\src\org\antlr\v4\semantics\BasicSemanticChecks.java,org.antlr.v4.semantics.BasicSemanticChecks,"boolean checkRuleRefOptions(RuleRefAST, GrammarAST, GrammarAST)","boolean checkRuleRefOptions(RuleRefAST elem, GrammarAST ID, GrammarAST valueAST) {
    Token optionID = ID.token;
    String fileName = optionID.getInputStream().getSourceName();
    // don't care about id<SimpleValue> options
    if (valueAST != null && !Grammar.ruleRefOptions.contains(optionID.getText())) {
        g.tool.errMgr.grammarError(ErrorType.ILLEGAL_OPTION, fileName, optionID, optionID.getText());
        return false;
    }
    // TODO: extra checks depending on rule kind?
    return true;
}", ,"// don't care about id<SimpleValue> options
[[SEP]]// TODO: extra checks depending on rule kind?
",// don't care about id<SimpleValue> options[[SEP]]// TODO: extra checks depending on rule kind?,555,568,[0],0,"[0, 1]",1,"[0, 1]",1,1,1,1,"checkRuleRefOptions(RuleRefAST, GrammarAST, GrammarAST)",org.antlr.v4.semantics.BasicSemanticChecks,"checkRuleRefOptions/3[org.antlr.v4.tool.ast.RuleRefAST,org.antlr.v4.tool.ast.GrammarAST,org.antlr.v4.tool.ast.GrammarAST]",False,555,4,2,1,1,3,5,9,2,2,3,5,0,0,0,1,0,0,0,0,2,0,1,0,0,0,17,0,0,False
1157,..\projects\antlr4-4.11.0\tool\src\org\antlr\v4\semantics\BasicSemanticChecks.java,org.antlr.v4.semantics.BasicSemanticChecks,"boolean checkTokenOptions(TerminalAST, GrammarAST, GrammarAST)","boolean checkTokenOptions(TerminalAST elem, GrammarAST ID, GrammarAST valueAST) {
    Token optionID = ID.token;
    String fileName = optionID.getInputStream().getSourceName();
    // don't care about ID<ASTNodeName> options
    if (valueAST != null && !Grammar.tokenOptions.contains(optionID.getText())) {
        g.tool.errMgr.grammarError(ErrorType.ILLEGAL_OPTION, fileName, optionID, optionID.getText());
        return false;
    }
    // TODO: extra checks depending on terminal kind?
    return true;
}", ,"// don't care about ID<ASTNodeName> options
[[SEP]]// TODO: extra checks depending on terminal kind?
",// don't care about ID<ASTNodeName> options[[SEP]]// TODO: extra checks depending on terminal kind?,570,583,[0],0,"[0, 1]",1,"[0, 1]",1,1,1,1,"checkTokenOptions(TerminalAST, GrammarAST, GrammarAST)",org.antlr.v4.semantics.BasicSemanticChecks,"checkTokenOptions/3[org.antlr.v4.tool.ast.TerminalAST,org.antlr.v4.tool.ast.GrammarAST,org.antlr.v4.tool.ast.GrammarAST]",False,570,4,2,1,1,3,5,9,2,2,3,5,0,0,0,1,0,0,0,0,2,0,1,0,0,0,16,0,0,False
1158,..\projects\antlr4-4.11.0\tool\src\org\antlr\v4\semantics\RuleCollector.java,org.antlr.v4.semantics.RuleCollector,"void discoverRule(RuleAST, GrammarAST, List<GrammarAST>, ActionAST, ActionAST, GrammarAST, GrammarAST, ActionAST, List<GrammarAST>, GrammarAST)","@Override
public void discoverRule(RuleAST rule, GrammarAST ID, List<GrammarAST> modifiers, ActionAST arg, ActionAST returns, GrammarAST thrws, GrammarAST options, ActionAST locals, List<GrammarAST> actions, GrammarAST block) {
    int numAlts = block.getChildCount();
    Rule r;
    if (LeftRecursiveRuleAnalyzer.hasImmediateRecursiveRuleRefs(rule, ID.getText())) {
        r = new LeftRecursiveRule(g, ID.getText(), rule);
    } else {
        r = new Rule(g, ID.getText(), rule, numAlts);
    }
    rules.put(r.name, r);
    if (arg != null) {
        r.args = ScopeParser.parseTypedArgList(arg, arg.getText(), g);
        r.args.type = AttributeDict.DictType.ARG;
        r.args.ast = arg;
        arg.resolver = r.alt[currentOuterAltNumber];
    }
    if (returns != null) {
        r.retvals = ScopeParser.parseTypedArgList(returns, returns.getText(), g);
        r.retvals.type = AttributeDict.DictType.RET;
        r.retvals.ast = returns;
    }
    if (locals != null) {
        r.locals = ScopeParser.parseTypedArgList(locals, locals.getText(), g);
        r.locals.type = AttributeDict.DictType.LOCAL;
        r.locals.ast = locals;
    }
    for (GrammarAST a : actions) {
        // a = ^(AT ID ACTION)
        ActionAST action = (ActionAST) a.getChild(1);
        r.namedActions.put(a.getChild(0).getText(), action);
        action.resolver = r;
    }
}", ,"// a = ^(AT ID ACTION)
",// a = ^(AT ID ACTION),47,90,[0],0,[0],0,[0],0,0,0,0,"discoverRule(RuleAST, GrammarAST, List<GrammarAST>, ActionAST, ActionAST, GrammarAST, GrammarAST, ActionAST, List<GrammarAST>, GrammarAST)",org.antlr.v4.semantics.RuleCollector,"discoverRule/10[org.antlr.v4.tool.ast.RuleAST,org.antlr.v4.tool.ast.GrammarAST,java.util.List<org.antlr.v4.tool.ast.GrammarAST>,org.antlr.v4.tool.ast.ActionAST,org.antlr.v4.tool.ast.ActionAST,org.antlr.v4.tool.ast.GrammarAST,org.antlr.v4.tool.ast.GrammarAST,org.antlr.v4.tool.ast.ActionAST,java.util.List<org.antlr.v4.tool.ast.GrammarAST>,org.antlr.v4.tool.ast.GrammarAST]",False,54,6,3,0,3,6,7,32,0,3,10,7,0,0,1,3,0,0,0,2,15,0,1,0,0,0,20,1,0,False
1159,..\projects\antlr4-4.11.0\tool\src\org\antlr\v4\semantics\SemanticPipeline.java,org.antlr.v4.semantics.SemanticPipeline,void process(),"public void process() {
    if (g.ast == null)
        return;
    // COLLECT RULE OBJECTS
    RuleCollector ruleCollector = new RuleCollector(g);
    ruleCollector.process(g.ast);
    // DO BASIC / EASY SEMANTIC CHECKS
    int prevErrors = g.tool.errMgr.getNumErrors();
    BasicSemanticChecks basics = new BasicSemanticChecks(g, ruleCollector);
    basics.process();
    if (g.tool.errMgr.getNumErrors() > prevErrors)
        return;
    // TRANSFORM LEFT-RECURSIVE RULES
    prevErrors = g.tool.errMgr.getNumErrors();
    LeftRecursiveRuleTransformer lrtrans = new LeftRecursiveRuleTransformer(g.ast, ruleCollector.rules.values(), g);
    lrtrans.translateLeftRecursiveRules();
    // don't continue if we got errors during left-recursion elimination
    if (g.tool.errMgr.getNumErrors() > prevErrors)
        return;
    // STORE RULES IN GRAMMAR
    for (Rule r : ruleCollector.rules.values()) {
        g.defineRule(r);
    }
    // COLLECT SYMBOLS: RULES, ACTIONS, TERMINALS, ...
    SymbolCollector collector = new SymbolCollector(g);
    collector.process(g.ast);
    // CHECK FOR SYMBOL COLLISIONS
    SymbolChecks symcheck = new SymbolChecks(g, collector);
    // side-effect: strip away redef'd rules.
    symcheck.process();
    for (GrammarAST a : collector.namedActions) {
        g.defineAction(a);
    }
    // LINK (outermost) ALT NODES WITH Alternatives
    for (Rule r : g.rules.values()) {
        for (int i = 1; i <= r.numberOfAlts; i++) {
            r.alt[i].ast.alt = r.alt[i];
        }
    }
    // ASSIGN TOKEN TYPES
    g.importTokensFromTokensFile();
    if (g.isLexer()) {
        assignLexerTokenTypes(g, collector.tokensDefs);
    } else {
        assignTokenTypes(g, collector.tokensDefs, collector.tokenIDRefs, collector.terminals);
    }
    symcheck.checkForModeConflicts(g);
    symcheck.checkForUnreachableTokens(g);
    assignChannelTypes(g, collector.channelDefs);
    // CHECK RULE REFS NOW (that we've defined rules in grammar)
    symcheck.checkRuleArgs(g, collector.rulerefs);
    identifyStartRules(collector);
    symcheck.checkForQualifiedRuleIssues(g, collector.qualifiedRulerefs);
    // don't continue if we got symbol errors
    if (g.tool.getNumErrors() > 0)
        return;
    // CHECK ATTRIBUTE EXPRESSIONS FOR SEMANTIC VALIDITY
    AttributeChecks.checkAllAttributeExpressions(g);
    UseDefAnalyzer.trackTokenRuleRefsInActions(g);
}", ,"// COLLECT RULE OBJECTS
[[SEP]]// DO BASIC / EASY SEMANTIC CHECKS
[[SEP]]// TRANSFORM LEFT-RECURSIVE RULES
[[SEP]]// don't continue if we got errors during left-recursion elimination
[[SEP]]// STORE RULES IN GRAMMAR
[[SEP]]// COLLECT SYMBOLS: RULES, ACTIONS, TERMINALS, ...
[[SEP]]// CHECK FOR SYMBOL COLLISIONS
[[SEP]]// side-effect: strip away redef'd rules.
[[SEP]]// LINK (outermost) ALT NODES WITH Alternatives
[[SEP]]// ASSIGN TOKEN TYPES
[[SEP]]// CHECK RULE REFS NOW (that we've defined rules in grammar)
[[SEP]]// don't continue if we got symbol errors
[[SEP]]// CHECK ATTRIBUTE EXPRESSIONS FOR SEMANTIC VALIDITY
","// COLLECT RULE OBJECTS[[SEP]]// DO BASIC / EASY SEMANTIC CHECKS[[SEP]]// TRANSFORM LEFT-RECURSIVE RULES[[SEP]]// don't continue if we got errors during left-recursion elimination[[SEP]]// STORE RULES IN GRAMMAR[[SEP]]// COLLECT SYMBOLS: RULES, ACTIONS, TERMINALS, ...[[SEP]]// CHECK FOR SYMBOL COLLISIONS[[SEP]]// side-effect: strip away redef'd rules.[[SEP]]// LINK (outermost) ALT NODES WITH Alternatives[[SEP]]// ASSIGN TOKEN TYPES[[SEP]]// CHECK RULE REFS NOW (that we've defined rules in grammar)[[SEP]]// don't continue if we got symbol errors[[SEP]]// CHECK ATTRIBUTE EXPRESSIONS FOR SEMANTIC VALIDITY",54,127,[0],0,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]",0,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]",0,0,0,0,process(),org.antlr.v4.semantics.SemanticPipeline,process/0,False,54,11,28,4,24,10,22,44,4,7,0,22,4,2,4,1,0,0,0,2,9,0,2,0,0,0,34,1,0,False
1160,..\projects\antlr4-4.11.0\tool\src\org\antlr\v4\semantics\SemanticPipeline.java,org.antlr.v4.semantics.SemanticPipeline,"void assignLexerTokenTypes(Grammar, List<GrammarAST>)","void assignLexerTokenTypes(Grammar g, List<GrammarAST> tokensDefs) {
    // put in root, even if imported
    Grammar G = g.getOutermostGrammar();
    for (GrammarAST def : tokensDefs) {
        // tokens { id (',' id)* } so must check IDs not TOKEN_REF
        if (Grammar.isTokenName(def.getText())) {
            G.defineTokenName(def.getText());
        }
    }
    /* Define token types for nonfragment rules which do not include a 'type(...)'
		 * or 'more' lexer command.
		 */
    for (Rule r : g.rules.values()) {
        if (!r.isFragment() && !hasTypeOrMoreCommand(r)) {
            G.defineTokenName(r.name);
        }
    }
    // FOR ALL X : 'xxx'; RULES, DEFINE 'xxx' AS TYPE X
    List<Pair<GrammarAST, GrammarAST>> litAliases = Grammar.getStringLiteralAliasesFromLexerRules(g.ast);
    Set<String> conflictingLiterals = new HashSet<String>();
    if (litAliases != null) {
        for (Pair<GrammarAST, GrammarAST> pair : litAliases) {
            GrammarAST nameAST = pair.a;
            GrammarAST litAST = pair.b;
            if (!G.stringLiteralToTypeMap.containsKey(litAST.getText())) {
                G.defineTokenAlias(nameAST.getText(), litAST.getText());
            } else {
                // oops two literal defs in two rules (within or across modes).
                conflictingLiterals.add(litAST.getText());
            }
        }
        for (String lit : conflictingLiterals) {
            // Remove literal if repeated across rules so it's not
            // found by parser grammar.
            Integer value = G.stringLiteralToTypeMap.remove(lit);
            if (value != null && value > 0 && value < G.typeToStringLiteralList.size() && lit.equals(G.typeToStringLiteralList.get(value))) {
                G.typeToStringLiteralList.set(value, null);
            }
        }
    }
}", ,"// put in root, even if imported
[[SEP]]// tokens { id (',' id)* } so must check IDs not TOKEN_REF
[[SEP]]/* Define token types for nonfragment rules which do not include a 'type(...)'
		 * or 'more' lexer command.
		 */
[[SEP]]// FOR ALL X : 'xxx'; RULES, DEFINE 'xxx' AS TYPE X
[[SEP]]// oops two literal defs in two rules (within or across modes).
[[SEP]]// Remove literal if repeated across rules so it's not
[[SEP]]// found by parser grammar.
","// put in root, even if imported[[SEP]]// tokens { id (',' id)* } so must check IDs not TOKEN_REF[[SEP]]/* Define token types for nonfragment rules which do not include a 'type(...)'		 * or 'more' lexer command.		 */[[SEP]]// FOR ALL X : 'xxx'; RULES, DEFINE 'xxx' AS TYPE X[[SEP]]// oops two literal defs in two rules (within or across modes).[[SEP]]// Remove literal if repeated across rules so it's not// found by parser grammar.",137,180,[0],0,"[0, 0, 0, 0, 0, 0, 0]",0,"[0, 0, 0, 0, 0, 0]",0,1,0,0,"assignLexerTokenTypes(Grammar, List<GrammarAST>)",org.antlr.v4.semantics.SemanticPipeline,"assignLexerTokenTypes/2[org.antlr.v4.tool.Grammar,java.util.List<org.antlr.v4.tool.ast.GrammarAST>]",False,137,5,8,1,7,14,16,33,0,6,2,16,1,1,4,2,0,0,0,1,6,0,3,0,0,0,28,0,0,False
1161,..\projects\antlr4-4.11.0\tool\src\org\antlr\v4\semantics\SemanticPipeline.java,org.antlr.v4.semantics.SemanticPipeline,boolean hasTypeOrMoreCommand(Rule),"boolean hasTypeOrMoreCommand(Rule r) {
    GrammarAST ast = r.ast;
    if (ast == null) {
        return false;
    }
    GrammarAST altActionAst = (GrammarAST) ast.getFirstDescendantWithType(ANTLRParser.LEXER_ALT_ACTION);
    if (altActionAst == null) {
        // the rule isn't followed by any commands
        return false;
    }
    // first child is the alt itself, subsequent are the actions
    for (int i = 1; i < altActionAst.getChildCount(); i++) {
        GrammarAST node = (GrammarAST) altActionAst.getChild(i);
        if (node.getType() == ANTLRParser.LEXER_ACTION_CALL) {
            if (""type"".equals(node.getChild(0).getText())) {
                return true;
            }
        } else if (""more"".equals(node.getText())) {
            return true;
        }
    }
    return false;
}", ,"// the rule isn't followed by any commands
[[SEP]]// first child is the alt itself, subsequent are the actions
","// the rule isn't followed by any commands[[SEP]]// first child is the alt itself, subsequent are the actions",182,208,[0],0,"[0, 0]",0,"[0, 0]",0,0,0,0,hasTypeOrMoreCommand(Rule),org.antlr.v4.semantics.SemanticPipeline,hasTypeOrMoreCommand/1[org.antlr.v4.tool.Rule],False,182,2,2,1,1,7,6,22,5,4,1,6,0,0,1,3,0,0,2,2,4,0,3,0,0,0,20,0,0,False
1162,..\projects\antlr4-4.11.0\tool\src\org\antlr\v4\semantics\SemanticPipeline.java,org.antlr.v4.semantics.SemanticPipeline,"void assignTokenTypes(Grammar, List<GrammarAST>, List<GrammarAST>, List<GrammarAST>)","void assignTokenTypes(Grammar g, List<GrammarAST> tokensDefs, List<GrammarAST> tokenIDs, List<GrammarAST> terminals) {
    // Grammar G = g.getOutermostGrammar(); // put in root, even if imported
    // create token types for tokens { A, B, C } ALIASES
    for (GrammarAST alias : tokensDefs) {
        if (g.getTokenType(alias.getText()) != Token.INVALID_TYPE) {
            g.tool.errMgr.grammarError(ErrorType.TOKEN_NAME_REASSIGNMENT, g.fileName, alias.token, alias.getText());
        }
        g.defineTokenName(alias.getText());
    }
    // DEFINE TOKEN TYPES FOR TOKEN REFS LIKE ID, INT
    for (GrammarAST idAST : tokenIDs) {
        if (g.getTokenType(idAST.getText()) == Token.INVALID_TYPE) {
            g.tool.errMgr.grammarError(ErrorType.IMPLICIT_TOKEN_DEFINITION, g.fileName, idAST.token, idAST.getText());
        }
        g.defineTokenName(idAST.getText());
    }
    // VERIFY TOKEN TYPES FOR STRING LITERAL REFS LIKE 'while', ';'
    for (GrammarAST termAST : terminals) {
        if (termAST.getType() != ANTLRParser.STRING_LITERAL) {
            continue;
        }
        if (g.getTokenType(termAST.getText()) == Token.INVALID_TYPE) {
            g.tool.errMgr.grammarError(ErrorType.IMPLICIT_STRING_DEFINITION, g.fileName, termAST.token, termAST.getText());
        }
    }
    g.tool.log(""semantics"", ""tokens="" + g.tokenNameToTypeMap);
    g.tool.log(""semantics"", ""strings="" + g.stringLiteralToTypeMap);
}", ,"// Grammar G = g.getOutermostGrammar(); // put in root, even if imported
[[SEP]]// create token types for tokens { A, B, C } ALIASES
[[SEP]]// DEFINE TOKEN TYPES FOR TOKEN REFS LIKE ID, INT
[[SEP]]// VERIFY TOKEN TYPES FOR STRING LITERAL REFS LIKE 'while', ';'
","// Grammar G = g.getOutermostGrammar(); // put in root, even if imported// create token types for tokens { A, B, C } ALIASES[[SEP]]// DEFINE TOKEN TYPES FOR TOKEN REFS LIKE ID, INT[[SEP]]// VERIFY TOKEN TYPES FOR STRING LITERAL REFS LIKE 'while', ';'",210,246,[0],0,"[0, 0, 0, 0]",0,"[0, 0, 0]",0,0,0,0,"assignTokenTypes(Grammar, List<GrammarAST>, List<GrammarAST>, List<GrammarAST>)",org.antlr.v4.semantics.SemanticPipeline,"assignTokenTypes/4[org.antlr.v4.tool.Grammar,java.util.List<org.antlr.v4.tool.ast.GrammarAST>,java.util.List<org.antlr.v4.tool.ast.GrammarAST>,java.util.List<org.antlr.v4.tool.ast.GrammarAST>]",False,212,4,5,1,4,8,6,24,0,0,4,6,0,0,3,4,0,0,4,0,0,2,2,0,0,0,16,0,0,False
1163,..\projects\antlr4-4.11.0\tool\src\org\antlr\v4\semantics\SemanticPipeline.java,org.antlr.v4.semantics.SemanticPipeline,"void assignChannelTypes(Grammar, List<GrammarAST>)","/**
 * Assign constant values to custom channels defined in a grammar.
 *
 * @param g The grammar.
 * @param channelDefs A collection of AST nodes defining individual channels
 * within a {@code channels{}} block in the grammar.
 */
void assignChannelTypes(Grammar g, List<GrammarAST> channelDefs) {
    Grammar outermost = g.getOutermostGrammar();
    for (GrammarAST channel : channelDefs) {
        String channelName = channel.getText();
        // Channel names can't alias tokens or modes, because constant
        // values are also assigned to them and the ->channel(NAME) lexer
        // command does not distinguish between the various ways a constant
        // can be declared. This method does not verify that channels do not
        // alias rules, because rule names are not associated with constant
        // values in ANTLR grammar semantics.
        if (g.getTokenType(channelName) != Token.INVALID_TYPE) {
            g.tool.errMgr.grammarError(ErrorType.CHANNEL_CONFLICTS_WITH_TOKEN, g.fileName, channel.token, channelName);
        }
        if (LexerATNFactory.COMMON_CONSTANTS.containsKey(channelName)) {
            g.tool.errMgr.grammarError(ErrorType.CHANNEL_CONFLICTS_WITH_COMMON_CONSTANTS, g.fileName, channel.token, channelName);
        }
        if (outermost instanceof LexerGrammar) {
            LexerGrammar lexerGrammar = (LexerGrammar) outermost;
            if (lexerGrammar.modes.containsKey(channelName)) {
                g.tool.errMgr.grammarError(ErrorType.CHANNEL_CONFLICTS_WITH_MODE, g.fileName, channel.token, channelName);
            }
        }
        outermost.defineChannelName(channel.getText());
    }
}","/**
 * Assign constant values to custom channels defined in a grammar.
 *
 * @param g The grammar.
 * @param channelDefs A collection of AST nodes defining individual channels
 * within a {@code channels{}} block in the grammar.
 */
","// Channel names can't alias tokens or modes, because constant
[[SEP]]// values are also assigned to them and the ->channel(NAME) lexer
[[SEP]]// command does not distinguish between the various ways a constant
[[SEP]]// can be declared. This method does not verify that channels do not
[[SEP]]// alias rules, because rule names are not associated with constant
[[SEP]]// values in ANTLR grammar semantics.
","/** * Assign constant values to custom channels defined in a grammar. * * @param g The grammar. * @param channelDefs A collection of AST nodes defining individual channels * within a {@code channels{}} block in the grammar. */[[SEP]]// Channel names can't alias tokens or modes, because constant// values are also assigned to them and the ->channel(NAME) lexer// command does not distinguish between the various ways a constant// can be declared. This method does not verify that channels do not// alias rules, because rule names are not associated with constant// values in ANTLR grammar semantics.",255,284,[0],0,"[0, 0, 0, 0, 0, 0]",0,"[0, 0]",0,0,0,0,"assignChannelTypes(Grammar, List<GrammarAST>)",org.antlr.v4.semantics.SemanticPipeline,"assignChannelTypes/2[org.antlr.v4.tool.Grammar,java.util.List<org.antlr.v4.tool.ast.GrammarAST>]",False,255,4,5,1,4,6,6,19,0,3,2,6,0,0,1,1,0,0,0,0,3,0,3,0,0,0,32,0,0,True
1164,..\projects\antlr4-4.11.0\tool\src\org\antlr\v4\semantics\SymbolChecks.java,org.antlr.v4.semantics.SymbolChecks,void process(),"public void process() {
    // methods affect fields, but no side-effects outside this object
    // So, call order sensitive
    // First collect all rules for later use in checkForLabelConflict()
    if (g.rules != null) {
        for (Rule r : g.rules.values()) nameToRuleMap.put(r.name, r);
    }
    checkReservedNames(g.rules.values());
    checkActionRedefinitions(collector.namedActions);
    checkForLabelConflicts(g.rules.values());
}", ,"// methods affect fields, but no side-effects outside this object
[[SEP]]// So, call order sensitive
[[SEP]]// First collect all rules for later use in checkForLabelConflict()
","// methods affect fields, but no side-effects outside this object// So, call order sensitive// First collect all rules for later use in checkForLabelConflict()",69,79,[0],0,"[0, 0, 0]",0,[0],0,0,0,0,process(),org.antlr.v4.semantics.SymbolChecks,process/0,False,69,1,4,1,3,3,5,8,0,0,0,5,3,4,1,1,0,0,0,0,0,0,2,0,0,0,12,1,0,False
1165,..\projects\antlr4-4.11.0\tool\src\org\antlr\v4\semantics\SymbolChecks.java,org.antlr.v4.semantics.SymbolChecks,void checkActionRedefinitions(List<GrammarAST>),"public void checkActionRedefinitions(List<GrammarAST> actions) {
    if (actions == null)
        return;
    String scope = g.getDefaultActionScope();
    String name;
    GrammarAST nameNode;
    for (GrammarAST ampersandAST : actions) {
        nameNode = (GrammarAST) ampersandAST.getChild(0);
        if (ampersandAST.getChildCount() == 2) {
            name = nameNode.getText();
        } else {
            scope = nameNode.getText();
            name = ampersandAST.getChild(1).getText();
        }
        Set<String> scopeActions = actionScopeToActionNames.get(scope);
        if (scopeActions == null) {
            // init scope
            scopeActions = new HashSet<String>();
            actionScopeToActionNames.put(scope, scopeActions);
        }
        if (!scopeActions.contains(name)) {
            scopeActions.add(name);
        } else {
            errMgr.grammarError(ErrorType.ACTION_REDEFINITION, g.fileName, nameNode.token, name);
        }
    }
}", ,"// init scope
",// init scope,81,108,[0],0,[0],0,[0],0,0,0,0,checkActionRedefinitions(List<GrammarAST>),org.antlr.v4.semantics.SymbolChecks,checkActionRedefinitions/1[java.util.List<org.antlr.v4.tool.ast.GrammarAST>],False,81,3,3,1,2,6,9,27,1,4,1,9,0,0,1,3,0,0,0,3,7,0,2,0,0,0,14,1,0,False
1166,..\projects\antlr4-4.11.0\tool\src\org\antlr\v4\semantics\SymbolChecks.java,org.antlr.v4.semantics.SymbolChecks,void checkForLabelConflicts(Collection<Rule>),"/**
 * Make sure a label doesn't conflict with another symbol.
 * Labels must not conflict with: rules, tokens, scope names,
 * return values, parameters, and rule-scope dynamic attributes
 * defined in surrounding rule.  Also they must have same type
 * for repeated defs.
 */
public void checkForLabelConflicts(Collection<Rule> rules) {
    for (Rule r : rules) {
        checkForAttributeConflicts(r);
        Map<String, LabelElementPair> labelNameSpace = new HashMap<>();
        for (int i = 1; i <= r.numberOfAlts; i++) {
            Alternative a = r.alt[i];
            for (List<LabelElementPair> pairs : a.labelDefs.values()) {
                if (r.hasAltSpecificContexts()) {
                    // Collect labelName-labeledRules map for rule with alternative labels.
                    Map<String, List<LabelElementPair>> labelPairs = new HashMap<>();
                    for (LabelElementPair p : pairs) {
                        String labelName = findAltLabelName(p.label);
                        if (labelName != null) {
                            List<LabelElementPair> list;
                            if (labelPairs.containsKey(labelName)) {
                                list = labelPairs.get(labelName);
                            } else {
                                list = new ArrayList<>();
                                labelPairs.put(labelName, list);
                            }
                            list.add(p);
                        }
                    }
                    for (List<LabelElementPair> internalPairs : labelPairs.values()) {
                        labelNameSpace.clear();
                        checkLabelPairs(r, labelNameSpace, internalPairs);
                    }
                } else {
                    checkLabelPairs(r, labelNameSpace, pairs);
                }
            }
        }
    }
}","/**
 * Make sure a label doesn't conflict with another symbol.
 * Labels must not conflict with: rules, tokens, scope names,
 * return values, parameters, and rule-scope dynamic attributes
 * defined in surrounding rule.  Also they must have same type
 * for repeated defs.
 */
","// Collect labelName-labeledRules map for rule with alternative labels.
","/** * Make sure a label doesn't conflict with another symbol. * Labels must not conflict with: rules, tokens, scope names, * return values, parameters, and rule-scope dynamic attributes * defined in surrounding rule.  Also they must have same type * for repeated defs. */[[SEP]]// Collect labelName-labeledRules map for rule with alternative labels.",117,154,[0],0,[0],0,"[0, 0]",0,0,0,0,checkForLabelConflicts(Collection<Rule>),org.antlr.v4.semantics.SymbolChecks,checkForLabelConflicts/1[java.util.Collection<org.antlr.v4.tool.Rule>],False,117,4,5,1,4,9,11,35,0,6,1,11,3,3,5,1,0,0,0,1,7,0,7,0,0,0,46,1,0,True
1167,..\projects\antlr4-4.11.0\tool\src\org\antlr\v4\semantics\SymbolChecks.java,org.antlr.v4.semantics.SymbolChecks,"void checkForTypeMismatch(Rule, LabelElementPair, LabelElementPair)","private void checkForTypeMismatch(Rule r, LabelElementPair prevLabelPair, LabelElementPair labelPair) {
    // label already defined; if same type, no problem
    if (prevLabelPair.type != labelPair.type) {
        // Current behavior: take a token of rule declaration in case of left-recursive rule
        // Desired behavior: take a token of proper label declaration in case of left-recursive rule
        // See https://github.com/antlr/antlr4/pull/1585
        // Such behavior is referring to the fact that the warning is typically reported on the actual label redefinition,
        // but for left-recursive rules the warning is reported on the enclosing rule.
        org.antlr.runtime.Token token = r instanceof LeftRecursiveRule ? ((GrammarAST) r.ast.getChild(0)).getToken() : labelPair.label.token;
        errMgr.grammarError(ErrorType.LABEL_TYPE_CONFLICT, g.fileName, token, labelPair.label.getText(), labelPair.type + ""!="" + prevLabelPair.type);
    }
    if (!prevLabelPair.element.getText().equals(labelPair.element.getText()) && (prevLabelPair.type.equals(LabelType.RULE_LABEL) || prevLabelPair.type.equals(LabelType.RULE_LIST_LABEL)) && (labelPair.type.equals(LabelType.RULE_LABEL) || labelPair.type.equals(LabelType.RULE_LIST_LABEL))) {
        org.antlr.runtime.Token token = r instanceof LeftRecursiveRule ? ((GrammarAST) r.ast.getChild(0)).getToken() : labelPair.label.token;
        String prevLabelOp = prevLabelPair.type.equals(LabelType.RULE_LIST_LABEL) ? ""+="" : ""="";
        String labelOp = labelPair.type.equals(LabelType.RULE_LIST_LABEL) ? ""+="" : ""="";
        errMgr.grammarError(ErrorType.LABEL_TYPE_CONFLICT, g.fileName, token, labelPair.label.getText() + labelOp + labelPair.element.getText(), prevLabelPair.label.getText() + prevLabelOp + prevLabelPair.element.getText());
    }
}", ,"// label already defined; if same type, no problem
[[SEP]]// Current behavior: take a token of rule declaration in case of left-recursive rule
[[SEP]]// Desired behavior: take a token of proper label declaration in case of left-recursive rule
[[SEP]]// See https://github.com/antlr/antlr4/pull/1585
[[SEP]]// Such behavior is referring to the fact that the warning is typically reported on the actual label redefinition,
[[SEP]]// but for left-recursive rules the warning is reported on the enclosing rule.
","// label already defined; if same type, no problem[[SEP]]// Current behavior: take a token of rule declaration in case of left-recursive rule// Desired behavior: take a token of proper label declaration in case of left-recursive rule// See https://github.com/antlr/antlr4/pull/1585// Such behavior is referring to the fact that the warning is typically reported on the actual label redefinition,// but for left-recursive rules the warning is reported on the enclosing rule.",191,225,[0],0,"[0, 0, 0, 0, 0, 0]",0,"[0, 0]",0,0,0,0,"checkForTypeMismatch(Rule, LabelElementPair, LabelElementPair)",org.antlr.v4.semantics.SymbolChecks,"checkForTypeMismatch/3[org.antlr.v4.tool.Rule,org.antlr.v4.tool.LabelElementPair,org.antlr.v4.tool.LabelElementPair]",False,191,6,2,1,1,11,6,12,0,4,3,6,0,0,0,1,0,4,5,2,4,3,1,0,0,0,18,2,0,False
1168,..\projects\antlr4-4.11.0\tool\src\org\antlr\v4\semantics\SymbolChecks.java,org.antlr.v4.semantics.SymbolChecks,void checkForUnreachableTokens(Grammar),"/**
 * Algorithm steps:
 * 1. Collect all simple string literals (i.e. 'asdf', 'as' 'df', but not [a-z]+, 'a'..'z')
 *    for all lexer rules in each mode except of autogenerated tokens ({@link #getSingleTokenValues(Rule) getSingleTokenValues})
 * 2. Compare every string literal with each other ({@link #checkForOverlap(Grammar, Rule, Rule, List<String>, List<String>) checkForOverlap})
 *    and throw TOKEN_UNREACHABLE warning if the same string found.
 * Complexity: O(m * n^2 / 2), approximately equals to O(n^2)
 * where m - number of modes, n - average number of lexer rules per mode.
 * See also testUnreachableTokens unit test for details.
 */
public void checkForUnreachableTokens(Grammar g) {
    if (g.isLexer()) {
        LexerGrammar lexerGrammar = (LexerGrammar) g;
        for (List<Rule> rules : lexerGrammar.modes.values()) {
            // Collect string literal lexer rules for each mode
            List<Rule> stringLiteralRules = new ArrayList<>();
            List<List<String>> stringLiteralValues = new ArrayList<>();
            for (int i = 0; i < rules.size(); i++) {
                Rule rule = rules.get(i);
                List<String> ruleStringAlts = getSingleTokenValues(rule);
                if (ruleStringAlts != null && ruleStringAlts.size() > 0) {
                    stringLiteralRules.add(rule);
                    stringLiteralValues.add(ruleStringAlts);
                }
            }
            // Check string sets intersection
            for (int i = 0; i < stringLiteralRules.size(); i++) {
                List<String> firstTokenStringValues = stringLiteralValues.get(i);
                Rule rule1 = stringLiteralRules.get(i);
                checkForOverlap(g, rule1, rule1, firstTokenStringValues, stringLiteralValues.get(i));
                // Check fragment rules only with themself
                if (!rule1.isFragment()) {
                    for (int j = i + 1; j < stringLiteralRules.size(); j++) {
                        Rule rule2 = stringLiteralRules.get(j);
                        if (!rule2.isFragment()) {
                            checkForOverlap(g, rule1, stringLiteralRules.get(j), firstTokenStringValues, stringLiteralValues.get(j));
                        }
                    }
                }
            }
        }
    }
}","/**
 * Algorithm steps:
 * 1. Collect all simple string literals (i.e. 'asdf', 'as' 'df', but not [a-z]+, 'a'..'z')
 *    for all lexer rules in each mode except of autogenerated tokens ({@link #getSingleTokenValues(Rule) getSingleTokenValues})
 * 2. Compare every string literal with each other ({@link #checkForOverlap(Grammar, Rule, Rule, List<String>, List<String>) checkForOverlap})
 *    and throw TOKEN_UNREACHABLE warning if the same string found.
 * Complexity: O(m * n^2 / 2), approximately equals to O(n^2)
 * where m - number of modes, n - average number of lexer rules per mode.
 * See also testUnreachableTokens unit test for details.
 */
","// Collect string literal lexer rules for each mode
[[SEP]]// Check string sets intersection
[[SEP]]// Check fragment rules only with themself
","/** * Algorithm steps: * 1. Collect all simple string literals (i.e. 'asdf', 'as' 'df', but not [a-z]+, 'a'..'z') *    for all lexer rules in each mode except of autogenerated tokens ({@link #getSingleTokenValues(Rule) getSingleTokenValues}) * 2. Compare every string literal with each other ({@link #checkForOverlap(Grammar, Rule, Rule, List<String>, List<String>) checkForOverlap}) *    and throw TOKEN_UNREACHABLE warning if the same string found. * Complexity: O(m * n^2 / 2), approximately equals to O(n^2) * where m - number of modes, n - average number of lexer rules per mode. * See also testUnreachableTokens unit test for details. */[[SEP]]// Collect string literal lexer rules for each mode[[SEP]]// Check string sets intersection[[SEP]]// Check fragment rules only with themself",338,373,[0],0,"[0, 0, 0]",0,"[0, 0, 0, 0]",0,0,0,0,checkForUnreachableTokens(Grammar),org.antlr.v4.semantics.SymbolChecks,checkForUnreachableTokens/1[org.antlr.v4.tool.Grammar],False,338,4,5,1,4,10,11,30,0,11,1,11,2,1,4,1,0,0,0,4,11,1,6,0,0,0,76,1,0,True
1169,..\projects\antlr4-4.11.0\tool\src\org\antlr\v4\semantics\SymbolChecks.java,org.antlr.v4.semantics.SymbolChecks,List<String> getSingleTokenValues(Rule),"/**
 * {@return} list of simple string literals for rule {@param rule}
 */
private List<String> getSingleTokenValues(Rule rule) {
    List<String> values = new ArrayList<>();
    for (Alternative alt : rule.alt) {
        if (alt != null) {
            // select first alt if token has a command
            Tree rootNode = alt.ast.getChildCount() == 2 && alt.ast.getChild(0) instanceof AltAST && alt.ast.getChild(1) instanceof GrammarAST ? alt.ast.getChild(0) : alt.ast;
            if (rootNode.getTokenStartIndex() == -1) {
                // ignore autogenerated tokens from combined grammars that start with T__
                continue;
            }
            // Ignore alt if contains not only string literals (repetition, optional)
            boolean ignore = false;
            StringBuilder currentValue = new StringBuilder();
            for (int i = 0; i < rootNode.getChildCount(); i++) {
                Tree child = rootNode.getChild(i);
                if (!(child instanceof TerminalAST)) {
                    ignore = true;
                    break;
                }
                TerminalAST terminalAST = (TerminalAST) child;
                if (terminalAST.token.getType() != ANTLRLexer.STRING_LITERAL) {
                    ignore = true;
                    break;
                } else {
                    String text = terminalAST.token.getText();
                    currentValue.append(text.substring(1, text.length() - 1));
                }
            }
            if (!ignore) {
                values.add(currentValue.toString());
            }
        }
    }
    return values;
}","/**
 * {@return} list of simple string literals for rule {@param rule}
 */
","// select first alt if token has a command
[[SEP]]// ignore autogenerated tokens from combined grammars that start with T__
[[SEP]]// Ignore alt if contains not only string literals (repetition, optional)
","/** * {@return} list of simple string literals for rule {@param rule} */[[SEP]]// select first alt if token has a command[[SEP]]// ignore autogenerated tokens from combined grammars that start with T__[[SEP]]// Ignore alt if contains not only string literals (repetition, optional)",378,420,[0],0,"[0, 0, 0]",0,"[0, 0, 0, 0]",0,0,0,0,getSingleTokenValues(Rule),org.antlr.v4.semantics.SymbolChecks,getSingleTokenValues/1[org.antlr.v4.tool.Rule],False,379,5,1,1,0,11,10,33,1,8,1,10,0,0,2,4,0,1,0,8,10,1,4,0,0,0,35,2,0,True
1170,..\projects\antlr4-4.11.0\tool\src\org\antlr\v4\semantics\SymbolChecks.java,org.antlr.v4.semantics.SymbolChecks,"void checkForOverlap(Grammar, Rule, Rule, List<String>, List<String>)","/**
 * For same rule compare values from next index:
 * TOKEN_WITH_SAME_VALUES: 'asdf' | 'asdf';
 * For different rules compare from start value:
 * TOKEN1: 'asdf';
 * TOKEN2: 'asdf';
 */
private void checkForOverlap(Grammar g, Rule rule1, Rule rule2, List<String> firstTokenStringValues, List<String> secondTokenStringValues) {
    for (int i = 0; i < firstTokenStringValues.size(); i++) {
        int secondTokenInd = rule1 == rule2 ? i + 1 : 0;
        String str1 = firstTokenStringValues.get(i);
        for (int j = secondTokenInd; j < secondTokenStringValues.size(); j++) {
            String str2 = secondTokenStringValues.get(j);
            if (str1.equals(str2)) {
                errMgr.grammarError(ErrorType.TOKEN_UNREACHABLE, g.fileName, ((GrammarAST) rule2.ast.getChild(0)).token, rule2.name, str2, rule1.name);
            }
        }
    }
}","/**
 * For same rule compare values from next index:
 * TOKEN_WITH_SAME_VALUES: 'asdf' | 'asdf';
 * For different rules compare from start value:
 * TOKEN1: 'asdf';
 * TOKEN2: 'asdf';
 */
", ,/** * For same rule compare values from next index: * TOKEN_WITH_SAME_VALUES: 'asdf' | 'asdf'; * For different rules compare from start value: * TOKEN1: 'asdf'; * TOKEN2: 'asdf'; */,429,441,[0],0,[0],0,[0],0,0,0,0,"checkForOverlap(Grammar, Rule, Rule, List<String>, List<String>)",org.antlr.v4.semantics.SymbolChecks,"checkForOverlap/5[org.antlr.v4.tool.Grammar,org.antlr.v4.tool.Rule,org.antlr.v4.tool.Rule,java.util.List<java.lang.String>,java.util.List<java.lang.String>]",False,429,4,2,1,1,5,5,12,0,5,5,5,0,0,2,1,0,1,0,4,5,1,3,0,0,0,27,2,0,True
1171,..\projects\antlr4-4.11.0\tool\src\org\antlr\v4\semantics\SymbolChecks.java,org.antlr.v4.semantics.SymbolChecks,"void checkRuleArgs(Grammar, List<GrammarAST>)","// CAN ONLY CALL THE TWO NEXT METHODS AFTER GRAMMAR HAS RULE DEFS (see semanticpipeline)
public void checkRuleArgs(Grammar g, List<GrammarAST> rulerefs) {
    if (rulerefs == null)
        return;
    for (GrammarAST ref : rulerefs) {
        String ruleName = ref.getText();
        Rule r = g.getRule(ruleName);
        GrammarAST arg = (GrammarAST) ref.getFirstChildWithType(ANTLRParser.ARG_ACTION);
        if (arg != null && (r == null || r.args == null)) {
            errMgr.grammarError(ErrorType.RULE_HAS_NO_ARGS, g.fileName, ref.token, ruleName);
        } else if (arg == null && (r != null && r.args != null)) {
            errMgr.grammarError(ErrorType.MISSING_RULE_ARGS, g.fileName, ref.token, ruleName);
        }
    }
}","// CAN ONLY CALL THE TWO NEXT METHODS AFTER GRAMMAR HAS RULE DEFS (see semanticpipeline)
", ,// CAN ONLY CALL THE TWO NEXT METHODS AFTER GRAMMAR HAS RULE DEFS (see semanticpipeline),444,460,[0],0,[0],0,[0],0,0,0,0,"checkRuleArgs(Grammar, List<GrammarAST>)",org.antlr.v4.semantics.SymbolChecks,"checkRuleArgs/2[org.antlr.v4.tool.Grammar,java.util.List<org.antlr.v4.tool.ast.GrammarAST>]",False,444,4,3,1,2,9,4,14,1,3,2,4,0,0,1,7,0,2,0,0,3,0,2,0,0,0,14,1,0,False
1172,..\projects\antlr4-4.11.0\tool\src\org\antlr\v4\semantics\SymbolCollector.java,org.antlr.v4.semantics.SymbolCollector,"void ruleRef(GrammarAST, ActionAST)","@Override
public void ruleRef(GrammarAST ref, ActionAST arg) {
    // if ( inContext(""DOT ..."") ) qualifiedRulerefs.add((GrammarAST)ref.getParent());
    rulerefs.add(ref);
    if (currentRule != null) {
        currentRule.alt[currentOuterAltNumber].ruleRefs.map(ref.getText(), ref);
    }
}", ,"// if ( inContext(""DOT ..."") ) qualifiedRulerefs.add((GrammarAST)ref.getParent());
","// if ( inContext(""DOT ..."") ) qualifiedRulerefs.add((GrammarAST)ref.getParent());",154,161,[0],0,[0],0,[0],0,0,0,0,"ruleRef(GrammarAST, ActionAST)",org.antlr.v4.semantics.SymbolCollector,"ruleRef/2[org.antlr.v4.tool.ast.GrammarAST,org.antlr.v4.tool.ast.ActionAST]",False,155,2,0,0,0,2,3,6,0,0,2,3,0,0,0,1,0,0,0,0,0,0,1,0,0,0,11,1,0,False
1173,..\projects\antlr4-4.11.0\tool\src\org\antlr\v4\semantics\SymbolCollector.java,org.antlr.v4.semantics.SymbolCollector,void setActionResolver(GrammarAST),"/**
 * In case of option id={...}, set resolve in case they use $foo
 */
private void setActionResolver(GrammarAST valueAST) {
    if (valueAST instanceof ActionAST) {
        ((ActionAST) valueAST).resolver = currentRule.alt[currentOuterAltNumber];
    }
}","/**
 * In case of option id={...}, set resolve in case they use $foo
 */
", ,"/** * In case of option id={...}, set resolve in case they use $foo */",184,188,[0],0,[0],0,[0],0,0,0,0,setActionResolver(GrammarAST),org.antlr.v4.semantics.SymbolCollector,setActionResolver/1[org.antlr.v4.tool.ast.GrammarAST],False,184,2,4,4,0,2,0,5,0,0,1,0,0,0,0,0,0,1,0,0,1,0,1,0,0,0,16,2,0,True
1174,..\projects\antlr4-4.11.0\tool\src\org\antlr\v4\semantics\UseDefAnalyzer.java,org.antlr.v4.semantics.UseDefAnalyzer,void trackTokenRuleRefsInActions(Grammar),"// side-effect: updates Alternative with refs in actions
public static void trackTokenRuleRefsInActions(Grammar g) {
    for (Rule r : g.rules.values()) {
        for (int i = 1; i <= r.numberOfAlts; i++) {
            Alternative alt = r.alt[i];
            for (ActionAST a : alt.actions) {
                ActionSniffer sniffer = new ActionSniffer(g, r, alt, a, a.token);
                sniffer.examineAction();
            }
        }
    }
}","// side-effect: updates Alternative with refs in actions
", ,// side-effect: updates Alternative with refs in actions,31,41,[0],0,[0],0,[0],0,0,0,0,trackTokenRuleRefsInActions(Grammar),org.antlr.v4.semantics.UseDefAnalyzer,trackTokenRuleRefsInActions/1[org.antlr.v4.tool.Grammar],False,31,3,3,1,2,4,2,11,0,3,1,2,0,0,3,0,0,0,0,1,3,0,3,0,0,0,19,9,0,False
1175,..\projects\antlr4-4.11.0\tool\src\org\antlr\v4\semantics\UseDefAnalyzer.java,org.antlr.v4.semantics.UseDefAnalyzer,boolean actionIsContextDependent(ActionAST),"public static boolean actionIsContextDependent(ActionAST actionAST) {
    ANTLRStringStream in = new ANTLRStringStream(actionAST.token.getText());
    in.setLine(actionAST.token.getLine());
    in.setCharPositionInLine(actionAST.token.getCharPositionInLine());
    // can't be simple bool with anon class
    final boolean[] dependent = new boolean[] { false };
    ActionSplitterListener listener = new BlankActionSplitterListener() {

        @Override
        public void nonLocalAttr(String expr, Token x, Token y) {
            dependent[0] = true;
        }

        @Override
        public void qualifiedAttr(String expr, Token x, Token y) {
            dependent[0] = true;
        }

        @Override
        public void setAttr(String expr, Token x, Token rhs) {
            dependent[0] = true;
        }

        @Override
        public void setExprAttribute(String expr) {
            dependent[0] = true;
        }

        @Override
        public void setNonLocalAttr(String expr, Token x, Token y, Token rhs) {
            dependent[0] = true;
        }

        @Override
        public void attr(String expr, Token x) {
            dependent[0] = true;
        }
    };
    ActionSplitter splitter = new ActionSplitter(in, listener);
    // forces eval, triggers listener methods
    splitter.getActionTokens();
    return dependent[0];
}", ,"// can't be simple bool with anon class
[[SEP]]// forces eval, triggers listener methods
","// can't be simple bool with anon class[[SEP]]// forces eval, triggers listener methods",43,66,[0],0,"[0, 0]",0,"[0, 0]",0,0,0,0,actionIsContextDependent(ActionAST),org.antlr.v4.semantics.UseDefAnalyzer,actionIsContextDependent/1[org.antlr.v4.tool.ast.ActionAST],False,43,6,1,0,1,1,6,30,1,4,1,6,0,0,0,0,0,0,0,1,4,0,0,1,0,0,36,9,0,False
1176,..\projects\antlr4-4.11.0\tool\src\org\antlr\v4\semantics\UseDefAnalyzer.java,org.antlr.v4.semantics.UseDefAnalyzer,"Map<Rule, Set<Rule>> getRuleDependencies(Grammar)","/**
 * Find all rules reachable from r directly or indirectly for all r in g
 */
public static Map<Rule, Set<Rule>> getRuleDependencies(Grammar g) {
    return getRuleDependencies(g, g.rules.values());
}","/**
 * Find all rules reachable from r directly or indirectly for all r in g
 */
", ,/** * Find all rules reachable from r directly or indirectly for all r in g */,69,71,[0],0,[0],0,[0],0,0,0,0,getRuleDependencies(Grammar),org.antlr.v4.semantics.UseDefAnalyzer,getRuleDependencies/1[org.antlr.v4.tool.Grammar],False,69,3,1,0,1,1,2,3,1,0,1,2,1,1,0,0,0,0,0,0,0,0,0,0,0,0,15,9,0,True
1177,..\projects\antlr4-4.11.0\tool\src\org\antlr\v4\tool\ANTLRMessage.java,org.antlr.v4.tool.ANTLRMessage,ST getMessageTemplate(boolean),"public ST getMessageTemplate(boolean verbose) {
    ST messageST = new ST(getErrorType().msg);
    messageST.impl.name = errorType.name();
    messageST.add(""verbose"", verbose);
    Object[] args = getArgs();
    for (int i = 0; i < args.length; i++) {
        String attr = ""arg"";
        if (i > 0)
            attr += i + 1;
        messageST.add(attr, args[i]);
    }
    // some messages ref arg2
    if (args.length < 2)
        messageST.add(""arg2"", null);
    Throwable cause = getCause();
    if (cause != null) {
        messageST.add(""exception"", cause);
        messageST.add(""stackTrace"", cause.getStackTrace());
    } else {
        // avoid ST error msg
        messageST.add(""exception"", null);
        messageST.add(""stackTrace"", null);
    }
    return messageST;
}", ,"// some messages ref arg2
[[SEP]]// avoid ST error msg
",// some messages ref arg2[[SEP]]// avoid ST error msg,64,88,[0],0,"[0, 0]",0,"[0, 0]",0,0,0,0,getMessageTemplate(boolean),org.antlr.v4.tool.ANTLRMessage,getMessageTemplate/1[boolean],False,64,2,4,1,3,5,6,22,1,5,1,6,3,1,1,1,0,0,7,4,7,1,2,0,0,0,17,1,0,False
1178,..\projects\antlr4-4.11.0\tool\src\org\antlr\v4\tool\Alternative.java,org.antlr.v4.tool.Alternative,"boolean resolvesToAttributeDict(String, ActionAST)","@Override
public boolean resolvesToAttributeDict(String x, ActionAST node) {
    if (resolvesToToken(x, node))
        return true;
    // rule ref in this alt?
    if (ruleRefs.get(x) != null)
        return true;
    LabelElementPair anyLabelDef = getAnyLabelDef(x);
    if (anyLabelDef != null && anyLabelDef.type == LabelType.RULE_LABEL)
        return true;
    return false;
}", ,"// rule ref in this alt?
",// rule ref in this alt?,65,72,[0],0,[0],0,[0],0,0,0,0,"resolvesToAttributeDict(String, ActionAST)",org.antlr.v4.tool.Alternative,"resolvesToAttributeDict/2[java.lang.String,org.antlr.v4.tool.ast.ActionAST]",False,66,3,2,0,2,5,3,7,4,1,2,3,2,2,0,3,0,0,0,0,1,0,1,0,0,0,17,1,0,False
1179,..\projects\antlr4-4.11.0\tool\src\org\antlr\v4\tool\Alternative.java,org.antlr.v4.tool.Alternative,"Attribute resolveToAttribute(String, ActionAST)","/**
 *  $x		Attribute: rule arguments, return values, predefined rule prop.
 */
@Override
public Attribute resolveToAttribute(String x, ActionAST node) {
    // reuse that code
    return rule.resolveToAttribute(x, node);
}","/**
 *  $x		Attribute: rule arguments, return values, predefined rule prop.
 */
","// reuse that code
","/** *  $x		Attribute: rule arguments, return values, predefined rule prop. */[[SEP]]// reuse that code",76,79,[0],0,[0],0,"[0, 0]",0,0,0,0,"resolveToAttribute(String, ActionAST)",org.antlr.v4.tool.Alternative,"resolveToAttribute/2[java.lang.String,org.antlr.v4.tool.ast.ActionAST]",False,77,3,1,0,1,1,1,3,1,0,2,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,6,1,0,True
1180,..\projects\antlr4-4.11.0\tool\src\org\antlr\v4\tool\Alternative.java,org.antlr.v4.tool.Alternative,"Attribute resolveToAttribute(String, String, ActionAST)","/**
 * $x.y, x can be surrounding rule, token/rule/label ref. y is visible
 *  attr in that dictionary.  Can't see args on rule refs.
 */
@Override
public Attribute resolveToAttribute(String x, String y, ActionAST node) {
    if (tokenRefs.get(x) != null) {
        // token ref in this alt?
        return rule.getPredefinedScope(LabelType.TOKEN_LABEL).get(y);
    }
    if (ruleRefs.get(x) != null) {
        // rule ref in this alt?
        // look up rule, ask it to resolve y (must be retval or predefined)
        return rule.g.getRule(x).resolveRetvalOrProperty(y);
    }
    LabelElementPair anyLabelDef = getAnyLabelDef(x);
    if (anyLabelDef != null && anyLabelDef.type == LabelType.RULE_LABEL) {
        return rule.g.getRule(anyLabelDef.element.getText()).resolveRetvalOrProperty(y);
    } else if (anyLabelDef != null) {
        AttributeDict scope = rule.getPredefinedScope(anyLabelDef.type);
        if (scope == null) {
            return null;
        }
        return scope.get(y);
    }
    return null;
}","/**
 * $x.y, x can be surrounding rule, token/rule/label ref. y is visible
 *  attr in that dictionary.  Can't see args on rule refs.
 */
","// token ref in this alt?
[[SEP]]// rule ref in this alt?
[[SEP]]// look up rule, ask it to resolve y (must be retval or predefined)
","/** * $x.y, x can be surrounding rule, token/rule/label ref. y is visible *  attr in that dictionary.  Can't see args on rule refs. */[[SEP]]// token ref in this alt?[[SEP]]// rule ref in this alt?// look up rule, ask it to resolve y (must be retval or predefined)",84,106,[0],0,"[0, 0, 0]",0,"[0, 0, 0]",0,0,0,0,"resolveToAttribute(String, String, ActionAST)",org.antlr.v4.tool.Alternative,"resolveToAttribute/3[java.lang.String,java.lang.String,org.antlr.v4.tool.ast.ActionAST]",False,85,7,5,0,5,7,8,20,6,2,3,8,1,1,0,6,0,0,0,0,2,0,2,0,0,0,30,1,0,True
1181,..\projects\antlr4-4.11.0\tool\src\org\antlr\v4\tool\Alternative.java,org.antlr.v4.tool.Alternative,Rule resolveToRule(String),"/**
 * x can be ruleref or rule label.
 */
public Rule resolveToRule(String x) {
    if (ruleRefs.get(x) != null)
        return rule.g.getRule(x);
    LabelElementPair anyLabelDef = getAnyLabelDef(x);
    if (anyLabelDef != null && anyLabelDef.type == LabelType.RULE_LABEL) {
        return rule.g.getRule(anyLabelDef.element.getText());
    }
    return null;
}","/**
 * x can be ruleref or rule label.
 */
", ,/** * x can be ruleref or rule label. */,131,138,[0],0,[0],0,[0],0,0,0,0,resolveToRule(String),org.antlr.v4.tool.Alternative,resolveToRule/1[java.lang.String],False,131,4,2,0,2,4,4,8,3,1,1,4,1,1,0,3,0,0,0,0,1,0,1,0,0,0,17,1,0,True
1182,..\projects\antlr4-4.11.0\tool\src\org\antlr\v4\tool\BuildDependencyGenerator.java,org.antlr.v4.tool.BuildDependencyGenerator,List<File> getGeneratedFileList(),"/**
 * From T.g return a list of File objects that
 *  name files ANTLR will emit from T.g.
 */
public List<File> getGeneratedFileList() {
    List<File> files = new ArrayList<File>();
    // add generated recognizer; e.g., TParser.java
    if (generator.getTarget().needsHeader()) {
        files.add(getOutputFile(generator.getRecognizerFileName(true)));
    }
    files.add(getOutputFile(generator.getRecognizerFileName(false)));
    // add output vocab file; e.g., T.tokens. This is always generated to
    // the base output directory, which will be just . if there is no -o option
    // 
    files.add(getOutputFile(generator.getVocabFileName()));
    // are we generating a .h file?
    ST headerExtST = null;
    ST extST = generator.getTemplates().getInstanceOf(""codeFileExtension"");
    if (generator.getTemplates().isDefined(""headerFile"")) {
        headerExtST = generator.getTemplates().getInstanceOf(""headerFileExtension"");
        String suffix = Grammar.getGrammarTypeToFileNameSuffix(g.getType());
        String fileName = g.name + suffix + headerExtST.render();
        files.add(getOutputFile(fileName));
    }
    if (g.isCombined()) {
        // add autogenerated lexer; e.g., TLexer.java TLexer.h TLexer.tokens
        String suffix = Grammar.getGrammarTypeToFileNameSuffix(ANTLRParser.LEXER);
        String lexer = g.name + suffix + extST.render();
        files.add(getOutputFile(lexer));
        String lexerTokens = g.name + suffix + CodeGenerator.VOCAB_FILE_EXTENSION;
        files.add(getOutputFile(lexerTokens));
        // TLexer.h
        if (headerExtST != null) {
            String header = g.name + suffix + headerExtST.render();
            files.add(getOutputFile(header));
        }
    }
    if (g.tool.gen_listener) {
        // add generated listener; e.g., TListener.java
        if (generator.getTarget().needsHeader()) {
            files.add(getOutputFile(generator.getListenerFileName(true)));
        }
        files.add(getOutputFile(generator.getListenerFileName(false)));
        // add generated base listener; e.g., TBaseListener.java
        if (generator.getTarget().needsHeader()) {
            files.add(getOutputFile(generator.getBaseListenerFileName(true)));
        }
        files.add(getOutputFile(generator.getBaseListenerFileName(false)));
    }
    if (g.tool.gen_visitor) {
        // add generated visitor; e.g., TVisitor.java
        if (generator.getTarget().needsHeader()) {
            files.add(getOutputFile(generator.getVisitorFileName(true)));
        }
        files.add(getOutputFile(generator.getVisitorFileName(false)));
        // add generated base visitor; e.g., TBaseVisitor.java
        if (generator.getTarget().needsHeader()) {
            files.add(getOutputFile(generator.getBaseVisitorFileName(true)));
        }
        files.add(getOutputFile(generator.getBaseVisitorFileName(false)));
    }
    // handle generated files for imported grammars
    List<Grammar> imports = g.getAllImportedGrammars();
    if (imports != null) {
        for (Grammar g : imports) {
            // File outputDir = tool.getOutputDirectory(g.fileName);
            // String fname = groomQualifiedFileName(outputDir.toString(), g.getRecognizerName() + extST.render());
            // files.add(new File(outputDir, fname));
            files.add(getOutputFile(g.fileName));
        }
    }
    if (files.isEmpty()) {
        return null;
    }
    return files;
}","/**
 * From T.g return a list of File objects that
 *  name files ANTLR will emit from T.g.
 */
","// add output vocab file; e.g., T.tokens. This is always generated to
[[SEP]]// the base output directory, which will be just . if there is no -o option
[[SEP]]// add generated recognizer; e.g., TParser.java
[[SEP]]// 
[[SEP]]// are we generating a .h file?
[[SEP]]// add autogenerated lexer; e.g., TLexer.java TLexer.h TLexer.tokens
[[SEP]]// TLexer.h
[[SEP]]// add generated listener; e.g., TListener.java
[[SEP]]// add generated base listener; e.g., TBaseListener.java
[[SEP]]// add generated visitor; e.g., TVisitor.java
[[SEP]]// add generated base visitor; e.g., TBaseVisitor.java
[[SEP]]// handle generated files for imported grammars
[[SEP]]// File outputDir = tool.getOutputDirectory(g.fileName);
[[SEP]]// String fname = groomQualifiedFileName(outputDir.toString(), g.getRecognizerName() + extST.render());
[[SEP]]// files.add(new File(outputDir, fname));
","/** * From T.g return a list of File objects that *  name files ANTLR will emit from T.g. */[[SEP]]// add generated recognizer; e.g., TParser.java[[SEP]]// add output vocab file; e.g., T.tokens. This is always generated to// the base output directory, which will be just . if there is no -o option//[[SEP]]// are we generating a .h file?[[SEP]]// add autogenerated lexer; e.g., TLexer.java TLexer.h TLexer.tokens[[SEP]]// TLexer.h[[SEP]]// add generated listener; e.g., TListener.java[[SEP]]// add generated base listener; e.g., TBaseListener.java[[SEP]]// add generated visitor; e.g., TVisitor.java[[SEP]]// add generated base visitor; e.g., TBaseVisitor.java[[SEP]]// handle generated files for imported grammars[[SEP]]// File outputDir = tool.getOutputDirectory(g.fileName);// String fname = groomQualifiedFileName(outputDir.toString(), g.getRecognizerName() + extST.render());// files.add(new File(outputDir, fname));",77,158,[0],0,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]",0,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]",0,0,0,0,getGeneratedFileList(),org.antlr.v4.tool.BuildDependencyGenerator,getGeneratedFileList/0,False,77,3,6,1,5,14,19,57,2,10,0,19,1,1,1,2,0,0,3,0,11,4,2,0,0,0,36,1,0,True
1183,..\projects\antlr4-4.11.0\tool\src\org\antlr\v4\tool\BuildDependencyGenerator.java,org.antlr.v4.tool.BuildDependencyGenerator,File getOutputFile(String),"public File getOutputFile(String fileName) {
    File outputDir = tool.getOutputDirectory(g.fileName);
    if (outputDir.toString().equals(""."")) {
        // pay attention to -o then
        outputDir = tool.getOutputDirectory(fileName);
    }
    if (outputDir.toString().equals(""."")) {
        return new File(fileName);
    }
    if (outputDir.getName().equals(""."")) {
        String fname = outputDir.toString();
        int dot = fname.lastIndexOf('.');
        outputDir = new File(outputDir.toString().substring(0, dot));
    }
    if (outputDir.getName().indexOf(' ') >= 0) {
        // has spaces?
        String escSpaces = outputDir.toString().replace("" "", ""\\ "");
        outputDir = new File(escSpaces);
    }
    return new File(outputDir, fileName);
}", ,"// pay attention to -o then
[[SEP]]// has spaces?
",// pay attention to -o then[[SEP]]// has spaces?,160,180,[0],0,"[0, 0]",0,"[0, 0]",0,0,0,0,getOutputFile(String),org.antlr.v4.tool.BuildDependencyGenerator,getOutputFile/1[java.lang.String],False,160,1,2,1,1,5,8,19,2,4,1,8,0,0,0,0,0,0,5,2,7,0,1,0,0,0,11,1,0,False
1184,..\projects\antlr4-4.11.0\tool\src\org\antlr\v4\tool\BuildDependencyGenerator.java,org.antlr.v4.tool.BuildDependencyGenerator,List<File> getDependenciesFileList(),"/**
 * Return a list of File objects that name files ANTLR will read
 * to process T.g; This can be .tokens files if the grammar uses the tokenVocab option
 * as well as any imported grammar files.
 */
public List<File> getDependenciesFileList() {
    // Find all the things other than imported grammars
    List<File> files = getNonImportDependenciesFileList();
    // Handle imported grammars
    List<Grammar> imports = g.getAllImportedGrammars();
    if (imports != null) {
        for (Grammar g : imports) {
            String libdir = tool.libDirectory;
            String fileName = groomQualifiedFileName(libdir, g.fileName);
            files.add(new File(fileName));
        }
    }
    if (files.isEmpty()) {
        return null;
    }
    return files;
}","/**
 * Return a list of File objects that name files ANTLR will read
 * to process T.g; This can be .tokens files if the grammar uses the tokenVocab option
 * as well as any imported grammar files.
 */
","// Find all the things other than imported grammars
[[SEP]]// Handle imported grammars
",/** * Return a list of File objects that name files ANTLR will read * to process T.g; This can be .tokens files if the grammar uses the tokenVocab option * as well as any imported grammar files. */[[SEP]]// Find all the things other than imported grammars[[SEP]]// Handle imported grammars,187,205,[0],0,"[0, 0]",0,"[0, 0, 0]",0,0,0,0,getDependenciesFileList(),org.antlr.v4.tool.BuildDependencyGenerator,getDependenciesFileList/0,False,187,2,4,1,3,4,5,15,2,4,0,5,2,1,1,1,0,0,0,0,4,0,2,0,0,0,45,1,0,True
1185,..\projects\antlr4-4.11.0\tool\src\org\antlr\v4\tool\BuildDependencyGenerator.java,org.antlr.v4.tool.BuildDependencyGenerator,List<File> getNonImportDependenciesFileList(),"/**
 * Return a list of File objects that name files ANTLR will read
 * to process T.g; This can only be .tokens files and only
 * if they use the tokenVocab option.
 *
 * @return List of dependencies other than imported grammars
 */
public List<File> getNonImportDependenciesFileList() {
    List<File> files = new ArrayList<File>();
    // handle token vocabulary loads
    String tokenVocab = g.getOptionString(""tokenVocab"");
    if (tokenVocab != null) {
        String fileName = tokenVocab + CodeGenerator.VOCAB_FILE_EXTENSION;
        File vocabFile;
        if (tool.libDirectory.equals(""."")) {
            vocabFile = new File(fileName);
        } else {
            vocabFile = new File(tool.libDirectory, fileName);
        }
        files.add(vocabFile);
    }
    return files;
}","/**
 * Return a list of File objects that name files ANTLR will read
 * to process T.g; This can only be .tokens files and only
 * if they use the tokenVocab option.
 *
 * @return List of dependencies other than imported grammars
 */
","// handle token vocabulary loads
",/** * Return a list of File objects that name files ANTLR will read * to process T.g; This can only be .tokens files and only * if they use the tokenVocab option. * * @return List of dependencies other than imported grammars */[[SEP]]// handle token vocabulary loads,214,233,[0],0,[0],0,"[0, 0]",0,0,0,0,getNonImportDependenciesFileList(),org.antlr.v4.tool.BuildDependencyGenerator,getNonImportDependenciesFileList/0,False,214,1,2,1,1,3,3,16,1,4,0,3,0,0,0,1,0,0,2,0,5,1,2,0,0,0,42,1,0,True
1186,..\projects\antlr4-4.11.0\tool\src\org\antlr\v4\tool\BuildDependencyGenerator.java,org.antlr.v4.tool.BuildDependencyGenerator,"String groomQualifiedFileName(String, String)","public String groomQualifiedFileName(String outputDir, String fileName) {
    if (outputDir.equals(""."")) {
        return fileName;
    } else if (outputDir.indexOf(' ') >= 0) {
        // has spaces?
        String escSpaces = outputDir.replace("" "", ""\\ "");
        return escSpaces + File.separator + fileName;
    } else {
        return outputDir + File.separator + fileName;
    }
}", ,"// has spaces?
",// has spaces?,254,265,[0],0,[0],0,[0],0,0,0,0,"groomQualifiedFileName(String, String)",org.antlr.v4.tool.BuildDependencyGenerator,"groomQualifiedFileName/2[java.lang.String,java.lang.String]",False,254,0,1,1,0,3,3,12,3,1,2,3,0,0,0,0,0,0,3,1,1,2,1,0,0,0,9,1,0,False
1187,..\projects\antlr4-4.11.0\tool\src\org\antlr\v4\tool\DOTGenerator.java,org.antlr.v4.tool.DOTGenerator,"String getDOT(DFA, boolean)","public String getDOT(DFA dfa, boolean isLexer) {
    if (dfa.s0 == null)
        return null;
    ST dot = stlib.getInstanceOf(""dfa"");
    dot.add(""name"", ""DFA"" + dfa.decision);
    dot.add(""startState"", dfa.s0.stateNumber);
    // dot.add(""useBox"", Tool.internalOption_ShowATNConfigsInDFA);
    dot.add(""rankdir"", rankdir);
    // define stop states first; seems to be a bug in DOT where doublecircle
    for (DFAState d : dfa.states.keySet()) {
        if (!d.isAcceptState)
            continue;
        ST st = stlib.getInstanceOf(""stopstate"");
        st.add(""name"", ""s"" + d.stateNumber);
        st.add(""label"", getStateLabel(d));
        dot.add(""states"", st);
    }
    for (DFAState d : dfa.states.keySet()) {
        if (d.isAcceptState)
            continue;
        if (d.stateNumber == Integer.MAX_VALUE)
            continue;
        ST st = stlib.getInstanceOf(""state"");
        st.add(""name"", ""s"" + d.stateNumber);
        st.add(""label"", getStateLabel(d));
        dot.add(""states"", st);
    }
    for (DFAState d : dfa.states.keySet()) {
        if (d.edges != null) {
            for (int i = 0; i < d.edges.length; i++) {
                DFAState target = d.edges[i];
                if (target == null)
                    continue;
                if (target.stateNumber == Integer.MAX_VALUE)
                    continue;
                // we shift up for EOF as -1 for parser
                int ttype = i - 1;
                String label = String.valueOf(ttype);
                if (isLexer)
                    label = ""'"" + getEdgeLabel(new StringBuilder().appendCodePoint(i).toString()) + ""'"";
                else if (grammar != null)
                    label = grammar.getTokenDisplayName(ttype);
                ST st = stlib.getInstanceOf(""edge"");
                st.add(""label"", label);
                st.add(""src"", ""s"" + d.stateNumber);
                st.add(""target"", ""s"" + target.stateNumber);
                st.add(""arrowhead"", arrowhead);
                dot.add(""edges"", st);
            }
        }
    }
    String output = dot.render();
    return Utils.sortLinesInString(output);
}", ,"// dot.add(""useBox"", Tool.internalOption_ShowATNConfigsInDFA);
[[SEP]]// define stop states first; seems to be a bug in DOT where doublecircle
[[SEP]]// we shift up for EOF as -1 for parser
","// dot.add(""useBox"", Tool.internalOption_ShowATNConfigsInDFA);[[SEP]]// define stop states first; seems to be a bug in DOT where doublecircle[[SEP]]// we shift up for EOF as -1 for parser",60,109,[0],0,"[0, 0, 0]",0,"[0, 0, 0]",0,0,0,0,"getDOT(DFA, boolean)",org.antlr.v4.tool.DOTGenerator,"getDOT/2[org.antlr.v4.tool.DFA,boolean]",False,60,6,6,2,4,14,11,43,2,9,2,11,2,1,4,6,0,0,25,2,11,7,5,0,0,0,24,1,0,False
1188,..\projects\antlr4-4.11.0\tool\src\org\antlr\v4\tool\DOTGenerator.java,org.antlr.v4.tool.DOTGenerator,String getStateLabel(DFAState),"protected String getStateLabel(DFAState s) {
    if (s == null)
        return ""null"";
    StringBuilder buf = new StringBuilder(250);
    buf.append('s');
    buf.append(s.stateNumber);
    if (s.isAcceptState) {
        buf.append(""=>"").append(s.prediction);
    }
    if (s.requiresFullContext) {
        buf.append(""^"");
    }
    if (grammar != null) {
        Set<Integer> alts = s.getAltSet();
        if (alts != null) {
            buf.append(""\\n"");
            // separate alts
            IntegerList altList = new IntegerList();
            altList.addAll(alts);
            altList.sort();
            Set<ATNConfig> configurations = s.configs;
            for (int altIndex = 0; altIndex < altList.size(); altIndex++) {
                int alt = altList.get(altIndex);
                if (altIndex > 0) {
                    buf.append(""\\n"");
                }
                buf.append(""alt"");
                buf.append(alt);
                buf.append(':');
                // get a list of configs for just this alt
                // it will help us print better later
                List<ATNConfig> configsInAlt = new ArrayList<ATNConfig>();
                for (ATNConfig c : configurations) {
                    if (c.alt != alt)
                        continue;
                    configsInAlt.add(c);
                }
                int n = 0;
                for (int cIndex = 0; cIndex < configsInAlt.size(); cIndex++) {
                    ATNConfig c = configsInAlt.get(cIndex);
                    n++;
                    buf.append(c.toString(null, false));
                    if ((cIndex + 1) < configsInAlt.size()) {
                        buf.append("", "");
                    }
                    if (n % 5 == 0 && (configsInAlt.size() - cIndex) > 3) {
                        buf.append(""\\n"");
                    }
                }
            }
        }
    }
    String stateLabel = buf.toString();
    return stateLabel;
}", ,"// separate alts
[[SEP]]// get a list of configs for just this alt
[[SEP]]// it will help us print better later
",// separate alts[[SEP]]// get a list of configs for just this alt// it will help us print better later,111,163,[0],0,"[0, 0, 0]",0,"[0, 0]",0,0,0,0,getStateLabel(DFAState),org.antlr.v4.tool.DOTGenerator,getStateLabel/1[org.antlr.v4.tool.DFAState],False,111,3,2,2,0,14,12,50,2,11,1,12,0,0,3,5,0,2,8,9,11,3,5,0,0,0,27,4,0,False
1189,..\projects\antlr4-4.11.0\tool\src\org\antlr\v4\tool\DOTGenerator.java,org.antlr.v4.tool.DOTGenerator,"String getDOT(ATNState, String[], boolean)","/**
 * Return a String containing a DOT description that, when displayed,
 *  will show the incoming state machine visually.  All nodes reachable
 *  from startState will be included.
 */
public String getDOT(ATNState startState, String[] ruleNames, boolean isLexer) {
    if (startState == null)
        return null;
    // The output DOT graph for visualization
    Set<ATNState> markedStates = new HashSet<ATNState>();
    ST dot = stlib.getInstanceOf(""atn"");
    dot.add(""startState"", startState.stateNumber);
    dot.add(""rankdir"", rankdir);
    List<ATNState> work = new LinkedList<ATNState>();
    work.add(startState);
    while (!work.isEmpty()) {
        ATNState s = work.get(0);
        if (markedStates.contains(s)) {
            work.remove(0);
            continue;
        }
        markedStates.add(s);
        // don't go past end of rule node to the follow states
        if (s instanceof RuleStopState)
            continue;
        // special case: if decision point, then line up the alt start states
        // unless it's an end of block
        // if ( s instanceof BlockStartState ) {
        // ST rankST = stlib.getInstanceOf(""decision-rank"");
        // DecisionState alt = (DecisionState)s;
        // for (int i=0; i<alt.getNumberOfTransitions(); i++) {
        // ATNState target = alt.transition(i).target;
        // if ( target!=null ) {
        // rankST.add(""states"", target.stateNumber);
        // }
        // }
        // dot.add(""decisionRanks"", rankST);
        // }
        // make a DOT edge for each transition
        ST edgeST;
        for (int i = 0; i < s.getNumberOfTransitions(); i++) {
            Transition edge = s.transition(i);
            if (edge instanceof RuleTransition) {
                RuleTransition rr = ((RuleTransition) edge);
                // don't jump to other rules, but display edge to follow node
                edgeST = stlib.getInstanceOf(""edge"");
                String label = ""<"" + ruleNames[rr.ruleIndex];
                if (((RuleStartState) rr.target).isLeftRecursiveRule) {
                    label += ""["" + rr.precedence + ""]"";
                }
                label += "">"";
                edgeST.add(""label"", label);
                edgeST.add(""src"", ""s"" + s.stateNumber);
                edgeST.add(""target"", ""s"" + rr.followState.stateNumber);
                edgeST.add(""arrowhead"", arrowhead);
                dot.add(""edges"", edgeST);
                work.add(rr.followState);
                continue;
            }
            if (edge instanceof ActionTransition) {
                edgeST = stlib.getInstanceOf(""action-edge"");
                edgeST.add(""label"", getEdgeLabel(edge.toString()));
            } else if (edge instanceof AbstractPredicateTransition) {
                edgeST = stlib.getInstanceOf(""edge"");
                edgeST.add(""label"", getEdgeLabel(edge.toString()));
            } else if (edge.isEpsilon()) {
                edgeST = stlib.getInstanceOf(""epsilon-edge"");
                edgeST.add(""label"", getEdgeLabel(edge.toString()));
                boolean loopback = false;
                if (edge.target instanceof PlusBlockStartState) {
                    loopback = s.equals(((PlusBlockStartState) edge.target).loopBackState);
                } else if (edge.target instanceof StarLoopEntryState) {
                    loopback = s.equals(((StarLoopEntryState) edge.target).loopBackState);
                }
                edgeST.add(""loopback"", loopback);
            } else if (edge instanceof AtomTransition) {
                edgeST = stlib.getInstanceOf(""edge"");
                AtomTransition atom = (AtomTransition) edge;
                String label = String.valueOf(atom.label);
                if (isLexer)
                    label = ""'"" + getEdgeLabel(new StringBuilder().appendCodePoint(atom.label).toString()) + ""'"";
                else if (grammar != null)
                    label = grammar.getTokenDisplayName(atom.label);
                edgeST.add(""label"", getEdgeLabel(label));
            } else if (edge instanceof SetTransition) {
                edgeST = stlib.getInstanceOf(""edge"");
                SetTransition set = (SetTransition) edge;
                String label = set.label().toString();
                if (isLexer)
                    label = set.label().toString(true);
                else if (grammar != null)
                    label = set.label().toString(grammar.getVocabulary());
                if (edge instanceof NotSetTransition)
                    label = ""~"" + label;
                edgeST.add(""label"", getEdgeLabel(label));
            } else if (edge instanceof RangeTransition) {
                edgeST = stlib.getInstanceOf(""edge"");
                RangeTransition range = (RangeTransition) edge;
                String label = range.label().toString();
                if (isLexer)
                    label = range.toString();
                else if (grammar != null)
                    label = range.label().toString(grammar.getVocabulary());
                edgeST.add(""label"", getEdgeLabel(label));
            } else {
                edgeST = stlib.getInstanceOf(""edge"");
                edgeST.add(""label"", getEdgeLabel(edge.toString()));
            }
            edgeST.add(""src"", ""s"" + s.stateNumber);
            edgeST.add(""target"", ""s"" + edge.target.stateNumber);
            edgeST.add(""arrowhead"", arrowhead);
            if (s.getNumberOfTransitions() > 1) {
                edgeST.add(""transitionIndex"", i);
            } else {
                edgeST.add(""transitionIndex"", false);
            }
            dot.add(""edges"", edgeST);
            work.add(edge.target);
        }
    }
    // define nodes we visited (they will appear first in DOT output)
    // this is an example of ST's lazy eval :)
    // define stop state first; seems to be a bug in DOT where doublecircle
    // shape only works if we define them first. weird.
    // ATNState stopState = startState.atn.ruleToStopState.get(startState.rule);
    // if ( stopState!=null ) {
    // ST st = stlib.getInstanceOf(""stopstate"");
    // st.add(""name"", ""s""+stopState.stateNumber);
    // st.add(""label"", getStateLabel(stopState));
    // dot.add(""states"", st);
    // }
    for (ATNState s : markedStates) {
        if (!(s instanceof RuleStopState))
            continue;
        ST st = stlib.getInstanceOf(""stopstate"");
        st.add(""name"", ""s"" + s.stateNumber);
        st.add(""label"", getStateLabel(s));
        dot.add(""states"", st);
    }
    for (ATNState s : markedStates) {
        if (s instanceof RuleStopState)
            continue;
        ST st = stlib.getInstanceOf(""state"");
        st.add(""name"", ""s"" + s.stateNumber);
        st.add(""label"", getStateLabel(s));
        st.add(""transitions"", s.getTransitions());
        dot.add(""states"", st);
    }
    return dot.render();
}","/**
 * Return a String containing a DOT description that, when displayed,
 *  will show the incoming state machine visually.  All nodes reachable
 *  from startState will be included.
 */
","// define nodes we visited (they will appear first in DOT output)
[[SEP]]// this is an example of ST's lazy eval :)
[[SEP]]// define stop state first; seems to be a bug in DOT where doublecircle
[[SEP]]// shape only works if we define them first. weird.
[[SEP]]// ATNState stopState = startState.atn.ruleToStopState.get(startState.rule);
[[SEP]]// if ( stopState!=null ) {
[[SEP]]// ST st = stlib.getInstanceOf(""stopstate"");
[[SEP]]// st.add(""name"", ""s""+stopState.stateNumber);
[[SEP]]// st.add(""label"", getStateLabel(stopState));
[[SEP]]// dot.add(""states"", st);
[[SEP]]// The output DOT graph for visualization
[[SEP]]// special case: if decision point, then line up the alt start states
[[SEP]]// unless it's an end of block
[[SEP]]// if ( s instanceof BlockStartState ) {
[[SEP]]// ST rankST = stlib.getInstanceOf(""decision-rank"");
[[SEP]]// DecisionState alt = (DecisionState)s;
[[SEP]]// for (int i=0; i<alt.getNumberOfTransitions(); i++) {
[[SEP]]// ATNState target = alt.transition(i).target;
[[SEP]]// if ( target!=null ) {
[[SEP]]// rankST.add(""states"", target.stateNumber);
[[SEP]]// }
[[SEP]]// }
[[SEP]]// dot.add(""decisionRanks"", rankST);
[[SEP]]// }
[[SEP]]// don't go past end of rule node to the follow states
[[SEP]]// make a DOT edge for each transition
[[SEP]]// don't jump to other rules, but display edge to follow node
[[SEP]]// }
","/** * Return a String containing a DOT description that, when displayed, *  will show the incoming state machine visually.  All nodes reachable *  from startState will be included. */[[SEP]]// The output DOT graph for visualization[[SEP]]// don't go past end of rule node to the follow states[[SEP]]// special case: if decision point, then line up the alt start states// unless it's an end of block// if ( s instanceof BlockStartState ) {// ST rankST = stlib.getInstanceOf(""decision-rank"");// DecisionState alt = (DecisionState)s;// for (int i=0; i<alt.getNumberOfTransitions(); i++) {// ATNState target = alt.transition(i).target;// if ( target!=null ) {// rankST.add(""states"", target.stateNumber);// }// }// dot.add(""decisionRanks"", rankST);// }// make a DOT edge for each transition[[SEP]]// don't jump to other rules, but display edge to follow node[[SEP]]// define nodes we visited (they will appear first in DOT output)// this is an example of ST's lazy eval :)// define stop state first; seems to be a bug in DOT where doublecircle// shape only works if we define them first. weird.// ATNState stopState = startState.atn.ruleToStopState.get(startState.rule);// if ( stopState!=null ) {// ST st = stlib.getInstanceOf(""stopstate"");// st.add(""name"", ""s""+stopState.stateNumber);// st.add(""label"", getStateLabel(stopState));// dot.add(""states"", st);// }",181,330,[0],0,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]",0,"[0, 0, 0, 0, 0, 1]",1,0,1,1,"getDOT(ATNState, String[], boolean)",org.antlr.v4.tool.DOTGenerator,"getDOT/3[org.antlr.v4.tool.ATNState,java.lang.String[],boolean]",False,181,16,5,1,4,28,20,114,2,18,3,20,2,1,4,4,0,5,52,4,36,10,5,0,0,0,65,1,0,True
1190,..\projects\antlr4-4.11.0\tool\src\org\antlr\v4\tool\DOTGenerator.java,org.antlr.v4.tool.DOTGenerator,String getEdgeLabel(String),"/**
 * Do a depth-first walk of the state machine graph and
 *  fill a DOT description template.  Keep filling the
 *  states and edges attributes.  We know this is an ATN
 *  for a rule so don't traverse edges to other rules and
 *  don't go past rule end state.
 */
// protected void walkRuleATNCreatingDOT(ST dot,
// ATNState s)
// {
// if ( markedStates.contains(s) ) {
// return; // already visited this node
// }
// 
// markedStates.add(s.stateNumber); // mark this node as completed.
// 
// // first add this node
// ST stateST;
// if ( s instanceof RuleStopState ) {
// stateST = stlib.getInstanceOf(""stopstate"");
// }
// else {
// stateST = stlib.getInstanceOf(""state"");
// }
// stateST.add(""name"", getStateLabel(s));
// dot.add(""states"", stateST);
// 
// if ( s instanceof RuleStopState )  {
// return; // don't go past end of rule node to the follow states
// }
// 
// // special case: if decision point, then line up the alt start states
// // unless it's an end of block
// if ( s instanceof DecisionState ) {
// GrammarAST n = ((ATNState)s).ast;
// if ( n!=null && s instanceof BlockEndState ) {
// ST rankST = stlib.getInstanceOf(""decision-rank"");
// ATNState alt = (ATNState)s;
// while ( alt!=null ) {
// rankST.add(""states"", getStateLabel(alt));
// if ( alt.transition(1) !=null ) {
// alt = (ATNState)alt.transition(1).target;
// }
// else {
// alt=null;
// }
// }
// dot.add(""decisionRanks"", rankST);
// }
// }
// 
// // make a DOT edge for each transition
// ST edgeST = null;
// for (int i = 0; i < s.getNumberOfTransitions(); i++) {
// Transition edge = (Transition) s.transition(i);
// if ( edge instanceof RuleTransition ) {
// RuleTransition rr = ((RuleTransition)edge);
// // don't jump to other rules, but display edge to follow node
// edgeST = stlib.getInstanceOf(""edge"");
// if ( rr.rule.g != grammar ) {
// edgeST.add(""label"", ""<""+rr.rule.g.name+"".""+rr.rule.name+"">"");
// }
// else {
// edgeST.add(""label"", ""<""+rr.rule.name+"">"");
// }
// edgeST.add(""src"", getStateLabel(s));
// edgeST.add(""target"", getStateLabel(rr.followState));
// edgeST.add(""arrowhead"", arrowhead);
// dot.add(""edges"", edgeST);
// walkRuleATNCreatingDOT(dot, rr.followState);
// continue;
// }
// if ( edge instanceof ActionTransition ) {
// edgeST = stlib.getInstanceOf(""action-edge"");
// }
// else if ( edge instanceof PredicateTransition ) {
// edgeST = stlib.getInstanceOf(""edge"");
// }
// else if ( edge.isEpsilon() ) {
// edgeST = stlib.getInstanceOf(""epsilon-edge"");
// }
// else {
// edgeST = stlib.getInstanceOf(""edge"");
// }
// edgeST.add(""label"", getEdgeLabel(edge.toString(grammar)));
// edgeST.add(""src"", getStateLabel(s));
// edgeST.add(""target"", getStateLabel(edge.target));
// edgeST.add(""arrowhead"", arrowhead);
// dot.add(""edges"", edgeST);
// walkRuleATNCreatingDOT(dot, edge.target); // keep walkin'
// }
// }
/**
 * Fix edge strings so they print out in DOT properly;
 *  generate any gated predicates on edge too.
 */
protected String getEdgeLabel(String label) {
    label = label.replace(""\\"", ""\\\\"");
    label = label.replace(""\"""", ""\\\"""");
    label = label.replace(""\n"", ""\\\\n"");
    label = label.replace(""\r"", """");
    return label;
}","/**
 * Fix edge strings so they print out in DOT properly;
 *  generate any gated predicates on edge too.
 */
", ,"/** * Do a depth-first walk of the state machine graph and *  fill a DOT description template.  Keep filling the *  states and edges attributes.  We know this is an ATN *  for a rule so don't traverse edges to other rules and *  don't go past rule end state. */[[SEP]]// protected void walkRuleATNCreatingDOT(ST dot,// ATNState s)// {// if ( markedStates.contains(s) ) {// return; // already visited this node// }//// markedStates.add(s.stateNumber); // mark this node as completed.//// // first add this node// ST stateST;// if ( s instanceof RuleStopState ) {// stateST = stlib.getInstanceOf(""stopstate"");// }// else {// stateST = stlib.getInstanceOf(""state"");// }// stateST.add(""name"", getStateLabel(s));// dot.add(""states"", stateST);//// if ( s instanceof RuleStopState )  {// return; // don't go past end of rule node to the follow states// }//// // special case: if decision point, then line up the alt start states// // unless it's an end of block// if ( s instanceof DecisionState ) {// GrammarAST n = ((ATNState)s).ast;// if ( n!=null && s instanceof BlockEndState ) {// ST rankST = stlib.getInstanceOf(""decision-rank"");// ATNState alt = (ATNState)s;// while ( alt!=null ) {// rankST.add(""states"", getStateLabel(alt));// if ( alt.transition(1) !=null ) {// alt = (ATNState)alt.transition(1).target;// }// else {// alt=null;// }// }// dot.add(""decisionRanks"", rankST);// }// }//// // make a DOT edge for each transition// ST edgeST = null;// for (int i = 0; i < s.getNumberOfTransitions(); i++) {// Transition edge = (Transition) s.transition(i);// if ( edge instanceof RuleTransition ) {// RuleTransition rr = ((RuleTransition)edge);// // don't jump to other rules, but display edge to follow node// edgeST = stlib.getInstanceOf(""edge"");// if ( rr.rule.g != grammar ) {// edgeST.add(""label"", ""<""+rr.rule.g.name+"".""+rr.rule.name+"">"");// }// else {// edgeST.add(""label"", ""<""+rr.rule.name+"">"");// }// edgeST.add(""src"", getStateLabel(s));// edgeST.add(""target"", getStateLabel(rr.followState));// edgeST.add(""arrowhead"", arrowhead);// dot.add(""edges"", edgeST);// walkRuleATNCreatingDOT(dot, rr.followState);// continue;// }// if ( edge instanceof ActionTransition ) {// edgeST = stlib.getInstanceOf(""action-edge"");// }// else if ( edge instanceof PredicateTransition ) {// edgeST = stlib.getInstanceOf(""edge"");// }// else if ( edge.isEpsilon() ) {// edgeST = stlib.getInstanceOf(""epsilon-edge"");// }// else {// edgeST = stlib.getInstanceOf(""edge"");// }// edgeST.add(""label"", getEdgeLabel(edge.toString(grammar)));// edgeST.add(""src"", getStateLabel(s));// edgeST.add(""target"", getStateLabel(edge.target));// edgeST.add(""arrowhead"", arrowhead);// dot.add(""edges"", edgeST);// walkRuleATNCreatingDOT(dot, edge.target); // keep walkin'// }// }[[SEP]]/** * Fix edge strings so they print out in DOT properly; *  generate any gated predicates on edge too. */",428,434,[0],0,[0],0,"[0, 0, 0]",0,0,0,0,getEdgeLabel(String),org.antlr.v4.tool.DOTGenerator,getEdgeLabel/1[java.lang.String],False,428,0,2,2,0,1,1,7,1,0,1,1,0,0,0,0,0,0,8,0,4,0,0,0,0,0,21,4,0,True
1191,..\projects\antlr4-4.11.0\tool\src\org\antlr\v4\tool\ErrorManager.java,org.antlr.v4.tool.ErrorManager,ST getMessageTemplate(ANTLRMessage),"public ST getMessageTemplate(ANTLRMessage msg) {
    ST messageST = msg.getMessageTemplate(tool.longMessages);
    ST locationST = getLocationFormat();
    ST reportST = getReportFormat(msg.getErrorType().severity);
    ST messageFormatST = getMessageFormat();
    boolean locationValid = false;
    if (msg.line != -1) {
        locationST.add(""line"", msg.line);
        locationValid = true;
    }
    if (msg.charPosition != -1) {
        locationST.add(""column"", msg.charPosition);
        locationValid = true;
    }
    if (msg.fileName != null) {
        String displayFileName = msg.fileName;
        if (formatName.equals(""antlr"")) {
            // Don't show path to file in messages in ANTLR format;
            // they're too long.
            File f = new File(msg.fileName);
            if (f.exists()) {
                displayFileName = f.getName();
            }
        } else {
            // For other message formats, use the full filename in the
            // message.  This assumes that these formats are intended to
            // be parsed by IDEs, and so they need the full path to
            // resolve correctly.
        }
        locationST.add(""file"", displayFileName);
        locationValid = true;
    }
    messageFormatST.add(""id"", msg.getErrorType().code);
    messageFormatST.add(""text"", messageST);
    if (locationValid)
        reportST.add(""location"", locationST);
    reportST.add(""message"", messageFormatST);
    // ((DebugST)reportST).inspect();
    // reportST.impl.dump();
    return reportST;
}", ,"// ((DebugST)reportST).inspect();
[[SEP]]// Don't show path to file in messages in ANTLR format;
[[SEP]]// they're too long.
[[SEP]]// For other message formats, use the full filename in the
[[SEP]]// message.  This assumes that these formats are intended to
[[SEP]]// be parsed by IDEs, and so they need the full path to
[[SEP]]// resolve correctly.
[[SEP]]// reportST.impl.dump();
","// Don't show path to file in messages in ANTLR format;// they're too long.[[SEP]]// For other message formats, use the full filename in the// message.  This assumes that these formats are intended to// be parsed by IDEs, and so they need the full path to// resolve correctly.[[SEP]]// ((DebugST)reportST).inspect();// reportST.impl.dump();",47,90,[0],0,"[0, 0, 0, 0, 0, 0, 0, 0]",0,"[0, 0, 0]",0,0,0,0,getMessageTemplate(ANTLRMessage),org.antlr.v4.tool.ErrorManager,getMessageTemplate/1[org.antlr.v4.tool.ANTLRMessage],False,47,3,8,3,5,7,9,33,1,7,1,9,3,1,0,3,0,0,8,2,11,0,3,0,0,0,24,1,0,False
1192,..\projects\antlr4-4.11.0\tool\src\org\antlr\v4\tool\ErrorManager.java,org.antlr.v4.tool.ErrorManager,ST getLocationFormat(),"/**
 * Return a StringTemplate that refers to the current format used for
 * emitting messages.
 */
public ST getLocationFormat() {
    return format.getInstanceOf(""location"");
}","/**
 * Return a StringTemplate that refers to the current format used for
 * emitting messages.
 */
", ,/** * Return a StringTemplate that refers to the current format used for * emitting messages. */,95,97,[0],0,[0],0,[0],0,0,0,0,getLocationFormat(),org.antlr.v4.tool.ErrorManager,getLocationFormat/0,False,95,1,1,1,0,1,1,3,1,0,0,1,0,0,0,0,0,0,1,0,0,0,0,0,0,0,17,1,0,True
1193,..\projects\antlr4-4.11.0\tool\src\org\antlr\v4\tool\ErrorManager.java,org.antlr.v4.tool.ErrorManager,"void toolError(ErrorType, Object...)","/**
 * Raise a predefined message with some number of parameters for the StringTemplate but for which there
 * is no location information possible.
 * @param errorType The Message Descriptor
 * @param args The arguments to pass to the StringTemplate
 */
public void toolError(ErrorType errorType, Object... args) {
    toolError(errorType, null, args);
}","/**
 * Raise a predefined message with some number of parameters for the StringTemplate but for which there
 * is no location information possible.
 * @param errorType The Message Descriptor
 * @param args The arguments to pass to the StringTemplate
 */
", ,/** * Raise a predefined message with some number of parameters for the StringTemplate but for which there * is no location information possible. * @param errorType The Message Descriptor * @param args The arguments to pass to the StringTemplate */,147,149,[0],0,[0],0,[0],0,0,0,0,"toolError(ErrorType, Object[])",org.antlr.v4.tool.ErrorManager,"toolError/2[org.antlr.v4.tool.ErrorType,java.lang.Object[]]",False,147,2,4,3,1,1,1,3,0,0,2,1,1,2,0,0,0,0,0,0,0,0,0,0,0,0,30,1,0,True
1194,..\projects\antlr4-4.11.0\tool\src\org\antlr\v4\tool\ErrorManager.java,org.antlr.v4.tool.ErrorManager,StackTraceElement getLastNonErrorManagerCodeLocation(Throwable),"/**
 * Return first non ErrorManager code location for generating messages
 */
private static StackTraceElement getLastNonErrorManagerCodeLocation(Throwable e) {
    StackTraceElement[] stack = e.getStackTrace();
    int i = 0;
    for (; i < stack.length; i++) {
        StackTraceElement t = stack[i];
        if (!t.toString().contains(""ErrorManager"")) {
            break;
        }
    }
    StackTraceElement location = stack[i];
    return location;
}","/**
 * Return first non ErrorManager code location for generating messages
 */
", ,/** * Return first non ErrorManager code location for generating messages */,177,188,[0],0,[0],0,[0],0,0,0,0,getLastNonErrorManagerCodeLocation(Throwable),org.antlr.v4.tool.ErrorManager,getLastNonErrorManagerCodeLocation/1[java.lang.Throwable],False,177,0,2,2,0,3,3,12,1,4,1,3,0,0,1,0,0,0,1,1,4,0,2,0,0,0,22,10,0,True
1195,..\projects\antlr4-4.11.0\tool\src\org\antlr\v4\tool\ErrorManager.java,org.antlr.v4.tool.ErrorManager,"void emit(ErrorType, ANTLRMessage)","// S U P P O R T  C O D E
@SuppressWarnings(""fallthrough"")
public void emit(ErrorType etype, ANTLRMessage msg) {
    switch(etype.severity) {
        case WARNING_ONE_OFF:
            if (errorTypes.contains(etype))
                break;
        // fall thru
        case WARNING:
            warnings++;
            tool.warning(msg);
            break;
        case ERROR_ONE_OFF:
            if (errorTypes.contains(etype))
                break;
        // fall thru
        case ERROR:
            errors++;
            tool.error(msg);
            break;
        default:
            break;
    }
    errorTypes.add(etype);
}", ,"// fall thru
[[SEP]]// fall thru
",// S U P P O R T  C O D E[[SEP]]// fall thru[[SEP]]// fall thru,192,213,[0],0,"[0, 0]",0,"[0, 0, 0]",0,0,0,0,"emit(ErrorType, ANTLRMessage)",org.antlr.v4.tool.ErrorManager,"emit/2[org.antlr.v4.tool.ErrorType,org.antlr.v4.tool.ANTLRMessage]",False,193,3,6,4,2,7,4,19,0,0,2,4,0,0,0,0,0,0,1,0,0,0,2,0,0,0,7,1,1,False
1196,..\projects\antlr4-4.11.0\tool\src\org\antlr\v4\tool\ErrorManager.java,org.antlr.v4.tool.ErrorManager,void setFormat(String),"/**
 * The format gets reset either from the Tool if the user supplied a command line option to that effect
 *  Otherwise we just use the default ""antlr"".
 */
public void setFormat(String formatName) {
    STGroupFile loadedFormat;
    synchronized (loadedFormats) {
        loadedFormat = loadedFormats.get(formatName);
        if (loadedFormat == null) {
            String fileName = FORMATS_DIR + formatName + STGroup.GROUP_FILE_EXTENSION;
            ClassLoader cl = Thread.currentThread().getContextClassLoader();
            URL url = cl.getResource(fileName);
            if (url == null) {
                cl = ErrorManager.class.getClassLoader();
                url = cl.getResource(fileName);
            }
            if (url == null && formatName.equals(""antlr"")) {
                rawError(""ANTLR installation corrupted; cannot find ANTLR messages format file "" + fileName);
                panic();
            } else if (url == null) {
                rawError(""no such message format file "" + fileName + "" retrying with default ANTLR format"");
                // recurse on this rule, trying the default message format
                setFormat(""antlr"");
                return;
            }
            loadedFormat = new STGroupFile(url, ""UTF-8"", '<', '>');
            loadedFormat.load();
            loadedFormats.put(formatName, loadedFormat);
        }
    }
    this.formatName = formatName;
    this.format = loadedFormat;
    if (!initSTListener.errors.isEmpty()) {
        rawError(""ANTLR installation corrupted; can't load messages format file:\n"" + initSTListener.toString());
        panic();
    }
    boolean formatOK = verifyFormat();
    if (!formatOK && formatName.equals(""antlr"")) {
        rawError(""ANTLR installation corrupted; ANTLR messages format file "" + formatName + "".stg incomplete"");
        panic();
    } else if (!formatOK) {
        // recurse on this rule, trying the default message format
        setFormat(""antlr"");
    }
}","/**
 * The format gets reset either from the Tool if the user supplied a command line option to that effect
 *  Otherwise we just use the default ""antlr"".
 */
","// recurse on this rule, trying the default message format
[[SEP]]// recurse on this rule, trying the default message format
","/** * The format gets reset either from the Tool if the user supplied a command line option to that effect *  Otherwise we just use the default ""antlr"". */[[SEP]]// recurse on this rule, trying the default message format[[SEP]]// recurse on this rule, trying the default message format",218,264,[0],0,"[0, 0]",0,"[0, 0, 0]",0,0,0,0,setFormat(String),org.antlr.v4.tool.ErrorManager,setFormat/1[java.lang.String],False,218,2,6,2,4,10,14,41,1,5,1,14,4,1,0,4,0,0,11,0,10,5,3,0,0,0,62,1,0,True
1197,..\projects\antlr4-4.11.0\tool\src\org\antlr\v4\tool\ErrorManager.java,org.antlr.v4.tool.ErrorManager,boolean verifyFormat(),"/**
 * Verify the message format template group
 */
protected boolean verifyFormat() {
    boolean ok = true;
    if (!format.isDefined(""location"")) {
        System.err.println(""Format template 'location' not found in "" + formatName);
        ok = false;
    }
    if (!format.isDefined(""message"")) {
        System.err.println(""Format template 'message' not found in "" + formatName);
        ok = false;
    }
    if (!format.isDefined(""report"")) {
        System.err.println(""Format template 'report' not found in "" + formatName);
        ok = false;
    }
    return ok;
}","/**
 * Verify the message format template group
 */
", ,/** * Verify the message format template group */,267,282,[0],0,[0],0,[0],0,0,0,0,verifyFormat(),org.antlr.v4.tool.ErrorManager,verifyFormat/0,False,267,0,1,1,0,4,2,16,1,1,0,2,0,0,0,0,0,0,6,0,4,3,1,0,0,0,15,4,0,True
1198,..\projects\antlr4-4.11.0\tool\src\org\antlr\v4\tool\ErrorManager.java,org.antlr.v4.tool.ErrorManager,void rawError(String),"/**
 * If there are errors during ErrorManager init, we have no choice
 *  but to go to System.err.
 */
static void rawError(String msg) {
    System.err.println(msg);
}","/**
 * If there are errors during ErrorManager init, we have no choice
 *  but to go to System.err.
 */
", ,"/** * If there are errors during ErrorManager init, we have no choice *  but to go to System.err. */",287,289,[0],0,[0],0,[0],0,0,0,0,rawError(String),org.antlr.v4.tool.ErrorManager,rawError/1[java.lang.String],False,287,0,3,3,0,1,1,3,0,0,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,16,8,0,True
1199,..\projects\antlr4-4.11.0\tool\src\org\antlr\v4\tool\ErrorManager.java,org.antlr.v4.tool.ErrorManager,void panic(),"public static void panic() {
    // can't call tool.panic since there may be multiple tools; just
    // one error manager
    throw new Error(""ANTLR ErrorManager panic"");
}", ,"// can't call tool.panic since there may be multiple tools; just
[[SEP]]// one error manager
",// can't call tool.panic since there may be multiple tools; just// one error manager,311,315,[0],0,"[0, 0]",0,[0],0,0,0,0,panic(),org.antlr.v4.tool.ErrorManager,panic/0,False,311,0,2,2,0,1,0,3,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,3,9,0,False
1200,..\projects\antlr4-4.11.0\tool\src\org\antlr\v4\tool\Grammar.java,org.antlr.v4.tool.Grammar,void initTokenSymbolTables(),"protected void initTokenSymbolTables() {
    tokenNameToTypeMap.put(""EOF"", Token.EOF);
    // reserve a spot for the INVALID token
    typeToTokenList.add(null);
}", ,"// reserve a spot for the INVALID token
",// reserve a spot for the INVALID token,367,372,[0],0,[0],0,[0],0,0,0,0,initTokenSymbolTables(),org.antlr.v4.tool.Grammar,initTokenSymbolTables/0,False,367,0,2,2,0,1,2,4,0,0,0,2,0,0,0,0,0,0,1,0,0,0,0,0,0,0,5,4,0,False
1201,..\projects\antlr4-4.11.0\tool\src\org\antlr\v4\tool\Grammar.java,org.antlr.v4.tool.Grammar,void loadImportedGrammars(Set<String>),"private void loadImportedGrammars(Set<String> visited) {
    if (ast == null)
        return;
    GrammarAST i = (GrammarAST) ast.getFirstChildWithType(ANTLRParser.IMPORT);
    if (i == null)
        return;
    visited.add(this.name);
    importedGrammars = new ArrayList<Grammar>();
    for (Object c : i.getChildren()) {
        GrammarAST t = (GrammarAST) c;
        String importedGrammarName = null;
        if (t.getType() == ANTLRParser.ASSIGN) {
            t = (GrammarAST) t.getChild(1);
            importedGrammarName = t.getText();
        } else if (t.getType() == ANTLRParser.ID) {
            importedGrammarName = t.getText();
        }
        if (visited.contains(importedGrammarName)) {
            // ignore circular refs
            continue;
        }
        Grammar g;
        try {
            g = tool.loadImportedGrammar(this, t);
        } catch (IOException ioe) {
            tool.errMgr.grammarError(ErrorType.ERROR_READING_IMPORTED_GRAMMAR, importedGrammarName, t.getToken(), importedGrammarName, name);
            continue;
        }
        // did it come back as error node or missing?
        if (g == null)
            continue;
        g.parent = this;
        importedGrammars.add(g);
        // recursively pursue any imports in this import
        g.loadImportedGrammars(visited);
    }
}", ,"// ignore circular refs
[[SEP]]// did it come back as error node or missing?
[[SEP]]// recursively pursue any imports in this import
",// ignore circular refs[[SEP]]// did it come back as error node or missing?[[SEP]]// recursively pursue any imports in this import,379,416,[0],0,"[0, 0, 0]",0,"[0, 0, 0]",0,0,0,0,loadImportedGrammars(Set<String>),org.antlr.v4.tool.Grammar,loadImportedGrammars/1[java.util.Set<java.lang.String>],False,379,4,5,2,3,9,12,33,2,4,1,12,1,0,1,5,1,0,0,1,9,0,2,0,0,0,21,2,0,False
1202,..\projects\antlr4-4.11.0\tool\src\org\antlr\v4\tool\Grammar.java,org.antlr.v4.tool.Grammar,boolean defineRule(Rule),"/**
 * Define the specified rule in the grammar. This method assigns the rule's
 * {@link Rule#index} according to the {@link #ruleNumber} field, and adds
 * the {@link Rule} instance to {@link #rules} and {@link #indexToRule}.
 *
 * @param r The rule to define in the grammar.
 * @return {@code true} if the rule was added to the {@link Grammar}
 * instance; otherwise, {@code false} if a rule with this name already
 * existed in the grammar instance.
 */
public boolean defineRule(Rule r) {
    if (rules.get(r.name) != null) {
        return false;
    }
    rules.put(r.name, r);
    r.index = ruleNumber++;
    indexToRule.add(r);
    return true;
}","/**
 * Define the specified rule in the grammar. This method assigns the rule's
 * {@link Rule#index} according to the {@link #ruleNumber} field, and adds
 * the {@link Rule} instance to {@link #rules} and {@link #indexToRule}.
 *
 * @param r The rule to define in the grammar.
 * @return {@code true} if the rule was added to the {@link Grammar}
 * instance; otherwise, {@code false} if a rule with this name already
 * existed in the grammar instance.
 */
", ,"/** * Define the specified rule in the grammar. This method assigns the rule's * {@link Rule#index} according to the {@link #ruleNumber} field, and adds * the {@link Rule} instance to {@link #rules} and {@link #indexToRule}. * * @param r The rule to define in the grammar. * @return {@code true} if the rule was added to the {@link Grammar} * instance; otherwise, {@code false} if a rule with this name already * existed in the grammar instance. */",443,451,[0],0,[0],0,[0],0,0,0,0,defineRule(Rule),org.antlr.v4.tool.Grammar,defineRule/1[org.antlr.v4.tool.Rule],False,443,1,1,1,0,2,3,9,2,0,1,3,0,0,0,1,0,0,0,0,1,0,1,0,0,0,29,1,0,True
1203,..\projects\antlr4-4.11.0\tool\src\org\antlr\v4\tool\Grammar.java,org.antlr.v4.tool.Grammar,boolean undefineRule(Rule),"/**
 * Undefine the specified rule from this {@link Grammar} instance. The
 * instance {@code r} is removed from {@link #rules} and
 * {@link #indexToRule}. This method updates the {@link Rule#index} field
 * for all rules defined after {@code r}, and decrements {@link #ruleNumber}
 * in preparation for adding new rules.
 * <p>
 * This method does nothing if the current {@link Grammar} does not contain
 * the instance {@code r} at index {@code r.index} in {@link #indexToRule}.
 * </p>
 *
 * @param r
 * @return {@code true} if the rule was removed from the {@link Grammar}
 * instance; otherwise, {@code false} if the specified rule was not defined
 * in the grammar.
 */
public boolean undefineRule(Rule r) {
    if (r.index < 0 || r.index >= indexToRule.size() || indexToRule.get(r.index) != r) {
        return false;
    }
    assert rules.get(r.name) == r;
    rules.remove(r.name);
    indexToRule.remove(r.index);
    for (int i = r.index; i < indexToRule.size(); i++) {
        assert indexToRule.get(i).index == i + 1;
        indexToRule.get(i).index--;
    }
    ruleNumber--;
    return true;
}","/**
 * Undefine the specified rule from this {@link Grammar} instance. The
 * instance {@code r} is removed from {@link #rules} and
 * {@link #indexToRule}. This method updates the {@link Rule#index} field
 * for all rules defined after {@code r}, and decrements {@link #ruleNumber}
 * in preparation for adding new rules.
 * <p>
 * This method does nothing if the current {@link Grammar} does not contain
 * the instance {@code r} at index {@code r.index} in {@link #indexToRule}.
 * </p>
 *
 * @param r
 * @return {@code true} if the rule was removed from the {@link Grammar}
 * instance; otherwise, {@code false} if the specified rule was not defined
 * in the grammar.
 */
", ,"/** * Undefine the specified rule from this {@link Grammar} instance. The * instance {@code r} is removed from {@link #rules} and * {@link #indexToRule}. This method updates the {@link Rule#index} field * for all rules defined after {@code r}, and decrements {@link #ruleNumber} * in preparation for adding new rules. * <p> * This method does nothing if the current {@link Grammar} does not contain * the instance {@code r} at index {@code r.index} in {@link #indexToRule}. * </p> * * @param r * @return {@code true} if the rule was removed from the {@link Grammar} * instance; otherwise, {@code false} if the specified rule was not defined * in the grammar. */",469,485,[0],0,[0],0,[0],0,0,0,0,undefineRule(Rule),org.antlr.v4.tool.Grammar,undefineRule/1[org.antlr.v4.tool.Rule],False,469,1,0,0,0,6,5,14,2,1,1,5,0,0,1,3,0,0,0,2,1,1,1,0,0,0,41,1,0,True
1204,..\projects\antlr4-4.11.0\tool\src\org\antlr\v4\tool\Grammar.java,org.antlr.v4.tool.Grammar,Rule getRule(String),"// public int getNumRules() {
// int n = rules.size();
// List<Grammar> imports = getAllImportedGrammars();
// if ( imports!=null ) {
// for (Grammar g : imports) n += g.getNumRules();
// }
// return n;
// }
public Rule getRule(String name) {
    Rule r = rules.get(name);
    if (r != null)
        return r;
    return null;
    /*
		List<Grammar> imports = getAllImportedGrammars();
		if ( imports==null ) return null;
		for (Grammar g : imports) {
			r = g.getRule(name); // recursively walk up hierarchy
			if ( r!=null ) return r;
		}
		return null;
		*/
}", ,"/*
		List<Grammar> imports = getAllImportedGrammars();
		if ( imports==null ) return null;
		for (Grammar g : imports) {
			r = g.getRule(name); // recursively walk up hierarchy
			if ( r!=null ) return r;
		}
		return null;
		*/
",// public int getNumRules() {// int n = rules.size();// List<Grammar> imports = getAllImportedGrammars();// if ( imports!=null ) {// for (Grammar g : imports) n += g.getNumRules();// }// return n;// }[[SEP]]/*		List<Grammar> imports = getAllImportedGrammars();		if ( imports==null ) return null;		for (Grammar g : imports) {			r = g.getRule(name); // recursively walk up hierarchy			if ( r!=null ) return r;		}		return null;		*/,496,509,[0],0,[0],0,"[0, 0]",0,0,0,0,getRule(String),org.antlr.v4.tool.Grammar,getRule/1[java.lang.String],False,496,1,23,23,0,2,1,5,2,1,1,1,0,0,0,1,0,0,0,0,1,0,1,0,0,0,5,1,0,False
1205,..\projects\antlr4-4.11.0\tool\src\org\antlr\v4\tool\Grammar.java,org.antlr.v4.tool.Grammar,"Rule getRule(String, String)","public Rule getRule(String grammarName, String ruleName) {
    if (grammarName != null) {
        // scope override
        Grammar g = getImportedGrammar(grammarName);
        if (g == null) {
            return null;
        }
        return g.rules.get(ruleName);
    }
    return getRule(ruleName);
}", ,"// scope override
",// scope override,521,530,[0],0,[0],0,[0],0,0,0,0,"getRule(String, String)",org.antlr.v4.tool.Grammar,"getRule/2[java.lang.String,java.lang.String]",False,521,2,3,1,2,3,3,10,3,1,2,3,2,1,0,2,0,0,0,0,1,0,2,0,0,0,9,1,0,False
1206,..\projects\antlr4-4.11.0\tool\src\org\antlr\v4\tool\Grammar.java,org.antlr.v4.tool.Grammar,List<Grammar> getAllImportedGrammars(),"/**
 * Get list of all imports from all grammars in the delegate subtree of g.
 *  The grammars are in import tree preorder.  Don't include ourselves
 *  in list as we're not a delegate of ourselves.
 */
public List<Grammar> getAllImportedGrammars() {
    if (importedGrammars == null) {
        return null;
    }
    LinkedHashMap<String, Grammar> delegates = new LinkedHashMap<String, Grammar>();
    for (Grammar d : importedGrammars) {
        delegates.put(d.fileName, d);
        List<Grammar> ds = d.getAllImportedGrammars();
        if (ds != null) {
            for (Grammar imported : ds) {
                delegates.put(imported.fileName, imported);
            }
        }
    }
    return new ArrayList<Grammar>(delegates.values());
}","/**
 * Get list of all imports from all grammars in the delegate subtree of g.
 *  The grammars are in import tree preorder.  Don't include ourselves
 *  in list as we're not a delegate of ourselves.
 */
", ,/** * Get list of all imports from all grammars in the delegate subtree of g. *  The grammars are in import tree preorder.  Don't include ourselves *  in list as we're not a delegate of ourselves. */,536,553,[0],0,[0],0,[0],0,0,0,0,getAllImportedGrammars(),org.antlr.v4.tool.Grammar,getAllImportedGrammars/0,False,536,1,6,5,1,5,3,16,2,2,0,3,1,0,2,2,0,0,0,0,2,0,3,0,0,0,29,1,0,True
1207,..\projects\antlr4-4.11.0\tool\src\org\antlr\v4\tool\Grammar.java,org.antlr.v4.tool.Grammar,Grammar load(String),"/**
 * convenience method for Tool.loadGrammar()
 */
public static Grammar load(String fileName) {
    Tool antlr = new Tool();
    return antlr.loadGrammar(fileName);
}","/**
 * convenience method for Tool.loadGrammar()
 */
", ,/** * convenience method for Tool.loadGrammar() */,562,565,[0],0,[0],0,[0],0,0,0,0,load(String),org.antlr.v4.tool.Grammar,load/1[java.lang.String],False,562,2,2,0,2,1,1,4,1,1,1,1,0,0,0,0,0,0,0,0,1,0,0,0,0,0,8,9,0,True
1208,..\projects\antlr4-4.11.0\tool\src\org\antlr\v4\tool\Grammar.java,org.antlr.v4.tool.Grammar,List<Grammar> getGrammarAncestors(),"/**
 * Return list of imported grammars from root down to our parent.
 *  Order is [root, ..., this.parent].  (us not included).
 */
public List<Grammar> getGrammarAncestors() {
    Grammar root = getOutermostGrammar();
    if (this == root)
        return null;
    List<Grammar> grammars = new ArrayList<Grammar>();
    // walk backwards to root, collecting grammars
    Grammar p = this.parent;
    while (p != null) {
        // add to head so in order later
        grammars.add(0, p);
        p = p.parent;
    }
    return grammars;
}","/**
 * Return list of imported grammars from root down to our parent.
 *  Order is [root, ..., this.parent].  (us not included).
 */
","// walk backwards to root, collecting grammars
[[SEP]]// add to head so in order later
","/** * Return list of imported grammars from root down to our parent. *  Order is [root, ..., this.parent].  (us not included). */[[SEP]]// walk backwards to root, collecting grammars[[SEP]]// add to head so in order later",570,581,[0],0,"[0, 0]",0,"[0, 0, 0]",0,0,0,0,getGrammarAncestors(),org.antlr.v4.tool.Grammar,getGrammarAncestors/0,False,570,1,2,1,1,3,2,11,2,3,0,2,1,1,1,2,0,0,0,1,4,0,1,0,0,0,21,1,0,True
1209,..\projects\antlr4-4.11.0\tool\src\org\antlr\v4\tool\Grammar.java,org.antlr.v4.tool.Grammar,Grammar getOutermostGrammar(),"/**
 * Return the grammar that imported us and our parents. Return this
 *  if we're root.
 */
public Grammar getOutermostGrammar() {
    if (parent == null)
        return this;
    return parent.getOutermostGrammar();
}","/**
 * Return the grammar that imported us and our parents. Return this
 *  if we're root.
 */
", ,/** * Return the grammar that imported us and our parents. Return this *  if we're root. */,586,589,[0],0,[0],0,[0],0,0,0,0,getOutermostGrammar(),org.antlr.v4.tool.Grammar,getOutermostGrammar/0,False,586,1,6,5,1,2,1,4,2,0,0,1,1,0,0,1,0,0,0,0,0,0,1,0,0,0,13,1,0,True
1210,..\projects\antlr4-4.11.0\tool\src\org\antlr\v4\tool\Grammar.java,org.antlr.v4.tool.Grammar,String getRecognizerName(),"/**
 * Get the name of the generated recognizer; may or may not be same
 *  as grammar name.
 *  Recognizer is TParser and TLexer from T if combined, else
 *  just use T regardless of grammar type.
 */
public String getRecognizerName() {
    String suffix = """";
    List<Grammar> grammarsFromRootToMe = getOutermostGrammar().getGrammarAncestors();
    String qualifiedName = name;
    if (grammarsFromRootToMe != null) {
        StringBuilder buf = new StringBuilder();
        for (Grammar g : grammarsFromRootToMe) {
            buf.append(g.name);
            buf.append('_');
        }
        buf.append(name);
        qualifiedName = buf.toString();
    }
    if (isCombined() || (isLexer() && implicitLexer != null)) {
        suffix = Grammar.getGrammarTypeToFileNameSuffix(getType());
    }
    return qualifiedName + suffix;
}","/**
 * Get the name of the generated recognizer; may or may not be same
 *  as grammar name.
 *  Recognizer is TParser and TLexer from T if combined, else
 *  just use T regardless of grammar type.
 */
", ,"/** * Get the name of the generated recognizer; may or may not be same *  as grammar name. *  Recognizer is TParser and TLexer from T if combined, else *  just use T regardless of grammar type. */",596,615,[0],0,[0],0,[0],0,0,0,0,getRecognizerName(),org.antlr.v4.tool.Grammar,getRecognizerName/0,False,596,1,6,0,6,6,9,18,1,4,0,9,6,4,1,2,0,1,1,0,6,1,2,0,0,0,42,1,0,True
1211,..\projects\antlr4-4.11.0\tool\src\org\antlr\v4\tool\Grammar.java,org.antlr.v4.tool.Grammar,Grammar getImportedGrammar(String),"/**
 * Return grammar directly imported by this grammar
 */
public Grammar getImportedGrammar(String name) {
    for (Grammar g : importedGrammars) {
        if (g.name.equals(name))
            return g;
    }
    return null;
}","/**
 * Return grammar directly imported by this grammar
 */
", ,/** * Return grammar directly imported by this grammar */,622,627,[0],0,[0],0,[0],0,0,0,0,getImportedGrammar(String),org.antlr.v4.tool.Grammar,getImportedGrammar/1[java.lang.String],False,622,1,3,3,0,3,1,6,2,0,1,1,0,0,1,0,0,0,0,0,0,0,2,0,0,0,12,1,0,True
1212,..\projects\antlr4-4.11.0\tool\src\org\antlr\v4\tool\Grammar.java,org.antlr.v4.tool.Grammar,int getTokenType(String),"public int getTokenType(String token) {
    Integer I;
    if (token.charAt(0) == '\'') {
        I = stringLiteralToTypeMap.get(token);
    } else {
        // must be a label like ID
        I = tokenNameToTypeMap.get(token);
    }
    int i = (I != null) ? I : Token.INVALID_TYPE;
    // tool.log(""grammar"", ""grammar type ""+type+"" ""+tokenName+""->""+i);
    return i;
}", ,"// must be a label like ID
[[SEP]]// tool.log(""grammar"", ""grammar type ""+type+"" ""+tokenName+""->""+i);
","// must be a label like ID[[SEP]]// tool.log(""grammar"", ""grammar type ""+type+"" ""+tokenName+""->""+i);",629,640,[0],0,"[0, 0]",0,"[0, 0]",0,0,0,0,getTokenType(String),org.antlr.v4.tool.Grammar,getTokenType/1[java.lang.String],False,629,0,4,4,0,3,2,11,1,2,1,2,0,0,0,2,0,1,0,1,3,0,1,0,0,0,8,1,0,False
1213,..\projects\antlr4-4.11.0\tool\src\org\antlr\v4\tool\Grammar.java,org.antlr.v4.tool.Grammar,String getTokenDisplayName(int),"/**
 * Given a token type, get a meaningful name for it such as the ID
 *  or string literal.  If this is a lexer and the ttype is in the
 *  char vocabulary, compute an ANTLR-valid (possibly escaped) char literal.
 */
public String getTokenDisplayName(int ttype) {
    // inside any target's char range and is lexer grammar?
    if (isLexer() && ttype >= Lexer.MIN_CHAR_VALUE && ttype <= Lexer.MAX_CHAR_VALUE) {
        return CharSupport.getANTLRCharLiteralForChar(ttype);
    }
    if (ttype == Token.EOF) {
        return ""EOF"";
    }
    if (ttype == Token.INVALID_TYPE) {
        return INVALID_TOKEN_NAME;
    }
    if (ttype >= 0 && ttype < typeToStringLiteralList.size() && typeToStringLiteralList.get(ttype) != null) {
        return typeToStringLiteralList.get(ttype);
    }
    if (ttype >= 0 && ttype < typeToTokenList.size() && typeToTokenList.get(ttype) != null) {
        return typeToTokenList.get(ttype);
    }
    return String.valueOf(ttype);
}","/**
 * Given a token type, get a meaningful name for it such as the ID
 *  or string literal.  If this is a lexer and the ttype is in the
 *  char vocabulary, compute an ANTLR-valid (possibly escaped) char literal.
 */
","// inside any target's char range and is lexer grammar?
","/** * Given a token type, get a meaningful name for it such as the ID *  or string literal.  If this is a lexer and the ttype is in the *  char vocabulary, compute an ANTLR-valid (possibly escaped) char literal. */[[SEP]]// inside any target's char range and is lexer grammar?",656,681,[0],0,[0],0,"[0, 0]",0,0,0,0,getTokenDisplayName(int),org.antlr.v4.tool.Grammar,getTokenDisplayName/1[int],False,656,1,5,4,1,12,5,18,6,0,1,5,1,2,0,4,0,0,1,2,0,0,1,0,0,0,41,1,0,True
1214,..\projects\antlr4-4.11.0\tool\src\org\antlr\v4\tool\Grammar.java,org.antlr.v4.tool.Grammar,String getTokenName(int),"/**
 * Gets the name by which a token can be referenced in the generated code.
 * For tokens defined in a {@code tokens{}} block or via a lexer rule, this
 * is the declared name of the token. For token types generated by the use
 * of a string literal within a parser rule of a combined grammar, this is
 * the automatically generated token type which includes the
 * {@link #AUTO_GENERATED_TOKEN_NAME_PREFIX} prefix. For types which are not
 * associated with a defined token, this method returns
 * {@link #INVALID_TOKEN_NAME}.
 *
 * @param ttype The token type.
 * @return The name of the token with the specified type.
 */
public String getTokenName(int ttype) {
    // inside any target's char range and is lexer grammar?
    if (isLexer() && ttype >= Lexer.MIN_CHAR_VALUE && ttype <= Lexer.MAX_CHAR_VALUE) {
        return CharSupport.getANTLRCharLiteralForChar(ttype);
    }
    if (ttype == Token.EOF) {
        return ""EOF"";
    }
    if (ttype >= 0 && ttype < typeToTokenList.size() && typeToTokenList.get(ttype) != null) {
        return typeToTokenList.get(ttype);
    }
    return INVALID_TOKEN_NAME;
}", ,"// inside any target's char range and is lexer grammar?
","/** * Gets the name by which a token can be referenced in the generated code. * For tokens defined in a {@code tokens{}} block or via a lexer rule, this * is the declared name of the token. For token types generated by the use * of a string literal within a parser rule of a combined grammar, this is * the automatically generated token type which includes the * {@link #AUTO_GENERATED_TOKEN_NAME_PREFIX} prefix. For types which are not * associated with a defined token, this method returns * {@link #INVALID_TOKEN_NAME}. * * @param ttype The token type. * @return The name of the token with the specified type. */[[SEP]]// inside any target's char range and is lexer grammar?",697,714,[0],0,[0],0,"[0, 0]",0,0,0,0,getTokenName(int),org.antlr.v4.tool.Grammar,getTokenName/1[int],False,697,1,3,2,1,8,4,12,4,0,1,4,1,2,0,2,0,0,1,1,0,0,1,0,0,0,59,1,0,True
1215,..\projects\antlr4-4.11.0\tool\src\org\antlr\v4\tool\Grammar.java,org.antlr.v4.tool.Grammar,int getChannelValue(String),"/**
 * Gets the constant channel value for a user-defined channel.
 *
 * <p>
 * This method only returns channel values for user-defined channels. All
 * other channels, including the predefined channels
 * {@link Token#DEFAULT_CHANNEL} and {@link Token#HIDDEN_CHANNEL} along with
 * any channel defined in code (e.g. in a {@code @members{}} block), are
 * ignored.</p>
 *
 * @param channel The channel name.
 * @return The channel value, if {@code channel} is the name of a known
 * user-defined token channel; otherwise, -1.
 */
public int getChannelValue(String channel) {
    Integer I = channelNameToValueMap.get(channel);
    int i = (I != null) ? I : -1;
    return i;
}","/**
 * Gets the constant channel value for a user-defined channel.
 *
 * <p>
 * This method only returns channel values for user-defined channels. All
 * other channels, including the predefined channels
 * {@link Token#DEFAULT_CHANNEL} and {@link Token#HIDDEN_CHANNEL} along with
 * any channel defined in code (e.g. in a {@code @members{}} block), are
 * ignored.</p>
 *
 * @param channel The channel name.
 * @return The channel value, if {@code channel} is the name of a known
 * user-defined token channel; otherwise, -1.
 */
", ,"/** * Gets the constant channel value for a user-defined channel. * * <p> * This method only returns channel values for user-defined channels. All * other channels, including the predefined channels * {@link Token#DEFAULT_CHANNEL} and {@link Token#HIDDEN_CHANNEL} along with * any channel defined in code (e.g. in a {@code @members{}} block), are * ignored.</p> * * @param channel The channel name. * @return The channel value, if {@code channel} is the name of a known * user-defined token channel; otherwise, -1. */",730,734,[0],0,[0],0,[0],0,0,0,0,getChannelValue(String),org.antlr.v4.tool.Grammar,getChannelValue/1[java.lang.String],False,730,0,0,0,0,2,1,5,1,2,1,1,0,0,0,1,0,1,0,1,2,0,0,0,0,0,38,1,0,True
1216,..\projects\antlr4-4.11.0\tool\src\org\antlr\v4\tool\Grammar.java,org.antlr.v4.tool.Grammar,String[] getRuleNames(),"/**
 * Gets an array of rule names for rules defined or imported by the
 * grammar. The array index is the rule index, and the value is the name of
 * the rule with the corresponding {@link Rule#index}.
 *
 * <p>If no rule is defined with an index for an element of the resulting
 * array, the value of that element is {@link #INVALID_RULE_NAME}.</p>
 *
 * @return The names of all rules defined in the grammar.
 */
public String[] getRuleNames() {
    String[] result = new String[rules.size()];
    Arrays.fill(result, INVALID_RULE_NAME);
    for (Rule rule : rules.values()) {
        result[rule.index] = rule.name;
    }
    return result;
}","/**
 * Gets an array of rule names for rules defined or imported by the
 * grammar. The array index is the rule index, and the value is the name of
 * the rule with the corresponding {@link Rule#index}.
 *
 * <p>If no rule is defined with an index for an element of the resulting
 * array, the value of that element is {@link #INVALID_RULE_NAME}.</p>
 *
 * @return The names of all rules defined in the grammar.
 */
", ,"/** * Gets an array of rule names for rules defined or imported by the * grammar. The array index is the rule index, and the value is the name of * the rule with the corresponding {@link Rule#index}. * * <p>If no rule is defined with an index for an element of the resulting * array, the value of that element is {@link #INVALID_RULE_NAME}.</p> * * @return The names of all rules defined in the grammar. */",746,754,[0],0,[0],0,[0],0,0,0,0,getRuleNames(),org.antlr.v4.tool.Grammar,getRuleNames/0,False,746,0,10,10,0,2,3,8,1,1,0,3,0,0,1,0,0,0,0,0,2,0,1,0,0,0,32,1,0,True
1217,..\projects\antlr4-4.11.0\tool\src\org\antlr\v4\tool\Grammar.java,org.antlr.v4.tool.Grammar,String[] getTokenNames(),"/**
 * Gets an array of token names for tokens defined or imported by the
 * grammar. The array index is the token type, and the value is the result
 * of {@link #getTokenName} for the corresponding token type.
 *
 * @see #getTokenName
 * @return The token names of all tokens defined in the grammar.
 */
public String[] getTokenNames() {
    int numTokens = getMaxTokenType();
    String[] tokenNames = new String[numTokens + 1];
    for (int i = 0; i < tokenNames.length; i++) {
        tokenNames[i] = getTokenName(i);
    }
    return tokenNames;
}","/**
 * Gets an array of token names for tokens defined or imported by the
 * grammar. The array index is the token type, and the value is the result
 * of {@link #getTokenName} for the corresponding token type.
 *
 * @see #getTokenName
 * @return The token names of all tokens defined in the grammar.
 */
", ,"/** * Gets an array of token names for tokens defined or imported by the * grammar. The array index is the token type, and the value is the result * of {@link #getTokenName} for the corresponding token type. * * @see #getTokenName * @return The token names of all tokens defined in the grammar. */",764,772,[0],0,[0],0,[0],0,0,0,0,getTokenNames(),org.antlr.v4.tool.Grammar,getTokenNames/0,False,764,1,32,30,2,2,2,8,1,3,0,2,2,3,1,0,0,0,0,2,4,1,1,0,0,0,30,1,0,True
1218,..\projects\antlr4-4.11.0\tool\src\org\antlr\v4\tool\Grammar.java,org.antlr.v4.tool.Grammar,String[] getTokenDisplayNames(),"/**
 * Gets an array of display names for tokens defined or imported by the
 * grammar. The array index is the token type, and the value is the result
 * of {@link #getTokenDisplayName} for the corresponding token type.
 *
 * @see #getTokenDisplayName
 * @return The display names of all tokens defined in the grammar.
 */
public String[] getTokenDisplayNames() {
    int numTokens = getMaxTokenType();
    String[] tokenNames = new String[numTokens + 1];
    for (int i = 0; i < tokenNames.length; i++) {
        tokenNames[i] = getTokenDisplayName(i);
    }
    return tokenNames;
}","/**
 * Gets an array of display names for tokens defined or imported by the
 * grammar. The array index is the token type, and the value is the result
 * of {@link #getTokenDisplayName} for the corresponding token type.
 *
 * @see #getTokenDisplayName
 * @return The display names of all tokens defined in the grammar.
 */
", ,"/** * Gets an array of display names for tokens defined or imported by the * grammar. The array index is the token type, and the value is the result * of {@link #getTokenDisplayName} for the corresponding token type. * * @see #getTokenDisplayName * @return The display names of all tokens defined in the grammar. */",782,790,[0],0,[0],0,[0],0,0,0,0,getTokenDisplayNames(),org.antlr.v4.tool.Grammar,getTokenDisplayNames/0,False,782,1,3,1,2,2,2,8,1,3,0,2,2,3,1,0,0,0,0,2,4,1,1,0,0,0,32,1,0,True
1219,..\projects\antlr4-4.11.0\tool\src\org\antlr\v4\tool\Grammar.java,org.antlr.v4.tool.Grammar,String getSemanticContextDisplayString(SemanticContext),"/**
 * Given an arbitrarily complex SemanticContext, walk the ""tree"" and get display string.
 *  Pull predicates from grammar text.
 */
public String getSemanticContextDisplayString(SemanticContext semctx) {
    if (semctx instanceof SemanticContext.Predicate) {
        return getPredicateDisplayString((SemanticContext.Predicate) semctx);
    }
    if (semctx instanceof SemanticContext.AND) {
        SemanticContext.AND and = (SemanticContext.AND) semctx;
        return joinPredicateOperands(and, "" and "");
    }
    if (semctx instanceof SemanticContext.OR) {
        SemanticContext.OR or = (SemanticContext.OR) semctx;
        return joinPredicateOperands(or, "" or "");
    }
    return semctx.toString();
}","/**
 * Given an arbitrarily complex SemanticContext, walk the ""tree"" and get display string.
 *  Pull predicates from grammar text.
 */
", ,"/** * Given an arbitrarily complex SemanticContext, walk the ""tree"" and get display string. *  Pull predicates from grammar text. */",843,856,[0],0,[0],0,[0],0,0,0,0,getSemanticContextDisplayString(SemanticContext),org.antlr.v4.tool.Grammar,getSemanticContextDisplayString/1[org.antlr.v4.tool.SemanticContext],False,843,2,3,1,2,4,3,14,4,2,1,3,2,2,0,0,0,0,2,0,2,0,1,0,0,0,22,1,0,True
1220,..\projects\antlr4-4.11.0\tool\src\org\antlr\v4\tool\Grammar.java,org.antlr.v4.tool.Grammar,int getMaxCharValue(),"/**
 * What is the max char value possible for this grammar's target?  Use
 *  unicode max if no target defined.
 */
public int getMaxCharValue() {
    return org.antlr.v4.runtime.Lexer.MAX_CHAR_VALUE;
    // if ( generator!=null ) {
    // return generator.getTarget().getMaxCharValue(generator);
    // }
    // else {
    // return Label.MAX_CHAR_VALUE;
    // }
}","/**
 * What is the max char value possible for this grammar's target?  Use
 *  unicode max if no target defined.
 */
","// if ( generator!=null ) {
[[SEP]]// return generator.getTarget().getMaxCharValue(generator);
[[SEP]]// }
[[SEP]]// else {
[[SEP]]// return Label.MAX_CHAR_VALUE;
[[SEP]]// }
",/** * What is the max char value possible for this grammar's target?  Use *  unicode max if no target defined. */[[SEP]]// if ( generator!=null ) {// return generator.getTarget().getMaxCharValue(generator);// }// else {// return Label.MAX_CHAR_VALUE;// },895,903,[0],0,"[0, 0, 0, 0, 0, 0]",0,"[0, 0]",0,0,0,0,getMaxCharValue(),org.antlr.v4.tool.Grammar,getMaxCharValue/0,False,895,0,1,1,0,1,0,3,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,14,1,0,True
1221,..\projects\antlr4-4.11.0\tool\src\org\antlr\v4\tool\Grammar.java,org.antlr.v4.tool.Grammar,IntSet getTokenTypes(),"/**
 * Return a set of all possible token or char types for this grammar
 */
public IntSet getTokenTypes() {
    if (isLexer()) {
        return getAllCharValues();
    }
    return IntervalSet.of(Token.MIN_USER_TOKEN_TYPE, getMaxTokenType());
}","/**
 * Return a set of all possible token or char types for this grammar
 */
", ,/** * Return a set of all possible token or char types for this grammar */,906,911,[0],0,[0],0,[0],0,0,0,0,getTokenTypes(),org.antlr.v4.tool.Grammar,getTokenTypes/0,False,906,2,3,0,3,2,4,6,2,0,0,4,3,3,0,0,0,0,0,0,0,0,1,0,0,0,20,1,0,True
1222,..\projects\antlr4-4.11.0\tool\src\org\antlr\v4\tool\Grammar.java,org.antlr.v4.tool.Grammar,IntSet getAllCharValues(),"/**
 * Return min to max char as defined by the target.
 *  If no target, use max unicode char value.
 */
public IntSet getAllCharValues() {
    return IntervalSet.of(Lexer.MIN_CHAR_VALUE, getMaxCharValue());
}","/**
 * Return min to max char as defined by the target.
 *  If no target, use max unicode char value.
 */
", ,"/** * Return min to max char as defined by the target. *  If no target, use max unicode char value. */",916,918,[0],0,[0],0,[0],0,0,0,0,getAllCharValues(),org.antlr.v4.tool.Grammar,getAllCharValues/0,False,916,2,2,1,1,1,2,3,1,0,0,2,1,1,0,0,0,0,0,0,0,0,0,0,0,0,18,1,0,True
1223,..\projects\antlr4-4.11.0\tool\src\org\antlr\v4\tool\Grammar.java,org.antlr.v4.tool.Grammar,int getMaxTokenType(),"/**
 * How many token types have been allocated so far?
 */
public int getMaxTokenType() {
    // don't count 0 (invalid)
    return typeToTokenList.size() - 1;
}","/**
 * How many token types have been allocated so far?
 */
","// don't count 0 (invalid)
",/** * How many token types have been allocated so far? */[[SEP]]// don't count 0 (invalid),921,923,[0],0,[0],0,"[0, 0]",0,0,0,0,getMaxTokenType(),org.antlr.v4.tool.Grammar,getMaxTokenType/0,False,921,0,5,5,0,1,1,3,1,0,0,1,0,0,0,0,0,0,0,1,0,1,0,0,0,0,12,1,0,True
1224,..\projects\antlr4-4.11.0\tool\src\org\antlr\v4\tool\Grammar.java,org.antlr.v4.tool.Grammar,int getNewTokenType(),"/**
 * Return a new unique integer in the token type space
 */
public int getNewTokenType() {
    maxTokenType++;
    return maxTokenType;
}","/**
 * Return a new unique integer in the token type space
 */
", ,/** * Return a new unique integer in the token type space */,926,929,[0],0,[0],0,[0],0,0,0,0,getNewTokenType(),org.antlr.v4.tool.Grammar,getNewTokenType/0,False,926,0,2,2,0,1,0,4,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,14,1,0,True
1225,..\projects\antlr4-4.11.0\tool\src\org\antlr\v4\tool\Grammar.java,org.antlr.v4.tool.Grammar,int getNewChannelNumber(),"/**
 * Return a new unique integer in the channel value space.
 */
public int getNewChannelNumber() {
    maxChannelType++;
    return maxChannelType;
}","/**
 * Return a new unique integer in the channel value space.
 */
", ,/** * Return a new unique integer in the channel value space. */,932,935,[0],0,[0],0,[0],0,0,0,0,getNewChannelNumber(),org.antlr.v4.tool.Grammar,getNewChannelNumber/0,False,932,0,1,1,0,1,0,4,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,14,1,0,True
1226,..\projects\antlr4-4.11.0\tool\src\org\antlr\v4\tool\Grammar.java,org.antlr.v4.tool.Grammar,void importVocab(Grammar),"public void importVocab(Grammar importG) {
    for (String tokenName : importG.tokenNameToTypeMap.keySet()) {
        defineTokenName(tokenName, importG.tokenNameToTypeMap.get(tokenName));
    }
    for (String tokenName : importG.stringLiteralToTypeMap.keySet()) {
        defineStringLiteral(tokenName, importG.stringLiteralToTypeMap.get(tokenName));
    }
    for (Map.Entry<String, Integer> channel : importG.channelNameToValueMap.entrySet()) {
        defineChannelName(channel.getKey(), channel.getValue());
    }
    // this.tokenNameToTypeMap.putAll( importG.tokenNameToTypeMap );
    // this.stringLiteralToTypeMap.putAll( importG.stringLiteralToTypeMap );
    int max = Math.max(this.typeToTokenList.size(), importG.typeToTokenList.size());
    Utils.setSize(typeToTokenList, max);
    for (int ttype = 0; ttype < importG.typeToTokenList.size(); ttype++) {
        maxTokenType = Math.max(maxTokenType, ttype);
        this.typeToTokenList.set(ttype, importG.typeToTokenList.get(ttype));
    }
    max = Math.max(this.channelValueToNameList.size(), importG.channelValueToNameList.size());
    Utils.setSize(channelValueToNameList, max);
    for (int channelValue = 0; channelValue < importG.channelValueToNameList.size(); channelValue++) {
        maxChannelType = Math.max(maxChannelType, channelValue);
        this.channelValueToNameList.set(channelValue, importG.channelValueToNameList.get(channelValue));
    }
}", ,"// this.tokenNameToTypeMap.putAll( importG.tokenNameToTypeMap );
[[SEP]]// this.stringLiteralToTypeMap.putAll( importG.stringLiteralToTypeMap );
",// this.tokenNameToTypeMap.putAll( importG.tokenNameToTypeMap );// this.stringLiteralToTypeMap.putAll( importG.stringLiteralToTypeMap );,950,975,[0],0,"[0, 0]",0,[0],0,0,0,0,importVocab(Grammar),org.antlr.v4.tool.Grammar,importVocab/1[org.antlr.v4.tool.Grammar],False,950,2,9,5,4,6,13,23,0,3,1,13,3,4,5,0,0,0,0,2,6,0,1,0,0,0,16,1,0,False
1227,..\projects\antlr4-4.11.0\tool\src\org\antlr\v4\tool\Grammar.java,org.antlr.v4.tool.Grammar,"int defineStringLiteral(String, int)","public int defineStringLiteral(String lit, int ttype) {
    if (!stringLiteralToTypeMap.containsKey(lit)) {
        stringLiteralToTypeMap.put(lit, ttype);
        // track in reverse index too
        if (ttype >= typeToStringLiteralList.size()) {
            Utils.setSize(typeToStringLiteralList, ttype + 1);
        }
        typeToStringLiteralList.set(ttype, lit);
        setTokenForType(ttype, lit);
        return ttype;
    }
    return Token.INVALID_TYPE;
}", ,"// track in reverse index too
",// track in reverse index too,1000,1013,[0],0,[0],0,[0],0,0,0,0,"defineStringLiteral(String, int)",org.antlr.v4.tool.Grammar,"defineStringLiteral/2[java.lang.String,int]",False,1000,2,5,3,2,3,6,12,2,0,2,6,1,1,0,0,0,0,0,1,0,1,2,0,0,0,9,1,0,False
1228,..\projects\antlr4-4.11.0\tool\src\org\antlr\v4\tool\Grammar.java,org.antlr.v4.tool.Grammar,"void setTokenForType(int, String)","public void setTokenForType(int ttype, String text) {
    if (ttype == Token.EOF) {
        // ignore EOF, it will be reported as an error separately
        return;
    }
    if (ttype >= typeToTokenList.size()) {
        Utils.setSize(typeToTokenList, ttype + 1);
    }
    String prevToken = typeToTokenList.get(ttype);
    if (prevToken == null || prevToken.charAt(0) == '\'') {
        // only record if nothing there before or if thing before was a literal
        typeToTokenList.set(ttype, text);
    }
}", ,"// ignore EOF, it will be reported as an error separately
[[SEP]]// only record if nothing there before or if thing before was a literal
","// ignore EOF, it will be reported as an error separately[[SEP]]// only record if nothing there before or if thing before was a literal",1022,1036,[0],0,"[0, 0]",0,"[0, 0]",0,0,0,0,"setTokenForType(int, String)",org.antlr.v4.tool.Grammar,"setTokenForType/2[int,java.lang.String]",False,1022,1,4,3,1,5,5,12,1,1,2,5,0,0,0,3,0,0,0,2,1,1,1,0,0,0,8,1,0,False
1229,..\projects\antlr4-4.11.0\tool\src\org\antlr\v4\tool\Grammar.java,org.antlr.v4.tool.Grammar,int defineChannelName(String),"/**
 * Define a token channel with a specified name.
 *
 * <p>
 * If a channel with the specified name already exists, the previously
 * assigned channel value is returned.</p>
 *
 * @param name The channel name.
 * @return The constant channel value assigned to the channel.
 */
public int defineChannelName(String name) {
    Integer prev = channelNameToValueMap.get(name);
    if (prev == null) {
        return defineChannelName(name, getNewChannelNumber());
    }
    return prev;
}","/**
 * Define a token channel with a specified name.
 *
 * <p>
 * If a channel with the specified name already exists, the previously
 * assigned channel value is returned.</p>
 *
 * @param name The channel name.
 * @return The constant channel value assigned to the channel.
 */
", ,"/** * Define a token channel with a specified name. * * <p> * If a channel with the specified name already exists, the previously * assigned channel value is returned.</p> * * @param name The channel name. * @return The constant channel value assigned to the channel. */",1048,1055,[0],0,[0],0,[0],0,0,0,0,defineChannelName(String),org.antlr.v4.tool.Grammar,defineChannelName/1[java.lang.String],False,1048,1,3,1,2,2,3,7,2,1,1,3,2,2,0,1,0,0,0,0,1,0,1,0,0,0,24,1,0,True
1230,..\projects\antlr4-4.11.0\tool\src\org\antlr\v4\tool\Grammar.java,org.antlr.v4.tool.Grammar,"int defineChannelName(String, int)","/**
 * Define a token channel with a specified name.
 *
 * <p>
 * If a channel with the specified name already exists, the previously
 * assigned channel value is not altered.</p>
 *
 * @param name The channel name.
 * @return The constant channel value assigned to the channel.
 */
public int defineChannelName(String name, int value) {
    Integer prev = channelNameToValueMap.get(name);
    if (prev != null) {
        return prev;
    }
    channelNameToValueMap.put(name, value);
    setChannelNameForValue(value, name);
    maxChannelType = Math.max(maxChannelType, value);
    return value;
}","/**
 * Define a token channel with a specified name.
 *
 * <p>
 * If a channel with the specified name already exists, the previously
 * assigned channel value is not altered.</p>
 *
 * @param name The channel name.
 * @return The constant channel value assigned to the channel.
 */
", ,"/** * Define a token channel with a specified name. * * <p> * If a channel with the specified name already exists, the previously * assigned channel value is not altered.</p> * * @param name The channel name. * @return The constant channel value assigned to the channel. */",1067,1077,[0],0,[0],0,[0],0,0,0,0,"defineChannelName(String, int)",org.antlr.v4.tool.Grammar,"defineChannelName/2[java.lang.String,int]",False,1067,1,3,2,1,2,4,10,2,1,2,4,1,1,0,1,0,0,0,0,2,0,1,0,0,0,30,1,0,True
1231,..\projects\antlr4-4.11.0\tool\src\org\antlr\v4\tool\Grammar.java,org.antlr.v4.tool.Grammar,"void setChannelNameForValue(int, String)","/**
 * Sets the channel name associated with a particular channel value.
 *
 * <p>
 * If a name has already been assigned to the channel with constant value
 * {@code channelValue}, this method does nothing.</p>
 *
 * @param channelValue The constant value for the channel.
 * @param name The channel name.
 */
public void setChannelNameForValue(int channelValue, String name) {
    if (channelValue >= channelValueToNameList.size()) {
        Utils.setSize(channelValueToNameList, channelValue + 1);
    }
    String prevChannel = channelValueToNameList.get(channelValue);
    if (prevChannel == null) {
        channelValueToNameList.set(channelValue, name);
    }
}","/**
 * Sets the channel name associated with a particular channel value.
 *
 * <p>
 * If a name has already been assigned to the channel with constant value
 * {@code channelValue}, this method does nothing.</p>
 *
 * @param channelValue The constant value for the channel.
 * @param name The channel name.
 */
", ,"/** * Sets the channel name associated with a particular channel value. * * <p> * If a name has already been assigned to the channel with constant value * {@code channelValue}, this method does nothing.</p> * * @param channelValue The constant value for the channel. * @param name The channel name. */",1089,1098,[0],0,[0],0,[0],0,0,0,0,"setChannelNameForValue(int, String)",org.antlr.v4.tool.Grammar,"setChannelNameForValue/2[int,java.lang.String]",False,1089,1,2,1,1,3,4,9,0,1,2,4,0,0,0,1,0,0,0,1,1,1,1,0,0,0,27,1,0,True
1232,..\projects\antlr4-4.11.0\tool\src\org\antlr\v4\tool\Grammar.java,org.antlr.v4.tool.Grammar,"Attribute resolveToAttribute(String, ActionAST)","// no isolated attr at grammar action level
@Override
public Attribute resolveToAttribute(String x, ActionAST node) {
    return null;
}","// no isolated attr at grammar action level
", ,// no isolated attr at grammar action level,1101,1104,[0],0,[0],0,[0],0,0,0,0,"resolveToAttribute(String, ActionAST)",org.antlr.v4.tool.Grammar,"resolveToAttribute/2[java.lang.String,org.antlr.v4.tool.ast.ActionAST]",False,1102,2,0,0,0,1,0,3,1,0,2,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,5,1,0,False
1233,..\projects\antlr4-4.11.0\tool\src\org\antlr\v4\tool\Grammar.java,org.antlr.v4.tool.Grammar,"Attribute resolveToAttribute(String, String, ActionAST)","// no $x.y makes sense here
@Override
public Attribute resolveToAttribute(String x, String y, ActionAST node) {
    return null;
}","// no $x.y makes sense here
", ,// no $x.y makes sense here,1107,1110,[0],0,[0],0,[0],0,0,0,0,"resolveToAttribute(String, String, ActionAST)",org.antlr.v4.tool.Grammar,"resolveToAttribute/3[java.lang.String,java.lang.String,org.antlr.v4.tool.ast.ActionAST]",False,1108,2,0,0,0,1,0,3,1,0,3,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,5,1,0,False
1234,..\projects\antlr4-4.11.0\tool\src\org\antlr\v4\tool\Grammar.java,org.antlr.v4.tool.Grammar,String getDefaultActionScope(),"/**
 * Given a grammar type, what should be the default action scope?
 *  If I say @members in a COMBINED grammar, for example, the
 *  default scope should be ""parser"".
 */
public String getDefaultActionScope() {
    switch(getType()) {
        case ANTLRParser.LEXER:
            return ""lexer"";
        case ANTLRParser.PARSER:
        case ANTLRParser.COMBINED:
            return ""parser"";
    }
    return null;
}","/**
 * Given a grammar type, what should be the default action scope?
 *  If I say @members in a COMBINED grammar, for example, the
 *  default scope should be ""parser"".
 */
", ,"/** * Given a grammar type, what should be the default action scope? *  If I say @members in a COMBINED grammar, for example, the *  default scope should be ""parser"". */",1130,1139,[0],0,[0],0,[0],0,0,0,0,getDefaultActionScope(),org.antlr.v4.tool.Grammar,getDefaultActionScope/0,False,1130,1,3,2,1,4,1,10,3,0,0,1,1,1,0,0,0,0,2,0,0,0,1,0,0,0,26,1,0,True
1235,..\projects\antlr4-4.11.0\tool\src\org\antlr\v4\tool\Grammar.java,org.antlr.v4.tool.Grammar,boolean isTokenName(String),"/**
 * Is id a valid token name? Does id start with an uppercase letter?
 */
public static boolean isTokenName(String id) {
    return Character.isUpperCase(id.charAt(0));
}","/**
 * Is id a valid token name? Does id start with an uppercase letter?
 */
", ,/** * Is id a valid token name? Does id start with an uppercase letter? */,1156,1158,[0],0,[0],0,[0],0,0,0,0,isTokenName(String),org.antlr.v4.tool.Grammar,isTokenName/1[java.lang.String],False,1156,0,5,5,0,1,2,3,1,0,1,2,0,0,0,0,0,0,0,1,0,0,0,0,0,0,13,9,0,True
1236,..\projects\antlr4-4.11.0\tool\src\org\antlr\v4\tool\Grammar.java,org.antlr.v4.tool.Grammar,String getGrammarTypeToFileNameSuffix(int),"public static String getGrammarTypeToFileNameSuffix(int type) {
    switch(type) {
        case ANTLRParser.LEXER:
            return ""Lexer"";
        case ANTLRParser.PARSER:
            return ""Parser"";
        // if combined grammar, gen Parser and Lexer will be done later
        // TODO: we are separate now right?
        case ANTLRParser.COMBINED:
            return ""Parser"";
        default:
            return ""<invalid>"";
    }
}", ,"// if combined grammar, gen Parser and Lexer will be done later
[[SEP]]// TODO: we are separate now right?
","// if combined grammar, gen Parser and Lexer will be done later// TODO: we are separate now right?",1165,1175,[0],0,"[0, 1]",1,[1],1,1,1,1,getGrammarTypeToFileNameSuffix(int),org.antlr.v4.tool.Grammar,getGrammarTypeToFileNameSuffix/1[int],False,1165,0,3,3,0,4,0,12,4,0,1,0,0,0,0,0,0,0,4,0,0,0,1,0,0,0,8,9,0,False
1237,..\projects\antlr4-4.11.0\tool\src\org\antlr\v4\tool\Grammar.java,org.antlr.v4.tool.Grammar,"void setNodeOptions(GrammarAST, GrammarAST)","/**
 * Given ^(TOKEN_REF ^(OPTIONS ^(ELEMENT_OPTIONS (= assoc right))))
 *  set option assoc=right in TOKEN_REF.
 */
public static void setNodeOptions(GrammarAST node, GrammarAST options) {
    if (options == null)
        return;
    GrammarASTWithOptions t = (GrammarASTWithOptions) node;
    if (t.getChildCount() == 0 || options.getChildCount() == 0)
        return;
    for (Object o : options.getChildren()) {
        GrammarAST c = (GrammarAST) o;
        if (c.getType() == ANTLRParser.ASSIGN) {
            t.setOption(c.getChild(0).getText(), (GrammarAST) c.getChild(1));
        } else {
            // no arg such as ID<VarNodeType>
            t.setOption(c.getText(), null);
        }
    }
}","/**
 * Given ^(TOKEN_REF ^(OPTIONS ^(ELEMENT_OPTIONS (= assoc right))))
 *  set option assoc=right in TOKEN_REF.
 */
","// no arg such as ID<VarNodeType>
",/** * Given ^(TOKEN_REF ^(OPTIONS ^(ELEMENT_OPTIONS (= assoc right)))) *  set option assoc=right in TOKEN_REF. */[[SEP]]// no arg such as ID<VarNodeType>,1186,1199,[0],0,[0],0,"[0, 0]",0,0,0,0,"setNodeOptions(GrammarAST, GrammarAST)",org.antlr.v4.tool.Grammar,"setNodeOptions/2[org.antlr.v4.tool.ast.GrammarAST,org.antlr.v4.tool.ast.GrammarAST]",False,1186,2,1,0,1,6,6,14,2,2,2,6,0,0,1,4,0,0,0,4,2,0,2,0,0,0,31,9,0,True
1238,..\projects\antlr4-4.11.0\tool\src\org\antlr\v4\tool\Grammar.java,org.antlr.v4.tool.Grammar,"List<Pair<GrammarAST, GrammarAST>> getStringLiteralAliasesFromLexerRules(GrammarRootAST)","/**
 * Return list of (TOKEN_NAME node, 'literal' node) pairs
 */
public static List<Pair<GrammarAST, GrammarAST>> getStringLiteralAliasesFromLexerRules(GrammarRootAST ast) {
    String[] patterns = { ""(RULE %name:TOKEN_REF (BLOCK (ALT %lit:STRING_LITERAL)))"", ""(RULE %name:TOKEN_REF (BLOCK (ALT %lit:STRING_LITERAL ACTION)))"", ""(RULE %name:TOKEN_REF (BLOCK (ALT %lit:STRING_LITERAL SEMPRED)))"", ""(RULE %name:TOKEN_REF (BLOCK (LEXER_ALT_ACTION (ALT %lit:STRING_LITERAL) .)))"", ""(RULE %name:TOKEN_REF (BLOCK (LEXER_ALT_ACTION (ALT %lit:STRING_LITERAL) . .)))"", ""(RULE %name:TOKEN_REF (BLOCK (LEXER_ALT_ACTION (ALT %lit:STRING_LITERAL) (LEXER_ACTION_CALL . .))))"", ""(RULE %name:TOKEN_REF (BLOCK (LEXER_ALT_ACTION (ALT %lit:STRING_LITERAL) . (LEXER_ACTION_CALL . .))))"", ""(RULE %name:TOKEN_REF (BLOCK (LEXER_ALT_ACTION (ALT %lit:STRING_LITERAL) (LEXER_ACTION_CALL . .) .)))"" // TODO: allow doc comment in there
    };
    GrammarASTAdaptor adaptor = new GrammarASTAdaptor(ast.token.getInputStream());
    org.antlr.runtime.tree.TreeWizard wiz = new org.antlr.runtime.tree.TreeWizard(adaptor, ANTLRParser.tokenNames);
    List<Pair<GrammarAST, GrammarAST>> lexerRuleToStringLiteral = new ArrayList<Pair<GrammarAST, GrammarAST>>();
    List<GrammarAST> ruleNodes = ast.getNodesWithType(ANTLRParser.RULE);
    if (ruleNodes == null || ruleNodes.isEmpty())
        return null;
    for (GrammarAST r : ruleNodes) {
        // tool.log(""grammar"", r.toStringTree());
        // System.out.println(""chk: ""+r.toStringTree());
        org.antlr.runtime.tree.Tree name = r.getChild(0);
        if (name.getType() == ANTLRParser.TOKEN_REF) {
            // check rule against patterns
            boolean isLitRule;
            for (String pattern : patterns) {
                isLitRule = defAlias(r, pattern, wiz, lexerRuleToStringLiteral);
                if (isLitRule)
                    break;
            }
            // if ( !isLitRule ) System.out.println(""no pattern matched"");
        }
    }
    return lexerRuleToStringLiteral;
}","/**
 * Return list of (TOKEN_NAME node, 'literal' node) pairs
 */
","// TODO: allow doc comment in there
[[SEP]]// tool.log(""grammar"", r.toStringTree());
[[SEP]]// System.out.println(""chk: ""+r.toStringTree());
[[SEP]]// if ( !isLitRule ) System.out.println(""no pattern matched"");
[[SEP]]// check rule against patterns
","/** * Return list of (TOKEN_NAME node, 'literal' node) pairs */[[SEP]]// TODO: allow doc comment in there[[SEP]]// tool.log(""grammar"", r.toStringTree());// System.out.println(""chk: ""+r.toStringTree());[[SEP]]// check rule against patterns[[SEP]]// if ( !isLitRule ) System.out.println(""no pattern matched"");",1202,1238,[0],0,"[1, 0, 0, 0, 0]",1,"[0, 1, 0, 0, 0]",1,1,0,1,getStringLiteralAliasesFromLexerRules(GrammarRootAST),org.antlr.v4.tool.Grammar,getStringLiteralAliasesFromLexerRules/1[org.antlr.v4.tool.ast.GrammarRootAST],False,1202,6,5,2,3,7,6,19,2,7,1,6,1,1,2,2,0,0,8,1,7,0,4,0,0,0,50,9,0,True
1239,..\projects\antlr4-4.11.0\tool\src\org\antlr\v4\tool\Grammar.java,org.antlr.v4.tool.Grammar,"Map<Integer, Interval> getStateToGrammarRegionMap(GrammarRootAST, IntervalSet)","public static Map<Integer, Interval> getStateToGrammarRegionMap(GrammarRootAST ast, IntervalSet grammarTokenTypes) {
    Map<Integer, Interval> stateToGrammarRegionMap = new HashMap<Integer, Interval>();
    if (ast == null)
        return stateToGrammarRegionMap;
    List<GrammarAST> nodes = ast.getNodesWithType(grammarTokenTypes);
    for (GrammarAST n : nodes) {
        if (n.atnState != null) {
            Interval tokenRegion = Interval.of(n.getTokenStartIndex(), n.getTokenStopIndex());
            org.antlr.runtime.tree.Tree ruleNode = null;
            // RULEs, BLOCKs of transformed recursive rules point to original token interval
            switch(n.getType()) {
                case ANTLRParser.RULE:
                    ruleNode = n;
                    break;
                case ANTLRParser.BLOCK:
                case ANTLRParser.CLOSURE:
                    ruleNode = n.getAncestor(ANTLRParser.RULE);
                    break;
            }
            if (ruleNode instanceof RuleAST) {
                String ruleName = ((RuleAST) ruleNode).getRuleName();
                Rule r = ast.g.getRule(ruleName);
                if (r instanceof LeftRecursiveRule) {
                    RuleAST originalAST = ((LeftRecursiveRule) r).getOriginalAST();
                    tokenRegion = Interval.of(originalAST.getTokenStartIndex(), originalAST.getTokenStopIndex());
                }
            }
            stateToGrammarRegionMap.put(n.atnState.stateNumber, tokenRegion);
        }
    }
    return stateToGrammarRegionMap;
}", ,"// RULEs, BLOCKs of transformed recursive rules point to original token interval
","// RULEs, BLOCKs of transformed recursive rules point to original token interval",1274,1305,[0],0,[0],0,[0],0,0,0,0,"getStateToGrammarRegionMap(GrammarRootAST, IntervalSet)",org.antlr.v4.tool.Grammar,"getStateToGrammarRegionMap/2[org.antlr.v4.tool.ast.GrammarRootAST,org.antlr.v4.tool.IntervalSet]",False,1274,10,5,1,4,9,10,30,2,7,2,10,1,1,1,2,0,2,0,0,10,0,4,0,0,0,28,9,0,False
1240,..\projects\antlr4-4.11.0\tool\src\org\antlr\v4\tool\Grammar.java,org.antlr.v4.tool.Grammar,Interval getStateToGrammarRegion(int),"/**
 * Given an ATN state number, return the token index range within the grammar from which that ATN state was derived.
 */
public Interval getStateToGrammarRegion(int atnStateNumber) {
    if (stateToGrammarRegionMap == null) {
        // map all nodes with non-null atn state ptr
        stateToGrammarRegionMap = getStateToGrammarRegionMap(ast, null);
    }
    if (stateToGrammarRegionMap == null)
        return Interval.INVALID;
    return stateToGrammarRegionMap.get(atnStateNumber);
}","/**
 * Given an ATN state number, return the token index range within the grammar from which that ATN state was derived.
 */
","// map all nodes with non-null atn state ptr
","/** * Given an ATN state number, return the token index range within the grammar from which that ATN state was derived. */[[SEP]]// map all nodes with non-null atn state ptr",1308,1315,[0],0,[0],0,"[0, 0]",0,0,0,0,getStateToGrammarRegion(int),org.antlr.v4.tool.Grammar,getStateToGrammarRegion/1[int],False,1308,2,1,0,1,3,2,7,2,0,1,2,1,2,0,2,0,0,0,0,1,0,1,0,0,0,26,1,0,True
1241,..\projects\antlr4-4.11.0\tool\src\org\antlr\v4\tool\Grammar.java,org.antlr.v4.tool.Grammar,LexerInterpreter createLexerInterpreter(CharStream),"public LexerInterpreter createLexerInterpreter(CharStream input) {
    if (this.isParser()) {
        throw new IllegalStateException(""A lexer interpreter can only be created for a lexer or combined grammar."");
    }
    if (this.isCombined()) {
        return implicitLexer.createLexerInterpreter(input);
    }
    List<String> allChannels = new ArrayList<String>();
    allChannels.add(""DEFAULT_TOKEN_CHANNEL"");
    allChannels.add(""HIDDEN"");
    allChannels.addAll(channelValueToNameList);
    // must run ATN through serializer to set some state flags
    IntegerList serialized = ATNSerializer.getSerialized(atn);
    ATN deserializedATN = new ATNDeserializer().deserialize(serialized.toArray());
    return new LexerInterpreter(fileName, getVocabulary(), Arrays.asList(getRuleNames()), allChannels, ((LexerGrammar) this).modes.keySet(), deserializedATN, input);
}", ,"// must run ATN through serializer to set some state flags
",// must run ATN through serializer to set some state flags,1317,1342,[0],0,[0],0,[0],0,0,0,0,createLexerInterpreter(CharStream),org.antlr.v4.tool.Grammar,createLexerInterpreter/1[org.antlr.v4.tool.CharStream],False,1317,7,24,19,5,3,12,15,2,3,1,12,5,6,0,0,0,1,3,0,3,0,1,0,0,0,37,1,0,False
1242,..\projects\antlr4-4.11.0\tool\src\org\antlr\v4\tool\Grammar.java,org.antlr.v4.tool.Grammar,GrammarParserInterpreter createGrammarParserInterpreter(TokenStream),"/**
 * @since 4.5.1
 */
public GrammarParserInterpreter createGrammarParserInterpreter(TokenStream tokenStream) {
    if (this.isLexer()) {
        throw new IllegalStateException(""A parser interpreter can only be created for a parser or combined grammar."");
    }
    // must run ATN through serializer to set some state flags
    IntegerList serialized = ATNSerializer.getSerialized(atn);
    ATN deserializedATN = new ATNDeserializer().deserialize(serialized.toArray());
    return new GrammarParserInterpreter(this, deserializedATN, tokenStream);
}","/**
 * @since 4.5.1
 */
","// must run ATN through serializer to set some state flags
",/** * @since 4.5.1 */[[SEP]]// must run ATN through serializer to set some state flags,1345,1354,[0],0,[0],0,"[0, 0]",0,0,0,0,createGrammarParserInterpreter(TokenStream),org.antlr.v4.tool.Grammar,createGrammarParserInterpreter/1[org.antlr.v4.tool.TokenStream],False,1345,6,8,6,2,2,4,8,1,2,1,4,1,2,0,0,0,0,1,0,2,0,1,0,0,0,28,1,0,True
1243,..\projects\antlr4-4.11.0\tool\src\org\antlr\v4\tool\Grammar.java,org.antlr.v4.tool.Grammar,ParserInterpreter createParserInterpreter(TokenStream),"public ParserInterpreter createParserInterpreter(TokenStream tokenStream) {
    if (this.isLexer()) {
        throw new IllegalStateException(""A parser interpreter can only be created for a parser or combined grammar."");
    }
    // must run ATN through serializer to set some state flags
    IntegerList serialized = ATNSerializer.getSerialized(atn);
    ATN deserializedATN = new ATNDeserializer().deserialize(serialized.toArray());
    return new ParserInterpreter(fileName, getVocabulary(), Arrays.asList(getRuleNames()), deserializedATN, tokenStream);
}", ,"// must run ATN through serializer to set some state flags
",// must run ATN through serializer to set some state flags,1356,1366,[0],0,[0],0,[0],0,0,0,0,createParserInterpreter(TokenStream),org.antlr.v4.tool.Grammar,createParserInterpreter/1[org.antlr.v4.tool.TokenStream],False,1356,6,5,2,3,2,7,8,1,2,1,7,3,5,0,0,0,0,1,0,2,0,1,0,0,0,30,1,0,False
1244,..\projects\antlr4-4.11.0\tool\src\org\antlr\v4\tool\GrammarInterpreterRuleContext.java,org.antlr.v4.tool.GrammarInterpreterRuleContext,int getOuterAltNum(),"/**
 * The predicted outermost alternative for the rule associated
 *  with this context object.  If this node left recursive, the true original
 *  outermost alternative is returned.
 */
public int getOuterAltNum() {
    return outerAltNum;
}","/**
 * The predicted outermost alternative for the rule associated
 *  with this context object.  If this node left recursive, the true original
 *  outermost alternative is returned.
 */
", ,"/** * The predicted outermost alternative for the rule associated *  with this context object.  If this node left recursive, the true original *  outermost alternative is returned. */",28,28,[0],0,[0],0,[0],0,0,0,0,getOuterAltNum(),org.antlr.v4.tool.GrammarInterpreterRuleContext,getOuterAltNum/0,False,28,0,1,1,0,1,0,3,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,20,1,0,True
1245,..\projects\antlr4-4.11.0\tool\src\org\antlr\v4\tool\GrammarInterpreterRuleContext.java,org.antlr.v4.tool.GrammarInterpreterRuleContext,int getAltNumber(),"@Override
public int getAltNumber() {
    // override here and called old functionality; makes it backward compatible vs changing names
    return getOuterAltNum();
}", ,"// override here and called old functionality; makes it backward compatible vs changing names
",// override here and called old functionality; makes it backward compatible vs changing names,34,38,[0],0,[0],0,[0],0,0,0,0,getAltNumber(),org.antlr.v4.tool.GrammarInterpreterRuleContext,getAltNumber/0,False,35,1,1,0,1,1,1,3,1,0,0,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,5,1,0,False
1246,..\projects\antlr4-4.11.0\tool\src\org\antlr\v4\tool\GrammarParserInterpreter.java,org.antlr.v4.tool.GrammarParserInterpreter,BitSet findOuterMostDecisionStates(),"/**
 * identify the ATN states where we need to set the outer alt number.
 *  For regular rules, that's the block at the target to rule start state.
 *  For left-recursive rules, we track the primary block, which looks just
 *  like a regular rule's outer block, and the star loop block (always
 *  there even if 1 alt).
 */
public BitSet findOuterMostDecisionStates() {
    BitSet track = new BitSet(atn.states.size());
    int numberOfDecisions = atn.getNumberOfDecisions();
    for (int i = 0; i < numberOfDecisions; i++) {
        DecisionState decisionState = atn.getDecisionState(i);
        RuleStartState startState = atn.ruleToStartState[decisionState.ruleIndex];
        // Look for StarLoopEntryState that is in any left recursive rule
        if (decisionState instanceof StarLoopEntryState) {
            StarLoopEntryState loopEntry = (StarLoopEntryState) decisionState;
            if (loopEntry.isPrecedenceDecision) {
                // Recursive alts always result in a (...)* in the transformed
                // left recursive rule and that always has a BasicBlockStartState
                // even if just 1 recursive alt exists.
                ATNState blockStart = loopEntry.transition(0).target;
                // track the StarBlockStartState associated with the recursive alternatives
                track.set(blockStart.stateNumber);
            }
        } else if (startState.transition(0).target == decisionState) {
            // always track outermost block for any rule if it exists
            track.set(decisionState.stateNumber);
        }
    }
    return track;
}","/**
 * identify the ATN states where we need to set the outer alt number.
 *  For regular rules, that's the block at the target to rule start state.
 *  For left-recursive rules, we track the primary block, which looks just
 *  like a regular rule's outer block, and the star loop block (always
 *  there even if 1 alt).
 */
","// Look for StarLoopEntryState that is in any left recursive rule
[[SEP]]// Recursive alts always result in a (...)* in the transformed
[[SEP]]// left recursive rule and that always has a BasicBlockStartState
[[SEP]]// even if just 1 recursive alt exists.
[[SEP]]// track the StarBlockStartState associated with the recursive alternatives
[[SEP]]// always track outermost block for any rule if it exists
","/** * identify the ATN states where we need to set the outer alt number. *  For regular rules, that's the block at the target to rule start state. *  For left-recursive rules, we track the primary block, which looks just *  like a regular rule's outer block, and the star loop block (always *  there even if 1 alt). */[[SEP]]// Look for StarLoopEntryState that is in any left recursive rule[[SEP]]// Recursive alts always result in a (...)* in the transformed// left recursive rule and that always has a BasicBlockStartState// even if just 1 recursive alt exists.[[SEP]]// track the StarBlockStartState associated with the recursive alternatives[[SEP]]// always track outermost block for any rule if it exists",101,125,[0],0,"[0, 0, 0, 0, 0, 0]",0,"[0, 0, 0, 0, 0]",0,0,0,0,findOuterMostDecisionStates(),org.antlr.v4.tool.GrammarParserInterpreter,findOuterMostDecisionStates/0,False,101,4,1,1,0,5,5,19,1,7,0,5,0,0,1,1,0,0,0,3,7,0,3,0,0,0,53,1,0,True
1247,..\projects\antlr4-4.11.0\tool\src\org\antlr\v4\tool\GrammarParserInterpreter.java,org.antlr.v4.tool.GrammarParserInterpreter,int visitDecisionState(DecisionState),"/**
 *  Override this method so that we can record which alternative
 *   was taken at each decision point. For non-left recursive rules,
 *   it's simple. Set decisionStatesThatSetOuterAltNumInContext
 *   indicates which decision states should set the outer alternative number.
 *
 *   <p>Left recursive rules are much more complicated to deal with:
 *   there is typically a decision for the primary alternatives and a
 *   decision to choose between the recursive operator alternatives.
 *   For example, the following left recursive rule has two primary and 2
 *   recursive alternatives.</p>
 *
 * 		 e : e '*' e
 * 		   | '-' INT
 * 		   | e '+' e
 * 		   | ID
 * 		   ;
 *
 *   <p>ANTLR rewrites that rule to be</p>
 *
 * 		 e[int precedence]
 * 			 : ('-' INT | ID)
 * 			 ( {...}? '*' e[5]
 * 			 | {...}? '+' e[3]
 * 			 )*
 * 			;
 *
 *   <p>So, there are two decisions associated with picking the outermost alt.
 *   This complicates our tracking significantly. The outermost alternative number
 *   is a function of the decision (ATN state) within a left recursive rule and the
 *   predicted alternative coming back from adaptivePredict().
 *
 *   We use stateToAltsMap as a cache to avoid expensive calls to
 *   getRecursiveOpAlts().
 */
@Override
protected int visitDecisionState(DecisionState p) {
    int predictedAlt = super.visitDecisionState(p);
    if (p.getNumberOfTransitions() > 1) {
        // System.out.println(""decision ""+p.decision+"": ""+predictedAlt);
        if (p.decision == this.overrideDecision && this._input.index() == this.overrideDecisionInputIndex) {
            overrideDecisionRoot = (GrammarInterpreterRuleContext) getContext();
        }
    }
    GrammarInterpreterRuleContext ctx = (GrammarInterpreterRuleContext) _ctx;
    if (decisionStatesThatSetOuterAltNumInContext.get(p.stateNumber)) {
        ctx.outerAltNum = predictedAlt;
        Rule r = g.getRule(p.ruleIndex);
        if (atn.ruleToStartState[r.index].isLeftRecursiveRule) {
            int[] alts = stateToAltsMap[p.stateNumber];
            LeftRecursiveRule lr = (LeftRecursiveRule) g.getRule(p.ruleIndex);
            if (p.getStateType() == ATNState.BLOCK_START) {
                if (alts == null) {
                    alts = lr.getPrimaryAlts();
                    // cache it
                    stateToAltsMap[p.stateNumber] = alts;
                }
            } else if (p.getStateType() == ATNState.STAR_BLOCK_START) {
                if (alts == null) {
                    alts = lr.getRecursiveOpAlts();
                    // cache it
                    stateToAltsMap[p.stateNumber] = alts;
                }
            }
            ctx.outerAltNum = alts[predictedAlt];
        }
    }
    return predictedAlt;
}","/**
 *  Override this method so that we can record which alternative
 *   was taken at each decision point. For non-left recursive rules,
 *   it's simple. Set decisionStatesThatSetOuterAltNumInContext
 *   indicates which decision states should set the outer alternative number.
 *
 *   <p>Left recursive rules are much more complicated to deal with:
 *   there is typically a decision for the primary alternatives and a
 *   decision to choose between the recursive operator alternatives.
 *   For example, the following left recursive rule has two primary and 2
 *   recursive alternatives.</p>
 *
 * 		 e : e '*' e
 * 		   | '-' INT
 * 		   | e '+' e
 * 		   | ID
 * 		   ;
 *
 *   <p>ANTLR rewrites that rule to be</p>
 *
 * 		 e[int precedence]
 * 			 : ('-' INT | ID)
 * 			 ( {...}? '*' e[5]
 * 			 | {...}? '+' e[3]
 * 			 )*
 * 			;
 *
 *   <p>So, there are two decisions associated with picking the outermost alt.
 *   This complicates our tracking significantly. The outermost alternative number
 *   is a function of the decision (ATN state) within a left recursive rule and the
 *   predicted alternative coming back from adaptivePredict().
 *
 *   We use stateToAltsMap as a cache to avoid expensive calls to
 *   getRecursiveOpAlts().
 */
","// System.out.println(""decision ""+p.decision+"": ""+predictedAlt);
[[SEP]]// cache it
[[SEP]]// cache it
","/** *  Override this method so that we can record which alternative *   was taken at each decision point. For non-left recursive rules, *   it's simple. Set decisionStatesThatSetOuterAltNumInContext *   indicates which decision states should set the outer alternative number. * *   <p>Left recursive rules are much more complicated to deal with: *   there is typically a decision for the primary alternatives and a *   decision to choose between the recursive operator alternatives. *   For example, the following left recursive rule has two primary and 2 *   recursive alternatives.</p> * * 		 e : e '*' e * 		   | '-' INT * 		   | e '+' e * 		   | ID * 		   ; * *   <p>ANTLR rewrites that rule to be</p> * * 		 e[int precedence] * 			 : ('-' INT | ID) * 			 ( {...}? '*' e[5] * 			 | {...}? '+' e[3] * 			 )* * 			; * *   <p>So, there are two decisions associated with picking the outermost alt. *   This complicates our tracking significantly. The outermost alternative number *   is a function of the decision (ATN state) within a left recursive rule and the *   predicted alternative coming back from adaptivePredict(). * *   We use stateToAltsMap as a cache to avoid expensive calls to *   getRecursiveOpAlts(). */[[SEP]]// System.out.println(""decision ""+p.decision+"": ""+predictedAlt);[[SEP]]// cache it[[SEP]]// cache it",162,198,[0],0,"[0, 0, 0]",0,"[0, 0, 0, 0]",0,0,0,0,visitDecisionState(DecisionState),org.antlr.v4.tool.GrammarParserInterpreter,visitDecisionState/1[org.antlr.v4.tool.DecisionState],False,163,6,3,0,3,10,9,31,1,5,1,9,0,0,0,6,0,0,0,1,12,0,4,0,0,0,112,4,0,True
1248,..\projects\antlr4-4.11.0\tool\src\org\antlr\v4\tool\GrammarParserInterpreter.java,org.antlr.v4.tool.GrammarParserInterpreter,"List<ParserRuleContext> getAllPossibleParseTrees(Grammar, Parser, TokenStream, int, BitSet, int, int, int)","/**
 * Given an ambiguous parse information, return the list of ambiguous parse trees.
 *  An ambiguity occurs when a specific token sequence can be recognized
 *  in more than one way by the grammar. These ambiguities are detected only
 *  at decision points.
 *
 *  The list of trees includes the actual interpretation (that for
 *  the minimum alternative number) and all ambiguous alternatives.
 *  The actual interpretation is always first.
 *
 *  This method reuses the same physical input token stream used to
 *  detect the ambiguity by the original parser in the first place.
 *  This method resets/seeks within but does not alter originalParser.
 *
 *  The trees are rooted at the node whose start..stop token indices
 *  include the start and stop indices of this ambiguity event. That is,
 *  the trees returned will always include the complete ambiguous subphrase
 *  identified by the ambiguity event.  The subtrees returned will
 *  also always contain the node associated with the overridden decision.
 *
 *  Be aware that this method does NOT notify error or parse listeners as
 *  it would trigger duplicate or otherwise unwanted events.
 *
 *  This uses a temporary ParserATNSimulator and a ParserInterpreter
 *  so we don't mess up any statistics, event lists, etc...
 *  The parse tree constructed while identifying/making ambiguityInfo is
 *  not affected by this method as it creates a new parser interp to
 *  get the ambiguous interpretations.
 *
 *  Nodes in the returned ambig trees are independent of the original parse
 *  tree (constructed while identifying/creating ambiguityInfo).
 *
 *  @since 4.5.1
 *
 *  @param g              From which grammar should we drive alternative
 *                        numbers and alternative labels.
 *
 *  @param originalParser The parser used to create ambiguityInfo; it
 *                        is not modified by this routine and can be either
 *                        a generated or interpreted parser. It's token
 *                        stream *is* reset/seek()'d.
 *  @param tokens		  A stream of tokens to use with the temporary parser.
 *                        This will often be just the token stream within the
 *                        original parser but here it is for flexibility.
 *
 *  @param decision       Which decision to try different alternatives for.
 *
 *  @param alts           The set of alternatives to try while re-parsing.
 *
 *  @param startIndex	  The index of the first token of the ambiguous
 *                        input or other input of interest.
 *
 *  @param stopIndex      The index of the last token of the ambiguous input.
 *                        The start and stop indexes are used primarily to
 *                        identify how much of the resulting parse tree
 *                        to return.
 *
 *  @param startRuleIndex The start rule for the entire grammar, not
 *                        the ambiguous decision. We re-parse the entire input
 *                        and so we need the original start rule.
 *
 *  @return               The list of all possible interpretations of
 *                        the input for the decision in ambiguityInfo.
 *                        The actual interpretation chosen by the parser
 *                        is always given first because this method
 *                        retests the input in alternative order and
 *                        ANTLR always resolves ambiguities by choosing
 *                        the first alternative that matches the input.
 *                        The subtree returned
 *
 *  @throws RecognitionException Throws upon syntax error while matching
 *                               ambig input.
 */
public static List<ParserRuleContext> getAllPossibleParseTrees(Grammar g, Parser originalParser, TokenStream tokens, int decision, BitSet alts, int startIndex, int stopIndex, int startRuleIndex) throws RecognitionException {
    List<ParserRuleContext> trees = new ArrayList<ParserRuleContext>();
    // Create a new parser interpreter to parse the ambiguous subphrase
    ParserInterpreter parser = deriveTempParserInterpreter(g, originalParser, tokens);
    if (stopIndex >= (tokens.size() - 1)) {
        // if we are pointing at EOF token
        // EOF is not in tree, so must be 1 less than last non-EOF token
        stopIndex = tokens.size() - 2;
    }
    // get ambig trees
    int alt = alts.nextSetBit(0);
    while (alt >= 0) {
        // re-parse entire input for all ambiguous alternatives
        // (don't have to do first as it's been parsed, but do again for simplicity
        // using this temp parser.)
        parser.reset();
        parser.addDecisionOverride(decision, startIndex, alt);
        ParserRuleContext t = parser.parse(startRuleIndex);
        GrammarInterpreterRuleContext ambigSubTree = (GrammarInterpreterRuleContext) Trees.getRootOfSubtreeEnclosingRegion(t, startIndex, stopIndex);
        // Use higher of overridden decision tree or tree enclosing all tokens
        if (Trees.isAncestorOf(parser.getOverrideDecisionRoot(), ambigSubTree)) {
            ambigSubTree = (GrammarInterpreterRuleContext) parser.getOverrideDecisionRoot();
        }
        trees.add(ambigSubTree);
        alt = alts.nextSetBit(alt + 1);
    }
    return trees;
}","/**
 * Given an ambiguous parse information, return the list of ambiguous parse trees.
 *  An ambiguity occurs when a specific token sequence can be recognized
 *  in more than one way by the grammar. These ambiguities are detected only
 *  at decision points.
 *
 *  The list of trees includes the actual interpretation (that for
 *  the minimum alternative number) and all ambiguous alternatives.
 *  The actual interpretation is always first.
 *
 *  This method reuses the same physical input token stream used to
 *  detect the ambiguity by the original parser in the first place.
 *  This method resets/seeks within but does not alter originalParser.
 *
 *  The trees are rooted at the node whose start..stop token indices
 *  include the start and stop indices of this ambiguity event. That is,
 *  the trees returned will always include the complete ambiguous subphrase
 *  identified by the ambiguity event.  The subtrees returned will
 *  also always contain the node associated with the overridden decision.
 *
 *  Be aware that this method does NOT notify error or parse listeners as
 *  it would trigger duplicate or otherwise unwanted events.
 *
 *  This uses a temporary ParserATNSimulator and a ParserInterpreter
 *  so we don't mess up any statistics, event lists, etc...
 *  The parse tree constructed while identifying/making ambiguityInfo is
 *  not affected by this method as it creates a new parser interp to
 *  get the ambiguous interpretations.
 *
 *  Nodes in the returned ambig trees are independent of the original parse
 *  tree (constructed while identifying/creating ambiguityInfo).
 *
 *  @since 4.5.1
 *
 *  @param g              From which grammar should we drive alternative
 *                        numbers and alternative labels.
 *
 *  @param originalParser The parser used to create ambiguityInfo; it
 *                        is not modified by this routine and can be either
 *                        a generated or interpreted parser. It's token
 *                        stream *is* reset/seek()'d.
 *  @param tokens		  A stream of tokens to use with the temporary parser.
 *                        This will often be just the token stream within the
 *                        original parser but here it is for flexibility.
 *
 *  @param decision       Which decision to try different alternatives for.
 *
 *  @param alts           The set of alternatives to try while re-parsing.
 *
 *  @param startIndex	  The index of the first token of the ambiguous
 *                        input or other input of interest.
 *
 *  @param stopIndex      The index of the last token of the ambiguous input.
 *                        The start and stop indexes are used primarily to
 *                        identify how much of the resulting parse tree
 *                        to return.
 *
 *  @param startRuleIndex The start rule for the entire grammar, not
 *                        the ambiguous decision. We re-parse the entire input
 *                        and so we need the original start rule.
 *
 *  @return               The list of all possible interpretations of
 *                        the input for the decision in ambiguityInfo.
 *                        The actual interpretation chosen by the parser
 *                        is always given first because this method
 *                        retests the input in alternative order and
 *                        ANTLR always resolves ambiguities by choosing
 *                        the first alternative that matches the input.
 *                        The subtree returned
 *
 *  @throws RecognitionException Throws upon syntax error while matching
 *                               ambig input.
 */
","// Create a new parser interpreter to parse the ambiguous subphrase
[[SEP]]// if we are pointing at EOF token
[[SEP]]// EOF is not in tree, so must be 1 less than last non-EOF token
[[SEP]]// get ambig trees
[[SEP]]// re-parse entire input for all ambiguous alternatives
[[SEP]]// (don't have to do first as it's been parsed, but do again for simplicity
[[SEP]]// using this temp parser.)
[[SEP]]// Use higher of overridden decision tree or tree enclosing all tokens
","/** * Given an ambiguous parse information, return the list of ambiguous parse trees. *  An ambiguity occurs when a specific token sequence can be recognized *  in more than one way by the grammar. These ambiguities are detected only *  at decision points. * *  The list of trees includes the actual interpretation (that for *  the minimum alternative number) and all ambiguous alternatives. *  The actual interpretation is always first. * *  This method reuses the same physical input token stream used to *  detect the ambiguity by the original parser in the first place. *  This method resets/seeks within but does not alter originalParser. * *  The trees are rooted at the node whose start..stop token indices *  include the start and stop indices of this ambiguity event. That is, *  the trees returned will always include the complete ambiguous subphrase *  identified by the ambiguity event.  The subtrees returned will *  also always contain the node associated with the overridden decision. * *  Be aware that this method does NOT notify error or parse listeners as *  it would trigger duplicate or otherwise unwanted events. * *  This uses a temporary ParserATNSimulator and a ParserInterpreter *  so we don't mess up any statistics, event lists, etc... *  The parse tree constructed while identifying/making ambiguityInfo is *  not affected by this method as it creates a new parser interp to *  get the ambiguous interpretations. * *  Nodes in the returned ambig trees are independent of the original parse *  tree (constructed while identifying/creating ambiguityInfo). * *  @since 4.5.1 * *  @param g              From which grammar should we drive alternative *                        numbers and alternative labels. * *  @param originalParser The parser used to create ambiguityInfo; it *                        is not modified by this routine and can be either *                        a generated or interpreted parser. It's token *                        stream *is* reset/seek()'d. *  @param tokens		  A stream of tokens to use with the temporary parser. *                        This will often be just the token stream within the *                        original parser but here it is for flexibility. * *  @param decision       Which decision to try different alternatives for. * *  @param alts           The set of alternatives to try while re-parsing. * *  @param startIndex	  The index of the first token of the ambiguous *                        input or other input of interest. * *  @param stopIndex      The index of the last token of the ambiguous input. *                        The start and stop indexes are used primarily to *                        identify how much of the resulting parse tree *                        to return. * *  @param startRuleIndex The start rule for the entire grammar, not *                        the ambiguous decision. We re-parse the entire input *                        and so we need the original start rule. * *  @return               The list of all possible interpretations of *                        the input for the decision in ambiguityInfo. *                        The actual interpretation chosen by the parser *                        is always given first because this method *                        retests the input in alternative order and *                        ANTLR always resolves ambiguities by choosing *                        the first alternative that matches the input. *                        The subtree returned * *  @throws RecognitionException Throws upon syntax error while matching *                               ambig input. */[[SEP]]// Create a new parser interpreter to parse the ambiguous subphrase[[SEP]]// if we are pointing at EOF token// EOF is not in tree, so must be 1 less than last non-EOF token[[SEP]]// get ambig trees[[SEP]]// re-parse entire input for all ambiguous alternatives// (don't have to do first as it's been parsed, but do again for simplicity// using this temp parser.)[[SEP]]// Use higher of overridden decision tree or tree enclosing all tokens",272,310,[0],0,"[0, 0, 0, 0, 0, 0, 0, 0]",0,"[0, 0, 0, 0, 0, 0]",0,0,0,1,"getAllPossibleParseTrees(Grammar, Parser, TokenStream, int, BitSet, int, int, int)",org.antlr.v4.tool.GrammarParserInterpreter,"getAllPossibleParseTrees/8[org.antlr.v4.tool.Grammar,org.antlr.v4.tool.Parser,org.antlr.v4.tool.TokenStream,int,java.util.BitSet,int,int,int]",False,280,7,2,1,1,4,10,20,1,5,8,10,1,1,1,0,0,1,0,5,8,3,2,0,0,0,200,9,0,True
1249,..\projects\antlr4-4.11.0\tool\src\org\antlr\v4\tool\GrammarParserInterpreter.java,org.antlr.v4.tool.GrammarParserInterpreter,"List<ParserRuleContext> getLookaheadParseTrees(Grammar, ParserInterpreter, TokenStream, int, int, int, int)","/**
 *  Return a list of parse trees, one for each alternative in a decision
 *   given the same input.
 *
 *   Very similar to {@link #getAllPossibleParseTrees} except
 *   that it re-parses the input for every alternative in a decision,
 *   not just the ambiguous ones (there is no alts parameter here).
 *   This method also tries to reduce the size of the parse trees
 *   by stripping away children of the tree that are completely out of range
 *   of startIndex..stopIndex. Also, because errors are expected, we
 *   use a specialized error handler that more or less bails out
 *   but that also consumes the first erroneous token at least. This
 *   ensures that an error node will be in the parse tree for display.
 *
 *   NOTES:
 *     // we must parse the entire input now with decision overrides
 * 	// we cannot parse a subset because it could be that a decision
 * 	// above our decision of interest needs to read way past
 * 	// lookaheadInfo.stopIndex. It seems like there is no escaping
 * 	// the use of a full and complete token stream if we are
 * 	// resetting to token index 0 and re-parsing from the start symbol.
 * 	// It's not easy to restart parsing somewhere in the middle like a
 * 	// continuation because our call stack does not match the
 * 	// tree stack because of left recursive rule rewriting. grrrr!
 *
 *  @since 4.5.1
 */
public static List<ParserRuleContext> getLookaheadParseTrees(Grammar g, ParserInterpreter originalParser, TokenStream tokens, int startRuleIndex, int decision, int startIndex, int stopIndex) {
    List<ParserRuleContext> trees = new ArrayList<ParserRuleContext>();
    // Create a new parser interpreter to parse the ambiguous subphrase
    ParserInterpreter parser = deriveTempParserInterpreter(g, originalParser, tokens);
    DecisionState decisionState = originalParser.getATN().decisionToState.get(decision);
    for (int alt = 1; alt <= decisionState.getTransitions().length; alt++) {
        // re-parse entire input for all ambiguous alternatives
        // (don't have to do first as it's been parsed, but do again for simplicity
        // using this temp parser.)
        GrammarParserInterpreter.BailButConsumeErrorStrategy errorHandler = new GrammarParserInterpreter.BailButConsumeErrorStrategy();
        parser.setErrorHandler(errorHandler);
        parser.reset();
        parser.addDecisionOverride(decision, startIndex, alt);
        ParserRuleContext tt = parser.parse(startRuleIndex);
        int stopTreeAt = stopIndex;
        if (errorHandler.firstErrorTokenIndex >= 0) {
            // cut off rest at first error
            stopTreeAt = errorHandler.firstErrorTokenIndex;
        }
        Interval overallRange = tt.getSourceInterval();
        if (stopTreeAt > overallRange.b) {
            // If we try to look beyond range of tree, stopTreeAt must be EOF
            // for which there is no EOF ref in grammar. That means tree
            // will not have node for stopTreeAt; limit to overallRange.b
            stopTreeAt = overallRange.b;
        }
        ParserRuleContext subtree = Trees.getRootOfSubtreeEnclosingRegion(tt, startIndex, stopTreeAt);
        // Use higher of overridden decision tree or tree enclosing all tokens
        if (Trees.isAncestorOf(parser.getOverrideDecisionRoot(), subtree)) {
            subtree = parser.getOverrideDecisionRoot();
        }
        Trees.stripChildrenOutOfRange(subtree, parser.getOverrideDecisionRoot(), startIndex, stopTreeAt);
        trees.add(subtree);
    }
    return trees;
}","/**
 *  Return a list of parse trees, one for each alternative in a decision
 *   given the same input.
 *
 *   Very similar to {@link #getAllPossibleParseTrees} except
 *   that it re-parses the input for every alternative in a decision,
 *   not just the ambiguous ones (there is no alts parameter here).
 *   This method also tries to reduce the size of the parse trees
 *   by stripping away children of the tree that are completely out of range
 *   of startIndex..stopIndex. Also, because errors are expected, we
 *   use a specialized error handler that more or less bails out
 *   but that also consumes the first erroneous token at least. This
 *   ensures that an error node will be in the parse tree for display.
 *
 *   NOTES:
 *     // we must parse the entire input now with decision overrides
 * 	// we cannot parse a subset because it could be that a decision
 * 	// above our decision of interest needs to read way past
 * 	// lookaheadInfo.stopIndex. It seems like there is no escaping
 * 	// the use of a full and complete token stream if we are
 * 	// resetting to token index 0 and re-parsing from the start symbol.
 * 	// It's not easy to restart parsing somewhere in the middle like a
 * 	// continuation because our call stack does not match the
 * 	// tree stack because of left recursive rule rewriting. grrrr!
 *
 *  @since 4.5.1
 */
","// Create a new parser interpreter to parse the ambiguous subphrase
[[SEP]]// re-parse entire input for all ambiguous alternatives
[[SEP]]// (don't have to do first as it's been parsed, but do again for simplicity
[[SEP]]// using this temp parser.)
[[SEP]]// cut off rest at first error
[[SEP]]// If we try to look beyond range of tree, stopTreeAt must be EOF
[[SEP]]// for which there is no EOF ref in grammar. That means tree
[[SEP]]// will not have node for stopTreeAt; limit to overallRange.b
[[SEP]]// Use higher of overridden decision tree or tree enclosing all tokens
","/** *  Return a list of parse trees, one for each alternative in a decision *   given the same input. * *   Very similar to {@link #getAllPossibleParseTrees} except *   that it re-parses the input for every alternative in a decision, *   not just the ambiguous ones (there is no alts parameter here). *   This method also tries to reduce the size of the parse trees *   by stripping away children of the tree that are completely out of range *   of startIndex..stopIndex. Also, because errors are expected, we *   use a specialized error handler that more or less bails out *   but that also consumes the first erroneous token at least. This *   ensures that an error node will be in the parse tree for display. * *   NOTES: *     // we must parse the entire input now with decision overrides * 	// we cannot parse a subset because it could be that a decision * 	// above our decision of interest needs to read way past * 	// lookaheadInfo.stopIndex. It seems like there is no escaping * 	// the use of a full and complete token stream if we are * 	// resetting to token index 0 and re-parsing from the start symbol. * 	// It's not easy to restart parsing somewhere in the middle like a * 	// continuation because our call stack does not match the * 	// tree stack because of left recursive rule rewriting. grrrr! * *  @since 4.5.1 */[[SEP]]// Create a new parser interpreter to parse the ambiguous subphrase[[SEP]]// re-parse entire input for all ambiguous alternatives// (don't have to do first as it's been parsed, but do again for simplicity// using this temp parser.)[[SEP]]// cut off rest at first error[[SEP]]// If we try to look beyond range of tree, stopTreeAt must be EOF// for which there is no EOF ref in grammar. That means tree// will not have node for stopTreeAt; limit to overallRange.b[[SEP]]// Use higher of overridden decision tree or tree enclosing all tokens",338,385,[0],0,"[0, 0, 0, 0, 0, 0, 0, 0, 0]",0,"[0, 0, 0, 0, 0, 0]",0,0,0,1,"getLookaheadParseTrees(Grammar, ParserInterpreter, TokenStream, int, int, int, int)",org.antlr.v4.tool.GrammarParserInterpreter,"getLookaheadParseTrees/7[org.antlr.v4.tool.Grammar,org.antlr.v4.tool.ParserInterpreter,org.antlr.v4.tool.TokenStream,int,int,int,int]",False,344,8,3,1,2,5,14,27,1,9,7,14,1,1,1,0,0,0,0,2,12,0,2,0,0,0,137,9,0,True
1250,..\projects\antlr4-4.11.0\tool\src\org\antlr\v4\tool\GrammarParserInterpreter.java,org.antlr.v4.tool.GrammarParserInterpreter,"ParserInterpreter deriveTempParserInterpreter(Grammar, Parser, TokenStream)","/**
 * Derive a new parser from an old one that has knowledge of the grammar.
 *  The Grammar object is used to correctly compute outer alternative
 *  numbers for parse tree nodes. A parser of the same type is created
 *  for subclasses of {@link ParserInterpreter}.
 */
public static ParserInterpreter deriveTempParserInterpreter(Grammar g, Parser originalParser, TokenStream tokens) {
    ParserInterpreter parser;
    if (originalParser instanceof ParserInterpreter) {
        Class<? extends ParserInterpreter> c = originalParser.getClass().asSubclass(ParserInterpreter.class);
        try {
            Constructor<? extends ParserInterpreter> ctor = c.getConstructor(Grammar.class, ATN.class, TokenStream.class);
            parser = ctor.newInstance(g, originalParser.getATN(), originalParser.getTokenStream());
        } catch (Exception e) {
            throw new IllegalArgumentException(""can't create parser to match incoming "" + originalParser.getClass().getSimpleName(), e);
        }
    } else {
        // must've been a generated parser
        // IntegerList serialized = ATNSerializer.getSerialized(originalParser.getATN(), g.getLanguage());
        // ATN deserialized = new ATNDeserializer().deserialize(serialized.toArray());
        parser = new ParserInterpreter(originalParser.getGrammarFileName(), originalParser.getVocabulary(), Arrays.asList(originalParser.getRuleNames()), originalParser.getATN(), tokens);
    }
    parser.setInputStream(tokens);
    // Make sure that we don't get any error messages from using this temporary parser
    parser.setErrorHandler(new BailErrorStrategy());
    parser.removeErrorListeners();
    parser.removeParseListeners();
    parser.getInterpreter().setPredictionMode(PredictionMode.LL_EXACT_AMBIG_DETECTION);
    return parser;
}","/**
 * Derive a new parser from an old one that has knowledge of the grammar.
 *  The Grammar object is used to correctly compute outer alternative
 *  numbers for parse tree nodes. A parser of the same type is created
 *  for subclasses of {@link ParserInterpreter}.
 */
","// must've been a generated parser
[[SEP]]// IntegerList serialized = ATNSerializer.getSerialized(originalParser.getATN(), g.getLanguage());
[[SEP]]// ATN deserialized = new ATNDeserializer().deserialize(serialized.toArray());
[[SEP]]// Make sure that we don't get any error messages from using this temporary parser
","/** * Derive a new parser from an old one that has knowledge of the grammar. *  The Grammar object is used to correctly compute outer alternative *  numbers for parse tree nodes. A parser of the same type is created *  for subclasses of {@link ParserInterpreter}. */[[SEP]]// must've been a generated parser// IntegerList serialized = ATNSerializer.getSerialized(originalParser.getATN(), g.getLanguage());// ATN deserialized = new ATNDeserializer().deserialize(serialized.toArray());[[SEP]]// Make sure that we don't get any error messages from using this temporary parser",392,422,[0],0,"[0, 0, 0, 0]",0,"[0, 0, 0]",0,0,0,0,"deriveTempParserInterpreter(Grammar, Parser, TokenStream)",org.antlr.v4.tool.GrammarParserInterpreter,"deriveTempParserInterpreter/3[org.antlr.v4.tool.Grammar,org.antlr.v4.tool.Parser,org.antlr.v4.tool.TokenStream]",False,392,6,2,2,0,3,17,22,1,3,3,17,0,0,0,0,1,0,1,0,4,1,2,0,0,0,48,9,0,True
1251,..\projects\antlr4-4.11.0\tool\src\org\antlr\v4\tool\GrammarParserInterpreter.java,org.antlr.v4.tool.GrammarParserInterpreter.BailButConsumeErrorStrategy,"void recover(Parser, RecognitionException)","@Override
public void recover(Parser recognizer, RecognitionException e) {
    int errIndex = recognizer.getInputStream().index();
    if (firstErrorTokenIndex == -1) {
        // latch
        firstErrorTokenIndex = errIndex;
    }
    // System.err.println(""recover: error at "" + errIndex);
    TokenStream input = recognizer.getInputStream();
    if (input.index() < input.size() - 1) {
        // don't consume() eof
        // just kill this bad token and let it continue.
        recognizer.consume();
    }
}", ,"// latch
[[SEP]]// System.err.println(""recover: error at "" + errIndex);
[[SEP]]// don't consume() eof
[[SEP]]// just kill this bad token and let it continue.
","// latch[[SEP]]// System.err.println(""recover: error at "" + errIndex);[[SEP]]// don't consume() eof// just kill this bad token and let it continue.",433,444,[0],0,"[0, 0, 0, 0]",0,"[0, 0, 0]",0,0,1,0,"recover(Parser, RecognitionException)",org.antlr.v4.tool.GrammarParserInterpreter$BailButConsumeErrorStrategy,"recover/2[org.antlr.v4.tool.Parser,org.antlr.v4.tool.RecognitionException]",False,434,3,0,0,0,3,4,10,0,2,2,4,0,0,0,1,0,0,0,2,3,1,1,0,0,0,10,1,0,False
1252,..\projects\antlr4-4.11.0\tool\src\org\antlr\v4\tool\GrammarParserInterpreter.java,org.antlr.v4.tool.GrammarParserInterpreter.BailButConsumeErrorStrategy,Token recoverInline(Parser),"@Override
public Token recoverInline(Parser recognizer) throws RecognitionException {
    int errIndex = recognizer.getInputStream().index();
    if (firstErrorTokenIndex == -1) {
        // latch
        firstErrorTokenIndex = errIndex;
    }
    // System.err.println(""recoverInline: error at "" + errIndex);
    InputMismatchException e = new InputMismatchException(recognizer);
    // TokenStream input = recognizer.getInputStream(); // seek EOF
    // input.seek(input.size() - 1);
    throw e;
}", ,"// TokenStream input = recognizer.getInputStream(); // seek EOF
[[SEP]]// latch
[[SEP]]// System.err.println(""recoverInline: error at "" + errIndex);
[[SEP]]// input.seek(input.size() - 1);
","// latch[[SEP]]// System.err.println(""recoverInline: error at "" + errIndex);[[SEP]]// TokenStream input = recognizer.getInputStream(); // seek EOF// input.seek(input.size() - 1);",446,457,[0],0,"[0, 0, 0, 0]",0,"[0, 0, 0]",0,0,0,0,recoverInline(Parser),org.antlr.v4.tool.GrammarParserInterpreter$BailButConsumeErrorStrategy,recoverInline/1[org.antlr.v4.tool.Parser],False,447,3,0,0,0,2,2,8,0,2,1,2,0,0,0,1,0,0,0,1,3,0,1,0,0,0,14,1,0,False
1253,..\projects\antlr4-4.11.0\tool\src\org\antlr\v4\tool\GrammarParserInterpreter.java,org.antlr.v4.tool.GrammarParserInterpreter.BailButConsumeErrorStrategy,void sync(Parser),"@Override
public void sync(Parser recognizer) // don't consume anything; let it fail later
{
}", ,"// don't consume anything; let it fail later
",// don't consume anything; let it fail later,459,460,[0],0,[0],0,[0],0,0,0,0,sync(Parser),org.antlr.v4.tool.GrammarParserInterpreter$BailButConsumeErrorStrategy,sync/1[org.antlr.v4.tool.Parser],False,460,1,0,0,0,1,0,2,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,3,1,0,False
1254,..\projects\antlr4-4.11.0\tool\src\org\antlr\v4\tool\GrammarTransformPipeline.java,org.antlr.v4.tool.GrammarTransformPipeline,void expandParameterizedLoops(GrammarAST),"/**
 * Find and replace
 *      ID*[','] with ID (',' ID)*
 *      ID+[','] with ID (',' ID)+
 *      (x {action} y)+[','] with x {action} y (',' x {action} y)+
 *
 *  Parameter must be a token.
 *  todo: do we want?
 */
public void expandParameterizedLoops(GrammarAST root) {
    TreeVisitor v = new TreeVisitor(new GrammarASTAdaptor());
    v.visit(root, new TreeVisitorAction() {

        @Override
        public Object pre(Object t) {
            if (((GrammarAST) t).getType() == 3) {
                return expandParameterizedLoop((GrammarAST) t);
            }
            return t;
        }

        @Override
        public Object post(Object t) {
            return t;
        }
    });
}","/**
 * Find and replace
 *      ID*[','] with ID (',' ID)*
 *      ID+[','] with ID (',' ID)+
 *      (x {action} y)+[','] with x {action} y (',' x {action} y)+
 *
 *  Parameter must be a token.
 *  todo: do we want?
 */
", ,"/** * Find and replace *      ID*[','] with ID (',' ID)* *      ID+[','] with ID (',' ID)+ *      (x {action} y)+[','] with x {action} y (',' x {action} y)+ * *  Parameter must be a token. *  todo: do we want? */",76,89,[1],1,[0],0,[1],1,1,1,1,expandParameterizedLoops(GrammarAST),org.antlr.v4.tool.GrammarTransformPipeline,expandParameterizedLoops/1[org.antlr.v4.tool.ast.GrammarAST],False,76,4,2,1,1,1,1,15,0,1,1,1,0,0,0,0,0,0,0,0,1,0,0,1,0,0,32,1,0,True
1255,..\projects\antlr4-4.11.0\tool\src\org\antlr\v4\tool\GrammarTransformPipeline.java,org.antlr.v4.tool.GrammarTransformPipeline,GrammarAST expandParameterizedLoop(GrammarAST),"public GrammarAST expandParameterizedLoop(GrammarAST t) {
    // todo: update grammar, alter AST
    return t;
}", ,"// todo: update grammar, alter AST
","// todo: update grammar, alter AST",91,94,[0],0,[1],1,[1],1,1,0,1,expandParameterizedLoop(GrammarAST),org.antlr.v4.tool.GrammarTransformPipeline,expandParameterizedLoop/1[org.antlr.v4.tool.ast.GrammarAST],False,91,1,1,1,0,1,0,3,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,8,1,0,False
1256,..\projects\antlr4-4.11.0\tool\src\org\antlr\v4\tool\GrammarTransformPipeline.java,org.antlr.v4.tool.GrammarTransformPipeline,"void setGrammarPtr(Grammar, GrammarAST)","/**
 * Utility visitor that sets grammar ptr in each node
 */
public static void setGrammarPtr(final Grammar g, GrammarAST tree) {
    if (tree == null)
        return;
    // ensure each node has pointer to surrounding grammar
    TreeVisitor v = new TreeVisitor(new GrammarASTAdaptor());
    v.visit(tree, new TreeVisitorAction() {

        @Override
        public Object pre(Object t) {
            ((GrammarAST) t).g = g;
            return t;
        }

        @Override
        public Object post(Object t) {
            return t;
        }
    });
}","/**
 * Utility visitor that sets grammar ptr in each node
 */
","// ensure each node has pointer to surrounding grammar
",/** * Utility visitor that sets grammar ptr in each node */[[SEP]]// ensure each node has pointer to surrounding grammar,97,107,[0],0,[0],0,"[0, 0]",0,0,0,0,"setGrammarPtr(Grammar, GrammarAST)",org.antlr.v4.tool.GrammarTransformPipeline,"setGrammarPtr/2[org.antlr.v4.tool.Grammar,org.antlr.v4.tool.ast.GrammarAST]",False,97,5,2,1,1,2,1,14,1,1,2,1,0,0,0,1,0,0,0,0,1,0,1,1,0,0,27,9,0,True
1257,..\projects\antlr4-4.11.0\tool\src\org\antlr\v4\tool\GrammarTransformPipeline.java,org.antlr.v4.tool.GrammarTransformPipeline,"void augmentTokensWithOriginalPosition(Grammar, GrammarAST)","public static void augmentTokensWithOriginalPosition(final Grammar g, GrammarAST tree) {
    if (tree == null)
        return;
    List<GrammarAST> optionsSubTrees = tree.getNodesWithType(ANTLRParser.ELEMENT_OPTIONS);
    for (int i = 0; i < optionsSubTrees.size(); i++) {
        GrammarAST t = optionsSubTrees.get(i);
        CommonTree elWithOpt = t.parent;
        if (elWithOpt instanceof GrammarASTWithOptions) {
            Map<String, GrammarAST> options = ((GrammarASTWithOptions) elWithOpt).getOptions();
            if (options.containsKey(LeftRecursiveRuleTransformer.TOKENINDEX_OPTION_NAME)) {
                GrammarToken newTok = new GrammarToken(g, elWithOpt.getToken());
                newTok.originalTokenIndex = Integer.valueOf(options.get(LeftRecursiveRuleTransformer.TOKENINDEX_OPTION_NAME).getText());
                elWithOpt.token = newTok;
                GrammarAST originalNode = g.ast.getNodeWithTokenIndex(newTok.getTokenIndex());
                if (originalNode != null) {
                    // update the AST node start/stop index to match the values
                    // of the corresponding node in the original parse tree.
                    elWithOpt.setTokenStartIndex(originalNode.getTokenStartIndex());
                    elWithOpt.setTokenStopIndex(originalNode.getTokenStopIndex());
                } else {
                    // the original AST node could not be located by index;
                    // make sure to assign valid values for the start/stop
                    // index so toTokenString will not throw exceptions.
                    elWithOpt.setTokenStartIndex(newTok.getTokenIndex());
                    elWithOpt.setTokenStopIndex(newTok.getTokenIndex());
                }
            }
        }
    }
}", ,"// update the AST node start/stop index to match the values
[[SEP]]// of the corresponding node in the original parse tree.
[[SEP]]// the original AST node could not be located by index;
[[SEP]]// make sure to assign valid values for the start/stop
[[SEP]]// index so toTokenString will not throw exceptions.
",// update the AST node start/stop index to match the values// of the corresponding node in the original parse tree.[[SEP]]// the original AST node could not be located by index;// make sure to assign valid values for the start/stop// index so toTokenString will not throw exceptions.,109,140,[0],0,"[0, 0, 0, 0, 0]",0,"[0, 0]",0,0,0,0,"augmentTokensWithOriginalPosition(Grammar, GrammarAST)",org.antlr.v4.tool.GrammarTransformPipeline,"augmentTokensWithOriginalPosition/2[org.antlr.v4.tool.Grammar,org.antlr.v4.tool.ast.GrammarAST]",False,109,5,5,0,5,6,15,25,1,7,2,15,0,0,1,2,0,1,0,1,9,0,4,0,0,0,26,9,0,False
1258,..\projects\antlr4-4.11.0\tool\src\org\antlr\v4\tool\GrammarTransformPipeline.java,org.antlr.v4.tool.GrammarTransformPipeline,void integrateImportedGrammars(Grammar),"/**
 *  Merge all the rules, token definitions, and named actions from
 * 		imported grammars into the root grammar tree.  Perform:
 *
 * 	 	(tokens { X (= Y 'y')) + (tokens { Z )	-&gt;	(tokens { X (= Y 'y') Z)
 *
 * 	 	(@ members {foo}) + (@ members {bar})	-&gt;	(@ members {foobar})
 *
 * 	 	(RULES (RULE x y)) + (RULES (RULE z))	-&gt;	(RULES (RULE x y z))
 *
 * 	 	Rules in root prevent same rule from being appended to RULES node.
 *
 * 	 	The goal is a complete combined grammar so we can ignore subordinate
 * 	 	grammars.
 */
public void integrateImportedGrammars(Grammar rootGrammar) {
    List<Grammar> imports = rootGrammar.getAllImportedGrammars();
    if (imports == null)
        return;
    GrammarAST root = rootGrammar.ast;
    GrammarAST id = (GrammarAST) root.getChild(0);
    GrammarASTAdaptor adaptor = new GrammarASTAdaptor(id.token.getInputStream());
    GrammarAST channelsRoot = (GrammarAST) root.getFirstChildWithType(ANTLRParser.CHANNELS);
    GrammarAST tokensRoot = (GrammarAST) root.getFirstChildWithType(ANTLRParser.TOKENS_SPEC);
    List<GrammarAST> actionRoots = root.getNodesWithType(ANTLRParser.AT);
    // Compute list of rules in root grammar and ensure we have a RULES node
    GrammarAST RULES = (GrammarAST) root.getFirstChildWithType(ANTLRParser.RULES);
    Set<String> rootRuleNames = new HashSet<String>();
    // make list of rules we have in root grammar
    List<GrammarAST> rootRules = RULES.getNodesWithType(ANTLRParser.RULE);
    for (GrammarAST r : rootRules) rootRuleNames.add(r.getChild(0).getText());
    // make list of modes we have in root grammar
    List<GrammarAST> rootModes = root.getNodesWithType(ANTLRParser.MODE);
    Set<String> rootModeNames = new HashSet<String>();
    for (GrammarAST m : rootModes) rootModeNames.add(m.getChild(0).getText());
    List<GrammarAST> addedModes = new ArrayList<GrammarAST>();
    for (Grammar imp : imports) {
        // COPY CHANNELS
        GrammarAST imp_channelRoot = (GrammarAST) imp.ast.getFirstChildWithType(ANTLRParser.CHANNELS);
        if (imp_channelRoot != null) {
            rootGrammar.tool.log(""grammar"", ""imported channels: "" + imp_channelRoot.getChildren());
            if (channelsRoot == null) {
                channelsRoot = imp_channelRoot.dupTree();
                channelsRoot.g = rootGrammar;
                // ^(GRAMMAR ID TOKENS...)
                root.insertChild(1, channelsRoot);
            } else {
                for (int c = 0; c < imp_channelRoot.getChildCount(); ++c) {
                    String channel = imp_channelRoot.getChild(c).getText();
                    boolean channelIsInRootGrammar = false;
                    for (int rc = 0; rc < channelsRoot.getChildCount(); ++rc) {
                        String rootChannel = channelsRoot.getChild(rc).getText();
                        if (rootChannel.equals(channel)) {
                            channelIsInRootGrammar = true;
                            break;
                        }
                    }
                    if (!channelIsInRootGrammar) {
                        channelsRoot.addChild(imp_channelRoot.getChild(c).dupNode());
                    }
                }
            }
        }
        // COPY TOKENS
        GrammarAST imp_tokensRoot = (GrammarAST) imp.ast.getFirstChildWithType(ANTLRParser.TOKENS_SPEC);
        if (imp_tokensRoot != null) {
            rootGrammar.tool.log(""grammar"", ""imported tokens: "" + imp_tokensRoot.getChildren());
            if (tokensRoot == null) {
                tokensRoot = (GrammarAST) adaptor.create(ANTLRParser.TOKENS_SPEC, ""TOKENS"");
                tokensRoot.g = rootGrammar;
                // ^(GRAMMAR ID TOKENS...)
                root.insertChild(1, tokensRoot);
            }
            tokensRoot.addChildren(Arrays.asList(imp_tokensRoot.getChildren().toArray(new Tree[0])));
        }
        List<GrammarAST> all_actionRoots = new ArrayList<GrammarAST>();
        List<GrammarAST> imp_actionRoots = imp.ast.getAllChildrenWithType(ANTLRParser.AT);
        if (actionRoots != null)
            all_actionRoots.addAll(actionRoots);
        all_actionRoots.addAll(imp_actionRoots);
        // COPY ACTIONS
        if (imp_actionRoots != null) {
            DoubleKeyMap<String, String, GrammarAST> namedActions = new DoubleKeyMap<String, String, GrammarAST>();
            rootGrammar.tool.log(""grammar"", ""imported actions: "" + imp_actionRoots);
            for (GrammarAST at : all_actionRoots) {
                String scopeName = rootGrammar.getDefaultActionScope();
                GrammarAST scope, name, action;
                if (at.getChildCount() > 2) {
                    // must have a scope
                    scope = (GrammarAST) at.getChild(0);
                    scopeName = scope.getText();
                    name = (GrammarAST) at.getChild(1);
                    action = (GrammarAST) at.getChild(2);
                } else {
                    name = (GrammarAST) at.getChild(0);
                    action = (GrammarAST) at.getChild(1);
                }
                GrammarAST prevAction = namedActions.get(scopeName, name.getText());
                if (prevAction == null) {
                    namedActions.put(scopeName, name.getText(), action);
                } else {
                    if (prevAction.g == at.g) {
                        rootGrammar.tool.errMgr.grammarError(ErrorType.ACTION_REDEFINITION, at.g.fileName, name.token, name.getText());
                    } else {
                        String s1 = prevAction.getText();
                        s1 = s1.substring(1, s1.length() - 1);
                        String s2 = action.getText();
                        s2 = s2.substring(1, s2.length() - 1);
                        String combinedAction = ""{"" + s1 + '\n' + s2 + ""}"";
                        prevAction.token.setText(combinedAction);
                    }
                }
            }
            // at this point, we have complete list of combined actions,
            // some of which are already living in root grammar.
            // Merge in any actions not in root grammar into root's tree.
            for (String scopeName : namedActions.keySet()) {
                for (String name : namedActions.keySet(scopeName)) {
                    GrammarAST action = namedActions.get(scopeName, name);
                    rootGrammar.tool.log(""grammar"", action.g.name + "" "" + scopeName + "":"" + name + ""="" + action.getText());
                    if (action.g != rootGrammar) {
                        root.insertChild(1, action.getParent());
                    }
                }
            }
        }
        // COPY MODES
        // The strategy is to copy all the mode sections rules across to any
        // mode section in the new grammar with the same name or a new
        // mode section if no matching mode is resolved. Rules which are
        // already in the new grammar are ignored for copy. If the mode
        // section being added ends up empty it is not added to the merged
        // grammar.
        List<GrammarAST> modes = imp.ast.getNodesWithType(ANTLRParser.MODE);
        if (modes != null) {
            for (GrammarAST m : modes) {
                rootGrammar.tool.log(""grammar"", ""imported mode: "" + m.toStringTree());
                String name = m.getChild(0).getText();
                boolean rootAlreadyHasMode = rootModeNames.contains(name);
                GrammarAST destinationAST = null;
                if (rootAlreadyHasMode) {
                    for (GrammarAST m2 : rootModes) {
                        if (m2.getChild(0).getText().equals(name)) {
                            destinationAST = m2;
                            break;
                        }
                    }
                } else {
                    destinationAST = m.dupNode();
                    destinationAST.addChild(m.getChild(0).dupNode());
                }
                int addedRules = 0;
                List<GrammarAST> modeRules = m.getAllChildrenWithType(ANTLRParser.RULE);
                for (GrammarAST r : modeRules) {
                    rootGrammar.tool.log(""grammar"", ""imported rule: "" + r.toStringTree());
                    String ruleName = r.getChild(0).getText();
                    boolean rootAlreadyHasRule = rootRuleNames.contains(ruleName);
                    if (!rootAlreadyHasRule) {
                        destinationAST.addChild(r);
                        addedRules++;
                        rootRuleNames.add(ruleName);
                    }
                }
                if (!rootAlreadyHasMode && addedRules > 0) {
                    rootGrammar.ast.addChild(destinationAST);
                    rootModeNames.add(name);
                    rootModes.add(destinationAST);
                }
            }
        }
        // COPY RULES
        // Rules copied in the mode copy phase are not copied again.
        List<GrammarAST> rules = imp.ast.getNodesWithType(ANTLRParser.RULE);
        if (rules != null) {
            for (GrammarAST r : rules) {
                rootGrammar.tool.log(""grammar"", ""imported rule: "" + r.toStringTree());
                String name = r.getChild(0).getText();
                boolean rootAlreadyHasRule = rootRuleNames.contains(name);
                if (!rootAlreadyHasRule) {
                    // merge in if not overridden
                    RULES.addChild(r);
                    rootRuleNames.add(name);
                }
            }
        }
        GrammarAST optionsRoot = (GrammarAST) imp.ast.getFirstChildWithType(ANTLRParser.OPTIONS);
        if (optionsRoot != null) {
            // suppress the warning if the options match the options specified
            // in the root grammar
            // https://github.com/antlr/antlr4/issues/707
            boolean hasNewOption = false;
            for (Map.Entry<String, GrammarAST> option : imp.ast.getOptions().entrySet()) {
                String importOption = imp.ast.getOptionString(option.getKey());
                if (importOption == null) {
                    continue;
                }
                String rootOption = rootGrammar.ast.getOptionString(option.getKey());
                if (!importOption.equals(rootOption)) {
                    hasNewOption = true;
                    break;
                }
            }
            if (hasNewOption) {
                rootGrammar.tool.errMgr.grammarError(ErrorType.OPTIONS_IN_DELEGATE, optionsRoot.g.fileName, optionsRoot.token, imp.name);
            }
        }
    }
    rootGrammar.tool.log(""grammar"", ""Grammar: "" + rootGrammar.ast.toStringTree());
}","/**
 *  Merge all the rules, token definitions, and named actions from
 * 		imported grammars into the root grammar tree.  Perform:
 *
 * 	 	(tokens { X (= Y 'y')) + (tokens { Z )	-&gt;	(tokens { X (= Y 'y') Z)
 *
 * 	 	(@ members {foo}) + (@ members {bar})	-&gt;	(@ members {foobar})
 *
 * 	 	(RULES (RULE x y)) + (RULES (RULE z))	-&gt;	(RULES (RULE x y z))
 *
 * 	 	Rules in root prevent same rule from being appended to RULES node.
 *
 * 	 	The goal is a complete combined grammar so we can ignore subordinate
 * 	 	grammars.
 */
","// Compute list of rules in root grammar and ensure we have a RULES node
[[SEP]]// make list of rules we have in root grammar
[[SEP]]// make list of modes we have in root grammar
[[SEP]]// COPY MODES
[[SEP]]// The strategy is to copy all the mode sections rules across to any
[[SEP]]// mode section in the new grammar with the same name or a new
[[SEP]]// mode section if no matching mode is resolved. Rules which are
[[SEP]]// already in the new grammar are ignored for copy. If the mode
[[SEP]]// section being added ends up empty it is not added to the merged
[[SEP]]// COPY RULES
[[SEP]]// COPY CHANNELS
[[SEP]]// ^(GRAMMAR ID TOKENS...)
[[SEP]]// COPY TOKENS
[[SEP]]// ^(GRAMMAR ID TOKENS...)
[[SEP]]// COPY ACTIONS
[[SEP]]// at this point, we have complete list of combined actions,
[[SEP]]// some of which are already living in root grammar.
[[SEP]]// must have a scope
[[SEP]]// Merge in any actions not in root grammar into root's tree.
[[SEP]]// grammar.
[[SEP]]// Rules copied in the mode copy phase are not copied again.
[[SEP]]// merge in if not overridden
[[SEP]]// suppress the warning if the options match the options specified
[[SEP]]// in the root grammar
[[SEP]]// https://github.com/antlr/antlr4/issues/707
","/** *  Merge all the rules, token definitions, and named actions from * 		imported grammars into the root grammar tree.  Perform: * * 	 	(tokens { X (= Y 'y')) + (tokens { Z )	-&gt;	(tokens { X (= Y 'y') Z) * * 	 	(@ members {foo}) + (@ members {bar})	-&gt;	(@ members {foobar}) * * 	 	(RULES (RULE x y)) + (RULES (RULE z))	-&gt;	(RULES (RULE x y z)) * * 	 	Rules in root prevent same rule from being appended to RULES node. * * 	 	The goal is a complete combined grammar so we can ignore subordinate * 	 	grammars. */[[SEP]]// Compute list of rules in root grammar and ensure we have a RULES node[[SEP]]// make list of rules we have in root grammar[[SEP]]// make list of modes we have in root grammar[[SEP]]// COPY CHANNELS[[SEP]]// ^(GRAMMAR ID TOKENS...)[[SEP]]// COPY TOKENS[[SEP]]// ^(GRAMMAR ID TOKENS...)[[SEP]]// COPY ACTIONS[[SEP]]// must have a scope[[SEP]]// at this point, we have complete list of combined actions,// some of which are already living in root grammar.// Merge in any actions not in root grammar into root's tree.[[SEP]]// COPY MODES// The strategy is to copy all the mode sections rules across to any// mode section in the new grammar with the same name or a new// mode section if no matching mode is resolved. Rules which are// already in the new grammar are ignored for copy. If the mode// section being added ends up empty it is not added to the merged// grammar.[[SEP]]// COPY RULES// Rules copied in the mode copy phase are not copied again.[[SEP]]// merge in if not overridden[[SEP]]// suppress the warning if the options match the options specified// in the root grammar// https://github.com/antlr/antlr4/issues/707",156,366,[0],0,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]",0,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]",0,0,0,0,integrateImportedGrammars(Grammar),org.antlr.v4.tool.GrammarTransformPipeline,integrateImportedGrammars/1[org.antlr.v4.tool.Grammar],False,156,9,13,1,12,39,39,172,1,47,1,39,0,0,13,14,0,0,21,26,60,11,6,0,0,0,102,1,0,True
1259,..\projects\antlr4-4.11.0\tool\src\org\antlr\v4\tool\GrammarTransformPipeline.java,org.antlr.v4.tool.GrammarTransformPipeline,GrammarRootAST extractImplicitLexer(Grammar),"/**
 * Build lexer grammar from combined grammar that looks like:
 *
 *  (COMBINED_GRAMMAR A
 *      (tokens { X (= Y 'y'))
 *      (OPTIONS (= x 'y'))
 *      (@ members {foo})
 *      (@ lexer header {package jj;})
 *      (RULES (RULE .+)))
 *
 *  Move rules and actions to new tree, don't dup. Split AST apart.
 *  We'll have this Grammar share token symbols later; don't generate
 *  tokenVocab or tokens{} section.  Copy over named actions.
 *
 *  Side-effects: it removes children from GRAMMAR &amp; RULES nodes
 *                in combined AST.  Anything cut out is dup'd before
 *                adding to lexer to avoid ""who's ur daddy"" issues
 */
public GrammarRootAST extractImplicitLexer(Grammar combinedGrammar) {
    GrammarRootAST combinedAST = combinedGrammar.ast;
    // tool.log(""grammar"", ""before=""+combinedAST.toStringTree());
    GrammarASTAdaptor adaptor = new GrammarASTAdaptor(combinedAST.token.getInputStream());
    GrammarAST[] elements = combinedAST.getChildren().toArray(new GrammarAST[0]);
    // MAKE A GRAMMAR ROOT and ID
    String lexerName = combinedAST.getChild(0).getText() + ""Lexer"";
    GrammarRootAST lexerAST = new GrammarRootAST(new CommonToken(ANTLRParser.GRAMMAR, ""LEXER_GRAMMAR""), combinedGrammar.ast.tokenStream);
    lexerAST.grammarType = ANTLRParser.LEXER;
    lexerAST.token.setInputStream(combinedAST.token.getInputStream());
    lexerAST.addChild((GrammarAST) adaptor.create(ANTLRParser.ID, lexerName));
    // COPY OPTIONS
    GrammarAST optionsRoot = (GrammarAST) combinedAST.getFirstChildWithType(ANTLRParser.OPTIONS);
    if (optionsRoot != null && optionsRoot.getChildCount() != 0) {
        GrammarAST lexerOptionsRoot = (GrammarAST) adaptor.dupNode(optionsRoot);
        lexerAST.addChild(lexerOptionsRoot);
        GrammarAST[] options = optionsRoot.getChildren().toArray(new GrammarAST[0]);
        for (GrammarAST o : options) {
            String optionName = o.getChild(0).getText();
            if (Grammar.lexerOptions.contains(optionName) && !Grammar.doNotCopyOptionsToLexer.contains(optionName)) {
                GrammarAST optionTree = (GrammarAST) adaptor.dupTree(o);
                lexerOptionsRoot.addChild(optionTree);
                lexerAST.setOption(optionName, (GrammarAST) optionTree.getChild(1));
            }
        }
    }
    // COPY all named actions, but only move those with lexer:: scope
    List<GrammarAST> actionsWeMoved = new ArrayList<GrammarAST>();
    for (GrammarAST e : elements) {
        if (e.getType() == ANTLRParser.AT) {
            lexerAST.addChild((Tree) adaptor.dupTree(e));
            if (e.getChild(0).getText().equals(""lexer"")) {
                actionsWeMoved.add(e);
            }
        }
    }
    for (GrammarAST r : actionsWeMoved) {
        combinedAST.deleteChild(r);
    }
    GrammarAST combinedRulesRoot = (GrammarAST) combinedAST.getFirstChildWithType(ANTLRParser.RULES);
    if (combinedRulesRoot == null)
        return lexerAST;
    // MOVE lexer rules
    GrammarAST lexerRulesRoot = (GrammarAST) adaptor.create(ANTLRParser.RULES, ""RULES"");
    lexerAST.addChild(lexerRulesRoot);
    List<GrammarAST> rulesWeMoved = new ArrayList<GrammarAST>();
    GrammarASTWithOptions[] rules;
    if (combinedRulesRoot.getChildCount() > 0) {
        rules = combinedRulesRoot.getChildren().toArray(new GrammarASTWithOptions[0]);
    } else {
        rules = new GrammarASTWithOptions[0];
    }
    for (GrammarASTWithOptions r : rules) {
        String ruleName = r.getChild(0).getText();
        if (Grammar.isTokenName(ruleName)) {
            lexerRulesRoot.addChild((Tree) adaptor.dupTree(r));
            rulesWeMoved.add(r);
        }
    }
    for (GrammarAST r : rulesWeMoved) {
        combinedRulesRoot.deleteChild(r);
    }
    // Will track 'if' from IF : 'if' ; rules to avoid defining new token for 'if'
    List<Pair<GrammarAST, GrammarAST>> litAliases = Grammar.getStringLiteralAliasesFromLexerRules(lexerAST);
    Set<String> stringLiterals = combinedGrammar.getStringLiterals();
    // add strings from combined grammar (and imported grammars) into lexer
    // put them first as they are keywords; must resolve ambigs to these rules
    // tool.log(""grammar"", ""strings from parser: ""+stringLiterals);
    int insertIndex = 0;
    nextLit: for (String lit : stringLiterals) {
        // if lexer already has a rule for literal, continue
        if (litAliases != null) {
            for (Pair<GrammarAST, GrammarAST> pair : litAliases) {
                GrammarAST litAST = pair.b;
                if (lit.equals(litAST.getText()))
                    continue nextLit;
            }
        }
        // create for each literal: (RULE <uniquename> (BLOCK (ALT <lit>))
        String rname = combinedGrammar.getStringLiteralLexerRuleName(lit);
        // can't use wizard; need special node types
        GrammarAST litRule = new RuleAST(ANTLRParser.RULE);
        BlockAST blk = new BlockAST(ANTLRParser.BLOCK);
        AltAST alt = new AltAST(ANTLRParser.ALT);
        TerminalAST slit = new TerminalAST(new CommonToken(ANTLRParser.STRING_LITERAL, lit));
        alt.addChild(slit);
        blk.addChild(alt);
        CommonToken idToken = new CommonToken(ANTLRParser.TOKEN_REF, rname);
        litRule.addChild(new TerminalAST(idToken));
        litRule.addChild(blk);
        lexerRulesRoot.insertChild(insertIndex, litRule);
        // lexerRulesRoot.getChildren().add(0, litRule);
        // reset indexes and set litRule parent
        lexerRulesRoot.freshenParentAndChildIndexes();
        // next literal will be added after the one just added
        insertIndex++;
    }
    // TODO: take out after stable if slow
    lexerAST.sanityCheckParentAndChildIndexes();
    combinedAST.sanityCheckParentAndChildIndexes();
    // tool.log(""grammar"", combinedAST.toTokenString());
    combinedGrammar.tool.log(""grammar"", ""after extract implicit lexer ="" + combinedAST.toStringTree());
    combinedGrammar.tool.log(""grammar"", ""lexer ="" + lexerAST.toStringTree());
    if (lexerRulesRoot.getChildCount() == 0)
        return null;
    return lexerAST;
}","/**
 * Build lexer grammar from combined grammar that looks like:
 *
 *  (COMBINED_GRAMMAR A
 *      (tokens { X (= Y 'y'))
 *      (OPTIONS (= x 'y'))
 *      (@ members {foo})
 *      (@ lexer header {package jj;})
 *      (RULES (RULE .+)))
 *
 *  Move rules and actions to new tree, don't dup. Split AST apart.
 *  We'll have this Grammar share token symbols later; don't generate
 *  tokenVocab or tokens{} section.  Copy over named actions.
 *
 *  Side-effects: it removes children from GRAMMAR &amp; RULES nodes
 *                in combined AST.  Anything cut out is dup'd before
 *                adding to lexer to avoid ""who's ur daddy"" issues
 */
","// MOVE lexer rules
[[SEP]]// add strings from combined grammar (and imported grammars) into lexer
[[SEP]]// put them first as they are keywords; must resolve ambigs to these rules
[[SEP]]// tool.log(""grammar"", combinedAST.toTokenString());
[[SEP]]// tool.log(""grammar"", ""before=""+combinedAST.toStringTree());
[[SEP]]// MAKE A GRAMMAR ROOT and ID
[[SEP]]// COPY OPTIONS
[[SEP]]// COPY all named actions, but only move those with lexer:: scope
[[SEP]]// Will track 'if' from IF : 'if' ; rules to avoid defining new token for 'if'
[[SEP]]// tool.log(""grammar"", ""strings from parser: ""+stringLiterals);
[[SEP]]// lexerRulesRoot.getChildren().add(0, litRule);
[[SEP]]// if lexer already has a rule for literal, continue
[[SEP]]// create for each literal: (RULE <uniquename> (BLOCK (ALT <lit>))
[[SEP]]// can't use wizard; need special node types
[[SEP]]// reset indexes and set litRule parent
[[SEP]]// next literal will be added after the one just added
[[SEP]]// TODO: take out after stable if slow
","/** * Build lexer grammar from combined grammar that looks like: * *  (COMBINED_GRAMMAR A *      (tokens { X (= Y 'y')) *      (OPTIONS (= x 'y')) *      (@ members {foo}) *      (@ lexer header {package jj;}) *      (RULES (RULE .+))) * *  Move rules and actions to new tree, don't dup. Split AST apart. *  We'll have this Grammar share token symbols later; don't generate *  tokenVocab or tokens{} section.  Copy over named actions. * *  Side-effects: it removes children from GRAMMAR &amp; RULES nodes *                in combined AST.  Anything cut out is dup'd before *                adding to lexer to avoid ""who's ur daddy"" issues */[[SEP]]// tool.log(""grammar"", ""before=""+combinedAST.toStringTree());[[SEP]]// MAKE A GRAMMAR ROOT and ID[[SEP]]// COPY OPTIONS[[SEP]]// COPY all named actions, but only move those with lexer:: scope[[SEP]]// MOVE lexer rules[[SEP]]// Will track 'if' from IF : 'if' ; rules to avoid defining new token for 'if'[[SEP]]// add strings from combined grammar (and imported grammars) into lexer// put them first as they are keywords; must resolve ambigs to these rules// tool.log(""grammar"", ""strings from parser: ""+stringLiterals);[[SEP]]// if lexer already has a rule for literal, continue[[SEP]]// create for each literal: (RULE <uniquename> (BLOCK (ALT <lit>))[[SEP]]// can't use wizard; need special node types[[SEP]]// lexerRulesRoot.getChildren().add(0, litRule);// reset indexes and set litRule parent[[SEP]]// next literal will be added after the one just added[[SEP]]// TODO: take out after stable if slow[[SEP]]// tool.log(""grammar"", combinedAST.toTokenString());",385,510,[0],0,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]",1,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0]",1,1,1,1,extractImplicitLexer(Grammar),org.antlr.v4.tool.GrammarTransformPipeline,extractImplicitLexer/1[org.antlr.v4.tool.Grammar],False,385,13,16,1,15,20,28,88,3,26,1,28,0,0,7,6,0,0,8,13,28,3,4,0,0,0,108,1,0,True
1260,..\projects\antlr4-4.11.0\tool\src\org\antlr\v4\tool\LeftRecursiveRule.java,org.antlr.v4.tool.LeftRecursiveRule,int[] getPrimaryAlts(),"/**
 *  Return an array that maps predicted alt from primary decision
 *   to original alt of rule. For following rule, return [0, 2, 4]
 *
 * 		e : e '*' e
 * 		  | INT
 * 		  | e '+' e
 * 		  | ID
 * 		  ;
 *
 *   That maps predicted alt 1 to original alt 2 and predicted 2 to alt 4.
 *
 *   @since 4.5.1
 */
public int[] getPrimaryAlts() {
    if (recPrimaryAlts.size() == 0)
        return null;
    int[] alts = new int[recPrimaryAlts.size() + 1];
    for (int i = 0; i < recPrimaryAlts.size(); i++) {
        // recPrimaryAlts is a List not Map like recOpAlts
        LeftRecursiveRuleAltInfo altInfo = recPrimaryAlts.get(i);
        alts[i + 1] = altInfo.altNum;
    }
    return alts;
}","/**
 *  Return an array that maps predicted alt from primary decision
 *   to original alt of rule. For following rule, return [0, 2, 4]
 *
 * 		e : e '*' e
 * 		  | INT
 * 		  | e '+' e
 * 		  | ID
 * 		  ;
 *
 *   That maps predicted alt 1 to original alt 2 and predicted 2 to alt 4.
 *
 *   @since 4.5.1
 */
","// recPrimaryAlts is a List not Map like recOpAlts
","/** *  Return an array that maps predicted alt from primary decision *   to original alt of rule. For following rule, return [0, 2, 4] * * 		e : e '*' e * 		  | INT * 		  | e '+' e * 		  | ID * 		  ; * *   That maps predicted alt 1 to original alt 2 and predicted 2 to alt 4. * *   @since 4.5.1 */[[SEP]]// recPrimaryAlts is a List not Map like recOpAlts",81,89,[0],0,[0],0,"[0, 0]",0,0,0,0,getPrimaryAlts(),org.antlr.v4.tool.LeftRecursiveRule,getPrimaryAlts/0,False,81,2,4,4,0,3,2,9,2,3,0,2,0,0,1,1,0,0,0,4,4,2,1,0,0,0,33,1,0,True
1261,..\projects\antlr4-4.11.0\tool\src\org\antlr\v4\tool\LeftRecursiveRule.java,org.antlr.v4.tool.LeftRecursiveRule,int[] getRecursiveOpAlts(),"/**
 *  Return an array that maps predicted alt from recursive op decision
 *   to original alt of rule. For following rule, return [0, 1, 3]
 *
 * 		e : e '*' e
 * 		  | INT
 * 		  | e '+' e
 * 		  | ID
 * 		  ;
 *
 *   That maps predicted alt 1 to original alt 1 and predicted 2 to alt 3.
 *
 *   @since 4.5.1
 */
public int[] getRecursiveOpAlts() {
    if (recOpAlts.size() == 0)
        return null;
    int[] alts = new int[recOpAlts.size() + 1];
    int alt = 1;
    for (LeftRecursiveRuleAltInfo altInfo : recOpAlts.values()) {
        alts[alt] = altInfo.altNum;
        // recOpAlts has alts possibly with gaps
        alt++;
    }
    return alts;
}","/**
 *  Return an array that maps predicted alt from recursive op decision
 *   to original alt of rule. For following rule, return [0, 1, 3]
 *
 * 		e : e '*' e
 * 		  | INT
 * 		  | e '+' e
 * 		  | ID
 * 		  ;
 *
 *   That maps predicted alt 1 to original alt 1 and predicted 2 to alt 3.
 *
 *   @since 4.5.1
 */
","// recOpAlts has alts possibly with gaps
","/** *  Return an array that maps predicted alt from recursive op decision *   to original alt of rule. For following rule, return [0, 1, 3] * * 		e : e '*' e * 		  | INT * 		  | e '+' e * 		  | ID * 		  ; * *   That maps predicted alt 1 to original alt 1 and predicted 2 to alt 3. * *   @since 4.5.1 */[[SEP]]// recOpAlts has alts possibly with gaps",104,113,[0],0,[0],0,"[0, 0]",0,0,0,0,getRecursiveOpAlts(),org.antlr.v4.tool.LeftRecursiveRule,getRecursiveOpAlts/0,False,104,1,4,4,0,3,2,10,2,2,0,2,0,0,1,1,0,0,0,3,3,1,1,0,0,0,33,1,0,True
1262,..\projects\antlr4-4.11.0\tool\src\org\antlr\v4\tool\LeftRecursiveRule.java,org.antlr.v4.tool.LeftRecursiveRule,"Map<String, List<Pair<Integer, AltAST>>> getAltLabels()","/**
 * Get -&gt; labels from those alts we deleted for left-recursive rules.
 */
@Override
public Map<String, List<Pair<Integer, AltAST>>> getAltLabels() {
    Map<String, List<Pair<Integer, AltAST>>> labels = new HashMap<String, List<Pair<Integer, AltAST>>>();
    Map<String, List<Pair<Integer, AltAST>>> normalAltLabels = super.getAltLabels();
    if (normalAltLabels != null)
        labels.putAll(normalAltLabels);
    if (recPrimaryAlts != null) {
        for (LeftRecursiveRuleAltInfo altInfo : recPrimaryAlts) {
            if (altInfo.altLabel != null) {
                List<Pair<Integer, AltAST>> pairs = labels.get(altInfo.altLabel);
                if (pairs == null) {
                    pairs = new ArrayList<Pair<Integer, AltAST>>();
                    labels.put(altInfo.altLabel, pairs);
                }
                pairs.add(new Pair<Integer, AltAST>(altInfo.altNum, altInfo.originalAltAST));
            }
        }
    }
    if (recOpAlts != null) {
        for (int i = 0; i < recOpAlts.size(); i++) {
            LeftRecursiveRuleAltInfo altInfo = recOpAlts.getElement(i);
            if (altInfo.altLabel != null) {
                List<Pair<Integer, AltAST>> pairs = labels.get(altInfo.altLabel);
                if (pairs == null) {
                    pairs = new ArrayList<Pair<Integer, AltAST>>();
                    labels.put(altInfo.altLabel, pairs);
                }
                pairs.add(new Pair<Integer, AltAST>(altInfo.altNum, altInfo.originalAltAST));
            }
        }
    }
    if (labels.isEmpty())
        return null;
    return labels;
}","/**
 * Get -&gt; labels from those alts we deleted for left-recursive rules.
 */
", ,/** * Get -&gt; labels from those alts we deleted for left-recursive rules. */,116,150,[0],0,[0],0,[0],0,0,0,0,getAltLabels(),org.antlr.v4.tool.LeftRecursiveRule,getAltLabels/0,False,117,2,1,1,0,11,8,32,2,6,0,8,0,0,2,7,0,0,0,1,8,0,4,0,0,0,26,1,0,True
1263,..\projects\antlr4-4.11.0\tool\src\org\antlr\v4\tool\Rule.java,org.antlr.v4.tool.Rule,void defineLexerAction(ActionAST),"/**
 * Lexer actions are numbered across rules 0..n-1
 */
public void defineLexerAction(ActionAST actionAST) {
    actionIndex = g.lexerActions.size();
    if (g.lexerActions.get(actionAST) == null) {
        g.lexerActions.put(actionAST, actionIndex);
    }
}","/**
 * Lexer actions are numbered across rules 0..n-1
 */
", ,/** * Lexer actions are numbered across rules 0..n-1 */,132,137,[0],0,[0],0,[0],0,0,0,0,defineLexerAction(ActionAST),org.antlr.v4.tool.Rule,defineLexerAction/1[org.antlr.v4.tool.ast.ActionAST],False,132,1,1,1,0,2,3,6,0,0,1,3,0,0,0,1,0,0,0,0,1,0,1,0,0,0,14,1,0,True
1264,..\projects\antlr4-4.11.0\tool\src\org\antlr\v4\tool\Rule.java,org.antlr.v4.tool.Rule,int getOriginalNumberOfAlts(),"/**
 * Used for recursive rules (subclass), which have 1 alt, but many original alts
 */
public int getOriginalNumberOfAlts() {
    return numberOfAlts;
}","/**
 * Used for recursive rules (subclass), which have 1 alt, but many original alts
 */
", ,"/** * Used for recursive rules (subclass), which have 1 alt, but many original alts */",191,193,[0],0,[0],0,[0],0,0,0,0,getOriginalNumberOfAlts(),org.antlr.v4.tool.Rule,getOriginalNumberOfAlts/0,False,191,0,0,0,0,1,0,3,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,16,1,0,True
1265,..\projects\antlr4-4.11.0\tool\src\org\antlr\v4\tool\Rule.java,org.antlr.v4.tool.Rule,"Map<String, List<Pair<Integer, AltAST>>> getAltLabels()","/**
 * Get {@code #} labels. The keys of the map are the labels applied to outer
 * alternatives of a lexer rule, and the values are collections of pairs
 * (alternative number and {@link AltAST}) identifying the alternatives with
 * this label. Unlabeled alternatives are not included in the result.
 */
public Map<String, List<Pair<Integer, AltAST>>> getAltLabels() {
    Map<String, List<Pair<Integer, AltAST>>> labels = new LinkedHashMap<String, List<Pair<Integer, AltAST>>>();
    for (int i = 1; i <= numberOfAlts; i++) {
        GrammarAST altLabel = alt[i].ast.altLabel;
        if (altLabel != null) {
            List<Pair<Integer, AltAST>> list = labels.get(altLabel.getText());
            if (list == null) {
                list = new ArrayList<Pair<Integer, AltAST>>();
                labels.put(altLabel.getText(), list);
            }
            list.add(new Pair<Integer, AltAST>(i, alt[i].ast));
        }
    }
    if (labels.isEmpty())
        return null;
    return labels;
}","/**
 * Get {@code #} labels. The keys of the map are the labels applied to outer
 * alternatives of a lexer rule, and the values are collections of pairs
 * (alternative number and {@link AltAST}) identifying the alternatives with
 * this label. Unlabeled alternatives are not included in the result.
 */
", ,"/** * Get {@code #} labels. The keys of the map are the labels applied to outer * alternatives of a lexer rule, and the values are collections of pairs * (alternative number and {@link AltAST}) identifying the alternatives with * this label. Unlabeled alternatives are not included in the result. */",201,217,[0],0,[0],0,[0],0,0,0,0,getAltLabels(),org.antlr.v4.tool.Rule,getAltLabels/0,False,201,2,1,1,0,5,5,16,2,4,0,5,0,0,1,2,0,0,0,1,5,0,3,0,0,0,40,1,0,True
1266,..\projects\antlr4-4.11.0\tool\src\org\antlr\v4\tool\Rule.java,org.antlr.v4.tool.Rule,"Attribute resolveToAttribute(String, ActionAST)","/**
 *  $x		Attribute: rule arguments, return values, predefined rule prop.
 */
@Override
public Attribute resolveToAttribute(String x, ActionAST node) {
    if (args != null) {
        Attribute a = args.get(x);
        if (a != null)
            return a;
    }
    if (retvals != null) {
        Attribute a = retvals.get(x);
        if (a != null)
            return a;
    }
    if (locals != null) {
        Attribute a = locals.get(x);
        if (a != null)
            return a;
    }
    AttributeDict properties = getPredefinedScope(LabelType.RULE_LABEL);
    return properties.get(x);
}","/**
 *  $x		Attribute: rule arguments, return values, predefined rule prop.
 */
", ,"/** *  $x		Attribute: rule arguments, return values, predefined rule prop. */",231,244,[0],0,[0],0,[0],0,0,0,0,"resolveToAttribute(String, ActionAST)",org.antlr.v4.tool.Rule,"resolveToAttribute/2[java.lang.String,org.antlr.v4.tool.ast.ActionAST]",False,232,4,5,3,2,7,2,16,4,4,2,2,1,1,0,6,0,0,0,0,4,0,2,0,0,0,17,1,0,True
1267,..\projects\antlr4-4.11.0\tool\src\org\antlr\v4\tool\Rule.java,org.antlr.v4.tool.Rule,"Attribute resolveToAttribute(String, String, ActionAST)","/**
 * $x.y	Attribute: x is surrounding rule, label ref (in any alts)
 */
@Override
public Attribute resolveToAttribute(String x, String y, ActionAST node) {
    LabelElementPair anyLabelDef = getAnyLabelDef(x);
    if (anyLabelDef != null) {
        if (anyLabelDef.type == LabelType.RULE_LABEL) {
            return g.getRule(anyLabelDef.element.getText()).resolveRetvalOrProperty(y);
        } else {
            AttributeDict scope = getPredefinedScope(anyLabelDef.type);
            if (scope == null) {
                return null;
            }
            return scope.get(y);
        }
    }
    return null;
}","/**
 * $x.y	Attribute: x is surrounding rule, label ref (in any alts)
 */
", ,"/** * $x.y	Attribute: x is surrounding rule, label ref (in any alts) */",247,265,[0],0,[0],0,[0],0,0,0,0,"resolveToAttribute(String, String, ActionAST)",org.antlr.v4.tool.Rule,"resolveToAttribute/3[java.lang.String,java.lang.String,org.antlr.v4.tool.ast.ActionAST]",False,248,6,4,0,4,4,6,16,4,2,3,6,2,2,0,3,0,0,0,0,2,0,3,0,0,0,24,1,0,True
1268,..\projects\antlr4-4.11.0\tool\src\org\antlr\v4\tool\ast\GrammarAST.java,org.antlr.v4.tool.ast.GrammarAST,"void getNodesWithTypePreorderDFS_(List<GrammarAST>, IntervalSet)","public void getNodesWithTypePreorderDFS_(List<GrammarAST> nodes, IntervalSet types) {
    if (types.contains(this.getType()))
        nodes.add(this);
    // walk all children of root.
    for (int i = 0; i < getChildCount(); i++) {
        GrammarAST child = (GrammarAST) getChild(i);
        child.getNodesWithTypePreorderDFS_(nodes, types);
    }
}", ,"// walk all children of root.
",// walk all children of root.,95,102,[0],0,[0],0,[0],0,0,0,0,"getNodesWithTypePreorderDFS_(List<GrammarAST>, IntervalSet)",org.antlr.v4.tool.ast.GrammarAST,"getNodesWithTypePreorderDFS_/2[java.util.List<org.antlr.v4.tool.ast.GrammarAST>,org.antlr.v4.tool.ast.IntervalSet]",False,95,2,3,2,1,3,6,7,0,2,2,6,1,0,1,0,0,0,0,1,2,0,1,0,0,0,17,1,0,False
1269,..\projects\antlr4-4.11.0\tool\src\org\antlr\v4\tool\ast\GrammarAST.java,org.antlr.v4.tool.ast.GrammarAST,GrammarAST getNodeWithTokenIndex(int),"public GrammarAST getNodeWithTokenIndex(int index) {
    if (this.getToken() != null && this.getToken().getTokenIndex() == index) {
        return this;
    }
    // walk all children of root.
    for (int i = 0; i < getChildCount(); i++) {
        GrammarAST child = (GrammarAST) getChild(i);
        GrammarAST result = child.getNodeWithTokenIndex(index);
        if (result != null) {
            return result;
        }
    }
    return null;
}", ,"// walk all children of root.
",// walk all children of root.,104,117,[0],0,[0],0,[0],0,0,0,0,getNodeWithTokenIndex(int),org.antlr.v4.tool.ast.GrammarAST,getNodeWithTokenIndex/1[int],False,104,1,3,2,1,5,5,13,3,3,1,5,1,0,1,3,0,0,0,1,3,0,2,0,0,0,16,1,0,False
1270,..\projects\antlr4-4.11.0\tool\src\org\antlr\v4\tool\ast\GrammarAST.java,org.antlr.v4.tool.ast.GrammarAST,String getAltLabel(),"/**
 * Walk ancestors of this node until we find ALT with
 *  alt!=null or leftRecursiveAltInfo!=null. Then grab label if any.
 *  If not a rule element, just returns null.
 */
public String getAltLabel() {
    List<? extends Tree> ancestors = this.getAncestors();
    if (ancestors == null)
        return null;
    for (int i = ancestors.size() - 1; i >= 0; i--) {
        GrammarAST p = (GrammarAST) ancestors.get(i);
        if (p.getType() == ANTLRParser.ALT) {
            AltAST a = (AltAST) p;
            if (a.altLabel != null)
                return a.altLabel.getText();
            if (a.leftRecursiveAltInfo != null) {
                return a.leftRecursiveAltInfo.altLabel;
            }
        }
    }
    return null;
}","/**
 * Walk ancestors of this node until we find ALT with
 *  alt!=null or leftRecursiveAltInfo!=null. Then grab label if any.
 *  If not a rule element, just returns null.
 */
", ,"/** * Walk ancestors of this node until we find ALT with *  alt!=null or leftRecursiveAltInfo!=null. Then grab label if any. *  If not a rule element, just returns null. */",131,145,[0],0,[0],0,[0],0,0,0,0,getAltLabel(),org.antlr.v4.tool.ast.GrammarAST,getAltLabel/0,False,131,2,0,0,0,6,5,15,4,4,0,5,0,0,1,4,0,0,0,2,4,1,3,0,0,0,34,1,0,True
1271,..\projects\antlr4-4.11.0\tool\src\org\antlr\v4\tool\ast\GrammarAST.java,org.antlr.v4.tool.ast.GrammarAST,CommonTree getFirstDescendantWithType(int),"// TODO: move to basetree when i settle on how runtime works
// TODO: don't include this node!!
// TODO: reuse other method
public CommonTree getFirstDescendantWithType(int type) {
    if (getType() == type)
        return this;
    if (children == null)
        return null;
    for (Object c : children) {
        GrammarAST t = (GrammarAST) c;
        if (t.getType() == type)
            return t;
        CommonTree d = t.getFirstDescendantWithType(type);
        if (d != null)
            return d;
    }
    return null;
}","// TODO: reuse other method
", ,// TODO: move to basetree when i settle on how runtime works// TODO: don't include this node!!// TODO: reuse other method,161,171,[1],1,[0],0,[1],1,1,1,1,getFirstDescendantWithType(int),org.antlr.v4.tool.ast.GrammarAST,getFirstDescendantWithType/1[int],False,161,2,2,1,1,6,2,11,5,2,1,2,1,0,1,4,0,0,0,0,2,0,2,0,0,0,18,1,0,False
1272,..\projects\antlr4-4.11.0\tool\src\org\antlr\v4\tool\ast\GrammarAST.java,org.antlr.v4.tool.ast.GrammarAST,CommonTree getFirstDescendantWithType(org.antlr.runtime.BitSet),"// TODO: don't include this node!!
public CommonTree getFirstDescendantWithType(org.antlr.runtime.BitSet types) {
    if (types.member(getType()))
        return this;
    if (children == null)
        return null;
    for (Object c : children) {
        GrammarAST t = (GrammarAST) c;
        if (types.member(t.getType()))
            return t;
        CommonTree d = t.getFirstDescendantWithType(types);
        if (d != null)
            return d;
    }
    return null;
}","// TODO: don't include this node!!
", ,// TODO: don't include this node!!,174,184,[1],1,[0],0,[1],1,1,1,1,getFirstDescendantWithType(BitSet),org.antlr.v4.tool.ast.GrammarAST,getFirstDescendantWithType/1[org.antlr.runtime.BitSet],False,174,3,4,3,1,6,3,11,5,2,1,3,1,0,1,2,0,0,0,0,2,0,2,0,0,0,18,1,0,False
1273,..\projects\antlr4-4.11.0\tool\src\org\antlr\v4\tool\ast\GrammarAST.java,org.antlr.v4.tool.ast.GrammarAST,void setText(String),"// 
// @Override
// public String getText() {
// if ( textOverride!=null ) return textOverride;
// if ( token!=null ) {
// return token.getText();
// }
// return """";
// }
public void setText(String text) {
    // textOverride = text; // don't alt tokens as others might see
    // we delete surrounding tree, so ok to alter
    token.setText(text);
}", ,"// textOverride = text; // don't alt tokens as others might see
[[SEP]]// we delete surrounding tree, so ok to alter
","//// @Override// public String getText() {// if ( textOverride!=null ) return textOverride;// if ( token!=null ) {// return token.getText();// }// return """";// }[[SEP]]// textOverride = text; // don't alt tokens as others might see// we delete surrounding tree, so ok to alter",199,202,[0],0,"[0, 0]",0,"[0, 0]",0,0,0,0,setText(String),org.antlr.v4.tool.ast.GrammarAST,setText/1[java.lang.String],False,199,0,0,0,0,1,1,3,0,0,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,3,1,0,False
1274,..\projects\antlr4-4.11.0\tool\src\org\antlr\v4\tool\ast\GrammarASTVisitor.java,org.antlr.v4.tool.ast.GrammarASTVisitor,Object visit(GrammarAST),"/**
 * This is the generic visitor method that will be invoked
 *  for any other kind of AST node not covered by the other visit methods.
 */
Object visit(GrammarAST node);","/**
 * This is the generic visitor method that will be invoked
 *  for any other kind of AST node not covered by the other visit methods.
 */
", ,/** * This is the generic visitor method that will be invoked *  for any other kind of AST node not covered by the other visit methods. */,26,26,[0],0,[0],0,[0],0,0,0,0,visit(GrammarAST),org.antlr.v4.tool.ast.GrammarASTVisitor,visit/1[org.antlr.v4.tool.ast.GrammarAST],False,23,1,2,2,0,1,0,1,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,24,0,0,True
1275,..\projects\antlr4-4.11.0\tool\src\org\antlr\v4\tool\ast\GrammarASTWithOptions.java,org.antlr.v4.tool.ast.GrammarASTWithOptions,GrammarAST getOptionAST(String),"/**
 * Gets AST node holding value for option key; ignores default options
 *  and command-line forced options.
 */
public GrammarAST getOptionAST(String key) {
    if (options == null)
        return null;
    return options.get(key);
}","/**
 * Gets AST node holding value for option key; ignores default options
 *  and command-line forced options.
 */
", ,/** * Gets AST node holding value for option key; ignores default options *  and command-line forced options. */,57,60,[0],0,[0],0,[0],0,0,0,0,getOptionAST(String),org.antlr.v4.tool.ast.GrammarASTWithOptions,getOptionAST/1[java.lang.String],False,57,1,2,2,0,2,1,4,2,0,1,1,0,0,0,1,0,0,0,0,0,0,1,0,0,0,19,1,0,True
1276,..\projects\antlr4-4.11.0\tool\src\org\antlr\v4\tool\ast\RuleRefAST.java,org.antlr.v4.tool.ast.RuleRefAST,RuleRefAST dupNode(),"/**
 * Dup token too since we overwrite during LR rule transform
 */
@Override
public RuleRefAST dupNode() {
    RuleRefAST r = new RuleRefAST(this);
    // In LR transform, we alter original token stream to make e -> e[n]
    // Since we will be altering the dup, we need dup to have the
    // original token.  We can set this tree (the original) to have
    // a new token.
    r.token = this.token;
    this.token = new CommonToken(r.token);
    return r;
}","/**
 * Dup token too since we overwrite during LR rule transform
 */
","// In LR transform, we alter original token stream to make e -> e[n]
[[SEP]]// Since we will be altering the dup, we need dup to have the
[[SEP]]// original token.  We can set this tree (the original) to have
[[SEP]]// a new token.
","/** * Dup token too since we overwrite during LR rule transform */[[SEP]]// In LR transform, we alter original token stream to make e -> e[n]// Since we will be altering the dup, we need dup to have the// original token.  We can set this tree (the original) to have// a new token.",22,32,[0],0,"[0, 0, 0, 0]",0,"[0, 0]",0,0,0,0,dupNode(),org.antlr.v4.tool.ast.RuleRefAST,dupNode/0,False,23,2,1,0,1,1,0,6,1,1,0,0,0,0,0,0,0,0,0,0,3,0,0,0,0,0,21,1,0,True
1277,..\projects\antlr4-4.11.0\tool\src\org\antlr\v4\unicode\UnicodeDataTemplateController.java,org.antlr.v4.unicode.UnicodeDataTemplateController,"void addPropertyAliases(Map<String, String>, String, int)","private static void addPropertyAliases(Map<String, String> propertyAliases, String propertyName, int property) {
    int nameChoice = UProperty.NameChoice.LONG;
    while (true) {
        String alias;
        try {
            alias = UCharacter.getPropertyName(property, nameChoice);
        } catch (IllegalArgumentException e) {
            // No more aliases.
            break;
        }
        assert alias != null;
        addPropertyAlias(propertyAliases, alias, propertyName);
        nameChoice++;
    }
}", ,"// No more aliases.
",// No more aliases.,47,64,[0],0,[0],0,[0],0,0,0,0,"addPropertyAliases(Map<String, String>, String, int)",org.antlr.v4.unicode.UnicodeDataTemplateController,"addPropertyAliases/3[java.util.Map<java.lang.String,java.lang.String>,java.lang.String,int]",False,50,1,2,1,1,3,2,15,0,2,3,2,1,1,1,1,1,0,0,0,2,0,2,0,0,0,15,10,0,False
1278,..\projects\antlr4-4.11.0\tool\src\org\antlr\v4\unicode\UnicodeDataTemplateController.java,org.antlr.v4.unicode.UnicodeDataTemplateController,String getShortPropertyName(int),"private static String getShortPropertyName(int property) {
    String propertyName = UCharacter.getPropertyName(property, UProperty.NameChoice.SHORT);
    // For some reason, a few properties only have long names.
    if (propertyName == null) {
        propertyName = UCharacter.getPropertyName(property, UProperty.NameChoice.LONG);
    }
    return propertyName;
}", ,"// For some reason, a few properties only have long names.
","// For some reason, a few properties only have long names.",95,102,[0],0,[0],0,[0],0,0,0,0,getShortPropertyName(int),org.antlr.v4.unicode.UnicodeDataTemplateController,getShortPropertyName/1[int],False,95,0,4,4,0,2,1,7,1,1,1,1,0,0,0,1,0,0,0,0,2,0,1,0,0,0,6,10,0,False
1279,..\projects\antlr4-4.11.0\tool\src\org\antlr\v4\unicode\UnicodeDataTemplateController.java,org.antlr.v4.unicode.UnicodeDataTemplateController,"void addUnicodeCategoryCodesToCodePointRanges(Map<String, IntervalSet>)","private static void addUnicodeCategoryCodesToCodePointRanges(Map<String, IntervalSet> propertyCodePointRanges) {
    RangeValueIterator iter = UCharacter.getTypeIterator();
    RangeValueIterator.Element element = new RangeValueIterator.Element();
    while (iter.next(element)) {
        String categoryName = UCharacter.getPropertyValueName(UProperty.GENERAL_CATEGORY_MASK, 1 << element.value, UProperty.NameChoice.SHORT);
        addIntervalForCategory(propertyCodePointRanges, categoryName, element.start, element.limit - 1);
        // Add short category so Ll, Lu, Lo, etc. all show up under L
        String shortCategoryName = categoryName.substring(0, 1);
        addIntervalForCategory(propertyCodePointRanges, shortCategoryName, element.start, element.limit - 1);
    }
}", ,"// Add short category so Ll, Lu, Lo, etc. all show up under L
","// Add short category so Ll, Lu, Lo, etc. all show up under L",104,117,[0],0,[0],0,[0],0,0,0,0,"addUnicodeCategoryCodesToCodePointRanges(Map<String, IntervalSet>)",org.antlr.v4.unicode.UnicodeDataTemplateController,"addUnicodeCategoryCodesToCodePointRanges/1[java.util.Map<java.lang.String,org.antlr.v4.unicode.IntervalSet>]",False,104,3,2,1,1,2,5,10,0,4,1,5,1,1,1,0,0,0,0,5,4,3,1,0,0,0,19,10,0,False
1280,..\projects\antlr4-4.11.0\tool\src\org\antlr\v4\unicode\UnicodeDataTemplateController.java,org.antlr.v4.unicode.UnicodeDataTemplateController,"void addUnicodeCategoryCodesToNames(Map<String, String>)","private static void addUnicodeCategoryCodesToNames(Map<String, String> propertyAliases) {
    RangeValueIterator iter = UCharacter.getTypeIterator();
    RangeValueIterator.Element element = new RangeValueIterator.Element();
    while (iter.next(element)) {
        int generalCategoryMask = 1 << element.value;
        String categoryName = UCharacter.getPropertyValueName(UProperty.GENERAL_CATEGORY_MASK, generalCategoryMask, UProperty.NameChoice.SHORT);
        int nameChoice = UProperty.NameChoice.LONG;
        while (true) {
            String alias;
            try {
                alias = UCharacter.getPropertyValueName(UProperty.GENERAL_CATEGORY_MASK, generalCategoryMask, nameChoice);
            } catch (IllegalArgumentException e) {
                // No more aliases.
                break;
            }
            assert alias != null;
            addPropertyAlias(propertyAliases, alias, categoryName);
            nameChoice++;
        }
    }
    // Add short categories
    addPropertyAlias(propertyAliases, ""Control"", ""C"");
    addPropertyAlias(propertyAliases, ""Letter"", ""L"");
    addPropertyAlias(propertyAliases, ""Number"", ""N"");
    addPropertyAlias(propertyAliases, ""Mark"", ""M"");
    addPropertyAlias(propertyAliases, ""Punctuation"", ""P"");
    addPropertyAlias(propertyAliases, ""Symbol"", ""S"");
    addPropertyAlias(propertyAliases, ""Space"", ""Z"");
}", ,"// No more aliases.
[[SEP]]// Add short categories
",// No more aliases.[[SEP]]// Add short categories,119,153,[0],0,"[0, 0]",0,"[0, 0]",0,0,0,0,"addUnicodeCategoryCodesToNames(Map<String, String>)",org.antlr.v4.unicode.UnicodeDataTemplateController,"addUnicodeCategoryCodesToNames/1[java.util.Map<java.lang.String,java.lang.String>]",False,119,2,2,1,1,4,4,28,0,6,1,4,1,1,2,1,1,0,14,1,6,1,3,0,0,0,29,10,0,False
1281,..\projects\antlr4-4.11.0\tool\src\org\antlr\v4\unicode\UnicodeDataTemplateController.java,org.antlr.v4.unicode.UnicodeDataTemplateController,"void addTR35ExtendedPictographicPropertyCodesToCodePointRanges(Map<String, IntervalSet>)","private static void addTR35ExtendedPictographicPropertyCodesToCodePointRanges(Map<String, IntervalSet> propertyCodePointRanges) {
    IntervalSet set = new IntervalSet();
    // Generated using scripts/parse-extended-pictographic/parse.py
    set.add(0x1F774, 0x1F77F);
    set.add(0x2700, 0x2701);
    set.add(0x2703, 0x2704);
    set.add(0x270E);
    set.add(0x2710, 0x2711);
    set.add(0x2765, 0x2767);
    set.add(0x1F030, 0x1F093);
    set.add(0x1F094, 0x1F09F);
    set.add(0x1F10D, 0x1F10F);
    set.add(0x1F12F);
    set.add(0x1F16C, 0x1F16F);
    set.add(0x1F1AD, 0x1F1E5);
    set.add(0x1F260, 0x1F265);
    set.add(0x1F203, 0x1F20F);
    set.add(0x1F23C, 0x1F23F);
    set.add(0x1F249, 0x1F24F);
    set.add(0x1F252, 0x1F25F);
    set.add(0x1F266, 0x1F2FF);
    set.add(0x1F7D5, 0x1F7FF);
    set.add(0x1F000, 0x1F003);
    set.add(0x1F005, 0x1F02B);
    set.add(0x1F02C, 0x1F02F);
    set.add(0x1F322, 0x1F323);
    set.add(0x1F394, 0x1F395);
    set.add(0x1F398);
    set.add(0x1F39C, 0x1F39D);
    set.add(0x1F3F1, 0x1F3F2);
    set.add(0x1F3F6);
    set.add(0x1F4FE);
    set.add(0x1F53E, 0x1F548);
    set.add(0x1F54F);
    set.add(0x1F568, 0x1F56E);
    set.add(0x1F571, 0x1F572);
    set.add(0x1F57B, 0x1F586);
    set.add(0x1F588, 0x1F589);
    set.add(0x1F58E, 0x1F58F);
    set.add(0x1F591, 0x1F594);
    set.add(0x1F597, 0x1F5A3);
    set.add(0x1F5A6, 0x1F5A7);
    set.add(0x1F5A9, 0x1F5B0);
    set.add(0x1F5B3, 0x1F5BB);
    set.add(0x1F5BD, 0x1F5C1);
    set.add(0x1F5C5, 0x1F5D0);
    set.add(0x1F5D4, 0x1F5DB);
    set.add(0x1F5DF, 0x1F5E0);
    set.add(0x1F5E2);
    set.add(0x1F5E4, 0x1F5E7);
    set.add(0x1F5E9, 0x1F5EE);
    set.add(0x1F5F0, 0x1F5F2);
    set.add(0x1F5F4, 0x1F5F9);
    set.add(0x2605);
    set.add(0x2607, 0x260D);
    set.add(0x260F, 0x2610);
    set.add(0x2612);
    set.add(0x2616, 0x2617);
    set.add(0x2619, 0x261C);
    set.add(0x261E, 0x261F);
    set.add(0x2621);
    set.add(0x2624, 0x2625);
    set.add(0x2627, 0x2629);
    set.add(0x262B, 0x262D);
    set.add(0x2630, 0x2637);
    set.add(0x263B, 0x2647);
    set.add(0x2654, 0x265F);
    set.add(0x2661, 0x2662);
    set.add(0x2664);
    set.add(0x2667);
    set.add(0x2669, 0x267A);
    set.add(0x267C, 0x267E);
    set.add(0x2680, 0x2691);
    set.add(0x2695);
    set.add(0x2698);
    set.add(0x269A);
    set.add(0x269D, 0x269F);
    set.add(0x26A2, 0x26A9);
    set.add(0x26AC, 0x26AF);
    set.add(0x26B2, 0x26BC);
    set.add(0x26BF, 0x26C3);
    set.add(0x26C6, 0x26C7);
    set.add(0x26C9, 0x26CD);
    set.add(0x26D0);
    set.add(0x26D2);
    set.add(0x26D5, 0x26E8);
    set.add(0x26EB, 0x26EF);
    set.add(0x26F6);
    set.add(0x26FB, 0x26FC);
    set.add(0x26FE, 0x26FF);
    set.add(0x2388);
    set.add(0x1FA00, 0x1FFFD);
    set.add(0x1F0A0, 0x1F0AE);
    set.add(0x1F0B1, 0x1F0BF);
    set.add(0x1F0C1, 0x1F0CF);
    set.add(0x1F0D1, 0x1F0F5);
    set.add(0x1F0AF, 0x1F0B0);
    set.add(0x1F0C0);
    set.add(0x1F0D0);
    set.add(0x1F0F6, 0x1F0FF);
    set.add(0x1F80C, 0x1F80F);
    set.add(0x1F848, 0x1F84F);
    set.add(0x1F85A, 0x1F85F);
    set.add(0x1F888, 0x1F88F);
    set.add(0x1F8AE, 0x1F8FF);
    set.add(0x1F900, 0x1F90B);
    set.add(0x1F91F);
    set.add(0x1F928, 0x1F92F);
    set.add(0x1F931, 0x1F932);
    set.add(0x1F94C);
    set.add(0x1F95F, 0x1F96B);
    set.add(0x1F992, 0x1F997);
    set.add(0x1F9D0, 0x1F9E6);
    set.add(0x1F90C, 0x1F90F);
    set.add(0x1F93F);
    set.add(0x1F94D, 0x1F94F);
    set.add(0x1F96C, 0x1F97F);
    set.add(0x1F998, 0x1F9BF);
    set.add(0x1F9C1, 0x1F9CF);
    set.add(0x1F9E7, 0x1F9FF);
    set.add(0x1F6C6, 0x1F6CA);
    set.add(0x1F6D3, 0x1F6D4);
    set.add(0x1F6E6, 0x1F6E8);
    set.add(0x1F6EA);
    set.add(0x1F6F1, 0x1F6F2);
    set.add(0x1F6F7, 0x1F6F8);
    set.add(0x1F6D5, 0x1F6DF);
    set.add(0x1F6ED, 0x1F6EF);
    set.add(0x1F6F9, 0x1F6FF);
    propertyCodePointRanges.put(""Extended_Pictographic"", set);
    UnicodeSet emojiRKUnicodeSet = new UnicodeSet(""[\\p{GCB=Regional_Indicator}\\*#0-9\\u00a9\\u00ae\\u2122\\u3030\\u303d]"");
    IntervalSet emojiRKIntervalSet = new IntervalSet();
    addUnicodeSetToIntervalSet(emojiRKUnicodeSet, emojiRKIntervalSet);
    propertyCodePointRanges.put(""EmojiRK"", emojiRKIntervalSet);
    UnicodeSet emojiNRKUnicodeSet = new UnicodeSet(""[\\p{Emoji=Yes}]"");
    emojiNRKUnicodeSet.removeAll(emojiRKUnicodeSet);
    IntervalSet emojiNRKIntervalSet = new IntervalSet();
    addUnicodeSetToIntervalSet(emojiNRKUnicodeSet, emojiNRKIntervalSet);
    propertyCodePointRanges.put(""EmojiNRK"", emojiNRKIntervalSet);
}", ,"// Generated using scripts/parse-extended-pictographic/parse.py
",// Generated using scripts/parse-extended-pictographic/parse.py,210,351,[0],0,[0],0,[0],0,0,0,0,"addTR35ExtendedPictographicPropertyCodesToCodePointRanges(Map<String, IntervalSet>)",org.antlr.v4.unicode.UnicodeDataTemplateController,"addTR35ExtendedPictographicPropertyCodesToCodePointRanges/1[java.util.Map<java.lang.String,org.antlr.v4.unicode.IntervalSet>]",False,210,3,2,1,1,1,4,139,0,5,1,4,1,1,0,0,0,0,5,227,5,0,0,0,0,0,58,10,0,False
1282,..\projects\antlr4-4.11.0\tool\src\org\antlr\v4\unicode\UnicodeDataTemplateController.java,org.antlr.v4.unicode.UnicodeDataTemplateController,"void addIntPropertyAliases(int, String, Map<String, String>)","private static void addIntPropertyAliases(int property, String namePrefix, Map<String, String> propertyAliases) {
    String propertyName = getShortPropertyName(property);
    for (int propertyValue = UCharacter.getIntPropertyMinValue(property); propertyValue <= UCharacter.getIntPropertyMaxValue(property); propertyValue++) {
        String aliasTarget = propertyName + ""="" + UCharacter.getPropertyValueName(property, propertyValue, UProperty.NameChoice.SHORT);
        int nameChoice = UProperty.NameChoice.SHORT;
        String alias;
        while (true) {
            try {
                alias = namePrefix + UCharacter.getPropertyValueName(property, propertyValue, nameChoice);
            } catch (IllegalArgumentException e) {
                // No more aliases.
                break;
            }
            assert alias != null;
            addPropertyAlias(propertyAliases, alias, aliasTarget);
            nameChoice++;
        }
    }
}", ,"// No more aliases.
",// No more aliases.,370,390,[0],0,[0],0,[0],0,0,0,0,"addIntPropertyAliases(int, String, Map<String, String>)",org.antlr.v4.unicode.UnicodeDataTemplateController,"addIntPropertyAliases/3[int,java.lang.String,java.util.Map<java.lang.String,java.lang.String>]",False,370,1,5,3,2,4,5,19,0,5,3,5,2,1,2,1,1,0,1,0,5,2,3,0,0,0,22,10,0,False
1283,..\projects\antlr4-4.11.0\tool\src\org\antlr\v4\unicode\UnicodeDataTemplateController.java,org.antlr.v4.unicode.UnicodeDataTemplateController,"void addUnicodeIntPropertyCodesToNames(Map<String, String>)","private static void addUnicodeIntPropertyCodesToNames(Map<String, String> propertyAliases) {
    for (int property = UProperty.INT_START; property < UProperty.INT_LIMIT; property++) {
        int nameChoice = UProperty.NameChoice.SHORT + 1;
        while (true) {
            String propertyNameAlias;
            try {
                propertyNameAlias = UCharacter.getPropertyName(property, nameChoice);
            } catch (IllegalArgumentException e) {
                // No more aliases.
                break;
            }
            addIntPropertyAliases(property, propertyNameAlias + ""="", propertyAliases);
            nameChoice++;
        }
    }
}", ,"// No more aliases.
",// No more aliases.,400,417,[0],0,[0],0,[0],0,0,0,0,"addUnicodeIntPropertyCodesToNames(Map<String, String>)",org.antlr.v4.unicode.UnicodeDataTemplateController,"addUnicodeIntPropertyCodesToNames/1[java.util.Map<java.lang.String,java.lang.String>]",False,400,1,2,1,1,4,2,16,0,3,1,2,1,2,2,0,1,0,1,1,3,2,3,0,0,0,18,10,0,False
